<?xml version="1.0" encoding="UTF-8"?>

<root>

<totalfound>3041</totalfound>

<totalsearched>3834149</totalsearched>

<document>

<rank>1</rank>

<title><![CDATA[Cubist style rendering from photographs]]></title>

<authors><![CDATA[Collomosse, J.P.;  Hall, P.M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Bath, UK]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Appraisal]]></term>

<term><![CDATA[Art]]></term>

<term><![CDATA[Eyes]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Mouth]]></term>

<term><![CDATA[Nose]]></term>

<term><![CDATA[Painting]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[443]]></spage>

<epage><![CDATA[453]]></epage>

<abstract><![CDATA[The contribution of the paper is a novel nonphotorealistic rendering (NPR) technique, influenced by the style of Cubist art. Specifically, we are motivated by artists such as Picasso and Braque, who produced art work by composing elements of a scene taken from multiple points of view; paradoxically, such compositions convey a sense of motion without assuming temporal dependence between views. Our method accepts a set of two-dimensional images as input and produces a Cubist style painting with minimal user interaction. We use salient features identified within the image set, such as eyes, noses, and mouths, as compositional elements; we believe the use of such features to be a unique contribution to NPR. Before composing features into a final image, we geometrically distort them to produce the more angular forms common in Cubist art. Finally, we render the composition to give a painterly effect, using an automatic algorithm. This paper describes our method, illustrating the application of our algorithm with a gallery of images. We conclude with a critical appraisal and suggest the use of "high-level" features is of interest to NPR.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1260739]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1260739]]></doi>

<publicationId><![CDATA[1260739]]></publicationId>

<partnum><![CDATA[1260739]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260739&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260739]]></pdf>

</document>

<document>

<rank>2</rank>

<title><![CDATA[Creating and simulating skeletal muscle from the visible human data set]]></title>

<authors><![CDATA[Teran, J.;  Sifakis, E.;  Blemker, S.S.;  Ng-Thow-Hing, V.;  Lau, C.;  Fedkiw, R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stanford Univ., CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[muscle]]></term>

<term><![CDATA[orthopaedics]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[surgery]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Biomechanics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Muscles]]></term>

<term><![CDATA[Musculoskeletal system]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Tendons]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[317]]></spage>

<epage><![CDATA[328]]></epage>

<abstract><![CDATA[Simulation of the musculoskeletal system has important applications in biomechanics, biomedical engineering, surgery simulation, and computer graphics. The accuracy of the muscle, bone, and tendon geometry as well as the accuracy of muscle and tendon dynamic deformation are of paramount importance in all these applications. We present a framework for extracting and simulating high resolution musculoskeletal geometry from the segmented visible human data set. We simulate 30 contact/collision coupled muscles in the upper limb and describe a computationally tractable implementation using an embedded mesh framework. Muscle geometry is embedded in a nonmanifold, connectivity preserving simulation mesh molded out of a lower resolution BCC lattice containing identical, well-shaped elements, leading to a relaxed time step restriction for stability and, thus, reduced computational cost. The muscles are endowed with a transversely isotropic, quasiincompressible constitutive model that incorporates muscle fiber fields as well as passive and active components. The simulation takes advantage of a new robust finite element technique that handles both degenerate and inverted tetrahedra.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1407864]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.42]]></doi>

<publicationId><![CDATA[1407864]]></publicationId>

<partnum><![CDATA[1407864]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1407864&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407864]]></pdf>

</document>

<document>

<rank>3</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5946033]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.122]]></doi>

<publicationId><![CDATA[5946033]]></publicationId>

<partnum><![CDATA[5946033]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5946033&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946033]]></pdf>

</document>

<document>

<rank>4</rank>

<title><![CDATA[Quasi Interpolation With Voronoi Splines]]></title>

<authors><![CDATA[Mirzargar, M.;  Entezari, A.]]></authors>

<controlledterms>

<term><![CDATA[FIR filters]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[signal reconstruction]]></term>

<term><![CDATA[signal sampling]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1832]]></spage>

<epage><![CDATA[1841]]></epage>

<abstract><![CDATA[We present a quasi interpolation framework that attains the optimal approximation-order of Voronoi splines for reconstruction of volumetric data sampled on general lattices. The quasi interpolation framework of Voronoi splines provides an unbiased reconstruction method across various lattices. Therefore this framework allows us to analyze and contrast the sampling-theoretic performance of general lattices, using signal reconstruction, in an unbiased manner. Our quasi interpolation methodology is implemented as an efficient FIR filter that can be applied online or as a preprocessing step. We present visual and numerical experiments that demonstrate the improved accuracy of reconstruction across lattices, using the quasi interpolation framework.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064946]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.230]]></doi>

<publicationId><![CDATA[6064946]]></publicationId>

<partnum><![CDATA[6064946]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064946&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064946]]></pdf>

</document>

<document>

<rank>5</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1359724]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.5]]></doi>

<publicationId><![CDATA[1359724]]></publicationId>

<partnum><![CDATA[1359724]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359724&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359724]]></pdf>

</document>

<document>

<rank>6</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on the IEEE Virtual Reality Conference (VR)]]></title>

<authors><![CDATA[Kiyokawa, Kiyoshi;  Klinker, Gudrun;  Lok, Benjamin]]></authors>

<thesaurusterms>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1193]]></spage>

<epage><![CDATA[1194]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5946034]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.126]]></doi>

<publicationId><![CDATA[5946034]]></publicationId>

<partnum><![CDATA[5946034]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5946034&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946034]]></pdf>

</document>

<document>

<rank>7</rank>

<title><![CDATA[Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization]]></title>

<authors><![CDATA[Jian Chen;  Haipeng Cai;  Auchus, A.P.;  Laidlaw, D.H.]]></authors>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[brain]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[screens (display)]]></term>

<term><![CDATA[stereo image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Lesions]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Retina]]></term>

<term><![CDATA[Stereo image processing]]></term>

<term><![CDATA[Virtual environments]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2130]]></spage>

<epage><![CDATA[2139]]></epage>

<abstract><![CDATA[We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327218]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.216]]></doi>

<publicationId><![CDATA[6327218]]></publicationId>

<partnum><![CDATA[6327218]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327218&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327218]]></pdf>

</document>

<document>

<rank>8</rank>

<title><![CDATA[Hierarchical model for real time simulation of virtual human crowds]]></title>

<authors><![CDATA[Raupp Musse, S.;  Thalmann, D.]]></authors>

<affiliations><![CDATA[UNISINOS, Univ. do Vale do Rio dos Sinos, Rio Grande do Sul, Brazil]]></affiliations>

<controlledterms>

<term><![CDATA[behavioural sciences computing]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[real-time systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Autonomous agents]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Discrete event simulation]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[152]]></spage>

<epage><![CDATA[164]]></epage>

<abstract><![CDATA[We describe a model for simulating crowds of humans in real time. We deal with a hierarchy composed of virtual crowds, groups, and individuals. The groups are the most complex structure that can be controlled in different degrees of autonomy. This autonomy refers to the extent to which the virtual agents are independent of user intervention and also the amount of information needed to simulate crowds. Thus, depending on the complexity of the simulation, simple behaviors can be sufficient to simulate crowds. Otherwise, more complicated behavioral rules can be necessary and, in this case, it can be included in the simulation data in order to improve the realism of the animation. We present three different ways for controlling crowd behaviors: by using innate and scripted behaviors; by defining behavioral rules, using events and reactions; and by providing an external control to guide crowd behaviors in real time. The two main contributions of our approach are: the possibility of increasing the complexity of group/agent behaviors according to the problem to be simulated and the hierarchical structure based on groups to compose a crowd]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[928167]]></arnumber>

<doi><![CDATA[10.1109/2945.928167]]></doi>

<publicationId><![CDATA[928167]]></publicationId>

<partnum><![CDATA[928167]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=928167&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=928167]]></pdf>

</document>

<document>

<rank>9</rank>

<title><![CDATA[Focusing in algorithm explanation]]></title>

<authors><![CDATA[Braune, B.;  Wilhelm, R.]]></authors>

<affiliations><![CDATA[Fachbereich Inf., Saarlandes Univ., Saarbrucken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[program visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Abstracts]]></term>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Binary search trees]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Size measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[7]]></epage>

<abstract><![CDATA[Algorithm animation attempts to explain an algorithm by visualizing interesting events of the execution of the implemented algorithm on some sample input. Algorithm explanation describes the algorithm on some adequate level of abstraction, states invariants, explains how important steps of the algorithm preserve the invariants, and abstracts from the input data up to the relevant properties. It uses a small focus onto the execution state. This paper is concerned with the explanation of algorithms on linked data structures. The thesis of the paper is that shape analysis of such algorithms produces abstract representations of such data structures, which focus on the &ldquo;active&rdquo; parts, i.e., the parts of the data structures, which the algorithm can access during it's next steps. The paper presents a concept of visually executing an algorithm on these abstract representations of data]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[841117]]></arnumber>

<doi><![CDATA[10.1109/2945.841117]]></doi>

<publicationId><![CDATA[841117]]></publicationId>

<partnum><![CDATA[841117]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=841117&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=841117]]></pdf>

</document>

<document>

<rank>10</rank>

<title><![CDATA[Multi-Charts for Comparative 3D Ensemble Visualization]]></title>

<authors><![CDATA[Demir, I.;  Dick, C.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Garching, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2694]]></spage>

<epage><![CDATA[2703]]></epage>

<abstract><![CDATA[A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875990]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346448]]></doi>

<publicationId><![CDATA[6875990]]></publicationId>

<partnum><![CDATA[6875990]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875990&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875990]]></pdf>

</document>

<document>

<rank>11</rank>

<title><![CDATA[Topological Spines: A Structure-preserving Visual Representation of Scalar Fields]]></title>

<authors><![CDATA[Correa, C.;  Lindstrom, P.;  Bremer, P.-T.]]></authors>

<affiliations><![CDATA[Center for Appl. Sci. Comput. (CASC), Lawrence Livermore Nat. Lab., Livermore, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[natural sciences computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1842]]></spage>

<epage><![CDATA[1851]]></epage>

<abstract><![CDATA[We present topological spines-a new visual representation that preserves the topological and geometric structure of a scalar field. This representation encodes the spatial relationships of the extrema of a scalar field together with the local volume and nesting structure of the surrounding contours. Unlike other topological representations, such as contour trees, our approach preserves the local geometric structure of the scalar field, including structural cycles that are useful for exposing symmetries in the data. To obtain this representation, we describe a novel mechanism based on the extraction of extremum graphs-sparse subsets of the Morse-Smale complex that retain the important structural information without the clutter and occlusion problems that arise from visualizing the entire complex directly. Extremum graphs form a natural multiresolution structure that allows the user to suppress noise and enhance topological features via the specification of a persistence range. Applications of our approach include the visualization of 3D scalar fields without occlusion artifacts, and the exploratory analysis of high-dimensional functions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064947]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.244]]></doi>

<publicationId><![CDATA[6064947]]></publicationId>

<partnum><![CDATA[6064947]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064947&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064947]]></pdf>

</document>

<document>

<rank>12</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5714213]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.44]]></doi>

<publicationId><![CDATA[5714213]]></publicationId>

<partnum><![CDATA[5714213]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5714213&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714213]]></pdf>

</document>

<document>

<rank>13</rank>

<title><![CDATA[SensePath: Understanding the Sensemaking Process Through Analytic Provenance]]></title>

<authors><![CDATA[Nguyen, P.H.;  Kai Xu;  Wheat, A.;  Wong, B.L.W.;  Attfield, S.;  Fields, B.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human computer interaction]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Human computer interaction]]></term>

<term><![CDATA[Manuals]]></term>

<term><![CDATA[Visual analytics]]></term>

<term><![CDATA[Web pages]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[41]]></spage>

<epage><![CDATA[50]]></epage>

<abstract><![CDATA[Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7194834]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467611]]></doi>

<publicationId><![CDATA[7194834]]></publicationId>

<partnum><![CDATA[7194834]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7194834&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194834]]></pdf>

</document>

<document>

<rank>14</rank>

<title><![CDATA[TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data]]></title>

<authors><![CDATA[Walker, J.;  Borgo, R.;  Jones, M.W.]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[sensor fusion]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Rivers]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[549]]></spage>

<epage><![CDATA[558]]></epage>

<abstract><![CDATA[Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192735]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467751]]></doi>

<publicationId><![CDATA[7192735]]></publicationId>

<partnum><![CDATA[7192735]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192735&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192735]]></pdf>

</document>

<document>

<rank>15</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1359725]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.6]]></doi>

<publicationId><![CDATA[1359725]]></publicationId>

<partnum><![CDATA[1359725]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359725&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359725]]></pdf>

</document>

<document>

<rank>16</rank>

<title><![CDATA[Dynamic modeling of butterfly subdivision surfaces]]></title>

<authors><![CDATA[Mandal, C.;  Hong Qin;  Vemuri, B.C.]]></authors>

<affiliations><![CDATA[Sun Microsyst. Inc., Chelmsford, MA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[CAD]]></term>

<term><![CDATA[bibliographies]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[iterative methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Damping]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Manipulator dynamics]]></term>

<term><![CDATA[Motion estimation]]></term>

<term><![CDATA[Physics]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[265]]></spage>

<epage><![CDATA[287]]></epage>

<abstract><![CDATA[The authors develop integrated techniques that unify physics based modeling with geometric subdivision methodology and present a scheme for dynamic manipulation of the smooth limit surface generated by the (modified) butterfly scheme using physics based &ldquo;force&rdquo; tools. This procedure based surface model obtained through butterfly subdivision does not have a closed form analytic formulation (unlike other well known spline based models), and hence poses challenging problems to incorporate mass and damping distributions, internal deformation energy, forces, and other physical quantities required to develop a physics based model. Our primary contributions to computer graphics and geometric modeling include: (1) a new hierarchical formulation for locally parameterizing the butterfly subdivision surface over its initial control polyhedron, (2) formulation of dynamic butterfly subdivision surface as a set of novel finite elements, and (3) approximation of this new type of finite elements by a collection of existing finite elements subject to implicit geometric constraints. Our new physics based model can be sculpted directly by applying synthesized forces and its equilibrium is characterized by the minimum of a deformation energy subject to the imposed constraints. We demonstrate that this novel dynamic framework not only provides a direct and natural means of manipulating geometric shapes, but also facilitates hierarchical shape and nonrigid motion estimation from large range and volumetric data sets using very few degrees of freedom (control vertices that define the initial polyhedron)]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[879787]]></arnumber>

<doi><![CDATA[10.1109/2945.879787]]></doi>

<publicationId><![CDATA[879787]]></publicationId>

<partnum><![CDATA[879787]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=879787&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=879787]]></pdf>

</document>

<document>

<rank>17</rank>

<title><![CDATA[Using PVsolve to Analyze and Locate Positions of Parallel Vectors]]></title>

<authors><![CDATA[Van Gelder, A.;  Pang, A.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Univ. of California at Santa Cruz, Santa Cruz, CA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Diesel engines]]></term>

<term><![CDATA[Differential equations]]></term>

<term><![CDATA[Field-flow fractionation]]></term>

<term><![CDATA[Fluid flow]]></term>

<term><![CDATA[Mathematical analysis]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[682]]></spage>

<epage><![CDATA[695]]></epage>

<abstract><![CDATA[A new method for finding the locus of parallel vectors is presented, called PVsolve. A parallel-vector operator has been proposed as a visualization primitive, as several features can be expressed as the locus of points where two vector fields are parallel. Several applications of the idea have been reported, so accurate and efficient location of such points is an important problem. Previously published methods derive a tangent direction under the assumption that the two vector fields are parallel at the current point in space, then extend in that direction to a new point. PVsolve includes additional terms to allow for the fact that the two vector fields may not be parallel at the current point, and uses a root-finding approach. Mathematical analysis sheds new light on the feature flow field technique (FFF) as well. The root-finding property allows PVsolve to use larger step sizes for tracing parallel-vector curves, compared to previous methods, and does not rely on sophisticated differential equation techniques for accuracy. Experiments are reported on fluid flow simulations, comparing FFF and PVsolve.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4745635]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.11]]></doi>

<publicationId><![CDATA[4745635]]></publicationId>

<partnum><![CDATA[4745635]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4745635&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745635]]></pdf>

</document>

<document>

<rank>18</rank>

<title><![CDATA[GPU-Based Interactive Cut-Surface Extraction From High-Order Finite Element Fields]]></title>

<authors><![CDATA[Nelson, B.;  Haimes, R.;  Kirby, R.M.]]></authors>

<affiliations><![CDATA[Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Linear approximation]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1803]]></spage>

<epage><![CDATA[1811]]></epage>

<abstract><![CDATA[We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064943]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.206]]></doi>

<publicationId><![CDATA[6064943]]></publicationId>

<partnum><![CDATA[6064943]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064943&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064943]]></pdf>

</document>

<document>

<rank>19</rank>

<title><![CDATA[Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms]]></title>

<authors><![CDATA[Glaber, S.;  Lawonn, K.;  Hoffmann, T.;  Skalej, M.;  Preim, B.]]></authors>

<affiliations><![CDATA[Dept. for Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical ultrasonics]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[haemodynamics]]></term>

<term><![CDATA[medical image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aneurysms]]></term>

<term><![CDATA[Arteries]]></term>

<term><![CDATA[Biomedical image processing]]></term>

<term><![CDATA[Brain modeling]]></term>

<term><![CDATA[Hemodynamics]]></term>

<term><![CDATA[Risk management]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2506]]></spage>

<epage><![CDATA[2515]]></epage>

<abstract><![CDATA[For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6877722]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346406]]></doi>

<publicationId><![CDATA[6877722]]></publicationId>

<partnum><![CDATA[6877722]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6877722&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6877722]]></pdf>

</document>

<document>

<rank>20</rank>

<title><![CDATA[What's new in Transactions [advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[528]]></spage>

<epage><![CDATA[528]]></epage>

<abstract><![CDATA[Advertisement: Our new "What's New in Transactions" webpage provides an overview of our 14 peer-reviewed scholarly journals. Visit http://www.computer.org/whats-new today.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6129455]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.22]]></doi>

<publicationId><![CDATA[6129455]]></publicationId>

<partnum><![CDATA[6129455]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6129455&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129455]]></pdf>

</document>

<document>

<rank>21</rank>

<title><![CDATA[Mesh-Driven Vector Field Clustering and Visualization: An Image-Based Approach]]></title>

<authors><![CDATA[ZhenMin Peng;  Grundy, E.;  Laramee, R.S.;  Guoning Chen;  Croft, N.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Swansea Univ., Swansea, UK]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptation model]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[283]]></spage>

<epage><![CDATA[298]]></epage>

<abstract><![CDATA[Vector field visualization techniques have evolved very rapidly over the last two decades, however, visualizing vector fields on complex boundary surfaces from computational flow dynamics (CFD) still remains a challenging task. In part, this is due to the large, unstructured, adaptive resolution characteristics of the meshes used in the modeling and simulation process. Out of the wide variety of existing flow field visualization techniques, vector field clustering algorithms offer the advantage of capturing a detailed picture of important areas of the domain while presenting a simplified view of areas of less importance. This paper presents a novel, robust, automatic vector field clustering algorithm that produces intuitive and insightful images of vector fields on large, unstructured, adaptive resolution boundary meshes from CFD. Our bottom-up, hierarchical approach is the first to combine the properties of the underlying vector field and mesh into a unified error-driven representation. The motivation behind the approach is the fact that CFD engineers may increase the resolution of model meshes according to importance. The algorithm has several advantages. Clusters are generated automatically, no surface parameterization is required, and large meshes are processed efficiently. The most suggestive and important information contained in the meshes and vector fields is preserved while less important areas are simplified in the visualization. Users can interactively control the level of detail by adjusting a range of clustering distance measure parameters. We describe two data structures to accelerate the clustering process. We also introduce novel visualizations of clusters inspired by statistical methods. We apply our method to a series of synthetic and complex, real-world CFD meshes to demonstrate the clustering algorithm results.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5708140]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.25]]></doi>

<publicationId><![CDATA[5708140]]></publicationId>

<partnum><![CDATA[5708140]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5708140&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708140]]></pdf>

</document>

<document>

<rank>22</rank>

<title><![CDATA[Chess Evolution Visualization]]></title>

<authors><![CDATA[Wei-Li Lu;  Yu-Shuen Wang;  Wen-Chieh Lin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Nat. Chiao Tung Univ., Hsinchu, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[artificial intelligence]]></term>

<term><![CDATA[computer games]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision trees]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Artificial intelligence]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Decision trees]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Licenses]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[702]]></spage>

<epage><![CDATA[713]]></epage>

<abstract><![CDATA[We present a chess visualization to convey the changes in a game over successive generations. It contains a score chart, an evolution graph and a chess board, such that users can understand a game from global to local viewpoints. Unlike current graphical chess tools, which focus only on highlighting pieces that are under attack and require sequential investigation, our visualization shows potential outcomes after a piece is moved and indicates how much tactical advantage the player can have over the opponent. Users can first glance at the score chart to roughly obtain the growth and decline of advantages from both sides, and then examine the position relations and the piece placements, to know how the pieces are controlled and how the strategy works. To achieve this visualization, we compute the decision tree using artificial intelligence to analyze a game, in which each node represents a chess position and each edge connects two positions that are one-move different. We then merge nodes representing the same chess position, and shorten branches where nodes on them contain only two neighbors, in order to achieve readability. During the graph rendering, the nodes containing events such as draws, effective checks and checkmates, are highlighted because they show how a game is ended. As a result, our visualization helps players understand a chess game so that they can efficiently learn strategies and tactics. The presented results, evaluations, and the conducted user studies demonstrate the feasibility of our visualization design.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6710145]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2299803]]></doi>

<publicationId><![CDATA[6710145]]></publicationId>

<partnum><![CDATA[6710145]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6710145&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710145]]></pdf>

</document>

<document>

<rank>23</rank>

<title><![CDATA[Fast Animation of Lightning Using an Adaptive Mesh]]></title>

<authors><![CDATA[Kim, T.;  Lin, M.C.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[conjugate gradient methods]]></term>

<term><![CDATA[convolution]]></term>

<term><![CDATA[electric breakdown]]></term>

<term><![CDATA[matrix decomposition]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[octrees]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[stochastic processes]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Dielectric breakdown]]></term>

<term><![CDATA[Electric breakdown]]></term>

<term><![CDATA[Lightning]]></term>

<term><![CDATA[Pattern formation]]></term>

<term><![CDATA[Physics]]></term>

<term><![CDATA[Visual effects]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[390]]></spage>

<epage><![CDATA[402]]></epage>

<abstract><![CDATA[We present a fast method for simulating, animating, and rendering lightning using adaptive grids. The "dielectric breakdown model" is an elegant algorithm for electrical pattern formation that we extend to enable animation of lightning. The simulation can be slow, particularly in 3D, because it involves solving a large Poisson problem. Losasso et al. recently proposed an octree data structure for simulating water and smoke, and we show that this discretization can be applied to the problem of lightning simulation as well. However, implementing the incomplete Cholesky conjugate gradient (ICCG) solver for this problem can be daunting, so we provide an extensive discussion of implementation issues. ICCG solvers can usually be accelerated using "Eisenstat's trick," but the trick cannot be directly applied to the adaptive case. Fortunately, we show that an "almost incomplete Cholesky" factorization can be computed so that Eisenstat's trick can still be used. We then present a fast rendering method based on convolution that is competitive with Monte Carlo ray tracing but orders of magnitude faster, and we also show how to further improve the visual results using jittering]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4069246]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.38]]></doi>

<publicationId><![CDATA[4069246]]></publicationId>

<partnum><![CDATA[4069246]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4069246&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069246]]></pdf>

</document>

<document>

<rank>24</rank>

<title><![CDATA[Annual index]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[769]]></spage>

<epage><![CDATA[779]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under he primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1512027]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.91]]></doi>

<publicationId><![CDATA[1512027]]></publicationId>

<partnum><![CDATA[1512027]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512027&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512027]]></pdf>

</document>

<document>

<rank>25</rank>

<title><![CDATA[Automated Illustration of Molecular Flexibility]]></title>

<authors><![CDATA[Bryden, A.;  Phillips, G.N.;  Gleicher, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Wisconsin, Madison, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[affine transforms]]></term>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[extrapolation]]></term>

<term><![CDATA[molecular biophysics]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[proteins]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Amino acids]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Proteins]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[132]]></spage>

<epage><![CDATA[145]]></epage>

<abstract><![CDATA[In this paper, we present an approach to creating illustrations of molecular flexibility using normal mode analysis (NMA). The output of NMA is a collection of points corresponding to the locations of atoms and associated motion vectors, where a vector for each point is known. Our approach abstracts the complex object and its motion by grouping the points, models the motion of each group as an affine velocity, and depicts the motion of each group by automatically choosing glyphs such as arrows. Affine exponentials allow the extrapolation of nonlinear effects such as near rotations and spirals from the linear velocities. Our approach automatically groups points by finding sets of neighboring points whose motions fit the motion model. The geometry and motion models for each group are used to determine glyphs that depict the motion, with various aspects of the motion mapped to each glyph. We evaluated the utility of our system in real work done by structural biologists both by utilizing it in our own structural biology work and quantitatively measuring its usefulness on a set of known protein conformation changes. Additionally, in order to allow ourselves and our collaborators to effectively use our techniques we integrated our system with commonly used tools for molecular visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5669302]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.250]]></doi>

<publicationId><![CDATA[5669302]]></publicationId>

<partnum><![CDATA[5669302]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5669302&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669302]]></pdf>

</document>

<document>

<rank>26</rank>

<title><![CDATA[Interactive sound rendering in complex and dynamic scenes using frustum tracing]]></title>

<authors><![CDATA[Lauterbach, C.;  Chandak, A.;  Manocha, D.]]></authors>

<affiliations><![CDATA[Univ. of North Carolina-Chapel Hill, Chapel Hill]]></affiliations>

<controlledterms>

<term><![CDATA[acoustic signal processing]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Acoustic beams]]></term>

<term><![CDATA[Acoustic reflection]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1672]]></spage>

<epage><![CDATA[1679]]></epage>

<abstract><![CDATA[We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376201]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70567]]></doi>

<publicationId><![CDATA[4376201]]></publicationId>

<partnum><![CDATA[4376201]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376201&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376201]]></pdf>

</document>

<document>

<rank>27</rank>

<title><![CDATA[Interactive Exploration and Analysis of Large-Scale Simulations Using Topology-Based Data Segmentation]]></title>

<authors><![CDATA[Bremer, P.-T.;  Weber, G.;  Tierny, J.;  Pascucci, V.;  Day, M.;  Bell, J.]]></authors>

<affiliations><![CDATA[Center of Appl. Sci. Comput. (CASC), Lawrence Livermore Nat. Lab., Livermore, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[combustion]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Combustion]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Fuels]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1307]]></spage>

<epage><![CDATA[1324]]></epage>

<abstract><![CDATA[Large-scale simulations are increasingly being used to study complex scientific and engineering phenomena. As a result, advanced visualization and data analysis are also becoming an integral part of the scientific process. Often, a key step in extracting insight from these large simulations involves the definition, extraction, and evaluation of features in the space and time coordinates of the solution. However, in many applications, these features involve a range of parameters and decisions that will affect the quality and direction of the analysis. Examples include particular level sets of a specific scalar field, or local inequalities between derived quantities. A critical step in the analysis is to understand how these arbitrary parameters/decisions impact the statistical properties of the features, since such a characterization will help to evaluate the conclusions of the analysis as a whole. We present a new topological framework that in a single-pass extracts and encodes entire families of possible features definitions as well as their statistical properties. For each time step we construct a hierarchical merge tree a highly compact, yet flexible feature representation. While this data structure is more than two orders of magnitude smaller than the raw simulation data it allows us to extract a set of features for any given parameter selection in a postprocessing step. Furthermore, we augment the trees with additional attributes making it possible to gather a large number of useful global, local, as well as conditional statistic that would otherwise be extremely difficult to compile. We also use this representation to create tracking graphs that describe the temporal evolution of the features over time. Our system provides a linked-view interface to explore the time-evolution of the graph interactively alongside the segmentation, thus making it possible to perform extensive data analysis in a very efficient manner. We demonstrate our framework by extracting a- d analyzing burning cells from a large-scale turbulent combustion simulation. In particular, we show how the statistical analysis enabled by our techniques provides new insight into the combustion process.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5669296]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.253]]></doi>

<publicationId><![CDATA[5669296]]></publicationId>

<partnum><![CDATA[5669296]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5669296&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669296]]></pdf>

</document>

<document>

<rank>28</rank>

<title><![CDATA[A Five-Level Design Framework for Bicluster Visualizations]]></title>

<authors><![CDATA[Maoyuan Sun;  North, C.;  Ramakrishnan, N.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Cluster approximation]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1713]]></spage>

<epage><![CDATA[1722]]></epage>

<abstract><![CDATA[Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875974]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346665]]></doi>

<publicationId><![CDATA[6875974]]></publicationId>

<partnum><![CDATA[6875974]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875974&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875974]]></pdf>

</document>

<document>

<rank>29</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5714214]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.45]]></doi>

<publicationId><![CDATA[5714214]]></publicationId>

<partnum><![CDATA[5714214]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5714214&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714214]]></pdf>

</document>

<document>

<rank>30</rank>

<title><![CDATA[The Information Mural: a technique for displaying and navigating large information spaces]]></title>

<authors><![CDATA[Jerding, D.F.;  Stasko, J.T.]]></authors>

<affiliations><![CDATA[Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[antialiasing]]></term>

<term><![CDATA[colour graphics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[information retrieval]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Bandwidth]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Focusing]]></term>

<term><![CDATA[Large screen displays]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Software prototyping]]></term>

<term><![CDATA[Space technology]]></term>

<term><![CDATA[Two dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[257]]></spage>

<epage><![CDATA[271]]></epage>

<abstract><![CDATA[Information visualizations must allow users to browse information spaces and focus quickly on items of interest. Being able to see some representation of the entire information space provides an initial gestalt overview and gives context to support browsing and search tasks. However, the limited number of pixels on the screen constrain the information bandwidth and make it difficult to completely display large information spaces. The Information Mural is a two-dimensional, reduced representation of an entire information space that fits entirely within a display window or screen. The Mural creates a miniature version of the information space using visual attributes, such as gray-scale shading, intensity, color, and pixel size, along with antialiased compression techniques. Information Murals can be used as stand-alone visualizations or in global navigational views. We have built several prototypes to demonstrate the use of Information Murals in visualization applications; subject matter for these views includes computer software, scientific data, text documents and geographic information]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[722299]]></arnumber>

<doi><![CDATA[10.1109/2945.722299]]></doi>

<publicationId><![CDATA[722299]]></publicationId>

<partnum><![CDATA[722299]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=722299&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722299]]></pdf>

</document>

<document>

<rank>31</rank>

<title><![CDATA[MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data]]></title>

<authors><![CDATA[Sujin Jang;  Elmqvist, N.;  Ramani, K.]]></authors>

<affiliations><![CDATA[Purdue Univ. in West LafayetteWest Lafayette, West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[gesture recognition]]></term>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[object tracking]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[pose estimation]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Pattern analysis]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Tracking]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[21]]></spage>

<epage><![CDATA[30]]></epage>

<abstract><![CDATA[Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7194831]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2468292]]></doi>

<publicationId><![CDATA[7194831]]></publicationId>

<partnum><![CDATA[7194831]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7194831&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194831]]></pdf>

</document>

<document>

<rank>32</rank>

<title><![CDATA[The Role of Uncertainty, Awareness, and Trust in Visual Analytics]]></title>

<authors><![CDATA[Sacha, D.;  Senaratne, H.;  Bum Chul Kwon;  Ellis, G.;  Keim, D.A.]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision making]]></term>

<term><![CDATA[uncertainty handling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[240]]></spage>

<epage><![CDATA[249]]></epage>

<abstract><![CDATA[Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192716]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467591]]></doi>

<publicationId><![CDATA[7192716]]></publicationId>

<partnum><![CDATA[7192716]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192716&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192716]]></pdf>

</document>

<document>

<rank>33</rank>

<title><![CDATA[Importance-Driven Time-Varying Data Visualization]]></title>

<authors><![CDATA[Chaoli Wang;  Hongfeng Yu;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, CA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[entropy]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Chaos]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data engineering]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Earthquakes]]></term>

<term><![CDATA[Entropy]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Information theory]]></term>

<term><![CDATA[Time measurement]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1547]]></spage>

<epage><![CDATA[1554]]></epage>

<abstract><![CDATA[The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4658174]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.140]]></doi>

<publicationId><![CDATA[4658174]]></publicationId>

<partnum><![CDATA[4658174]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658174&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658174]]></pdf>

</document>

<document>

<rank>34</rank>

<title><![CDATA[Editor's note]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1359726]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.10]]></doi>

<publicationId><![CDATA[1359726]]></publicationId>

<partnum><![CDATA[1359726]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359726&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359726]]></pdf>

</document>

<document>

<rank>35</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on the Symposium on Interactive 3D Graphics and Games (I3D)]]></title>

<authors><![CDATA[Varshney, Amitabh;  Wyman, Chris]]></authors>

<affiliations><![CDATA[IEEE]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Real time systems]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1589]]></spage>

<epage><![CDATA[1590]]></epage>

<abstract><![CDATA[The three papers in this special section were presented at the Symposium on Interactive 3D Graphics and Games (I3D) that was held in San Francisco, CA, 18-20 February 2011.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6264045]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.164]]></doi>

<publicationId><![CDATA[6264045]]></publicationId>

<partnum><![CDATA[6264045]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6264045&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6264045]]></pdf>

</document>

<document>

<rank>36</rank>

<title><![CDATA[A generic rendering system]]></title>

<authors><![CDATA[Dollner, J.;  Hinrichs, K.]]></authors>

<affiliations><![CDATA[Hasso-Plattner Inst., Potsdam Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[application program interfaces]]></term>

<term><![CDATA[object-oriented programming]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[software architecture]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Engines]]></term>

<term><![CDATA[Functional programming]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Object oriented programming]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Software architecture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[99]]></spage>

<epage><![CDATA[118]]></epage>

<abstract><![CDATA[Describes the software architecture of a rendering system that follows a pragmatic approach to integrating and bundling the power of different low-level rendering systems within an object-oriented framework. The generic rendering system provides higher-level abstractions to existing rendering systems and serves as a framework for developing new rendering techniques. It wraps the functionality of several widely-used rendering systems, defines a unified object-oriented application programming interface and provides an extensible, customizable apparatus for evaluating and interpreting hierarchical scene information. As a fundamental property, individual features of a specific rendering system can be integrated into the generic rending system in a transparent way. The system is based on a state machine, called an "engine", which operates on "rendering components". Four major categories of rendering components constitute the generic rendering system: "shapes" represent geometries, "attributes" specify properties assigned to geometries and scenes, "handlers" encapsulate rendering algorithms, and "techniques" represent evaluation strategies for rendering components. As a proof of concept, we have implemented the described software architecture using the Virtual Rendering System, which currently wraps the functionality of the OpenGL, Radiance, POV Ray and RenderMan systems]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[998664]]></arnumber>

<doi><![CDATA[10.1109/2945.998664]]></doi>

<publicationId><![CDATA[998664]]></publicationId>

<partnum><![CDATA[998664]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=998664&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998664]]></pdf>

</document>

<document>

<rank>37</rank>

<title><![CDATA[A Survey of Visualization Systems for Network Security]]></title>

<authors><![CDATA[Shiravi, H.;  Shiravi, A.;  Ghorbani, A.A.]]></authors>

<affiliations><![CDATA[Inf. Security Centre of Excellence, Univ. of New Brunswick, Fredericton, NB, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computer network security]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[IP networks]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Security]]></term>

<term><![CDATA[Servers]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1313]]></spage>

<epage><![CDATA[1329]]></epage>

<abstract><![CDATA[Security Visualization is a very young term. It expresses the idea that common visualization techniques have been designed for use cases that are not supportive of security-related data, demanding novel techniques fine tuned for the purpose of thorough analysis. Significant amount of work has been published in this area, but little work has been done to study this emerging visualization discipline. We offer a comprehensive review of network security visualization and provide a taxonomy in the form of five use-case classes encompassing nearly all recent works in this area. We outline the incorporated visualization techniques and data sources and provide an informative table to display our findings. From the analysis of these systems, we examine issues and concerns regarding network security visualization and provide guidelines and directions for future researchers and visual system developers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6007132]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.144]]></doi>

<publicationId><![CDATA[6007132]]></publicationId>

<partnum><![CDATA[6007132]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6007132&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007132]]></pdf>

</document>

<document>

<rank>38</rank>

<title><![CDATA[Vectorizing Cartoon Animations]]></title>

<authors><![CDATA[Song-Hai Zhang;  Tao Chen;  Yi-Fei Zhang;  Shi-Min Hu;  Martin, R.R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image segmentation]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[618]]></spage>

<epage><![CDATA[629]]></epage>

<abstract><![CDATA[We present a system for vectorizing 2D raster format cartoon animations. The output animations are visually flicker free, smaller in file size, and easy to edit. We identify decorative lines separately from colored regions. We use an accurate and semantically meaningful image decomposition algorithm, supporting an arbitrary color model for each region. To ensure temporal coherence in the output, we reconstruct a universal background for all frames and separately extract foreground regions. Simple user-assistance is required to complete the background. Each region and decorative line is vectorized and stored together with their motions from frame to frame. The contributions of this paper are: 1) the new trapped-ball segmentation method, which is fast, supports nonuniformly colored regions, and allows robust region segmentation even in the presence of imperfectly linked region edges, 2) the separate handling of decorative lines as special objects during image decomposition, avoiding results containing multiple short, thin oversegmented regions, and 3) extraction of a single patch-based background for all frames, which provides a basis for consistent, flicker-free animations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4745633]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.9]]></doi>

<publicationId><![CDATA[4745633]]></publicationId>

<partnum><![CDATA[4745633]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4745633&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745633]]></pdf>

</document>

<document>

<rank>39</rank>

<title><![CDATA[InterAxis: Steering Scatterplot Axes via Observation-Level Interaction]]></title>

<authors><![CDATA[Hannah Kim;  Jaegul Choo;  Haesun Park;  Endert, A.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Semantics]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[131]]></spage>

<epage><![CDATA[140]]></epage>

<abstract><![CDATA[Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192671]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467615]]></doi>

<publicationId><![CDATA[7192671]]></publicationId>

<partnum><![CDATA[7192671]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192671&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192671]]></pdf>

</document>

<document>

<rank>40</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4276088]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70423]]></doi>

<publicationId><![CDATA[4276088]]></publicationId>

<partnum><![CDATA[4276088]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4276088&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4276088]]></pdf>

</document>

<document>

<rank>41</rank>

<title><![CDATA[Configuring Hierarchical Layouts to Address Research Questions]]></title>

<authors><![CDATA[Slingsby, A.;  Dykes, J.;  Wood, J.]]></authors>

<affiliations><![CDATA[Dept. of Inf. Sci., City Univ. London, London, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geography]]></term>

<term><![CDATA[temporal databases]]></term>

<term><![CDATA[visual databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Containers]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Facial animation]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Guidelines]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Marketing and sales]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Stacking]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[977]]></spage>

<epage><![CDATA[984]]></epage>

<abstract><![CDATA[We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290702]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.128]]></doi>

<publicationId><![CDATA[5290702]]></publicationId>

<partnum><![CDATA[5290702]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290702&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290702]]></pdf>

</document>

<document>

<rank>42</rank>

<title><![CDATA[3-D Navigation on Impossible Figures via Dynamically Reconfigurable Maze]]></title>

<authors><![CDATA[Lai, Chi-Fu;  Yeung, Sai-Kit;  Yan, X.;  Fu, Chi-Wing;  Tang, Chi-Keung]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Previous research on impossible figures focuses extensively on single view modeling and rendering. Existing computer games that employ impossible figures as navigation maze for gaming either use a fixed third-person view with axonometric projection to retain the figure&#x2019;s impossibility perception, or simply break the figure&#x2019;s impossibility upon view changes. In this paper, we present a new approach towards 3-D gaming with impossible figures, delivering for the first time navigation in 3-D mazes constructed from impossible figures. Such result cannot be achieved by previous research work in modeling impossible figures. To deliver seamless gaming navigation and interaction, we propose i) a set of guiding principles for bringing out subtle perceptions and ii) a novel computational approach to construct 3-D structures from impossible figure images and then to dynamically construct the impossible-figure maze subjected to user&#x2019;s view. In the end, we demonstrate and discuss our method with a variety of generic maze types.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7352362]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2507584]]></doi>

<publicationId><![CDATA[7352362]]></publicationId>

<partnum><![CDATA[7352362]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7352362&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352362]]></pdf>

</document>

<document>

<rank>43</rank>

<title><![CDATA[GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation]]></title>

<authors><![CDATA[Rieder, C.;  Kroeger, T.;  Schumann, C.;  Hahn, H.K.]]></authors>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[biomedical electrodes]]></term>

<term><![CDATA[blood vessels]]></term>

<term><![CDATA[cancer]]></term>

<term><![CDATA[cellular biophysics]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[haemodynamics]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[liver]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[numerical analysis]]></term>

<term><![CDATA[patient treatment]]></term>

<term><![CDATA[physiological models]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[tumours]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Ablation]]></term>

<term><![CDATA[Blood flow]]></term>

<term><![CDATA[Electrodes]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Heat sinks]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Radio frequency]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1812]]></spage>

<epage><![CDATA[1821]]></epage>

<abstract><![CDATA[Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064944]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.207]]></doi>

<publicationId><![CDATA[6064944]]></publicationId>

<partnum><![CDATA[6064944]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064944&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064944]]></pdf>

</document>

<document>

<rank>44</rank>

<title><![CDATA[Visualization of geologic stress perturbations using Mohr diagrams]]></title>

<authors><![CDATA[Crossno, P.;  Rogers, D.H.;  Brannon, R.M.;  Coblentz, D.;  Fredrich, J.T.]]></authors>

<affiliations><![CDATA[Sandia Nat. Lab., Albuquerque, NM, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[gas industry]]></term>

<term><![CDATA[geology]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[mechanical engineering]]></term>

<term><![CDATA[oil drilling]]></term>

<term><![CDATA[stress analysis]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Costing]]></term>

<term><![CDATA[Drilling]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Geology]]></term>

<term><![CDATA[Hydrocarbon reservoirs]]></term>

<term><![CDATA[Petroleum]]></term>

<term><![CDATA[Probes]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[508]]></spage>

<epage><![CDATA[518]]></epage>

<abstract><![CDATA[Huge salt formations, trapping large untapped oil and gas reservoirs, lie in the deepwater region of the Gulf of Mexico. Drilling in this region is high-risk and drilling failures have led to well abandonments, with each costing tens of millions of dollars. Salt tectonics plays a central role in these failures. To explore the geomechanical interactions between salt and the surrounding sand and shale formations, scientists have simulated the stresses in and around salt diapirs in the Gulf of Mexico using nonlinear finite element geomechanical modeling. In this paper, we describe novel techniques developed to visualize the simulated subsurface stress field. We present an adaptation of the Mohr diagram, a traditional paper-and-pencil graphical method long used by the material mechanics community for estimating coordinate transformations for stress tensors, as a new tensor glyph for dynamically exploring tensor variables within three-dimensional finite element models. This interactive glyph can be used as either a probe or a filter through brushing and linking.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1471688]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.86]]></doi>

<publicationId><![CDATA[1471688]]></publicationId>

<partnum><![CDATA[1471688]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1471688&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471688]]></pdf>

</document>

<document>

<rank>45</rank>

<title><![CDATA[Achieving dialogue with children with severe autism in an adaptive multisensory interaction: the "MEDIATE" project]]></title>

<authors><![CDATA[Pares, N.;  Masri, P.;  van Wolferen, G.;  Creed, C.]]></authors>

<affiliations><![CDATA[Exp. on Interactive Commun., Univ. Pompeu Fabra, Barcelona, Spain]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[handicapped aids]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[meta data]]></term>

<term><![CDATA[psychology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive control]]></term>

<term><![CDATA[Art]]></term>

<term><![CDATA[Autism]]></term>

<term><![CDATA[Human factors]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Pediatrics]]></term>

<term><![CDATA[Programmable control]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[734]]></spage>

<epage><![CDATA[743]]></epage>

<abstract><![CDATA[This paper presents an adaptive physical environment that allows children with severe autism to successfully interact with multimodal stimuli, giving them a sense of control of the interaction and, hence, providing them with a sense of agency. This has been an extremely important effort for two main reasons: 1) This user group cannot be typified, hence making the design of an interactive system to fit all the spectrum of individuals a very complex task; 2) each individual PAS (person on the autistic spectrum) user must be able to develop himself within the environment according to his own capacities and potentiality. Qualitative evaluation by psychologists shows very good results and sketches an encouraging future for research on these environments.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512023]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.88]]></doi>

<publicationId><![CDATA[1512023]]></publicationId>

<partnum><![CDATA[1512023]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512023&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512023]]></pdf>

</document>

<document>

<rank>46</rank>

<title><![CDATA[Generalized B-spline subdivision-surface wavelets for geometry compression]]></title>

<authors><![CDATA[Bertram, M.;  Duchaineau, M.A.;  Hamann, B.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Fachbereich Inf., Kaiserslautern Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data compression]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[splines (mathematics)]]></term>

<term><![CDATA[surface fitting]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Arithmetic]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Discrete wavelet transforms]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface waves]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Wavelet coefficients]]></term>

<term><![CDATA[Wavelet transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[326]]></spage>

<epage><![CDATA[338]]></epage>

<abstract><![CDATA[We present a new construction of lifted biorthogonal wavelets on surfaces of arbitrary two-manifold topology for compression and multiresolution representation. Our method combines three approaches: subdivision surfaces of arbitrary topology, B-spline wavelets, and the lifting scheme for biorthogonal wavelet construction. The simple building blocks of our wavelet transform are local lifting operations performed on polygonal meshes with subdivision hierarchy. Starting with a coarse, irregular polyhedral base mesh, our transform creates a subdivision hierarchy of meshes converging to a smooth limit surface. At every subdivision level, geometric detail is expanded from wavelet coefficients and added to the surface. We present wavelet constructions for bilinear, bicubic, and biquintic B-spline subdivision. While the bilinear and bicubic constructions perform well in numerical experiments, the biquintic construction turns out to be unstable. For lossless compression, our transform is computed in integer arithmetic, mapping integer coordinates of control points to integer wavelet coefficients. Our approach provides a highly efficient and progressive representation for complex geometries of arbitrary topology.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1272731]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1272731]]></doi>

<publicationId><![CDATA[1272731]]></publicationId>

<partnum><![CDATA[1272731]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1272731&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272731]]></pdf>

</document>

<document>

<rank>47</rank>

<title><![CDATA[ISMAR 2015 Conference Committee Members]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[ix]]></spage>

<epage><![CDATA[x]]></epage>

<abstract><![CDATA[Presents a listing of the conference committee members.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7283729]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2472775]]></doi>

<publicationId><![CDATA[7283729]]></publicationId>

<partnum><![CDATA[7283729]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7283729&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7283729]]></pdf>

</document>

<document>

<rank>48</rank>

<title><![CDATA[Natural Perspective Projections for Head-Mounted Displays]]></title>

<authors><![CDATA[Steinicke, F.;  Bruder, G.;  Kuhl, S.;  Willemsen, P.;  Lappe, M.;  Hinrichs, K.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Sci., Univ. of Munster, Mu&#x0308;nster, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[helmet mounted displays]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Calibration]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[888]]></spage>

<epage><![CDATA[899]]></epage>

<abstract><![CDATA[The display units integrated in today's head-mounted displays (HMDs) provide only a limited field of view (FOV) to the virtual world. In order to present an undistorted view to the virtual environment (VE), the perspective projection used to render the VE has to be adjusted to the limitations caused by the HMD characteristics. In particular, the geometric field of view (GFOV), which defines the virtual aperture angle used for rendering of the 3D scene, is set up according to the display field of view (DFOV). A discrepancy between these two fields of view distorts the geometry of the VE in a way that either minifies or magnifies the imagery displayed to the user. It has been shown that this distortion has the potential to affect a user's perception of the virtual space, sense of presence, and performance on visual search tasks. In this paper, we analyze the user's perception of a VE displayed in a HMD, which is rendered with different GFOVs. We introduce a psychophysical calibration method to determine the HMD's actual field of view, which may vary from the nominal values specified by the manufacturer. Furthermore, we conducted two experiments to identify perspective projections for HMDs, which are identified as natural by subjects-even if these perspectives deviate from the perspectives that are inherently defined by the DFOV. In the first experiment, subjects had to adjust the GFOV for a rendered virtual laboratory such that their perception of the virtual replica matched the perception of the real laboratory, which they saw before the virtual one. In the second experiment, we displayed the same virtual laboratory, but restricted the viewing condition in the real world to simulate the limited viewing condition in a HMD environment. We found that subjects evaluate a GFOV as natural when it is larger than the actual DFOV of the HMD-in some cases up to 50 percent-even when subjects viewed the real space with a limited field of view.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5620907]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.248]]></doi>

<publicationId><![CDATA[5620907]]></publicationId>

<partnum><![CDATA[5620907]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5620907&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620907]]></pdf>

</document>

<document>

<rank>49</rank>

<title><![CDATA[Restoration of Brick and Stone Relief from Single Rubbing Images]]></title>

<authors><![CDATA[Zhuwen Li;  Song Wang;  Jinhui Yu;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[image restoration]]></term>

<term><![CDATA[least squares approximations]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[partial differential equations]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Frequency estimation]]></term>

<term><![CDATA[Image restoration]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Skeleton]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[177]]></spage>

<epage><![CDATA[187]]></epage>

<abstract><![CDATA[We present a two-level approach for height map estimation from single images, aiming at restoring brick and stone relief (BSR) from their rubbing images in a visually plausible manner. In our approach, the base relief of the low frequency component is estimated automatically with a partial differential equation (PDE)-based mesh deformation scheme. A few vertices near the central area of the object region are selected and assigned with heights estimated by an erosion-based contour map. These vertices together with object boundary vertices, boundary normals as well as the partial differential properties of the mesh are taken as constraints to deform the mesh by minimizing a least-squares error functional. The high frequency detail is estimated directly from rubbing images automatically or optionally with minimal interactive processing. The final height map for a restored BSR is obtained by blending height maps of the base relief and high frequency detail. We demonstrate that our method can not only successfully restore several BSR maps from their rubbing images, but also restore some relief-like surfaces from photographic images.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5708141]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.26]]></doi>

<publicationId><![CDATA[5708141]]></publicationId>

<partnum><![CDATA[5708141]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5708141&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708141]]></pdf>

</document>

<document>

<rank>50</rank>

<title><![CDATA[Glyphs for visualizing uncertainty in vector fields]]></title>

<authors><![CDATA[Wittenbrink, C.M.;  Pang, A.T.;  Lodha, S.K.]]></authors>

<affiliations><![CDATA[Baskin Center for Comput. Eng. & Comput. Sci., California Univ., Santa Cruz, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geophysics]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[uncertainty handling]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Extraterrestrial measurements]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Ink]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Measurement uncertainty]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Sea measurements]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[266]]></spage>

<epage><![CDATA[279]]></epage>

<abstract><![CDATA[Environmental data have inherent uncertainty which is often ignored in visualization. Meteorological stations and doppler radars, including their time series averages, have a wealth of uncertainty information that traditional vector visualization methods such as meteorological wind barbs and arrow glyphs simply ignore. We have developed a new vector glyph to visualize uncertainty in winds and ocean currents. Our approach is to include uncertainty in direction and magnitude, as well as the mean direction and length, in vector glyph plots. Our glyph shows the variation in uncertainty, and provides fair comparisons of data from instruments, models, and time averages of varying certainty. We also define visualizations that incorporate uncertainty in an unambiguous manner as verity visualization. We use both quantitative and qualitative methods to compare our glyphs to traditional ones. Subjective comparison tests with experts are provided, as well as objective tests, where the information density of our new glyphs and traditional glyphs are compared. The design of the glyph and numerous examples using environmental data are given. We show enhanced visualizations, data together with their uncertainty information, that may improve understanding of environmental vector field data quality]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[537309]]></arnumber>

<doi><![CDATA[10.1109/2945.537309]]></doi>

<publicationId><![CDATA[537309]]></publicationId>

<partnum><![CDATA[537309]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=537309&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=537309]]></pdf>

</document>

<document>

<rank>51</rank>

<title><![CDATA[A Framework for Holographic Scene Representation and Image Synthesis]]></title>

<authors><![CDATA[Ziegler, R.;  Kaufmann, P.;  Gross, Markus]]></authors>

<affiliations><![CDATA[ETH Zentrum, Zurich]]></affiliations>

<controlledterms>

<term><![CDATA[holography]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Digital recording]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Holography]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optical propagation]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[403]]></spage>

<epage><![CDATA[415]]></epage>

<abstract><![CDATA[We present a framework for the holographic representation and display of graphics objects. As opposed to traditional graphics representations, our approach reconstructs the light wave reflected or emitted by the original object directly from the underlying digital hologram. Our novel holographic graphics pipeline consists of several stages including the digital recording of a full-parallax hologram, the reconstruction and propagation of its wavefront, and rendering of the final image onto conventional, framebuffer-based displays. The required view-dependent depth image is computed from the phase information inherently represented in the complex-valued wavefront. Our model also comprises a correct physical modeling of the camera taking into account optical elements, such as lens and aperture. It thus allows for a variety of effects including depth of field, diffraction, interference, and features built-in anti-aliasing. A central feature of our framework is its seamless integration into conventional rendering and display technology which enables us to elegantly combine traditional 3D object or scene representations with holograms. The presented work includes the theoretical foundations and allows for high quality rendering of objects consisting of large numbers of elementary waves while keeping the hologram at a reasonable size]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4069247]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.27]]></doi>

<publicationId><![CDATA[4069247]]></publicationId>

<partnum><![CDATA[4069247]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4069247&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069247]]></pdf>

</document>

<document>

<rank>52</rank>

<title><![CDATA[Comparison of path visualizations and cognitive measures relative to travel technique in a virtual environment]]></title>

<authors><![CDATA[Zanbaka, C.A.;  Lok, B.C.;  Babu, S.V.;  Ulinski, A.C.;  Hodges, L.F.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., North Carolina Univ., Charlotte, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cognition]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[problem solving]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Space exploration]]></term>

<term><![CDATA[Space technology]]></term>

<term><![CDATA[Tracking]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[694]]></spage>

<epage><![CDATA[705]]></epage>

<abstract><![CDATA[We describe a between-subjects experiment that compared four different methods of travel and their effect on cognition and paths taken in an immersive virtual environment (IVE). Participants answered a set of questions based on Crook's condensation of Bloom's taxonomy that assessed their cognition of the IVE with respect to knowledge, understanding and application, and higher mental processes. Participants also drew a sketch map of the IVE and the objects within it. The users' sense of presence was measured using the Steed-Usoh-Slater presence questionnaire. The participants' position and head orientation were automatically logged during their exposure to the virtual environment. These logs were later used to create visualizations of the paths taken. Path analysis, such as exploring the overlaid path visualizations and dwell data information, revealed further differences among the travel techniques. Our results suggest that, for applications where problem solving and evaluation of information is important or where opportunity to train is minimal, then having a large tracked space so that the participant can walk around the virtual environment provides benefits over common virtual travel techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512020]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.92]]></doi>

<publicationId><![CDATA[1512020]]></publicationId>

<partnum><![CDATA[1512020]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512020&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512020]]></pdf>

</document>

<document>

<rank>53</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5465875]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.69]]></doi>

<publicationId><![CDATA[5465875]]></publicationId>

<partnum><![CDATA[5465875]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5465875&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5465875]]></pdf>

</document>

<document>

<rank>54</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on the International Symposium on Mixed and Augmented Reality 2012]]></title>

<authors><![CDATA[Gandy, M.;  Kiyokawa, K.;  Reitmayr, G.]]></authors>

<affiliations><![CDATA[Interactive Media Technology Center, and the Media, Institute for People and Technology,]]></affiliations>

<thesaurusterms>

<term><![CDATA[Augmented reality]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Real-time systems]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[823]]></spage>

<epage><![CDATA[824]]></epage>

<abstract><![CDATA[The IEEE International Symposium on Mixed and Augmented Reality continues to be the leading venue for publishing the latest Mixed andAugmented Reality research, applications and technologies. This special section presents significantly extended versions of the four best papers of the IEEE ISMAR 2012 proceedings. These papers demonstrate the wide range of topics in Augmented Reality research. IEEE ISMAR 2012 had 143 submissions; each paper was reviewed by at least four experts in the field. An international program committee of 15 AR experts invited reviewers, led discussions, invited a rebuttal by the paper authors and prepared a consensus review. To select the final papers for publication, an in-person two-day PC meeting was held, where each paper was discussed, resulting in an overall acceptance rate of 27%. In an additional selection process, an independent Award Committee reviewed the 10 best ranked submissions again to determine the awards for Best Paper and Honorable Mention. For this special section, the authors of the award papers were invited to submit an extended version of their conference paper, with a clear focus on additional content that expands the scientific contribution of the original conference paper. A standard TVCG reviewing cycle was initiated and all four papers required multiple revisions and reviews.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6807545]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2310532]]></doi>

<publicationId><![CDATA[6807545]]></publicationId>

<partnum><![CDATA[6807545]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6807545&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6807545]]></pdf>

</document>

<document>

<rank>55</rank>

<title><![CDATA[Six degree-of-freedom haptic rendering using spatialized normal cone search]]></title>

<authors><![CDATA[Johnson, D.E.;  Willemsen, P.;  Cohen, E.]]></authors>

<affiliations><![CDATA[Sch. of Comput., Utah Univ., Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[haptic interfaces]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[virtual prototyping]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Design automation]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[System testing]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Virtual prototyping]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[661]]></spage>

<epage><![CDATA[670]]></epage>

<abstract><![CDATA[This paper describes a haptic rendering algorithm for arbitrary polygonal models using a six degree-of-freedom haptic interface. The algorithm supports activities such as virtual prototyping of complex polygonal models and adding haptic interaction to virtual environments. The underlying collision system computes local extrema in distance between the model controlled by the haptic device and the rest of the scene. The haptic rendering computes forces and torques on the moving model based on these local extrema. The system is demonstrated on models with tens of thousands of triangles and developed in an accessibility application for finding collision-free paths.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512017]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.106]]></doi>

<publicationId><![CDATA[1512017]]></publicationId>

<partnum><![CDATA[1512017]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512017&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512017]]></pdf>

</document>

<document>

<rank>56</rank>

<title><![CDATA[Fast projection-based ray-casting algorithm for rendering curvilinear volumes]]></title>

<authors><![CDATA[Lichan Hong;  Kaufman, A.E.]]></authors>

<affiliations><![CDATA[Dept. of Software Production Res., AT&T Bell Labs., Naperville, IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aerodynamics]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Robustness]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[322]]></spage>

<epage><![CDATA[332]]></epage>

<abstract><![CDATA[We present an efficient and robust ray-casting algorithm for directly rendering a curvilinear volume of arbitrarily-shaped cells. By projecting cell-faces onto the image plane, we have effectively addressed three critical steps of the ray-casting process, namely finding the entry cell-faces for a ray, traversing along the ray from one cell to another, and reconstructing data values at the ray/cell-face intersections. Our algorithm significantly reduces rendering time, alleviates memory space consumption, and overcomes the conventional limitation requiring cells to be convex. Application of this algorithm to several commonly used curvilinear data sets has produced a favorable performance when compared with recently reported algorithms]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[817349]]></arnumber>

<doi><![CDATA[10.1109/2945.817349]]></doi>

<publicationId><![CDATA[817349]]></publicationId>

<partnum><![CDATA[817349]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=817349&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=817349]]></pdf>

</document>

<document>

<rank>57</rank>

<title><![CDATA[Listener-based Analysis of Surface Importance for Acoustic Metrics]]></title>

<authors><![CDATA[Michel, F.;  Deines, E.;  Hering-Bertram, M.;  Garth, C.;  Hagen, H.]]></authors>

<affiliations><![CDATA[IRTG Kaiserslautern, Kaiserslautern]]></affiliations>

<controlledterms>

<term><![CDATA[architectural acoustics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[transient response]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Absorption]]></term>

<term><![CDATA[Acoustic applications]]></term>

<term><![CDATA[Acoustic measurements]]></term>

<term><![CDATA[Acoustic reflection]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Optical surface waves]]></term>

<term><![CDATA[Phonons]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1680]]></spage>

<epage><![CDATA[1687]]></epage>

<abstract><![CDATA[Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D<sub>50</sub>) and clarity (C<sub>50</sub>) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C<sub>50</sub>) values at listener positions throughout the room.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376202]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70575]]></doi>

<publicationId><![CDATA[4376202]]></publicationId>

<partnum><![CDATA[4376202]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376202&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376202]]></pdf>

</document>

<document>

<rank>58</rank>

<title><![CDATA[Steering Committees]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[xvii]]></spage>

<epage><![CDATA[xvii]]></epage>

<abstract><![CDATA[Provides a listing of current committee members.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327300]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.266]]></doi>

<publicationId><![CDATA[6327300]]></publicationId>

<partnum><![CDATA[6327300]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327300&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327300]]></pdf>

</document>

<document>

<rank>59</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on ACM VRST]]></title>

<authors><![CDATA[Lau, R.W.H.;  Seidel, H.-P.]]></authors>

<affiliations><![CDATA[IEEE]]></affiliations>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Context modeling]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Electrostatics]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hair]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Liquid crystal displays]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[129]]></spage>

<epage><![CDATA[130]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1580447]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.31]]></doi>

<publicationId><![CDATA[1580447]]></publicationId>

<partnum><![CDATA[1580447]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580447&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580447]]></pdf>

</document>

<document>

<rank>60</rank>

<title><![CDATA[Expressive Facial Animation Synthesis by Learning Speech Coarticulation and Expression Spaces]]></title>

<authors><![CDATA[Zhigang Deng;  Neumann, U.;  Lewis, J.P.;  Kim, T.-Y.;  Bulut, M.;  Narayanan, S.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Houston Univ., TX]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[emotion recognition]]></term>

<term><![CDATA[face recognition]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[motion estimation]]></term>

<term><![CDATA[speech processing]]></term>

<term><![CDATA[speech synthesis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Concatenated codes]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Facial animation]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Motion analysis]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Signal processing]]></term>

<term><![CDATA[Signal synthesis]]></term>

<term><![CDATA[Speech synthesis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1523]]></spage>

<epage><![CDATA[1534]]></epage>

<abstract><![CDATA[Synthesizing expressive facial animation is a very challenging topic within the graphics community. In this paper, we present an expressive facial animation synthesis system enabled by automated learning from facial motion capture data. Accurate 3D motions of the markers on the face of a human subject are captured while he/she recites a predesigned corpus, with specific spoken and visual expressions. We present a novel motion capture mining technique that "learns" speech coarticulation models for diphones and triphones from the recorded data. A phoneme-independent expression eigenspace (PIEES) that encloses the dynamic expression signals is constructed by motion signal processing (phoneme-based time-warping and subtraction) and principal component analysis (PCA) reduction. New expressive facial animations are synthesized as follows: First, the learned coarticulation models are concatenated to synthesize neutral visual speech according to novel speech input, then a texture-synthesis-based approach is used to generate a novel dynamic expression signal from the PIEES model, and finally the synthesized expression signal is blended with the synthesized neutral visual speech to create the final expressive facial animation. Our experiments demonstrate that the system can effectively synthesize realistic expressive facial animation]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1703372]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.90]]></doi>

<publicationId><![CDATA[1703372]]></publicationId>

<partnum><![CDATA[1703372]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1703372&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703372]]></pdf>

</document>

<document>

<rank>61</rank>

<title><![CDATA[Large-Scale Overlays and Trends: Visually Mining, Panning and Zoomingthe Observable Universe]]></title>

<authors><![CDATA[Luciani, T.B.;  Cherinka, B.;  Oliphant, D.;  Myers, S.;  Wood-Vasey, W.M.;  Labrinidis, A.;  Marai, G.E.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Pittsburgh, Pittsburgh, PA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[astronomical image processing]]></term>

<term><![CDATA[astronomical surveys]]></term>

<term><![CDATA[client-server systems]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Astronomy]]></term>

<term><![CDATA[Catalogs]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed databases]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Servers]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1048]]></spage>

<epage><![CDATA[1061]]></epage>

<abstract><![CDATA[We introduce a web-based computing infrastructure to assist the visual integration, mining and interactive navigation of large-scale astronomy observations. Following an analysis of the application domain, we design a client-server architecture to fetch distributed image data and to partition local data into a spatial index structure that allows prefix-matching of spatial objects. In conjunction with hardware-accelerated pixel-based overlays and an online cross-registration pipeline, this approach allows the fetching, displaying, panning and zooming of gigabit panoramas of the sky in real time. To further facilitate the integration and mining of spatial and non-spatial data, we introduce interactive trend images-compact visual representations for identifying outlier objects and for studying trends within large collections of spatial objects of a given class. In a demonstration, images from three sky surveys (SDSS, FIRST and simulated LSST results) are cross-registered and integrated as overlays, allowing cross-spectrum analysis of astronomy observations. Trend images are interactively generated from catalog data and used to visually mine astronomy observations of similar type. The front-end of the infrastructure uses the web technologies WebGL and HTML5 to enable cross-platform, web-based functionality. Our approach attains interactive rendering framerates; its power and flexibility enables it to serve the needs of the astronomy community. Evaluation on three case studies, as well as feedback from domain experts emphasize the benefits of this visual approach to the observational astronomy field; and its potential benefits to large scale geospatial visualization in general.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6767150]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2312008]]></doi>

<publicationId><![CDATA[6767150]]></publicationId>

<partnum><![CDATA[6767150]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6767150&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6767150]]></pdf>

</document>

<document>

<rank>62</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5714211]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.42]]></doi>

<publicationId><![CDATA[5714211]]></publicationId>

<partnum><![CDATA[5714211]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5714211&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714211]]></pdf>

</document>

<document>

<rank>63</rank>

<title><![CDATA[Conveying the 3D shape of smoothly curving transparent surfaces via texture]]></title>

<authors><![CDATA[Interrante, V.;  Fuchs, H.;  Pizer, S.M.]]></authors>

<affiliations><![CDATA[Inst. for Comput. Appl. in Sci. & Eng., Hampton, VA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[mathematical morphology]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[radiation therapy]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transparency]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical applications of radiation]]></term>

<term><![CDATA[Cancer]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optical refraction]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Shape measurement]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[98]]></spage>

<epage><![CDATA[117]]></epage>

<abstract><![CDATA[Transparency can be a useful device for depicting multiple overlapping surfaces in a single image. The challenge is to render the transparent surfaces in such a way that their 3D shape can be readily understood and their depth distance from underlying structures clearly perceived. This paper describes our investigations into the use of sparsely-distributed discrete, opaque texture as an artistic device for more explicitly indicating the relative depth of a transparent surface and for communicating the essential features of its 3D shape in an intuitively meaningful and minimally occluding way. The driving application for this work is the visualization of layered surfaces in radiation therapy treatment planning data, and the technique is illustrated on transparent isointensity surfaces of radiation dose. We describe the perceptual motivation and artistic inspiration for defining a stroke texture that is locally oriented in the direction of greatest normal curvature (and in which individual strokes are of a length proportional to the magnitude of the curvature in the direction they indicate), and we discuss two alternative methods for applying this texture to isointensity surfaces defined in a volume. We propose an experimental paradigm for objectively measuring observers' ability to judge the shape and depth of a layered transparent surface, in the course of a task which is relevant to the needs of radiotherapy treatment planning, and use this paradigm to evaluate the practical effectiveness of our approach through a controlled observer experiment based on images generated from actual clinical data]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[597794]]></arnumber>

<doi><![CDATA[10.1109/2945.597794]]></doi>

<publicationId><![CDATA[597794]]></publicationId>

<partnum><![CDATA[597794]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=597794&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=597794]]></pdf>

</document>

<document>

<rank>64</rank>

<title><![CDATA[TanGeoMS: Tangible Geospatial Modeling System]]></title>

<authors><![CDATA[Tateosian, L.;  Mitasova, H.;  Harmon, B.;  Fogleman, B.;  Weaver, K.;  Harmon, R.]]></authors>

<affiliations><![CDATA[North Carolina State Univ., Raleigh, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[terrain mapping]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Geospatial analysis]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Surface topography]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1605]]></spage>

<epage><![CDATA[1612]]></epage>

<abstract><![CDATA[We present TanGeoMS, a tangible geospatial modeling visualization system that couples a laser scanner, projector, and a flexible physical three-dimensional model with a standard geospatial information system (GIS) to create a tangible user interface for terrain data. TanGeoMS projects an image of real-world data onto a physical terrain model. Users can alter the topography of the model by modifying the clay surface or placing additional objects on the surface. The modified model is captured by an overhead laser scanner then imported into a GIS for analysis and simulation of real-world processes. The results are projected back onto the surface of the model providing feedback on the impact of the modifications on terrain parameters and simulated processes. Interaction with a physical model is highly intuitive, allowing users to base initial design decisions on geospatial data, test the impact of these decisions in GIS simulations, and use the feedback to improve their design. We demonstrate the system on three applications: investigating runoff management within a watershed, assessing the impact of storm surge on barrier islands, and exploring landscape rehabilitation in military training areas.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613503]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.202]]></doi>

<publicationId><![CDATA[5613503]]></publicationId>

<partnum><![CDATA[5613503]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613503&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613503]]></pdf>

</document>

<document>

<rank>65</rank>

<title><![CDATA[Multi-field Pattern Matching based on Sparse Feature Sampling]]></title>

<authors><![CDATA[Zhongjie Wang;  Seidel, H.-P.;  Weinkauf, T.]]></authors>

<affiliations><![CDATA[MPI for Inf., Saarbrucken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[numerical analysis]]></term>

<term><![CDATA[pattern matching]]></term>

<term><![CDATA[transforms]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Jacobian matrices]]></term>

<term><![CDATA[Pattern matching]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[807]]></spage>

<epage><![CDATA[816]]></epage>

<abstract><![CDATA[We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192721]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467292]]></doi>

<publicationId><![CDATA[7192721]]></publicationId>

<partnum><![CDATA[7192721]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192721&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192721]]></pdf>

</document>

<document>

<rank>66</rank>

<title><![CDATA[Metamorphosis of 3D polyhedral models using progressive connectivity transformations]]></title>

<authors><![CDATA[Chao-Hung Lin;  Tong-Yee Lee]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[image morphing]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Chaos]]></term>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Facial animation]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Merging]]></term>

<term><![CDATA[Processor scheduling]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[2]]></spage>

<epage><![CDATA[12]]></epage>

<abstract><![CDATA[Three-dimensional (3D) metamorphosis is a powerful technique to produce a 3D shape transformation between two or more existing models. We propose a novel 3D morphing technique that avoids creating a merged embedding that contains the faces, edges, and vertices of two given embeddings. This novel 3D morphing technique dynamically adds or removes vertices to gradually transform the connectivity of 3D polyhedrons from a source model into a target model and simultaneously creates the intermediate shapes. In addition, a priority control function provides the animators with control of arising or dissolving of input models' features in a morphing sequence. This is a useful tool to control a morphing sequence more easily and flexibly. Several examples of aesthetically pleasing morphs are demonstrated using the proposed method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1359727]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.12]]></doi>

<publicationId><![CDATA[1359727]]></publicationId>

<partnum><![CDATA[1359727]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359727&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359727]]></pdf>

</document>

<document>

<rank>67</rank>

<title><![CDATA[Efficient Optimization of Common Base Domains for Cross Parameterization]]></title>

<authors><![CDATA[Kwok, Tsz-Ho;  Zhang, Yunbo;  Wang, Charlie C.L.]]></authors>

<affiliations><![CDATA[The Chinese University of Hong Kong, Hong Kong]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1678]]></spage>

<epage><![CDATA[1692]]></epage>

<abstract><![CDATA[Given a set of corresponding user-specified anchor points on a pair of models having similar features and topologies, the cross parameterization technique can establish a bijective mapping constrained by the anchor points. In this paper, we present an efficient algorithm to optimize the complexes and the shape of common base domains in cross parameterization for reducing the distortion of the bijective mapping. The optimization is also constrained by the anchor points. We investigate a new signature, Length-Preserved Base Domain (LPBD), for measuring the level of stretch between surface patches in cross parameterization. This new signature well balances the accuracy of measurement and the computational speed. Based on LPBD, a set of metrics are studied and compared. The best ones are employed in our domain optimization algorithm that consists of two major operators, boundary swapping and patch merging. Experimental results show that our optimization algorithm can reduce the distortion in cross parameterization efficiently.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5928341]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.115]]></doi>

<publicationId><![CDATA[5928341]]></publicationId>

<partnum><![CDATA[5928341]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5928341&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928341]]></pdf>

</document>

<document>

<rank>68</rank>

<title><![CDATA[Texture-based Transfer Functions for Direct Volume Rendering]]></title>

<authors><![CDATA[Caban, J.J.;  Rheingans, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Maryland Univ., College Park, MD]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[image classification]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Lungs]]></term>

<term><![CDATA[Probes]]></term>

<term><![CDATA[Statistical analysis]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Visual system]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1364]]></spage>

<epage><![CDATA[1371]]></epage>

<abstract><![CDATA[Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658151]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.169]]></doi>

<publicationId><![CDATA[4658151]]></publicationId>

<partnum><![CDATA[4658151]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658151&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658151]]></pdf>

</document>

<document>

<rank>69</rank>

<title><![CDATA[Conjunctive Visual Forms]]></title>

<authors><![CDATA[Weaver, C.]]></authors>

<affiliations><![CDATA[Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[query processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Boolean functions]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Instruments]]></term>

<term><![CDATA[Intelligent sensors]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[929]]></spage>

<epage><![CDATA[936]]></epage>

<abstract><![CDATA[Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290696]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.129]]></doi>

<publicationId><![CDATA[5290696]]></publicationId>

<partnum><![CDATA[5290696]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290696&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290696]]></pdf>

</document>

<document>

<rank>70</rank>

<title><![CDATA[Join the IEEE Computer Society today! [advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[723]]></spage>

<epage><![CDATA[723]]></epage>

<abstract><![CDATA[Advertisement: Join the IEEE Computer Society.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4472709]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.47]]></doi>

<publicationId><![CDATA[4472709]]></publicationId>

<partnum><![CDATA[4472709]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4472709&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4472709]]></pdf>

</document>

<document>

<rank>71</rank>

<title><![CDATA[<italic>VEEVVIE:</italic> Visual Explorer for Empirical Visualization, VR and Interaction Experiments]]></title>

<authors><![CDATA[Papadopoulos, C.;  Gutenko, I.;  Kaufman, A.E.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[ontologies (artificial intelligence)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atmospheric measurements]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Human computer interaction]]></term>

<term><![CDATA[Ontologies]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Statistical analysis]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[111]]></spage>

<epage><![CDATA[120]]></epage>

<abstract><![CDATA[Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192692]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467954]]></doi>

<publicationId><![CDATA[7192692]]></publicationId>

<partnum><![CDATA[7192692]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192692&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192692]]></pdf>

</document>

<document>

<rank>72</rank>

<title><![CDATA[Fusing Multiview and Photometric Stereo for 3D Reconstruction under Uncalibrated Illumination]]></title>

<authors><![CDATA[Chenglei Wu;  Yebin Liu;  Qionghai Dai;  Wilburn, B.]]></authors>

<affiliations><![CDATA[Dept. of Autom., Tsinghua Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[stereo image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Harmonic analysis]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1082]]></spage>

<epage><![CDATA[1095]]></epage>

<abstract><![CDATA[We propose a method to obtain a complete and accurate 3D model from multiview images captured under a variety of unknown illuminations. Based on recent results showing that for Lambertian objects, general illumination can be approximated well using low-order spherical harmonics, we develop a robust alternating approach to recover surface normals. Surface normals are initialized using a multi-illumination multiview stereo algorithm, then refined using a robust alternating optimization method based on the &#x2113;<sub>1</sub> metric. Erroneous normal estimates are detected using a shape prior. Finally, the computed normals are used to improve the preliminary 3D model. The reconstruction system achieves watertight and robust 3D reconstruction while neither requiring manual interactions nor imposing any constraints on the illumination. Experimental results on both real world and synthetic data show that the technique can acquire accurate 3D models for Lambertian surfaces, and even tolerates small violations of the Lambertian assumption.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5611506]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.224]]></doi>

<publicationId><![CDATA[5611506]]></publicationId>

<partnum><![CDATA[5611506]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5611506&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611506]]></pdf>

</document>

<document>

<rank>73</rank>

<title><![CDATA[Guidelines for Effective Usage of Text Highlighting Techniques]]></title>

<authors><![CDATA[Strobelt, H.;  Oelke, D.;  Bum Chul Kwon;  Schreck, T.;  Pfister, H.]]></authors>

<controlledterms>

<term><![CDATA[character sets]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Interference]]></term>

<term><![CDATA[Natural language processing]]></term>

<term><![CDATA[Text analysis]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[489]]></spage>

<epage><![CDATA[498]]></epage>

<abstract><![CDATA[Semi-automatic text analysis involves manual inspection of text. Often, different text annotations (like part-of-speech or named entities) are indicated by using distinctive text highlighting techniques. In typesetting there exist well-known formatting conventions, such as bold typeface, italics, or background coloring, that are useful for highlighting certain parts of a given text. Also, many advanced techniques for visualization and highlighting of text exist; yet, standard typesetting is common, and the effects of standard typesetting on the perception of text are not fully understood. As such, we surveyed and tested the effectiveness of common text highlighting techniques, both individually and in combination, to discover how to maximize pop-out effects while minimizing visual interference between techniques. To validate our findings, we conducted a series of crowd-sourced experiments to determine: i) a ranking of nine commonly-used text highlighting techniques; ii) the degree of visual interference between pairs of text highlighting techniques; iii) the effectiveness of techniques for visual conjunctive search. Our results show that increasing font size works best as a single highlighting technique, and that there are significant visual interferences between some pairs of highlighting techniques. We discuss the pros and cons of different combinations as a design guideline to choose text highlighting techniques for text viewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192718]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467759]]></doi>

<publicationId><![CDATA[7192718]]></publicationId>

<partnum><![CDATA[7192718]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192718&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192718]]></pdf>

</document>

<document>

<rank>74</rank>

<title><![CDATA[Visualizing Social Photos on a Hasse Diagram for Eliciting Relations and Indexing New Photos]]></title>

<authors><![CDATA[Crampes, M.;  de Oliveira-Kumar, J.;  Ranwez, S.;  Villerd, J.]]></authors>

<affiliations><![CDATA[LGI2P/EMA Res. Center, France]]></affiliations>

<controlledterms>

<term><![CDATA[Galois fields]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[indexing]]></term>

<term><![CDATA[social networking (online)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Digital cameras]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Facebook]]></term>

<term><![CDATA[Indexing]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Tagging]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[985]]></spage>

<epage><![CDATA[992]]></epage>

<abstract><![CDATA[Social photos, which are taken during family events or parties, represent individuals or groups of people. We show in this paper how a Hasse diagram is an efficient visualization strategy for eliciting different groups and navigating through them. However, we do not limit this strategy to these traditional uses. Instead we show how it can also be used for assisting in indexing new photos. Indexing consists of identifying the event and people in photos. It is an integral phase that takes place before searching and sharing. In our method we use existing indexed photos to index new photos. This is performed through a manual drag and drop procedure followed by a content fusion process that we call 'propagation'. At the core of this process is the necessity to organize and visualize the photos that will be used for indexing in a manner that is easily recognizable and accessible by the user. In this respect we make use of an object Galois sub-hierarchy and display it using a Hasse diagram. The need for an incremental display that maintains the user's mental map also leads us to propose a novel way of building the Hasse diagram. To validate the approach, we present some tests conducted with a sample of users that confirm the interest of this organization, visualization and indexation approach. Finally, we conclude by considering scalability, the possibility to extract social networks and automatically create personalised albums.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290703]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.201]]></doi>

<publicationId><![CDATA[5290703]]></publicationId>

<partnum><![CDATA[5290703]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290703&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290703]]></pdf>

</document>

<document>

<rank>75</rank>

<title><![CDATA[Motion Effects Synthesis for 4D Films]]></title>

<authors><![CDATA[Lee, J.;  Han, B.;  Choi, S.]]></authors>

<affiliations><![CDATA[Jaebong Lee is with the Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), 77 Cheongam-ro. Nam-gu. Pohang. Gyeongbuk, Korea.(Email: novaever@postech.ac.kr)]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[4D film is an immersive entertainment system that presents various physical effects with a film in order to enhance viewers&#x2019; experiences. Despite the recent emergence of 4D theaters, production of 4D effects relies on manual authoring. In this paper, we present algorithms that synthesize three classes of motion effects from the audiovisual content of a film. The first class of motion effects is those responding to fast camera motion to enhance the immersiveness of point-of-view shots, delivering fast and dynamic vestibular feedback. The second class moves viewers as closely as possible to the trajectory of slowly moving camera. Such motion provides an illusional effect of observing the scene from a distance while moving slowly within the scene. For these two classes, our algorithms compute the relative camera motion and then map it to a motion command to the 4D chair using appropriate motion mapping algorithms. The last class is for special effects, such as explosions, and our algorithm uses sound for the synthesis of impulses and vibrations. We assessed the subjective quality of our algorithms by user experiments, and results indicated that our algorithms can provide compelling motion effects.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7352357]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2507591]]></doi>

<publicationId><![CDATA[7352357]]></publicationId>

<partnum><![CDATA[7352357]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7352357&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352357]]></pdf>

</document>

<document>

<rank>76</rank>

<title><![CDATA[Cover2]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6168455]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.82]]></doi>

<publicationId><![CDATA[6168455]]></publicationId>

<partnum><![CDATA[6168455]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6168455&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168455]]></pdf>

</document>

<document>

<rank>77</rank>

<title><![CDATA[Voronoi-Based Extraction and Visualization of Molecular Paths]]></title>

<authors><![CDATA[Lindow, N.;  Baum, D.;  Hege, H.-C.]]></authors>

<affiliations><![CDATA[Zuse Inst. Berlin, Berlin, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[information filtering]]></term>

<term><![CDATA[inspection]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[molecular biophysics]]></term>

<term><![CDATA[skin]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atomic measurements]]></term>

<term><![CDATA[Cavity resonators]]></term>

<term><![CDATA[Filtering theory]]></term>

<term><![CDATA[Logic gates]]></term>

<term><![CDATA[Molecular computing]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2025]]></spage>

<epage><![CDATA[2034]]></epage>

<abstract><![CDATA[Visual analysis is widely used to study the behavior of molecules. Of particular interest are the analysis of molecular interactions and the investigation of binding sites. For large molecules, however, it is difficult to detect possible binding sites and paths leading to these sites by pure visual inspection. In this paper, we present new methods for the computation and visualization of potential molecular paths. Using a novel filtering method, we extract the significant paths from the Voronoi diagram of spheres. For the interactive visualization of molecules and their paths, we present several methods using deferred shading and other state-of-theart techniques. To allow for a fast overview of reachable regions of the molecule, we illuminate the molecular surface using a large number of light sources placed on the extracted paths. We also provide a method to compute the extension surface of selected paths and visualize it using the skin surface. Furthermore, we use the extension surface to clip the molecule to allow easy visual tracking of even deeply buried paths. The methods are applied to several proteins to demonstrate their usefulness.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6064966]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.259]]></doi>

<publicationId><![CDATA[6064966]]></publicationId>

<partnum><![CDATA[6064966]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064966&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064966]]></pdf>

</document>

<document>

<rank>78</rank>

<title><![CDATA[Decorating surfaces with bidirectional texture functions]]></title>

<authors><![CDATA[Kun Zhou;  Peng Du;  Lifeng Wang;  Matsushita, Y.;  Jiaoying Shi;  Baining Guo;  Heung-Yeung Shum]]></authors>

<affiliations><![CDATA[Microsoft Res. Asia, Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[painting]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Painting]]></term>

<term><![CDATA[Paints]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Reflectivity]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Surface cracks]]></term>

<term><![CDATA[Surface fitting]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[519]]></spage>

<epage><![CDATA[528]]></epage>

<abstract><![CDATA[We present a system for decorating arbitrary surfaces with bidirectional texture functions (BTF). Our system generates BTFs in two steps. First, we automatically synthesize a BTF over the target surface from a given BTF sample. Then, we let the user interactively paint BTF patches onto the surface such that the painted patches seamlessly integrate with the background patterns. Our system is based on a patch-based texture synthesis approach known as quilting. We present a graphcut algorithm for BTF synthesis on surfaces and the algorithm works well for a wide variety of BTF samples, including those which present problems for existing algorithms. We also describe a graphcut texture painting algorithm for creating new surface imperfections (e.g., dirt, cracks, scratches) from existing imperfections found in input BTF samples. Using these algorithms, we can decorate surfaces with real-world textures that have spatially-variant reflectance, fine-scale geometry details, and surfaces imperfections. A particularly attractive feature of BTF painting is that it allows us to capture imperfections of real materials and paint them onto geometry models. We demonstrate the effectiveness of our system with examples.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1471689]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.78]]></doi>

<publicationId><![CDATA[1471689]]></publicationId>

<partnum><![CDATA[1471689]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1471689&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471689]]></pdf>

</document>

<document>

<rank>79</rank>

<title><![CDATA[Fast and Efficient Compression of Floating-Point Data]]></title>

<authors><![CDATA[Lindstrom, P.;  Isenburg, M.]]></authors>

<affiliations><![CDATA[Lawrence Livermore Nat. Lab., Berkeley, CA]]></affiliations>

<controlledterms>

<term><![CDATA[data compression]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[floating point arithmetic]]></term>

<term><![CDATA[mathematics computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Bandwidth]]></term>

<term><![CDATA[Data compression]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Entropy]]></term>

<term><![CDATA[File systems]]></term>

<term><![CDATA[Image coding]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Throughput]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1245]]></spage>

<epage><![CDATA[1250]]></epage>

<abstract><![CDATA[Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015488]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.143]]></doi>

<publicationId><![CDATA[4015488]]></publicationId>

<partnum><![CDATA[4015488]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015488&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015488]]></pdf>

</document>

<document>

<rank>80</rank>

<title><![CDATA[A Metric for the Evaluation of Dense Vector Field Visualizations]]></title>

<authors><![CDATA[Matvienko, V.;  Kruger, J.]]></authors>

<affiliations><![CDATA[IVDA group, Saarland Univ. Cluster of Excellence MMCI, Saarbrucken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Vectors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1122]]></spage>

<epage><![CDATA[1132]]></epage>

<abstract><![CDATA[In this work, we present an intuitive image-quality metric that is derived from the motivation of DVF visualization. It utilizes the features of the resulting image and effectively measures the similarity between the output of the visualization method and the input flow data. We use the angle between the gradient direction and the original vector field as a measure of such similarity and the gradient magnitude as an importance measure. Our metric enables the automatic evaluation of images for a given vector field and allows the comparison of different methods, parameters sets, and quality improvement strategies for a specific vector field. By integrating the metric into the image-computation process, our approach can be used to generate improved images by choosing the best parameter set. To verify the effectiveness of our method, we conducted an extensive user study that demonstrated the metric's applicability to various situations. For instance, our approach elucidated the robustness of a DVF visualization in the presence of data-altering filters, such as resampling.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6269874]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.170]]></doi>

<publicationId><![CDATA[6269874]]></publicationId>

<partnum><![CDATA[6269874]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6269874&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269874]]></pdf>

</document>

<document>

<rank>81</rank>

<title><![CDATA[Graphical Perception of Multiple Time Series]]></title>

<authors><![CDATA[Javed, W.;  McDonnel, B.;  Elmqvist, N.]]></authors>

<affiliations><![CDATA[Purdue Univ. in West Lafayette, West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphs]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clutter]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Time series analysis]]></term>

<term><![CDATA[Training]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[927]]></spage>

<epage><![CDATA[934]]></epage>

<abstract><![CDATA[Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613429]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.162]]></doi>

<publicationId><![CDATA[5613429]]></publicationId>

<partnum><![CDATA[5613429]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613429&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613429]]></pdf>

</document>

<document>

<rank>82</rank>

<title><![CDATA[Real-Time Volume-Based Ambient Occlusion]]></title>

<authors><![CDATA[Papaioannou, G.;  Menexi, M.L.;  Papadopoulos, C.]]></authors>

<affiliations><![CDATA[Dept. of Inf., Athens Univ. of Econ. & Bus., Athens, Greece]]></affiliations>

<controlledterms>

<term><![CDATA[hidden feature removal]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sampling methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Buffer storage]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Optical attenuators]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Shadow mapping]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[752]]></spage>

<epage><![CDATA[762]]></epage>

<abstract><![CDATA[Real-time rendering can benefit from global illumination methods to make the 3D environments look more convincing and lifelike. On the other hand, the conventional global illumination algorithms for the estimation of the diffuse surface interreflection make heavy usage of intra- and interobject visibility calculations, so they are time-consuming, and using them in real-time graphics applications can be prohibitive for complex scenes. Modern illumination approximations, such as ambient occlusion variants, use precalculated or frame-dependent data to reduce the problem to a local shading one. This paper presents a fast real-time method for visibility sampling using volumetric data in order to produce accurate inter- and intraobject ambient occlusion. The proposed volume sampling technique disassociates surface representation data from the visibility calculations, and therefore, makes the method suitable for both primitive-order or screen-order rendering, such as deferred rendering. The sampling mechanism can be used in any application that performs visibility queries or ray marching.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5383355]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.18]]></doi>

<publicationId><![CDATA[5383355]]></publicationId>

<partnum><![CDATA[5383355]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5383355&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383355]]></pdf>

</document>

<document>

<rank>83</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1512028]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.95]]></doi>

<publicationId><![CDATA[1512028]]></publicationId>

<partnum><![CDATA[1512028]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512028&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512028]]></pdf>

</document>

<document>

<rank>84</rank>

<title><![CDATA[Structural Modeling from Depth Images]]></title>

<authors><![CDATA[Thanh Nguyen;  Reitmayr, G.;  Schmalstieg, D.]]></authors>

<affiliations><![CDATA[Graz Univ. of Technol., Graz, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[SLAM (robots)]]></term>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Simultaneous localization and mapping]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1230]]></spage>

<epage><![CDATA[1240]]></epage>

<abstract><![CDATA[In this work, we present a new automatic system for scene reconstruction of high-level structural models. We start with identifying planar regions in depth images obtained with a SLAM system. Our main contribution is an approach which identifies constraints such as incidence and orthogonality of planar surfaces and uses them in an incremental optimization framework to extract high-level structural models. The result is a manifold mesh with a low number of polygons, immediately useful in many Augmented Reality applications such as inspection, interior design or spatial interaction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7165661]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2459831]]></doi>

<publicationId><![CDATA[7165661]]></publicationId>

<partnum><![CDATA[7165661]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7165661&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165661]]></pdf>

</document>

<document>

<rank>85</rank>

<title><![CDATA[Efficient Morse Decompositions of Vector Fields]]></title>

<authors><![CDATA[Guoning Chen;  Mischaikow, K.;  Laramee, R.S.;  Zhang, E.]]></authors>

<affiliations><![CDATA[Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[directed graphs]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[848]]></spage>

<epage><![CDATA[862]]></epage>

<abstract><![CDATA[Existing topology-based vector field analysis techniques rely on the ability to extract the individual trajectories such as fixed points, periodic orbits, and separatrices that are sensitive to noise and errors introduced by simulation and interpolation. This can make such vector field analysis unsuitable for rigorous interpretations. We advocate the use of Morse decompositions, which are robust with respect to perturbations, to encode the topological structures of a vector field in the form of a directed graph, called a Morse connection graph (MCG). While an MCG exists for every vector field, it need not be unique. Previous techniques for computing MCGs, while fast, are overly conservative and usually result in MCGs that are too coarse to be useful for the applications. To address this issue, we present a new technique for performing Morse decomposition based on the concept of tau-maps, which typically provides finer MCGs than existing techniques. Furthermore, the choice of tau provides a natural trade-off between the fineness of the MCGs and the computational costs. We provide efficient implementations of Morse decomposition based on tau-maps, which include the use of forward and backward mapping techniques and an adaptive approach in constructing better approximations of the images of the triangles in the meshes used for simulation. Furthermore, we propose the use of spatial tau-maps in addition to the original temporal tau-maps. These techniques provide additional trade-offs between the quality of the MCGs and the speed of computation. We demonstrate the utility of our technique with various examples in the plane and on surfaces including engine simulation data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4447667]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.33]]></doi>

<publicationId><![CDATA[4447667]]></publicationId>

<partnum><![CDATA[4447667]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4447667&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4447667]]></pdf>

</document>

<document>

<rank>86</rank>

<title><![CDATA[MGV: a system for visualizing massive multidigraphs]]></title>

<authors><![CDATA[Abello, J.;  Korn, J.]]></authors>

<affiliations><![CDATA[Shannon Labs., AT&T Labs-Research, Florham Park, NJ, USA]]></affiliations>

<controlledterms>

<term><![CDATA[client-server systems]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[directed graphs]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[tree data structures]]></term>

<term><![CDATA[tree searching]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Automatic control]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Plugs]]></term>

<term><![CDATA[Random access memory]]></term>

<term><![CDATA[Read-write memory]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Two dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[21]]></spage>

<epage><![CDATA[38]]></epage>

<abstract><![CDATA[Describes MGV (Massive Graph Visualizer), an integrated visualization and exploration system for massive multidigraph navigation. It adheres to the visual information-seeking mantra: overview first, zoom and filter, then details on demand. MGV's only assumption is that the vertex set of the underlying digraph corresponds to the set of leaves of a pre-determined tree T. MGV builds an out-of-core graph hierarchy and provides mechanisms to plug in arbitrary visual representations for each graph hierarchy slice. Navigation from one level to another of the hierarchy corresponds to the implementation of a drill-down interface. In order to provide the user with navigation control and interactive response, MGV incorporates a number of visualization techniques like interactive pixel-oriented 2D and 3D maps, statistical displays, color maps, multi-linked views and a zoomable label-based interface. This makes the association of geographic information and graph data very natural. To automate the creation of the vertex set hierarchy for MGV, we use the notion of graph sketches. They can be thought of as visual indices that guide the navigation of a multigraph too large to fit on the available display. MGV follows the client-server paradigm and it is implemented in C and Java-3D. We highlight the main algorithmic and visualization techniques behind the tools and, along the way, point out several possible application scenarios. Our techniques are being applied to multigraphs defined on vertex sets with sizes ranging from 100 million to 250 million vertices]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[981849]]></arnumber>

<doi><![CDATA[10.1109/2945.981849]]></doi>

<publicationId><![CDATA[981849]]></publicationId>

<partnum><![CDATA[981849]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=981849&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981849]]></pdf>

</document>

<document>

<rank>87</rank>

<title><![CDATA[Table of Contents]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[iii]]></spage>

<epage><![CDATA[iv]]></epage>

<abstract><![CDATA[Presents the table of contents from this conference.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7283719]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2472735]]></doi>

<publicationId><![CDATA[7283719]]></publicationId>

<partnum><![CDATA[7283719]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7283719&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7283719]]></pdf>

</document>

<document>

<rank>88</rank>

<title><![CDATA[Communicating centrality in policy network drawings]]></title>

<authors><![CDATA[Brandes, U.;  Kenis, P.;  Wagner, D.]]></authors>

<affiliations><![CDATA[Dept. of Math. & Comput. Sci., Passau Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphs]]></term>

<term><![CDATA[social sciences computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Drugs]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Instruments]]></term>

<term><![CDATA[Intelligent networks]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Public policy]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[241]]></spage>

<epage><![CDATA[253]]></epage>

<abstract><![CDATA[We introduce a network visualization technique that supports an analytical method applied in the social sciences. Policy network analysis is an approach to study policy making structures, processes, and outcomes, thereby concentrating on relations between policy actors. An important operational concept for the analysis of policy networks is the notion of centrality, i.e., the distinction of actors according to their importance in a relational structure. We integrate this measure in a layout model for networks by mapping structural to geometric centrality. Thus, centrality values and network data can be presented simultaneously and explored interactively.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1196010]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1196010]]></doi>

<publicationId><![CDATA[1196010]]></publicationId>

<partnum><![CDATA[1196010]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1196010&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196010]]></pdf>

</document>

<document>

<rank>89</rank>

<title><![CDATA[VisDock: A Toolkit for Cross-Cutting Interactions in Visualization]]></title>

<authors><![CDATA[Jungu Choi;  Deok Gun Park;  Yuet Ling Wong;  Fisher, E.;  Elmqvist, N.]]></authors>

<affiliations><![CDATA[Dept. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[Java]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[navigation]]></term>

<term><![CDATA[public domain software]]></term>

<term><![CDATA[software libraries]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Containers]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Reactive power]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1087]]></spage>

<epage><![CDATA[1100]]></epage>

<abstract><![CDATA[Standard user applications provide a range of cross-cutting interaction techniques that are common to virtually all such tools: selection, filtering, navigation, layer management, and cut-and-paste. We present VisDock, a JavaScript mixin library that provides a core set of these cross-cutting interaction techniques for visualization, including selection (lasso, paths, shape selection, etc), layer management (visibility, transparency, set operations, etc), navigation (pan, zoom, overview, magnifying lenses, etc), and annotation (point-based, region-based, data-space based, etc). To showcase the utility of the library, we have released it as Open Source and integrated it with a large number of existing web-based visualizations. Furthermore, we have evaluated VisDock using qualitative studies with both developers utilizing the toolkit to build new web-based visualizations, as well as with end-users utilizing it to explore movie ratings data. Results from these studies highlight the usability and effectiveness of the toolkit from both developer and end-user perspectives.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7063249]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2414454]]></doi>

<publicationId><![CDATA[7063249]]></publicationId>

<partnum><![CDATA[7063249]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7063249&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7063249]]></pdf>

</document>

<document>

<rank>90</rank>

<title><![CDATA[Robust feature detection and local classification for surfaces based on moment analysis]]></title>

<authors><![CDATA[Clarenz, U.;  Rumpf, M.;  Telea, A.]]></authors>

<affiliations><![CDATA[Inst. for Math., Duisburg Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[edge detection]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image classification]]></term>

<term><![CDATA[method of moments]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Detectors]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image denoising]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[516]]></spage>

<epage><![CDATA[524]]></epage>

<abstract><![CDATA[The stable local classification of discrete surfaces with respect to features such as edges and corners or concave and convex regions, respectively, is as quite difficult as well as indispensable for many surface processing applications. Usually, the feature detection is done via a local curvature analysis. If concerned with large triangular and irregular grids, e.g., generated via a marching cube algorithm, the detectors are tedious to treat and a robust classification is hard to achieve. Here, a local classification method on surfaces is presented which avoids the evaluation of discretized curvature quantities. Moreover, it provides an indicator for smoothness of a given discrete surface and comes together with a built-in multiscale. The proposed classification tool is based on local zero and first moments on the discrete surface. The corresponding integral quantities are stable to compute and they give less noisy results compared to discrete curvature quantities. The stencil width for the integration of the moments turns out to be the scale parameter. Prospective surface processing applications are the segmentation on surfaces, surface comparison, and matching and surface modeling. Here, a method for feature preserving fairing of surfaces is discussed to underline the applicability of the presented approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1310277]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.34]]></doi>

<publicationId><![CDATA[1310277]]></publicationId>

<partnum><![CDATA[1310277]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310277&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310277]]></pdf>

</document>

<document>

<rank>91</rank>

<title><![CDATA[Visualization of High-Dimensional Point Clouds Using Their Density Distribution's Topology]]></title>

<authors><![CDATA[Oesterling, P.;  Heine, C.;  Janicke, H.;  Scheuermann, G.;  Heyer, G.]]></authors>

<affiliations><![CDATA[Inst. fur Inf., Univ. Leipzig, Leipzig, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[cloud computing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[statistical distributions]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Density functional theory]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Piecewise linear approximation]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1547]]></spage>

<epage><![CDATA[1559]]></epage>

<abstract><![CDATA[We present a novel method to visualize multidimensional point clouds. While conventional visualization techniques, like scatterplot matrices or parallel coordinates, have issues with either overplotting of entities or handling many dimensions, we abstract the data using topological methods before presenting it. We assume the input points to be samples of a random variable with a high-dimensional probability distribution which we approximate using kernel density estimates on a suitably reconstructed mesh. From the resulting scalar field we extract the join tree and present it as a topological landscape, a visualization metaphor that utilizes the human capability of understanding natural terrains. In this landscape, dense clusters of points show up as hills. The nesting of hills indicates the nesting of clusters. We augment the landscape with the data points to allow selection and inspection of single points and point sets. We also present optimizations to make our algorithm applicable to large data sets and to allow interactive adaption of our visualization to the kernel window width used in the density estimation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5708142]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.27]]></doi>

<publicationId><![CDATA[5708142]]></publicationId>

<partnum><![CDATA[5708142]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5708142&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708142]]></pdf>

</document>

<document>

<rank>92</rank>

<title><![CDATA[Multiscale Time Activity Data Exploration via Temporal Clustering Visualization Spreadsheet]]></title>

<authors><![CDATA[Woodring, J.;  Han-Wei Shen]]></authors>

<affiliations><![CDATA[395 Dreese Lab., Ohio State Univ., Columbus, OH]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Brushes]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Filter bank]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Temperature]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Wavelet coefficients]]></term>

<term><![CDATA[Wavelet transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[123]]></spage>

<epage><![CDATA[137]]></epage>

<abstract><![CDATA[Time-varying data is usually explored by animation or arrays of static images. Neither is particularly effective for classifying data by different temporal activities. Important temporal trends can be missed due to the lack of ability to find them with current visualization methods. In this paper, we propose a method to explore data at different temporal resolutions to discover and highlight data based upon time-varying trends. Using the wavelet transform along the time axis, we transform data points into multi-scale time series curve sets. The time curves are clustered so that data of similar activity are grouped together, at different temporal resolutions. The data are displayed to the user in a global time view spreadsheet where she is able to select temporal clusters of data points, and filter and brush data across temporal scales. With our method, a user can interact with data based on time activities and create expressive visualizations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4515862]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.69]]></doi>

<publicationId><![CDATA[4515862]]></publicationId>

<partnum><![CDATA[4515862]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4515862&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4515862]]></pdf>

</document>

<document>

<rank>93</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1512009]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.93]]></doi>

<publicationId><![CDATA[1512009]]></publicationId>

<partnum><![CDATA[1512009]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512009&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512009]]></pdf>

</document>

<document>

<rank>94</rank>

<title><![CDATA[Fractal volume compression]]></title>

<authors><![CDATA[Cochran, W.O.;  Hart, J.C.;  Flynn, P.J.]]></authors>

<affiliations><![CDATA[Sch. of Electr. Eng. & Comput. Sci., Washington State Univ., Pullman, WA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data compression]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[discrete cosine transforms]]></term>

<term><![CDATA[fractals]]></term>

<term><![CDATA[image classification]]></term>

<term><![CDATA[image coding]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[vector quantisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Discrete cosine transforms]]></term>

<term><![CDATA[Fractals]]></term>

<term><![CDATA[Image coding]]></term>

<term><![CDATA[PSNR]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Senior members]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Vector quantization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[313]]></spage>

<epage><![CDATA[322]]></epage>

<abstract><![CDATA[This research explores the principles, implementation, and optimization of a competitive volume compression system based on fractal image compression. The extension of fractal image compression to volumetric data is trivial in theory. However, the simple addition of a dimension to existing fractal image compression algorithms results in infeasible compression times and noncompetitive volume compression results. This paper extends several fractal image compression enhancements to perform properly and efficiently on volumetric data, and introduces a new 3D edge classification scheme based on principal component analysis. Numerous experiments over the many parameters of fractal volume compression suggest aggressive settings of its system parameters. At this peak efficiency, fractal volume compression surpasses vector quantization and approaches within 1 dB PSNR of the discrete cosine transform. When compared to the DCT, fractal volume compression represents surfaces in volumes exceptionally well at high compression rates, and the artifacts of its compression error appear as noise instead of deceptive smoothing or distracting ringing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[556500]]></arnumber>

<doi><![CDATA[10.1109/2945.556500]]></doi>

<publicationId><![CDATA[556500]]></publicationId>

<partnum><![CDATA[556500]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=556500&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556500]]></pdf>

</document>

<document>

<rank>95</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6238450]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.153]]></doi>

<publicationId><![CDATA[6238450]]></publicationId>

<partnum><![CDATA[6238450]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6238450&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6238450]]></pdf>

</document>

<document>

<rank>96</rank>

<title><![CDATA[High-Quality Ultra-Compact Grid Layout of Grouped Networks]]></title>

<authors><![CDATA[Yoghourdjian, V.;  Dwyer, T.;  Gange, G.;  Kieffer, S.;  Klein, K.;  Marriott, K.]]></authors>

<controlledterms>

<term><![CDATA[complex networks]]></term>

<term><![CDATA[computability]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[integer programming]]></term>

<term><![CDATA[large-scale systems]]></term>

<term><![CDATA[search problems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Containers]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Routing]]></term>

<term><![CDATA[Standards]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[339]]></spage>

<epage><![CDATA[348]]></epage>

<abstract><![CDATA[Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192733]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467251]]></doi>

<publicationId><![CDATA[7192733]]></publicationId>

<partnum><![CDATA[7192733]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192733&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192733]]></pdf>

</document>

<document>

<rank>97</rank>

<title><![CDATA[180,000 aritlces in the IEEE Computer Society Digital Library [advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[416]]></spage>

<epage><![CDATA[416]]></epage>

<abstract><![CDATA[A critical computer science and information technology rlesource for academic, government, and corporate libraries around the world ... does your organization subscribe?]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4069248]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.26]]></doi>

<publicationId><![CDATA[4069248]]></publicationId>

<partnum><![CDATA[4069248]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4069248&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069248]]></pdf>

</document>

<document>

<rank>98</rank>

<title><![CDATA[Video-Based Crowd Synthesis]]></title>

<authors><![CDATA[Flagg, M.;  Rehg, J.M.]]></authors>

<affiliations><![CDATA[Coll. of Comput. Building, Georgia Inst. of Technol., Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[image representation]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[set theory]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collision avoidance]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Electron tubes]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1935]]></spage>

<epage><![CDATA[1947]]></epage>

<abstract><![CDATA[As a controllable medium, video-realistic crowds are important for creating the illusion of a populated reality in special effects, games, and architectural visualization. While recent progress in simulation and motion captured-based techniques for crowd synthesis has focused on natural macroscale behavior, this paper addresses the complementary problem of synthesizing crowds with realistic microscale behavior and appearance. Example-based synthesis methods such as video textures are an appealing alternative to conventional model-based methods, but current techniques are unable to represent and satisfy constraints between video sprites and the scene. This paper describes how to synthesize crowds by segmenting pedestrians from input videos of natural crowds and optimally placing them into an output video while satisfying environmental constraints imposed by the scene. We introduce crowd tubes, a representation of video objects designed to compose a crowd of video billboards while avoiding collisions between static and dynamic obstacles. The approach consists of representing crowd tube samples and constraint violations with a conflict graph. The maximal independent set yields a dense constraint-satisyfing crowd composition. We present a prototype system for the capture, analysis, synthesis, and control of video-based crowds. Several results demonstrate the system's ability to generate videos of crowds which exhibit a variety of natural behaviors.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6365628]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.317]]></doi>

<publicationId><![CDATA[6365628]]></publicationId>

<partnum><![CDATA[6365628]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6365628&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365628]]></pdf>

</document>

<document>

<rank>99</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5465876]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.70]]></doi>

<publicationId><![CDATA[5465876]]></publicationId>

<partnum><![CDATA[5465876]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5465876&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5465876]]></pdf>

</document>

<document>

<rank>100</rank>

<title><![CDATA[Interactive visualization of three-dimensional vector fields with flexible appearance control]]></title>

<authors><![CDATA[Han-Wei Shen;  Bordoloi, U.D.;  Li, G.-S.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[434]]></spage>

<epage><![CDATA[445]]></epage>

<abstract><![CDATA[We present an interactive texture-based algorithm for visualizing three-dimensional steady and unsteady vector fields. The goal of the algorithm is to provide a general volume rendering framework allowing the user to compute three-dimensional flow textures interactively and to modify the appearance of the visualization on the fly. To achieve our goal, we decouple the visualization pipeline into two disjoint stages. First, flow lines are generated from the 3D vector data. Various geometric properties of the flow paths are extracted and converted into a volumetric form using a hardware-assisted slice sweeping algorithm. In the second phase of the algorithm, the attributes stored in the volume are used as texture coordinates to look up an appearance texture to generate both informative and aesthetic representations of the vector field. Our algorithm allows the user to interactively navigate through different regions of interest in the underlying field and experiment with various appearance textures. With our algorithm, visualizations with enhanced structural perception using various visual cues can be rendered in real time. A myriad of existing geometry-based and texture-based visualization techniques can also be emulated.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1298800]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.13]]></doi>

<publicationId><![CDATA[1298800]]></publicationId>

<partnum><![CDATA[1298800]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1298800&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298800]]></pdf>

</document>

<document>

<rank>101</rank>

<title><![CDATA[Supporting Communication and Coordination in Collaborative Sensemaking]]></title>

<authors><![CDATA[Mahyar, N.;  Tory, M.]]></authors>

<affiliations><![CDATA[Univ. of Victoria, Victoria, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[team working]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Quality assessment]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Video recording]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1633]]></spage>

<epage><![CDATA[1642]]></epage>

<abstract><![CDATA[When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other's activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875986]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346573]]></doi>

<publicationId><![CDATA[6875986]]></publicationId>

<partnum><![CDATA[6875986]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875986&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875986]]></pdf>

</document>

<document>

<rank>102</rank>

<title><![CDATA[Stochastic DT-MRI Connectivity Mapping on the GPU]]></title>

<authors><![CDATA[McGraw, T.;  Nadar, M.]]></authors>

<affiliations><![CDATA[West Virginia Univ, Morgantown]]></affiliations>

<controlledterms>

<term><![CDATA[Bayes methods]]></term>

<term><![CDATA[biodiffusion]]></term>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[brain]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[neurophysiology]]></term>

<term><![CDATA[probability]]></term>

<term><![CDATA[stochastic processes]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Diffusion tensor imaging]]></term>

<term><![CDATA[Ellipsoids]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Injuries]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Stochastic processes]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1504]]></spage>

<epage><![CDATA[1511]]></epage>

<abstract><![CDATA[We present a method for stochastic fiber tract mapping from diffusion tensor MRI (DT-MRI) implemented on graphics hardware. From the simulated fibers we compute a connectivity map that gives an indication of the probability that two points in the dataset are connected by a neuronal fiber path. A Bayesian formulation of the fiber model is given and it is shown that the inversion method can be used to construct plausible connectivity. An implementation of this fiber model on the graphics processing unit (GPU) is presented. Since the fiber paths can be stochastically generated independently of one another, the algorithm is highly parallelizable. This allows us to exploit the data-parallel nature of the GPU fragment processors. We also present a framework for the connectivity computation on the GPU. Our implementation allows the user to interactively select regions of interest and observe the evolving connectivity results during computation. Results are presented from the stochastic generation of over 250,000 fiber steps per iteration at interactive frame rates on consumer-grade graphics hardware.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376180]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70597]]></doi>

<publicationId><![CDATA[4376180]]></publicationId>

<partnum><![CDATA[4376180]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376180&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376180]]></pdf>

</document>

<document>

<rank>103</rank>

<title><![CDATA[Message from the VIS Paper Chairs and Guest Editors]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Information technology]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Visual analytics]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[xi]]></spage>

<epage><![CDATA[xv]]></epage>

<abstract><![CDATA[The papers in this special issue were presented at IEEE VIS 2015, held during October 25-30, 2015 in Chicago, IL. VIS consists of three conferences, held concurrently: the IEEE Visual Analytics Science and Technology Conference (VAST 2015), the IEEE Information Visualization Conference (InfoVis 2015), and the IEEE Scientific Visualization Conference (SciVis 2015). Visualization continues to develop rapidly as a research discipline and the three conferences are maintaining their positions as the leading annual events for researchers and practitioners to share the most innovative and impactful results of an increasingly diverse and influential community.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7307931]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2468793]]></doi>

<publicationId><![CDATA[7307931]]></publicationId>

<partnum><![CDATA[7307931]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7307931&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307931]]></pdf>

</document>

<document>

<rank>104</rank>

<title><![CDATA[Vortex Visualization for Practical Engineering Applications]]></title>

<authors><![CDATA[Jankun-Kelly, M.;  Jiang, M.;  Thompson, D.;  Raghu Machiraju]]></authors>

<affiliations><![CDATA[Computational Simulation & Design Center, Mississippi State Univ., MS]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[external flows]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[missiles]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Missiles]]></term>

<term><![CDATA[Spinning]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[957]]></spage>

<epage><![CDATA[964]]></epage>

<abstract><![CDATA[In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015452]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.201]]></doi>

<publicationId><![CDATA[4015452]]></publicationId>

<partnum><![CDATA[4015452]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015452&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015452]]></pdf>

</document>

<document>

<rank>105</rank>

<title><![CDATA[Techniques for the Visualization of Topological Defect Behavior in Nematic Liquid Crystals]]></title>

<authors><![CDATA[Slavin, V.A.;  Pelcovits, Robert A.;  Loriot, G.;  Callan-Jones, Andrew;  Laidlaw, D.H.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[nematic liquid crystals]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Crystallization]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Liquid crystal devices]]></term>

<term><![CDATA[Liquid crystal displays]]></term>

<term><![CDATA[Liquid crystals]]></term>

<term><![CDATA[Numerical simulation]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1323]]></spage>

<epage><![CDATA[1328]]></epage>

<abstract><![CDATA[We present visualization tools for analyzing molecular simulations of liquid crystal (LC) behavior. The simulation data consists of terabytes of data describing the position and orientation of every molecule in the simulated system over time. Condensed matter physicists study the evolution of topological defects in these data, and our visualization tools focus on that goal. We first convert the discrete simulation data to a sampled version of a continuous second-order tensor field and then use combinations of visualization methods to simultaneously display combinations of contractions of the tensor data, providing an interactive environment for exploring these complicated data. The system, built using AVS, employs colored cutting planes, colored isosurfaces, and colored integral curves to display fields of tensor contractions including Westin's scalar c<sub>l</sub>, c<sub>p </sub>, and c<sub>s</sub> metrics and the principal eigenvector. Our approach has been in active use in the physics lab for over a year. It correctly displays structures already known; it displays the data in a spatially and temporally smoother way than earlier approaches, avoiding confusing grid effects and facilitating the study of multiple time steps; it extends the use of tools developed for visualizing diffusion tensor data, re-interpreting them in the context of molecular simulations; and it has answered long-standing questions regarding the orientation of molecules around defects and the conformational changes of the defects]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015498]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.182]]></doi>

<publicationId><![CDATA[4015498]]></publicationId>

<partnum><![CDATA[4015498]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015498&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015498]]></pdf>

</document>

<document>

<rank>106</rank>

<title><![CDATA[Exemplar-based Visualization of Large Document Corpus (InfoVis2009-1115)]]></title>

<authors><![CDATA[Yanhua Chen;  Lijun Wang;  Ming Dong;  Jing Hua]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[optimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Drugs]]></term>

<term><![CDATA[Indexing]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Matrix decomposition]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Text mining]]></term>

<term><![CDATA[Web sites]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1161]]></spage>

<epage><![CDATA[1168]]></epage>

<abstract><![CDATA[With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290725]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.140]]></doi>

<publicationId><![CDATA[5290725]]></publicationId>

<partnum><![CDATA[5290725]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290725&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290725]]></pdf>

</document>

<document>

<rank>107</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1580466]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.26]]></doi>

<publicationId><![CDATA[1580466]]></publicationId>

<partnum><![CDATA[1580466]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580466&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580466]]></pdf>

</document>

<document>

<rank>108</rank>

<title><![CDATA[IEEE Visualization and Graphics Technical Committee (VGTC)]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[xiii]]></spage>

<epage><![CDATA[xiii]]></epage>

<abstract><![CDATA[Provides a listing of current committee members.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327299]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.235]]></doi>

<publicationId><![CDATA[6327299]]></publicationId>

<partnum><![CDATA[6327299]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327299&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327299]]></pdf>

</document>

<document>

<rank>109</rank>

<title><![CDATA[Positional Uncertainty of Isocontours: Condition Analysis and Probabilistic Measures]]></title>

<authors><![CDATA[Pothkow, K.;  Hege, H.-C.]]></authors>

<affiliations><![CDATA[Konrad-Zuse-Zentrum fur Informationstechnik Berlin (ZIB), Berlin, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[probability]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Measurement uncertainty]]></term>

<term><![CDATA[Random variables]]></term>

<term><![CDATA[Systematics]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1393]]></spage>

<epage><![CDATA[1406]]></epage>

<abstract><![CDATA[Uncertainty is ubiquitous in science, engineering and medicine. Drawing conclusions from uncertain data is the normal case, not an exception. While the field of statistical graphics is well established, only a few 2D and 3D visualization and feature extraction methods have been devised that consider uncertainty. We present mathematical formulations for uncertain equivalents of isocontours based on standard probability theory and statistics and employ them in interactive visualization methods. As input data, we consider discretized uncertain scalar fields and model these as random fields. To create a continuous representation suitable for visualization we introduce interpolated probability density functions. Furthermore, we introduce numerical condition as a general means in feature-based visualization. The condition number-which potentially diverges in the isocontour problem-describes how errors in the input data are amplified in feature computation. We show how the average numerical condition of isocontours aids the selection of thresholds that correspond to robust isocontours. Additionally, we introduce the isocontour density and the level crossing probability field; these two measures for the spatial distribution of uncertain isocontours are directly based on the probabilistic model of the input data. Finally, we adapt interactive visualization methods to evaluate and display these measures and apply them to 2D and 3D data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5620906]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.247]]></doi>

<publicationId><![CDATA[5620906]]></publicationId>

<partnum><![CDATA[5620906]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5620906&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620906]]></pdf>

</document>

<document>

<rank>110</rank>

<title><![CDATA[The Impact of a Character Posture Model on the Communication of Affect in an Immersive Virtual Environment]]></title>

<authors><![CDATA[Vinayagamoorthy, V.;  Steed, A.;  Slater, M.]]></authors>

<affiliations><![CDATA[British Broadcasting Corp., Kingswood Warren]]></affiliations>

<controlledterms>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[965]]></spage>

<epage><![CDATA[982]]></epage>

<abstract><![CDATA[This paper presents the quantitative and qualitative findings from an experiment designed to evaluate a developing model of affective postures for full-body virtual characters in immersive virtual environments (IVEs). Forty-nine participants were each requested to explore a virtual environment by asking two virtual characters for instructions. The participants used a CAVE-like system to explore the environment. Participant responses and their impression of the virtual characters were evaluated through a wide variety of both quantitative and qualitative methods. Combining a controlled experimental approach with various data-collection methods provided a number of advantages such as providing a reason to the quantitative results. The quantitative results indicate that posture plays an important role in the communication of affect by virtual characters. The qualitative findings indicated that participants attribute a variety of psychological states to the behavioral cues displayed by virtual characters. In addition, participants tended to interpret the social context portrayed by the virtual characters in a holistic manner. This suggests that one aspect of the virtual scene colors the perception of the whole social context portrayed by the virtual characters. We conclude by discussing the importance of designing holistically congruent virtual characters especially in immersive settings.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4492773]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.62]]></doi>

<publicationId><![CDATA[4492773]]></publicationId>

<partnum><![CDATA[4492773]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4492773&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4492773]]></pdf>

</document>

<document>

<rank>111</rank>

<title><![CDATA[Visualizing Temporal Patterns in Large Multivariate Data using Modified Globbing]]></title>

<authors><![CDATA[Glatter, M.;  Huang, J.;  Ahern, S.;  Daniel, J.;  Aidong Lu]]></authors>

<affiliations><![CDATA[Univ. of Tennessee at Knoxville, Knoxville, TN]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern matching]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Capacitive sensors]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Pattern matching]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1467]]></spage>

<epage><![CDATA[1474]]></epage>

<abstract><![CDATA[Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658164]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.184]]></doi>

<publicationId><![CDATA[4658164]]></publicationId>

<partnum><![CDATA[4658164]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658164&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658164]]></pdf>

</document>

<document>

<rank>112</rank>

<title><![CDATA[A Unified Approach to Streamline Selection and Viewpoint Selection for 3D Flow Visualization]]></title>

<authors><![CDATA[Jun Tao;  Jun Ma;  Chaoli Wang;  Ching-Kuang Shene]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Michigan Technol. Univ., Houghton, MI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[information theory]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Mutual information]]></term>

<term><![CDATA[Probability distribution]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Silicon]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[393]]></spage>

<epage><![CDATA[406]]></epage>

<abstract><![CDATA[We treat streamline selection and viewpoint selection as symmetric problems which are formulated into a unified information-theoretic framework. This is achieved by building two interrelated information channels between a pool of candidate streamlines and a set of sample viewpoints. We define the streamline information to select best streamlines and in a similar manner, define the viewpoint information to select best viewpoints. Furthermore, we propose solutions to streamline clustering and viewpoint partitioning based on the representativeness of streamlines and viewpoints, respectively. Finally, we define a camera path that passes through all selected viewpoints for automatic flow field exploration. We demonstrate the robustness of our approach by showing experimental results with different flow data sets, and conducting rigorous comparisons between our algorithm and other seed placement or streamline selection algorithms based on information theory.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6226391]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.143]]></doi>

<publicationId><![CDATA[6226391]]></publicationId>

<partnum><![CDATA[6226391]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6226391&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226391]]></pdf>

</document>

<document>

<rank>113</rank>

<title><![CDATA[A geometric comparison of algorithms for fusion control in stereoscopic HTDs]]></title>

<authors><![CDATA[Wartell, Z.;  Hodges, L.F.;  Ribarsky, W.]]></authors>

<affiliations><![CDATA[Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[human factors]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[scaling phenomena]]></term>

<term><![CDATA[sensor fusion]]></term>

<term><![CDATA[three-dimensional displays]]></term>

<term><![CDATA[tracking]]></term>

<term><![CDATA[virtual reality]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Fusion power generation]]></term>

<term><![CDATA[Head]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Visual system]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[129]]></spage>

<epage><![CDATA[143]]></epage>

<abstract><![CDATA[This paper concerns stereoscopic virtual reality displays in which the head is tracked and the display is stationary, attached to a desk, tabletop or wall. These are called stereoscopic HTDs (head-tracked displays). Stereoscopic displays render two perspective views of a scene, each of which is seen by one eye of the user. Ideally, the user's natural visual system combines the stereo image pair into a single, 3D perceived image. Unfortunately, users often have difficulty fusing the stereo image pair. Researchers use a number of software techniques to reduce fusion problems. This paper geometrically examines and compares a number of these techniques and reaches the following conclusions: In interactive stereoscopic applications, the combination of view placement, scale, and either false eye separation or &alpha;-false eye separation can provide fusion control that is geometrically similar to image shifting and image scaling. However, in stereo HTDs, image shifting and image scaling also generate additional geometric artifacts that are not generated by the other methods. We anecdotally link some of these artifacts to exceeding the perceptual limitations of human vision. While formal perceptual studies are still needed, geometric analysis suggests that image shifting and image scaling may be less appropriate than the other methods for interactive, stereo HTDs]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[998666]]></arnumber>

<doi><![CDATA[10.1109/2945.998666]]></doi>

<publicationId><![CDATA[998666]]></publicationId>

<partnum><![CDATA[998666]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=998666&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998666]]></pdf>

</document>

<document>

<rank>114</rank>

<title><![CDATA[High-Quality and Interactive Animations of 3D Time-Varying Vector Fields]]></title>

<authors><![CDATA[Helgeland, A.;  Elboth, T.]]></authors>

<affiliations><![CDATA[Oslo Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Fluid dynamics]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Particle tracking]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1535]]></spage>

<epage><![CDATA[1546]]></epage>

<abstract><![CDATA[In this paper, we present an interactive texture-based method for visualizing three-dimensional unsteady vector fields. The visualization method uses a sparse and global representation of the flow, such that it does not suffer from the same perceptual issues as is the case for visualizing dense representations. The animation is made by injecting a collection of particles evenly distributed throughout the physical domain. These particles are then tracked along their path lines. At each time step, these particles are used as seed points to generate field lines using any vector field such as the velocity field or vorticity field. In this way, the animation shows the advection of particles while each frame in the animation shows the instantaneous vector field. In order to maintain a coherent particle density and to avoid clustering as time passes, we have developed a novel particle advection strategy which produces approximately evenly-spaced field lines at each time step. To improve rendering performance, we decouple the rendering stage from the preceding stages of the visualization method. This allows interactive exploration of multiple fields simultaneously, which sets the stage for a more complete analysis of the flow field. The final display is rendered using texture-based direct volume rendering]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1703373]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.95]]></doi>

<publicationId><![CDATA[1703373]]></publicationId>

<partnum><![CDATA[1703373]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1703373&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703373]]></pdf>

</document>

<document>

<rank>115</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5714212]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.43]]></doi>

<publicationId><![CDATA[5714212]]></publicationId>

<partnum><![CDATA[5714212]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5714212&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714212]]></pdf>

</document>

<document>

<rank>116</rank>

<title><![CDATA[ThemeRiver: visualizing thematic changes in large document collections]]></title>

<authors><![CDATA[Havre, S.;  Hetzler, E.;  Whitney, P.;  Nowell, L.]]></authors>

<affiliations><![CDATA[Battelle Pacific Northwest Div., Richland, WA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[information analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Information retrieval]]></term>

<term><![CDATA[Rivers]]></term>

<term><![CDATA[Self organizing feature maps]]></term>

<term><![CDATA[Wire]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[9]]></spage>

<epage><![CDATA[20]]></epage>

<abstract><![CDATA[The ThemeRiver visualization depicts thematic variations over time within a large collection of documents. The thematic changes are shown in the context of a time-line and corresponding external events. The focus on temporal thematic change within a context framework allows a user to discern patterns that suggest relationships or trends. For example, the sudden change of thematic strength following an external event may indicate a causal relationship. Such patterns are not readily accessible in other visualizations of the data. We use a river metaphor to convey several key notions. The document collection's time-line, selected thematic content and thematic strength are indicated by the river's directed flow, composition and changing width, respectively. The directed flow from left to right is interpreted as movement through time and the horizontal distance between two points on the river defines a time interval. At any point in time, the vertical distance, or width, of the river indicates the collective strength of the selected themes. Colored "currents" flowing within the river represent individual themes. A current's vertical width narrows or broadens to indicate decreases or increases in the strength of the individual theme]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[981848]]></arnumber>

<doi><![CDATA[10.1109/2945.981848]]></doi>

<publicationId><![CDATA[981848]]></publicationId>

<partnum><![CDATA[981848]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=981848&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981848]]></pdf>

</document>

<document>

<rank>117</rank>

<title><![CDATA[Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization]]></title>

<authors><![CDATA[Tarini, M.;  Cignoni, P.;  Montani, C.]]></authors>

<affiliations><![CDATA[Universita dell''Insubria, Varese]]></affiliations>

<controlledterms>

<term><![CDATA[biological techniques]]></term>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[molecular biophysics]]></term>

<term><![CDATA[molecular configurations]]></term>

<term><![CDATA[proteins]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Chemicals]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image databases]]></term>

<term><![CDATA[Inspection]]></term>

<term><![CDATA[Proteins]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Software systems]]></term>

<term><![CDATA[Visual databases]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1237]]></spage>

<epage><![CDATA[1244]]></epage>

<abstract><![CDATA[The paper presents a set of combined techniques to enhance the real-time visualization of simple or complex molecules (up to order of 10<sup>6</sup> atoms) space fill mode. The proposed approach includes an innovative technique for efficient computation and storage of ambient occlusion terms, a small set of GPU accelerated procedural impostors for space-fill and ball-and-stick rendering, and novel edge-cueing techniques. As a result, the user's understanding of the three-dimensional structure under inspection is strongly increased (even for'still images), while the rendering still occurs in real time]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015487]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.115]]></doi>

<publicationId><![CDATA[4015487]]></publicationId>

<partnum><![CDATA[4015487]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015487&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015487]]></pdf>

</document>

<document>

<rank>118</rank>

<title><![CDATA[Reviewers]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xx]]></spage>

<epage><![CDATA[xxii]]></epage>

<abstract><![CDATA[The publication offers a note of thanks and lists its reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634105]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.185]]></doi>

<publicationId><![CDATA[6634105]]></publicationId>

<partnum><![CDATA[6634105]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634105&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634105]]></pdf>

</document>

<document>

<rank>119</rank>

<title><![CDATA[Fast display of illuminated field lines]]></title>

<authors><![CDATA[Stalling, D.;  Zockler, M.;  Hege, H.-C.]]></authors>

<affiliations><![CDATA[Konrad-Zuse-Zentrum fur Informationstech., Berlin, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[electric fields]]></term>

<term><![CDATA[electrical engineering computing]]></term>

<term><![CDATA[image coding]]></term>

<term><![CDATA[image enhancement]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[light reflection]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[magnetic fields]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[realistic images]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transparency]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image coding]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Reflection]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Visualization]]></term>

<term><![CDATA[Workstations]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[118]]></spage>

<epage><![CDATA[128]]></epage>

<abstract><![CDATA[A new technique for interactive vector field visualization using large numbers of properly illuminated field lines is presented. Taking into account ambient, diffuse and specular reflection terms, as well as transparency and depth cueing, we employ a realistic shading model which significantly increases the quality and realism of the resulting images. While many graphics workstations offer hardware support for illuminating surface primitives, usually no means for an accurate shading of line primitives are provided. However, we show that proper illumination of lines can be implemented by exploiting the texture mapping capabilities of modern graphics hardware. In this way, high rendering performance with interactive frame rates can be achieved. We apply the technique to render large numbers of integral curves of a vector field. The impression of the resulting images can be further improved by a number of visual enhancements, like color coding or particle animation. We also describe methods for controlling the distribution of field lines in space. These methods enable us to use illuminated field lines for interactive exploration of vector fields]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[597795]]></arnumber>

<doi><![CDATA[10.1109/2945.597795]]></doi>

<publicationId><![CDATA[597795]]></publicationId>

<partnum><![CDATA[597795]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=597795&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=597795]]></pdf>

</document>

<document>

<rank>120</rank>

<title><![CDATA[Marker Optimization for Facial Motion Acquisition and Deformation]]></title>

<authors><![CDATA[Le, B.H.;  Mingyang Zhu;  Zhigang Deng]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[optimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Facial animation]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1859]]></spage>

<epage><![CDATA[1871]]></epage>

<abstract><![CDATA[A long-standing problem in marker-based facial motion capture is what are the optimal facial mocap marker layouts. Despite its wide range of potential applications, this problem has not yet been systematically explored to date. This paper describes an approach to compute optimized marker layouts for facial motion acquisition as optimization of characteristic control points from a set of high-resolution, ground-truth facial mesh sequences. Specifically, the thin-shell linear deformation model is imposed onto the example pose reconstruction process via optional hard constraints such as symmetry and multiresolution constraints. Through our experiments and comparisons, we validate the effectiveness, robustness, and accuracy of our approach. Besides guiding minimal yet effective placement of facial mocap markers, we also describe and demonstrate its two selected applications: marker-based facial mesh skinning and multiresolution facial performance capture.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6517176]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.84]]></doi>

<publicationId><![CDATA[6517176]]></publicationId>

<partnum><![CDATA[6517176]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6517176&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6517176]]></pdf>

</document>

<document>

<rank>121</rank>

<title><![CDATA[CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds]]></title>

<authors><![CDATA[Lingyun Yu;  Efstathiou, K.;  Isenberg, P.;  Isenberg, T.]]></authors>

<affiliations><![CDATA[Hangzhou Dianzi Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[ubiquitous computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Indexes]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[886]]></spage>

<epage><![CDATA[895]]></epage>

<abstract><![CDATA[We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192726]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467202]]></doi>

<publicationId><![CDATA[7192726]]></publicationId>

<partnum><![CDATA[7192726]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192726&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192726]]></pdf>

</document>

<document>

<rank>122</rank>

<title><![CDATA[Computing and rendering point set surfaces]]></title>

<authors><![CDATA[Alexa, M.;  Behr, J.;  Cohen-Or, D.;  Fleishman, S.;  Levin, D.;  Silva, Claudio T.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Tech. Univ. Darmstadt, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation error]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Error correction]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Least squares approximation]]></term>

<term><![CDATA[Multilevel systems]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Strontium]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[3]]></spage>

<epage><![CDATA[15]]></epage>

<abstract><![CDATA[We advocate the use of point sets to represent shapes. We provide a definition of a smooth manifold surface from a set of points close to the original surface. The definition is based on local maps from differential geometry, which are approximated by the method of moving least squares (MLS). The computation of points on the surface is local, which results in an out-of-core technique that can handle any point set. We show that the approximation error is bounded and present tools to increase or decrease the density of the points, thus allowing an adjustment of the spacing among the points to control the error. To display the point set surface, we introduce a novel point rendering technique. The idea is to evaluate the local maps according to the image resolution. This results in high quality shading effects and smooth silhouettes at interactive frame rates.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1175093]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1175093]]></doi>

<publicationId><![CDATA[1175093]]></publicationId>

<partnum><![CDATA[1175093]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1175093&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1175093]]></pdf>

</document>

<document>

<rank>123</rank>

<title><![CDATA[Transforming GIS Data into Functional Road Models for Large-Scale Traffic Simulation]]></title>

<authors><![CDATA[Wilkie, D.;  Sewall, J.;  Lin, M.C.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[traffic engineering computing]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geographic information systems]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Roads]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[890]]></spage>

<epage><![CDATA[901]]></epage>

<abstract><![CDATA[There exists a vast amount of geographic information system (GIS) data that model road networks around the world as polylines with attributes. In this form, the data are insufficient for applications such as simulation and 3D visualization-tools which will grow in power and demand as sensor data become more pervasive and as governments try to optimize their existing physical infrastructure. In this paper, we propose an efficient method for enhancing a road map from a GIS database to create a geometrically and topologically consistent 3D model to be used in real-time traffic simulation, interactive visualization of virtual worlds, and autonomous vehicle navigation. The resulting representation provides important road features for traffic simulations, including ramps, highways, overpasses, legal merge zones, and intersections with arbitrary states, and it is independent of the simulation methodologies. We test the 3D models of road networks generated by our algorithm on real-time traffic simulation using both macroscopic and microscopic techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5928342]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.116]]></doi>

<publicationId><![CDATA[5928342]]></publicationId>

<partnum><![CDATA[5928342]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5928342&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928342]]></pdf>

</document>

<document>

<rank>124</rank>

<title><![CDATA[The discrete analytical hyperspheres]]></title>

<authors><![CDATA[Andres, E.;  Jacob, M.-A.]]></authors>

<affiliations><![CDATA[Roswell Park Cancer Inst., Buffalo, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Focusing]]></term>

<term><![CDATA[Jacobian matrices]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[75]]></spage>

<epage><![CDATA[86]]></epage>

<abstract><![CDATA[An analytical definition of a discrete hypersphere with arbitrary center, radius, and thickness in dimension n is introduced. The new discrete hypersphere is called a discrete analytical hypersphere. The hypersphere has important original properties including exact point localization, space tiling, k-separation, etc. These properties are almost obvious with this new discrete analytical definition contrary to the classical approaches based on digitization schemes. The analytically defined circle is compared to Pham's (1992) classically defined circle. Efficient incremental circle and hypersphere generation algorithms are provided]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[582354]]></arnumber>

<doi><![CDATA[10.1109/2945.582354]]></doi>

<publicationId><![CDATA[582354]]></publicationId>

<partnum><![CDATA[582354]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=582354&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=582354]]></pdf>

</document>

<document>

<rank>125</rank>

<title><![CDATA[Large-Scale Point-Cloud Visualization through Localized Textured Surface Reconstruction]]></title>

<authors><![CDATA[Arikan, M.;  Preiner, R.;  Scheiblauer, C.;  Jeschke, S.;  Wimmer, M.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1280]]></spage>

<epage><![CDATA[1292]]></epage>

<abstract><![CDATA[In this paper, we introduce a novel scene representation for the visualization of large-scale point clouds accompanied by a set of high-resolution photographs. Many real-world applications deal with very densely sampled point-cloud data, which are augmented with photographs that often reveal lighting variations and inaccuracies in registration. Consequently, the high-quality representation of the captured data, i.e., both point clouds and photographs together, is a challenging and time-consuming task. We propose a two-phase approach, in which the first (preprocessing) phase generates multiple overlapping surface patches and handles the problem of seamless texture generation locally for each patch. The second phase stitches these patches at render-time to produce a high-quality visualization of the data. As a result of the proposed localization of the global texturing problem, our algorithm is more than an order of magnitude faster than equivalent mesh-based texturing techniques. Furthermore, since our preprocessing phase requires only a minor fraction of the whole data set at once, we provide maximum flexibility when dealing with growing data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6774475]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2312011]]></doi>

<publicationId><![CDATA[6774475]]></publicationId>

<partnum><![CDATA[6774475]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6774475&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774475]]></pdf>

</document>

<document>

<rank>126</rank>

<title><![CDATA[Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations]]></title>

<authors><![CDATA[McGuffin, M.J.;  Jurisica, I.]]></authors>

<affiliations><![CDATA[Ecole de Technol. Super., Montreal, QC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Biology computing]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Keyboards]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Software packages]]></term>

<term><![CDATA[Usability]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[937]]></spage>

<epage><![CDATA[944]]></epage>

<abstract><![CDATA[We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290697]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.151]]></doi>

<publicationId><![CDATA[5290697]]></publicationId>

<partnum><![CDATA[5290697]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290697&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290697]]></pdf>

</document>

<document>

<rank>127</rank>

<title><![CDATA[3D distance fields: a survey of techniques and applications]]></title>

<authors><![CDATA[Jones, M.;  Baerentzen, J.A.;  Sramek, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Swansea Univ., UK]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Physics]]></term>

<term><![CDATA[Production]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Skeleton]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[581]]></spage>

<epage><![CDATA[599]]></epage>

<abstract><![CDATA[A distance field is a representation where, at each point within the field, we know the distance from that point to the closest point on any object within the domain. In addition to distance, other properties may be derived from the distance field, such as the direction to the surface, and when the distance field is signed, we may also determine if the point is internal or external to objects within the domain. The distance field has been found to be a useful construction within the areas of computer vision, physics, and computer graphics. This paper serves as an exposition of methods for the production of distance fields, and a review of alternative representations and applications of distance fields. In the course of this paper, we present various methods from all three of the above areas, and we answer pertinent questions such as How accurate are these methods compared to each other? How simple are they to implement?, and What is the complexity and runtime of such methods?.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634323]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.56]]></doi>

<publicationId><![CDATA[1634323]]></publicationId>

<partnum><![CDATA[1634323]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634323&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634323]]></pdf>

</document>

<document>

<rank>128</rank>

<title><![CDATA[A Systematic Review on the Practice of Evaluating Visualization]]></title>

<authors><![CDATA[Isenberg, T.;  Isenberg, P.;  Jian Chen;  Sedlmair, M.;  Moller, T.]]></authors>

<affiliations><![CDATA[INRIA, Sophia-Antipolis, France]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[encoding]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Systematics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2818]]></spage>

<epage><![CDATA[2827]]></epage>

<abstract><![CDATA[We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6634108]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.126]]></doi>

<publicationId><![CDATA[6634108]]></publicationId>

<partnum><![CDATA[6634108]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634108&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634108]]></pdf>

</document>

<document>

<rank>129</rank>

<title><![CDATA[Silver Bullet Security Podcasts]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Communication system security]]></term>

<term><![CDATA[Computer security]]></term>

<term><![CDATA[Digital audio broadcasting]]></term>

<term><![CDATA[Information security]]></term>

<term><![CDATA[Intellectual property]]></term>

<term><![CDATA[Internet]]></term>

<term><![CDATA[Portable media players]]></term>

<term><![CDATA[Privacy]]></term>

<term><![CDATA[Silver]]></term>

<term><![CDATA[Streaming media]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[724]]></spage>

<epage><![CDATA[724]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4472710]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.48]]></doi>

<publicationId><![CDATA[4472710]]></publicationId>

<partnum><![CDATA[4472710]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4472710&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4472710]]></pdf>

</document>

<document>

<rank>130</rank>

<title><![CDATA[Hardware Accelerated Segmentation of Complex Volumetric Filament Networks]]></title>

<authors><![CDATA[Mayerich, D.;  Keyser, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Texas A&M Univ., College Station, TX]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[microscopy]]></term>

<term><![CDATA[ray tracing]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[670]]></spage>

<epage><![CDATA[681]]></epage>

<abstract><![CDATA[We present a framework for segmenting and storing filament networks from scalar volume data. Filament networks are encountered more and more commonly in biomedical imaging due to advances in high-throughput microscopy. These data sets are characterized by a complex volumetric network of thin filaments embedded in a scalar volume field. High-throughput microscopy volumes are also difficult to manage since they can require several terabytes of storage, even though the total volume of the embedded structure is much smaller. Filaments in microscopy data sets are difficult to segment because their diameter is often near the sampling resolution of the microscope, yet these networks can span large regions of the data set. We describe a novel method to trace filaments through scalar volume data sets that is robust to both noisy and undersampled data. We use graphics hardware to accelerate the tracing algorithm, making it more useful for large data sets. After the initial network is traced, we use an efficient encoding scheme to store volumetric data pertaining to the network.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4695828]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.196]]></doi>

<publicationId><![CDATA[4695828]]></publicationId>

<partnum><![CDATA[4695828]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4695828&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4695828]]></pdf>

</document>

<document>

<rank>131</rank>

<title><![CDATA[A comparative study between RadViz and Star Coordinates]]></title>

<authors><![CDATA[Rubio-Sanchez, M.;  Raya, L.;  Diaz, F.;  Sanchez, A.]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed databases]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Nonlinear distortion]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Springs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[619]]></spage>

<epage><![CDATA[628]]></epage>

<abstract><![CDATA[RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192699]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467324]]></doi>

<publicationId><![CDATA[7192699]]></publicationId>

<partnum><![CDATA[7192699]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192699&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192699]]></pdf>

</document>

<document>

<rank>132</rank>

<title><![CDATA[Structure-Aware Lighting Design for Volume Visualization]]></title>

<authors><![CDATA[Yubo Tao;  Hai Lin;  Feng Dong;  Chao Wang;  Clapworthy, G.;  Hujun Bao]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&amp;CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Entropy]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Stability analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2372]]></spage>

<epage><![CDATA[2381]]></epage>

<abstract><![CDATA[Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information - the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327242]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.267]]></doi>

<publicationId><![CDATA[6327242]]></publicationId>

<partnum><![CDATA[6327242]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327242&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327242]]></pdf>

</document>

<document>

<rank>133</rank>

<title><![CDATA[Interactive Mesh Cutting Using Constrained Random Walks]]></title>

<authors><![CDATA[Juyong Zhang;  Jianmin Zheng;  Jianfei Cai]]></authors>

<affiliations><![CDATA[Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[constraint handling]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[optimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer interfaces]]></term>

<term><![CDATA[Constraint optimization]]></term>

<term><![CDATA[Design optimization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Partitioning algorithms]]></term>

<term><![CDATA[Process design]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[User interfaces]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[357]]></spage>

<epage><![CDATA[367]]></epage>

<abstract><![CDATA[This paper considers the problem of interactively finding the cutting contour to extract components from an existing mesh. First, we propose a constrained random walks algorithm that can add constraints to the random walks procedure and thus allows for a variety of intuitive user inputs. Second, we design an optimization process that uses the shortest graph path to derive a nice cut contour. Then a new mesh cutting algorithm is developed based on the constrained random walks plus the optimization process. Within the same computational framework, the new algorithm provides a novel user interface for interactive mesh cutting that supports three typical user inputs and also their combinations: 1) foreground/background seed inputs: the user draws strokes specifying seeds for &#x201C;foreground&#x201D; (i.e., the part to be cut out) and &#x201C;background&#x201D; (i.e., the rest); 2) soft constraint inputs: the user draws strokes on the mesh indicating the region which the cuts should be made nearby; and 3) hard constraint inputs: the marks which the cutting contour must pass. The algorithm uses feature sensitive metrics that are based on surface geometric properties and cognitive theory. The integration of the constrained random walks algorithm, the optimization process, the feature sensitive metrics, and the varieties of user inputs makes the algorithm intuitive, flexible, and effective as well. The experimental examples show that the proposed cutting method is fast, reliable, and capable of producing good results reflecting user intention and geometric attributes.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5453359]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.57]]></doi>

<publicationId><![CDATA[5453359]]></publicationId>

<partnum><![CDATA[5453359]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5453359&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453359]]></pdf>

</document>

<document>

<rank>134</rank>

<title><![CDATA[Autocalibration of Multiprojector CAVE-Like Immersive Environments]]></title>

<authors><![CDATA[Sajadi, B.;  Majumder, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Irvine, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[calibration]]></term>

<term><![CDATA[cameras]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[display devices]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[optical projectors]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Calibration]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[381]]></spage>

<epage><![CDATA[393]]></epage>

<abstract><![CDATA[In this paper, we present the first method for the geometric autocalibration of multiple projectors on a set of CAVE-like immersive display surfaces including truncated domes and 4 or 5-wall CAVEs (three side walls, floor, and/or ceiling). All such surfaces can be categorized as swept surfaces and multiple projectors can be registered on them using a single uncalibrated camera without using any physical markers on the surface. Our method can also handle nonlinear distortion in the projectors, common in compact setups where a short throw lens is mounted on each projector. Further, when the whole swept surface is not visible from a single camera view, we can register the projectors using multiple pan and tilted views of the same camera. Thus, our method scales well with different size and resolution of the display. Since we recover the 3D shape of the display, we can achieve registration that is correct from any arbitrary viewpoint appropriate for head-tracked single-user virtual reality systems. We can also achieve wallpapered registration, more appropriate for multiuser collaborative explorations. Though much more immersive than common surfaces like planes and cylinders, general swept surfaces are used today only for niche display environments. Even the more popular 4 or 5-wall CAVE is treated as a piecewise planar surface for calibration purposes and hence projectors are not allowed to be overlapped across the corners. Our method opens up the possibility of using such swept surfaces to create more immersive VR systems without compromising the simplicity of having a completely automatic calibration technique. Such calibration allows completely arbitrary positioning of the projectors in a 5-wall CAVE, without respecting the corners.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6060818]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.271]]></doi>

<publicationId><![CDATA[6060818]]></publicationId>

<partnum><![CDATA[6060818]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6060818&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060818]]></pdf>

</document>

<document>

<rank>135</rank>

<title><![CDATA[IEEE Transactions on Visualization and Computer Graphics - 2014 IEEE Virtual Reality Conference [title page]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[i]]></spage>

<epage><![CDATA[ii]]></epage>

<abstract><![CDATA[Presents the title page of the proceedings record.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6777436]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.44]]></doi>

<publicationId><![CDATA[6777436]]></publicationId>

<partnum><![CDATA[6777436]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777436&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777436]]></pdf>

</document>

<document>

<rank>136</rank>

<title><![CDATA[Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles]]></title>

<authors><![CDATA[Matkovic, K.;  Gracanin, D.;  Splechtna, R.;  Jelovic, M.;  Stehno, B.;  Hauser, H.;  Purgathofer, W.]]></authors>

<affiliations><![CDATA[VRVis Res. Center, Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[design of experiments]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[parameter space methods]]></term>

<term><![CDATA[steering systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Simulation]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1803]]></spage>

<epage><![CDATA[1812]]></epage>

<abstract><![CDATA[In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a nai&#x0308;ve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the &#x201C;best&#x201D; points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876045]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346744]]></doi>

<publicationId><![CDATA[6876045]]></publicationId>

<partnum><![CDATA[6876045]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876045&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876045]]></pdf>

</document>

<document>

<rank>137</rank>

<title><![CDATA[Visual Encodings of Temporal Uncertainty: A Comparative User Study]]></title>

<authors><![CDATA[Gschwandtner, T.;  Bo&#x0308; gl, M.;  Federico, P.;  Miksch, S.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[encoding]]></term>

<term><![CDATA[probability]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bars]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[539]]></spage>

<epage><![CDATA[548]]></epage>

<abstract><![CDATA[A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation - using a lighter color value to represent uncertain regions - or error bars for judging durations and temporal bounds, and gradient plots - using fading color or transparency - for judging probability values.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192667]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467752]]></doi>

<publicationId><![CDATA[7192667]]></publicationId>

<partnum><![CDATA[7192667]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192667&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192667]]></pdf>

</document>

<document>

<rank>138</rank>

<title><![CDATA[Active Exploration of Large 3D Model Repositories]]></title>

<authors><![CDATA[Lin Gao;  Yan-Pei Cao;  Yu-Kun Lai;  Hao-Zhi Huang;  Kobbelt, L.;  Shi-Min Hu]]></authors>

<affiliations><![CDATA[TNlist, Tsinghua Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[query processing]]></term>

<term><![CDATA[user interfaces]]></term>

<term><![CDATA[very large databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Semisupervised learning]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1390]]></spage>

<epage><![CDATA[1402]]></epage>

<abstract><![CDATA[With broader availability of large-scale 3D model repositories, the need for efficient and effective exploration becomes more and more urgent. Existing model retrieval techniques do not scale well with the size of the database since often a large number of very similar objects are returned for a query, and the possibilities to refine the search are quite limited. We propose an interactive approach where the user feeds an active learning procedure by labeling either entire models or parts of them as &#x201C;like&#x201D; or &#x201C;dislike&#x201D; such that the system can automatically update an active set of recommended models. To provide an intuitive user interface, candidate models are presented based on their estimated relevance for the current query. From the methodological point of view, our main contribution is to exploit not only the similarity between a query and the database models but also the similarities among the database models themselves. We achieve this by an offline pre-processing stage, where global and local shape descriptors are computed for each model and a sparse distance metric is derived that can be evaluated efficiently even for very large databases. We demonstrate the effectiveness of our method by interactively exploring a repository containing over 100 K models.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6951464]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2369039]]></doi>

<publicationId><![CDATA[6951464]]></publicationId>

<partnum><![CDATA[6951464]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6951464&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6951464]]></pdf>

</document>

<document>

<rank>139</rank>

<title><![CDATA[IEEE Virtual Reality Conference 2013 [table of contents]]]></title>

<authors><![CDATA[Coquillart, S.;  LaViola, J.J., Jr.;  Schmalstieg, D.]]></authors>

<affiliations><![CDATA[INRIA, France]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[i]]></spage>

<epage><![CDATA[iii]]></epage>

<abstract><![CDATA[Presents the table of contents of the proceedings of the 2013 IEEE Virtual Reality Conference as published in this issue of the IEEE Transactions on Visualization and Computer Graphics .]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479164]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.47]]></doi>

<publicationId><![CDATA[6479164]]></publicationId>

<partnum><![CDATA[6479164]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479164&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479164]]></pdf>

</document>

<document>

<rank>140</rank>

<title><![CDATA[Interactive Tree Comparison for Co-located Collaborative Information Visualization]]></title>

<authors><![CDATA[Isenberg, P.;  Carpendale, S.]]></authors>

<affiliations><![CDATA[Univ. of Calgary, Calgary]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[groupware]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Collaborative tools]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Information processing]]></term>

<term><![CDATA[Technological innovation]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1232]]></spage>

<epage><![CDATA[1239]]></epage>

<abstract><![CDATA[In many domains, increased collaboration has lead to more innovation by fostering the sharing of knowledge, skills, and ideas. Shared analysis of information visualizations does not only lead to increased information processing power, but team members can also share, negotiate, and discuss their views and interpretations on a dataset and contribute unique perspectives on a given problem. Designing technologies to support collaboration around information visualizations poses special challenges and relatively few systems have been designed. We focus on supporting small groups collaborating around information visualizations in a co-located setting, using a shared interactive tabletop display. We introduce an analysis of challenges and requirements for the design of co-located collaborative information visualization systems. We then present a new system that facilitates hierarchical data comparison tasks for this type of collaborative work. Our system supports multi-user input, shared and individual views on the hierarchical data visualization, flexible use of representations, and flexible workspace organization to facilitate group work around visualizations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376145]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70568]]></doi>

<publicationId><![CDATA[4376145]]></publicationId>

<partnum><![CDATA[4376145]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376145&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376145]]></pdf>

</document>

<document>

<rank>141</rank>

<title><![CDATA[Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics]]></title>

<authors><![CDATA[Johansson, S.;  Johansson, J.]]></authors>

<affiliations><![CDATA[Norrkoping Visualization & Interaction Studio (NVIS), Linkoping Univ., Linkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[data reduction]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Product development]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Weight control]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[993]]></spage>

<epage><![CDATA[1000]]></epage>

<abstract><![CDATA[Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5290704]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.153]]></doi>

<publicationId><![CDATA[5290704]]></publicationId>

<partnum><![CDATA[5290704]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290704&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290704]]></pdf>

</document>

<document>

<rank>142</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1634306]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.62]]></doi>

<publicationId><![CDATA[1634306]]></publicationId>

<partnum><![CDATA[1634306]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634306&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634306]]></pdf>

</document>

<document>

<rank>143</rank>

<title><![CDATA[Time-Varying Data Visualization Using Functional Representations]]></title>

<authors><![CDATA[Yun Jang;  Ebert, D.S.;  Gaither, K.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Octrees]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Time varying systems]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[421]]></spage>

<epage><![CDATA[433]]></epage>

<abstract><![CDATA[In many scientific simulations, the temporal variation and analysis of features are important. Visualization and visual analysis of time series data is still a significant challenge because of the large volume of data. Irregular and scattered time series data sets are even more problematic to visualize interactively. Previous work proposed functional representation using basis functions as one solution for interactively visualizing scattered data by harnessing the power of modern PC graphics boards. In this paper, we use the functional representation approach for time-varying data sets and develop an efficient encoding technique utilizing temporal similarity between time steps. Our system utilizes a graduated approach of three methods with increasing time complexity based on the lack of similarity of the evolving data sets. Using this system, we are able to enhance the encoding performance for the time-varying data sets, reduce the data storage by saving only changed or additional basis functions over time, and interactively visualize the time-varying encoding results. Moreover, we present efficient rendering of the functional representations using binary space partitioning tree textures to increase the rendering performance.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5728946]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.54]]></doi>

<publicationId><![CDATA[5728946]]></publicationId>

<partnum><![CDATA[5728946]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5728946&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728946]]></pdf>

</document>

<document>

<rank>144</rank>

<title><![CDATA[Anisotropic Noise Samples]]></title>

<authors><![CDATA[Feng, L.;  Hotz, I.;  Hamann, B.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Univ. of California, Davis]]></affiliations>

<controlledterms>

<term><![CDATA[Fourier analysis]]></term>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[noise]]></term>

<term><![CDATA[relaxation theory]]></term>

<term><![CDATA[statistical distributions]]></term>

<term><![CDATA[stochastic processes]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[342]]></spage>

<epage><![CDATA[354]]></epage>

<abstract><![CDATA[We present a practical approach to generate stochastic anisotropic samples with Poisson-disk characteristic over a two-dimensional domain. In contrast to isotropic samples, we understand anisotropic samples as nonoverlapping ellipses whose size and density match a given anisotropic metric. Anisotropic noise samples are useful for many visualization and graphics applications. The spot samples can be used as input for texture generation, for example, line integral convolution (LIC), but can also be used directly for visualization. The definition of the spot samples using a metric tensor makes them especially suitable for the visualization of tensor fields that can be translated into a metric. Our work combines ideas from sampling theory and mesh generation to approximate generalized blue noise properties. To generate these samples with the desired properties, we first construct a set of nonoverlapping ellipses whose distribution closely matches the underlying metric. This set of samples is used as input for a generalized anisotropic Lloyd relaxation to distribute noise samples more evenly. Instead of computing the Voronoi tessellation explicitly, we introduce a discrete approach that combines the Voronoi cell and centroid computation in one step. Our method supports automatic packing of the elliptical samples, resulting in textures similar to those generated by anisotropic reaction-diffusion methods. We use Fourier analysis tools for quality measurement of uniformly distributed samples. The resulting samples have nice sampling properties, for example, they satisfy a blue noise property where low frequencies in the power spectrum are reduced to a minimum..]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359502]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70434]]></doi>

<publicationId><![CDATA[4359502]]></publicationId>

<partnum><![CDATA[4359502]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359502&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359502]]></pdf>

</document>

<document>

<rank>145</rank>

<title><![CDATA[Fast Edge-Aware Processing via First Order Proximal Approximation]]></title>

<authors><![CDATA[Badri, H.;  Yahia, H.;  Aboutajdine, D.]]></authors>

<affiliations><![CDATA[Bordeaux Sud-Ouest, INRIA, Talence, France]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[convolution]]></term>

<term><![CDATA[smoothing methods]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Laplace equations]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Smoothing methods]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[743]]></spage>

<epage><![CDATA[755]]></epage>

<abstract><![CDATA[We present a new framework for fast edge-aware processing of images and videos. The proposed smoothing method is based on an optimization formulation with a non-convex sparse regularization for a better smoothing behavior near strong edges. We develop mathematical tools based on first order approximation of proximal operators to accelerate the proposed method while maintaining high-quality smoothing. The first order approximation is used to estimate a solution of the proximal form in a half-quadratic solver, and also to derive a warm-start solution that can be calculated quickly when the image is loaded by the user. We extend the method to large-scale processing by estimating the smoothing operation with independent 1D convolution operations. This approach linearly scales to the size of the image and can fully take advantage of parallel processing. The method supports full color filtering and turns out to be temporally coherent for fast video processing. We demonstrate the performance of the proposed method on various applications including image smoothing, detail manipulation, HDR tone-mapping, fast edge simplification and video edge-aware processing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7018984]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2396064]]></doi>

<publicationId><![CDATA[7018984]]></publicationId>

<partnum><![CDATA[7018984]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7018984&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7018984]]></pdf>

</document>

<document>

<rank>146</rank>

<title><![CDATA[Understanding How Adolescents with Autism Respond to Facial Expressions in Virtual Reality Environments]]></title>

<authors><![CDATA[Bekele, E.;  Zhi Zheng;  Swanson, A.;  Crittendon, J.;  Warren, Z.;  Sarkar, N.]]></authors>

<affiliations><![CDATA[EECS Dept., Vanderbilt Univ., Nashville, TN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[emotion recognition]]></term>

<term><![CDATA[handicapped aids]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[patient treatment]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Autism]]></term>

<term><![CDATA[Biomedical monitoring]]></term>

<term><![CDATA[Emotion recognition]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Physiology]]></term>

<term><![CDATA[Variable speed drives]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[711]]></spage>

<epage><![CDATA[720]]></epage>

<abstract><![CDATA[Autism Spectrum Disorders (ASD) are characterized by atypical patterns of behaviors and impairments in social communication. Among the fundamental social impairments in the ASD population are challenges in appropriately recognizing and responding to facial expressions. Traditional intervention approaches often require intensive support and well-trained therapists to address core deficits, with many with ASD having tremendous difficulty accessing such care due to lack of available trained therapists as well as intervention costs. As a result, emerging technology such as virtual reality (VR) has the potential to offer useful technology-enabled intervention systems. In this paper, an innovative VR-based facial emotional expression presentation system was developed that allows monitoring of eye gaze and physiological signals related to emotion identification to explore new efficient therapeutic paradigms. A usability study of this new system involving ten adolescents with ASD and ten typically developing adolescents as a control group was performed. The eye tracking and physiological data were analyzed to determine intragroup and intergroup variations of gaze and physiological patterns. Performance data, eye tracking indices and physiological features indicated that there were differences in the way adolescents with ASD process and recognize emotional faces compared to their typically developing peers. These results will be used in the future for an online adaptive VR-based multimodal social interaction system to improve emotion recognition abilities of individuals with ASD.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6479212]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.42]]></doi>

<publicationId><![CDATA[6479212]]></publicationId>

<partnum><![CDATA[6479212]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479212&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479212]]></pdf>

</document>

<document>

<rank>147</rank>

<title><![CDATA[Just Noticeable Distortion Profile for Flat-Shaded 3D Mesh Surfaces]]></title>

<authors><![CDATA[Nader, G.;  Wang, K.;  Hetroy-Wheeler, F.;  Dupont, F.]]></authors>

<affiliations><![CDATA[Georges Nader is with the Universite de Lyon, LIRIS UMR 5205 CNRS, France.(Email: georges.nader@liris.cnrs.fr)]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[It is common that a 3D mesh undergoes some lossy operations (e.g., compression, watermarking and transmission through noisy channels), which can introduce geometric distortions as a change in vertex position. In most cases the end users of 3D meshes are human beings; therefore, it is important to evaluate the visibility of introduced vertex displacement. In this paper we present a model for computing a Just Noticeable Distortion (JND) profile for flat-shaded 3D meshes. The proposed model is based on an experimental study of the properties of the human visual system while observing a flat-shaded 3D mesh surface, in particular the contrast sensitivity function and contrast masking. We first define appropriate local perceptual properties on 3D meshes. We then detail the results of a series of psychophysical experiments where we have measured the threshold needed for a human observer to detect the change in vertex position. These results allow us to compute the JND profile for flat-shaded 3D meshes. The proposed JND model has been evaluated via a subjective experiment, and applied to guide 3D mesh simplification as well as to determine the optimal vertex coordinates quantization level for a 3D model.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7352354]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2507578]]></doi>

<publicationId><![CDATA[7352354]]></publicationId>

<partnum><![CDATA[7352354]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7352354&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352354]]></pdf>

</document>

<document>

<rank>148</rank>

<title><![CDATA[The 2013 VGTC Visualization Technical Achievement Award:Kwan-Liu Ma]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Awards]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xxvi]]></spage>

<epage><![CDATA[xxvi]]></epage>

<abstract><![CDATA[The 2013 VGTC Visualization Technical Achievement Award was presented to Kwan-Liu Ma.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634186]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.204]]></doi>

<publicationId><![CDATA[6634186]]></publicationId>

<partnum><![CDATA[6634186]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634186&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634186]]></pdf>

</document>

<document>

<rank>149</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on the IEEE Conference on Visual Analytics Science and Technology (VAST)]]></title>

<authors><![CDATA[MacEachren, Alan M.;  Miksch, Silvia]]></authors>

<thesaurusterms>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[660]]></spage>

<epage><![CDATA[661]]></epage>

<abstract><![CDATA[The articles in this special section contain selected papers from the IEEE Conference on Visual Analytics Science and Technology (VAST).]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6168456]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.85]]></doi>

<publicationId><![CDATA[6168456]]></publicationId>

<partnum><![CDATA[6168456]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6168456&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168456]]></pdf>

</document>

<document>

<rank>150</rank>

<title><![CDATA[Global Localization from Monocular SLAM on a Mobile Phone]]></title>

<authors><![CDATA[Ventura, J.;  Arth, C.;  Reitmayr, G.;  Schmalstieg, D.]]></authors>

<controlledterms>

<term><![CDATA[SLAM (robots)]]></term>

<term><![CDATA[image sensors]]></term>

<term><![CDATA[pose estimation]]></term>

<term><![CDATA[smart phones]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Global Positioning System]]></term>

<term><![CDATA[Mobile handsets]]></term>

<term><![CDATA[Real-time systems]]></term>

<term><![CDATA[Servers]]></term>

<term><![CDATA[Simultaneous localization and mapping]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[531]]></spage>

<epage><![CDATA[539]]></epage>

<abstract><![CDATA[We propose the combination of a keyframe-based monocular SLAM system and a global localization method. The SLAM system runs locally on a camera-equipped mobile client and provides continuous, relative 6DoF pose estimation as well as keyframe images with computed camera locations. As the local map expands, a server process localizes the keyframes with a pre-made, globally-registered map and returns the global registration correction to the mobile client. The localization result is updated each time a keyframe is added, and observations of global anchor points are added to the client-side bundle adjustment process to further refine the SLAM map registration and limit drift. The end result is a 6DoF tracking and mapping system which provides globally registered tracking in real-time on a mobile device, overcomes the difficulties of localization with a narrow field-of-view mobile phone camera, and is not limited to tracking only in areas covered by the offline reconstruction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6777443]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.27]]></doi>

<publicationId><![CDATA[6777443]]></publicationId>

<partnum><![CDATA[6777443]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777443&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777443]]></pdf>

</document>

<document>

<rank>151</rank>

<title><![CDATA[Symmetry in Scalar Field Topology]]></title>

<authors><![CDATA[Thomas, D.M.;  Natarajan, V.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[topology]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2035]]></spage>

<epage><![CDATA[2044]]></epage>

<abstract><![CDATA[Study of symmetric or repeating patterns in scalar fields is important in scientific data analysis because it gives deep insights into the properties of the underlying phenomenon. Though geometric symmetry has been well studied within areas like shape processing, identifying symmetry in scalar fields has remained largely unexplored due to the high computational cost of the associated algorithms. We propose a computationally efficient algorithm for detecting symmetric patterns in a scalar field distribution by analysing the topology of level sets of the scalar field. Our algorithm computes the contour tree of a given scalar field and identifies subtrees that are similar. We define a robust similarity measure for comparing subtrees of the contour tree and use it to group similar subtrees together. Regions of the domain corresponding to subtrees that belong to a common group are extracted and reported to be symmetric. Identifying symmetry in scalar fields finds applications in visualization, data exploration, and feature detection. We describe two applications in detail: symmetry-aware transfer function design and symmetry-aware isosurface extraction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064967]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.236]]></doi>

<publicationId><![CDATA[6064967]]></publicationId>

<partnum><![CDATA[6064967]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064967&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064967]]></pdf>

</document>

<document>

<rank>152</rank>

<title><![CDATA[Parallel Style-Aware Image Cloning for Artworks]]></title>

<authors><![CDATA[Yandan Zhao;  Xiaogang Jin;  Yingqing Xu;  Hanli Zhao;  Meng Ai;  Kun Zhou]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cloning]]></term>

<term><![CDATA[Coherence]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Real-time systems]]></term>

<term><![CDATA[Semantics]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[229]]></spage>

<epage><![CDATA[240]]></epage>

<abstract><![CDATA[We present style-aware image cloning, a novel image editing approach for artworks, which allows users to seamlessly insert any photorealistic or artificial objects into an artwork to create a new image that shares the same artistic style with the original artwork. To this end, a real-time image transfer algorithm is developed to stylize the cloned object according to a distance metric based on the artistic styles and semantic information. Several interactive functions, such as layering, shadowing, semantic labeling, and direction field editing, are provided to enhance the harmonization of the composite image. Extensive experimental results demonstrate the effectiveness of our method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6893032]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2355221]]></doi>

<publicationId><![CDATA[6893032]]></publicationId>

<partnum><![CDATA[6893032]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6893032&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893032]]></pdf>

</document>

<document>

<rank>153</rank>

<title><![CDATA[Accurate Interactive Visualization of Large Deformations and Variability in Biomedical Image Ensembles]]></title>

<authors><![CDATA[Hermann, M.;  Schunke, A.C.;  Schultz, T.;  Klein, R.]]></authors>

<affiliations><![CDATA[Inst. fur Inf. II, Univ. Bonn, Bonn, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[extrapolation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[shape recognition]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Extrapolation]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Tin]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[708]]></spage>

<epage><![CDATA[717]]></epage>

<abstract><![CDATA[Large image deformations pose a challenging problem for the visualization and statistical analysis of 3D image ensembles which have a multitude of applications in biology and medicine. Simple linear interpolation in the tangent space of the ensemble introduces artifactual anatomical structures that hamper the application of targeted visual shape analysis techniques. In this work we make use of the theory of stationary velocity fields to facilitate interactive non-linear image interpolation and plausible extrapolation for high quality rendering of large deformations and devise an efficient image warping method on the GPU. This does not only improve quality of existing visualization techniques, but opens up a field of novel interactive methods for shape ensemble analysis. Taking advantage of the efficient non-linear 3D image warping, we showcase four visualizations: 1) browsing on-the-fly computed group mean shapes to learn about shape differences between specific classes, 2) interactive reformation to investigate complex morphologies in a single view, 3) likelihood volumes to gain a concise overview of variability and 4) streamline visualization to show variation in detail, specifically uncovering its component tangential to a reference surface. Evaluation on a real world dataset shows that the presented method outperforms the state-of-the-art in terms of visual quality while retaining interactive frame rates. A case study with a domain expert was performed in which the novel analysis and visualization methods are applied on standard model structures, namely skull and mandible of different rodents, to investigate and compare influence of phylogeny, diet and geography on shape. The visualizations enable for instance to distinguish (population-)normal and pathological morphology, assist in uncovering correlation to extrinsic factors and potentially support assessment of model quality.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192678]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467198]]></doi>

<publicationId><![CDATA[7192678]]></publicationId>

<partnum><![CDATA[7192678]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192678&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192678]]></pdf>

</document>

<document>

<rank>154</rank>

<title><![CDATA[Minimally immersive flow visualization]]></title>

<authors><![CDATA[Ebert, D.S.;  Shaw, C.D.]]></authors>

<affiliations><![CDATA[Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Magnetic heads]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[343]]></spage>

<epage><![CDATA[350]]></epage>

<abstract><![CDATA[This paper describes a minimally immersive interactive system for flow visualization of multivariate volumetric data. The system, SFA, uses perceptually motivated rendering to increase the quantity and clarity of information perceived. Proprioception, stereopsis, perceptually motivated shape visualization, and three-dimensional interaction are combined in SFA to allow the three-dimensional volumetric visualization, manipulation, navigation, and analysis of multivariate, time-varying flow data]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[965348]]></arnumber>

<doi><![CDATA[10.1109/2945.965348]]></doi>

<publicationId><![CDATA[965348]]></publicationId>

<partnum><![CDATA[965348]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=965348&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965348]]></pdf>

</document>

<document>

<rank>155</rank>

<title><![CDATA[ResultMaps: Visualization for Search Interfaces]]></title>

<authors><![CDATA[Clarkson, E.;  Desai, K.;  Foley, J.D.]]></authors>

<affiliations><![CDATA[Georgia Tech, Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital libraries]]></term>

<term><![CDATA[query processing]]></term>

<term><![CDATA[search engines]]></term>

<term><![CDATA[trees (mathematics)]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1057]]></spage>

<epage><![CDATA[1064]]></epage>

<abstract><![CDATA[Hierarchical representations are common in digital repositories, yet are not always fully leveraged in their online search interfaces. This work describes ResultMaps, which use hierarchical treemap representations with query string-driven digital library search engines. We describe two lab experiments, which find that ResultsMap users yield significantly better results over a control condition on some subjective measures, and we find evidence that ResultMaps have ancillary benefits via increased understanding of some aspects of repository content. The ResultMap system and experiments contribute an understanding of the benefits-direct and indirect-of the ResultMap approach to repository search visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290712]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.176]]></doi>

<publicationId><![CDATA[5290712]]></publicationId>

<partnum><![CDATA[5290712]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290712&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290712]]></pdf>

</document>

<document>

<rank>156</rank>

<title><![CDATA[Adaptive projection operators in multiresolution scientific visualization]]></title>

<authors><![CDATA[Ohlberger, M.;  Rumpf, M.]]></authors>

<affiliations><![CDATA[Inst. fur Angewandte Math., Freiburg Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[adaptive optics]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[differential equations]]></term>

<term><![CDATA[error analysis]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mathematical operators]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[tensors]]></term>

<term><![CDATA[very large databases]]></term>

<term><![CDATA[visual databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Multigrid methods]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Visual databases]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[344]]></spage>

<epage><![CDATA[364]]></epage>

<abstract><![CDATA[Recently, multiresolution visualization methods have become an indispensable ingredient of real-time interactive postprocessing. The enormous databases, typically coming along with some hierarchical structure, are locally resolved on different levels of detail to achieve a significant savings of CPU and rendering time. In this paper, the method of adaptive projection and the corresponding operators on data functions, respectively, are introduced. They are defined and discussed as mathematically rigorous foundations for multiresolution data analysis. Keeping in mind data from efficient numerical multigrid methods, this approach applies to hierarchical nested grids consisting of elements which are any tensor product of simplices, generated recursively by an arbitrary, finite set of refinement rules from some coarse grid. The corresponding visualization algorithms, e.g. color shading on slices or isosurface rendering, are confined to an appropriate depth-first traversal of the grid hierarchy. A continuous projection of the data onto an adaptive, extracted subgrid is thereby calculated recursively. The presented concept covers different methods of local error measurement, time-dependent data which have to be interpolated from a sequence of key frames, and a tool for local data focusing. Furthermore, it allows for a continuous level of detail]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[765328]]></arnumber>

<doi><![CDATA[10.1109/2945.765328]]></doi>

<publicationId><![CDATA[765328]]></publicationId>

<partnum><![CDATA[765328]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=765328&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=765328]]></pdf>

</document>

<document>

<rank>157</rank>

<title><![CDATA[Uncovering Strengths and Weaknesses of Radial Visualizations---an Empirical Approach]]></title>

<authors><![CDATA[Diehl, S.;  Beck, F.;  Burch, M.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Univ. of Trier, Trier, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[935]]></spage>

<epage><![CDATA[942]]></epage>

<abstract><![CDATA[Radial visualizations play an important role in the information visualization community. But the decision to choose a radial coordinate system is rather based on intuition than on scientific foundations. The empirical approach presented in this paper aims at uncovering strengths and weaknesses of radial visualizations by comparing them to equivalent ones in Cartesian coordinate systems. We identified memorizing positions of visual elements as a generic task when working with visualizations. A first study with 674 participants provides a broad data spectrum for exploring differences between the two visualization types. A second, complementing study with fewer participants focuses on further questions raised by the first study. Our findings document that Cartesian visualizations tend to outperform their radial counterparts especially with respect to answer times. Nonetheless, radial visualization seem to be more appropriate for focusing on a particular data dimension.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613430]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.209]]></doi>

<publicationId><![CDATA[5613430]]></publicationId>

<partnum><![CDATA[5613430]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613430&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613430]]></pdf>

</document>

<document>

<rank>158</rank>

<title><![CDATA[Fast construction of k-nearest neighbor graphs for point clouds]]></title>

<authors><![CDATA[Connor, M.;  Kumar, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Florida State Univ., Tallahassee, FL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[parallel algorithms]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Multicore processing]]></term>

<term><![CDATA[Parallel algorithms]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[599]]></spage>

<epage><![CDATA[608]]></epage>

<abstract><![CDATA[We present a parallel algorithm for k-nearest neighbor graph construction that uses Morton ordering. Experiments show that our approach has the following advantages over existing methods: 1) faster construction of k-nearest neighbor graphs in practice on multicore machines, 2) less space usage, 3) better cache efficiency, 4) ability to handle large data sets, and 5) ease of parallelization and implementation. If the point set has a bounded expansion constant, our algorithm requires one-comparison-based parallel sort of points, according to Morton order plus near-linear additional steps to output the k-nearest neighbor graph.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5383353]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.9]]></doi>

<publicationId><![CDATA[5383353]]></publicationId>

<partnum><![CDATA[5383353]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5383353&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383353]]></pdf>

</document>

<document>

<rank>159</rank>

<title><![CDATA[View-Dependent Adaptive Cloth Simulation with Buckling Compensation]]></title>

<authors><![CDATA[Woojong Koh;  Narain, R.;  O'Brien, J.F.]]></authors>

<affiliations><![CDATA[Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, Berkeley, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[clothing]]></term>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image sensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptation models]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Strain]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1138]]></spage>

<epage><![CDATA[1145]]></epage>

<abstract><![CDATA[This paper describes a method for view-dependent cloth simulation using dynamically adaptive mesh refinement and coarsening. Given a prescribed camera motion, the method adjusts the criteria controlling refinement to account for visibility and apparent size in the camera's view. Objectionable dynamic artifacts are avoided by anticipative refinement and smoothed coarsening, while locking in extremely coarsened regions is inhibited by modifying the material model to compensate for unresolved sub-element buckling. This approach preserves the appearance of detailed cloth throughout the animation while avoiding the wasted effort of simulating details that would not be discernible to the viewer. The computational savings realized by this method increase as scene complexity grows. The approach produces a 2&#x00D7; speed-up for a single character and more than 4&#x00D7; for a small group as compared to view-independent adaptive simulations, and respectively 5&#x00D7; and 9&#x00D7; speed-ups as compared to non-adaptive simulations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7127098]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2446482]]></doi>

<publicationId><![CDATA[7127098]]></publicationId>

<partnum><![CDATA[7127098]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7127098&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7127098]]></pdf>

</document>

<document>

<rank>160</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1512029]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.96]]></doi>

<publicationId><![CDATA[1512029]]></publicationId>

<partnum><![CDATA[1512029]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512029&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512029]]></pdf>

</document>

<document>

<rank>161</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5762830]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.84]]></doi>

<publicationId><![CDATA[5762830]]></publicationId>

<partnum><![CDATA[5762830]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5762830&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5762830]]></pdf>

</document>

<document>

<rank>162</rank>

<title><![CDATA[Alias-free voxelization of geometric objects]]></title>

<authors><![CDATA[Sramek, M.;  Kaufman, A.E.]]></authors>

<affiliations><![CDATA[Inst. of Meas. Sci., Slovak Acad. of Sci., Bratislava, Slovakia]]></affiliations>

<controlledterms>

<term><![CDATA[antialiasing]]></term>

<term><![CDATA[buffer storage]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sampling methods]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Buffer storage]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[251]]></spage>

<epage><![CDATA[267]]></epage>

<abstract><![CDATA[Introduces a new concept for alias-free voxelization of geometric objects based on a voxelization model (V-model). The V-model of an object is its representation in 3D continuous space by a trivariate density function. This function is sampled during the voxelization and the resulting values are stored in a volume buffer. This concept enables us to study general issues of sampling and rendering separately from object-specific design issues. It provides us with a possibility to design such V-models, which are correct from the point of view of both the sampling and rendering, thus leading to both alias-free volumetric representation and alias-free rendered images. We performed numerous experiments with different combinations of V-models and reconstruction techniques. We have shown that the V-model with a Gaussian surface density profile combined with tricubic interpolation and Gabor derivative reconstruction outperforms the previously published technique with a linear density profile. This enables higher fidelity of images rendered from volume data due to increased sharpness of edges and thinner surface patches]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[795216]]></arnumber>

<doi><![CDATA[10.1109/2945.795216]]></doi>

<publicationId><![CDATA[795216]]></publicationId>

<partnum><![CDATA[795216]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=795216&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=795216]]></pdf>

</document>

<document>

<rank>163</rank>

<title><![CDATA[Local Geometric Consensus: A General Purpose Point Pattern-Based Tracking Algorithm]]></title>

<authors><![CDATA[Liming Yang;  Normand, J.-M.;  Moreau, G.]]></authors>

<affiliations><![CDATA[Ecole Centrale de Nantes, Nantes, France]]></affiliations>

<controlledterms>

<term><![CDATA[image matching]]></term>

<term><![CDATA[object tracking]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Containers]]></term>

<term><![CDATA[Generators]]></term>

<term><![CDATA[Jitter]]></term>

<term><![CDATA[Pattern matching]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1299]]></spage>

<epage><![CDATA[1308]]></epage>

<abstract><![CDATA[We present a method which can quickly and robustly match 2D and 3D point patterns based on their sole spatial distribution, but it can also handle other cues if available. This method can be easily adapted to many transformations such as similarity transformations in 2D/3D, and affine and perspective transformations in 2D. It is based on local geometric consensus among several local matchings and a refinement scheme. We provide two implementations of this general scheme, one for the 2D homography case (which can be used for marker or image tracking) and one for the 3D similarity case. We demonstrate the robustness and speed performance of our proposal on both synthetic and real images and show that our method can be used to augment any (textured/textureless) planar objects but also 3D objects.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7165652]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2459897]]></doi>

<publicationId><![CDATA[7165652]]></publicationId>

<partnum><![CDATA[7165652]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7165652&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165652]]></pdf>

</document>

<document>

<rank>164</rank>

<title><![CDATA[Time Dependent Processing in a Parallel Pipeline Architecture]]></title>

<authors><![CDATA[Biddiscombe, J.;  Geveci, B.;  Martin, K.;  Moreland, K.;  Thompson, D.]]></authors>

<affiliations><![CDATA[Swiss Nat. Supercomput. Centre, Manno]]></affiliations>

<controlledterms>

<term><![CDATA[data acquisition]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[parallel architectures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed computing]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Software algorithms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1376]]></spage>

<epage><![CDATA[1383]]></epage>

<abstract><![CDATA[Pipeline architectures provide a versatile and efficient mechanism for constructing visualizations, and they have been implemented in numerous libraries and applications over the past two decades. In addition to allowing developers and users to freely combine algorithms, visualization pipelines have proven to work well when streaming data and scale well on parallel distributed- memory computers. However, current pipeline visualization frameworks have a critical flaw: they are unable to manage time varying data. As data flows through the pipeline, each algorithm has access to only a single snapshot in time of the data. This prevents the implementation of algorithms that do any temporal processing such as particle tracing; plotting over time; or interpolation, fitting, or smoothing of time series data. As data acquisition technology improves, as simulation time-integration techniques become more complex, and as simulations save less frequently and regularly, the ability to analyze the time-behavior of data becomes more important. This paper describes a modification to the traditional pipeline architecture that allows it to accommodate temporal algorithms. Furthermore, the architecture allows temporal algorithms to be used in conjunction with algorithms expecting a single time snapshot, thus simplifying software design and allowing adoption into existing pipeline frameworks. Our architecture also continues to work well in parallel distributed-memory environments. We demonstrate our architecture by modifying the popular VTK framework and exposing the functionality to the ParaView application. We use this framework to apply time-dependent algorithms on large data with a parallel cluster computer and thereby exercise a functionality that previously did not exist.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376164]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70600]]></doi>

<publicationId><![CDATA[4376164]]></publicationId>

<partnum><![CDATA[4376164]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376164&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376164]]></pdf>

</document>

<document>

<rank>165</rank>

<title><![CDATA[GosperMap: Using a Gosper Curve for Laying Out Hierarchical Data]]></title>

<authors><![CDATA[Auber, D.;  Huet, C.;  Lambert, A.;  Renoust, B.;  Sallaberry, A.;  Saulnier, A.]]></authors>

<affiliations><![CDATA[LaBRI, Univ. Bordeaux I, Talence, France]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human factors]]></term>

<term><![CDATA[tree data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Fractals]]></term>

<term><![CDATA[Labeling]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Vegetation]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1820]]></spage>

<epage><![CDATA[1832]]></epage>

<abstract><![CDATA[The emergence of very large hierarchies that result from the increase in available data raises many problems of visualization and navigation. On data sets of such scale, classical graph drawing methods do not take advantage of certain human cognitive skills such as shape recognition. These cognitive skills could make it easier to remember the global structure of the data. In this paper, we propose a method that is based on the use of nested irregular shapes. We name it GosperMap as we rely on the use of a Gosper Curve to generate these shapes. By employing human perception mechanisms that were developed by handling, for example, cartographic maps, this technique facilitates the visualization and navigation of a hierarchy. An algorithm has been designed to preserve region containment according to the hierarchy and to set the leaves' sizes proportionally to a property, in such a way that the size of nonleaf regions corresponds to the sum of their children's sizes. Moreover, the input ordering of the hierarchy's nodes is preserved, i.e., the areas that represent two consecutive children of a node in the hierarchy are adjacent to one another. This property is especially useful because it guarantees some stability in our algorithm. We illustrate our technique by providing visualization examples of the repartition of tax money in the US over time. Furthermore, we validate the use of the GosperMap in a professional documentation context and show the stability and ease of memorization for this type of map.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6532285]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.91]]></doi>

<publicationId><![CDATA[6532285]]></publicationId>

<partnum><![CDATA[6532285]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6532285&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6532285]]></pdf>

</document>

<document>

<rank>166</rank>

<title><![CDATA[Comparison of Four Freely Available Frameworks for Image Processing and Visualization That Use ITK]]></title>

<authors><![CDATA[Bitter, I.;  Van Uitert, R.;  Wolf, I.;  Ibanez, L.;  Kuhnigk, J.-M.]]></authors>

<affiliations><![CDATA[Claron Technol. Inc., Toronto, Ont.]]></affiliations>

<controlledterms>

<term><![CDATA[C++ language]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[software libraries]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Automatic programming]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Functional programming]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Software prototyping]]></term>

<term><![CDATA[User interfaces]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[483]]></spage>

<epage><![CDATA[493]]></epage>

<abstract><![CDATA[Most image processing and visualization applications allow users to configure computation parameters and manipulate the resulting visualizations. SCIRun, VoIView, MeVisLab, and the Medical Interaction Toolkit (MITK) are four image processing and visualization frameworks that were built for these purposes. All frameworks are freely available and all allow the use of the ITK C++ library. In this paper, the benefits and limitations of each visualization framework are presented to aid both application developers and users in the decision of which framework may be best to use for their application. The analysis is based on more than 50 evaluation criteria, functionalities, and example applications. We report implementation times for various steps in the creation of a reference application in each of the compared frameworks. The data-flow programming frameworks, SCIRun and MeVisLab, were determined to be best for developing application prototypes, while VoIView was advantageous for nonautomatic end-user applications based on existing ITK functionalities, and MITK was preferable for automated end-user applications that might include new ITK classes specifically designed for the application]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4297688]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1001]]></doi>

<publicationId><![CDATA[4297688]]></publicationId>

<partnum><![CDATA[4297688]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297688&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297688]]></pdf>

</document>

<document>

<rank>167</rank>

<title><![CDATA[ISMAR 2015 Steering Committee Members]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[xi]]></spage>

<epage><![CDATA[xi]]></epage>

<abstract><![CDATA[Presents a listing of the conference steering committee members.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7283724]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2472777]]></doi>

<publicationId><![CDATA[7283724]]></publicationId>

<partnum><![CDATA[7283724]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7283724&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7283724]]></pdf>

</document>

<document>

<rank>168</rank>

<title><![CDATA[Effect of Text Outline and Contrast Polarity on AR Text Readability in Industrial Lighting]]></title>

<authors><![CDATA[Gattullo, M.;  Uva, A.E.;  Fiorentino, M.;  Monno, G.]]></authors>

<affiliations><![CDATA[Dept. of Mech., Math. & Manage., Polytech. Inst. of Bari, Bari, Italy]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Optical sensors]]></term>

<term><![CDATA[Standards]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[638]]></spage>

<epage><![CDATA[651]]></epage>

<abstract><![CDATA[Text readability with augmented reality head-worn displays is critical and at present time, there are no standard guidelines to follow. The readability depends mainly on background lighting, display technology (i.e., OST: optical see-through or VST: video see-through), and text style (e.g., plain text, outline or billboard). In this work, we addressed the readability limits for industrial activities. We experimented the effects of two background illuminances levels (1,000 lx for very fine basic industrial tasks and 4,000 lx for fine machining), two commercially available head-worn display technologies, variable outline widths and contrast polarity of text. We analyzed the performance of 12 subjects by collecting about 3,400 measurements using a specific test application and followed by qualitative interviews. With high illuminances, VST performed better than OST, regardless of contrast polarity and outline width. We found that negative contrast polarity is preferable with VST, and that just a minimum outline (1 px) around black text is optimal. On the contrary, positive contrast polarity should be used with OST and outline is not effective. Therefore, we evaluated the usage limits of the OST by sampling its contrast sensitivity function.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6994851]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2385056]]></doi>

<publicationId><![CDATA[6994851]]></publicationId>

<partnum><![CDATA[6994851]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6994851&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6994851]]></pdf>

</document>

<document>

<rank>169</rank>

<title><![CDATA[An Automated Approach for Slicing Plane Placement in Visual Data Analysis]]></title>

<authors><![CDATA[Obermaier, H.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1403]]></spage>

<epage><![CDATA[1414]]></epage>

<abstract><![CDATA[Effective display and visual analysis of complex 3D data is a challenging task. Occlusions, overlaps, and projective distortions-as frequently caused by typical 3D rendering techniques-can be major obstacles to unambiguous and robust data analysis. Slicing planes are a ubiquitous tool to resolve several of these issues. They act as simple clipping geometry to provide clear cut-away views of the data. We propose to enhance the visualization and analysis process by providing methods for automatic placement of such slicing planes based on local optimization of gradient vector flow. The final obtained slicing planes maximize the total amount of information displayed with respect to a pre-specified importance function. We demonstrate how such automated slicing plane placement is able to support and enrich 3D data visualization and analysis in multiple scenarios, such as volume or surface rendering, and evaluate its performance in several benchmark data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7063265]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2414455]]></doi>

<publicationId><![CDATA[7063265]]></publicationId>

<partnum><![CDATA[7063265]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7063265&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7063265]]></pdf>

</document>

<document>

<rank>170</rank>

<title><![CDATA[Coherency-Based Curve Compression for High-Order Finite Element Model Visualization]]></title>

<authors><![CDATA[Bock, A.;  Sunden, E.;  Bingchen Liu;  Wunsche, B.;  Ropinski, T.]]></authors>

<affiliations><![CDATA[Sci. Visualization Group, Linkoping Univ., Linkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[data compression]]></term>

<term><![CDATA[data reduction]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Splines (mathematics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2315]]></spage>

<epage><![CDATA[2324]]></epage>

<abstract><![CDATA[Finite element (FE) models are frequently used in engineering and life sciences within time-consuming simulations. In contrast with the regular grid structure facilitated by volumetric data sets, as used in medicine or geosciences, FE models are defined over a non-uniform grid. Elements can have curved faces and their interior can be defined through high-order basis functions, which pose additional challenges when visualizing these models. During ray-casting, the uniformly distributed sample points along each viewing ray must be transformed into the material space defined within each element. The computational complexity of this transformation makes a straightforward approach inadequate for interactive data exploration. In this paper, we introduce a novel coherency-based method which supports the interactive exploration of FE models by decoupling the expensive world-to-material space transformation from the rendering stage, thereby allowing it to be performed within a precomputation stage. Therefore, our approach computes view-independent proxy rays in material space, which are clustered to facilitate data reduction. During rendering, these proxy rays are accessed, and it becomes possible to visually analyze high-order FE models at interactive frame rates, even when they are time-varying or consist of multiple modalities. Within this paper, we provide the necessary background about the FE data, describe our decoupling method, and introduce our interactive rendering algorithm. Furthermore, we provide visual results and analyze the error introduced by the presented approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327236]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.206]]></doi>

<publicationId><![CDATA[6327236]]></publicationId>

<partnum><![CDATA[6327236]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327236&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327236]]></pdf>

</document>

<document>

<rank>171</rank>

<title><![CDATA[Message from the Editor-in-Chief]]></title>

<authors><![CDATA[Lin, Ming Lin]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[ix]]></spage>

<epage><![CDATA[ix]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6064929]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.221]]></doi>

<publicationId><![CDATA[6064929]]></publicationId>

<partnum><![CDATA[6064929]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064929&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064929]]></pdf>

</document>

<document>

<rank>172</rank>

<title><![CDATA[Perception-based fast rendering and antialiasing of walkthrough sequences]]></title>

<authors><![CDATA[Myszkowski, K.;  Rokita, P.;  Tawara, T.]]></authors>

<affiliations><![CDATA[Max-Planck-Inst. for Comput. Sci., Saarbrucken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[antialiasing]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[motion compensation]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[software metrics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Spatiotemporal phenomena]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[360]]></spage>

<epage><![CDATA[379]]></epage>

<abstract><![CDATA[We consider accelerated rendering of high quality walkthrough animation sequences along predefined paths. To improve rendering performance, we use a combination of a hybrid ray tracing and image-based rendering (IBR) technique and a novel perception-based antialiasing technique. In our rendering solution, we derive as many pixels as possible using inexpensive IBR techniques without affecting the animation quality. A perception-based spatiotemporal animation quality metric (AQM) is used to automatically guide such a hybrid rendering. The image flow (IF) obtained as a byproduct of the IBR computation is an integral part of the AQM. The final animation quality is enhanced by an efficient spatiotemporal antialiasing which utilizes the IF to perform a motion-compensated filtering. The filter parameters have been tuned using the AQM predictions of animation quality as perceived by the human observer. These parameters adapt locally to the visual pattern velocity]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[895880]]></arnumber>

<doi><![CDATA[10.1109/2945.895880]]></doi>

<publicationId><![CDATA[895880]]></publicationId>

<partnum><![CDATA[895880]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=895880&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=895880]]></pdf>

</document>

<document>

<rank>173</rank>

<title><![CDATA[Fast evolution of image manifolds and application to filtering and segmentation in 3D medical images]]></title>

<authors><![CDATA[Deschamps, T.;  Malladi, R.;  Ravve, I.]]></authors>

<affiliations><![CDATA[Dept. of Math., California Univ., Berkeley, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer vision]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[differential equations]]></term>

<term><![CDATA[diffusion]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[finite difference methods]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image denoising]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[medical image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Convergence]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Noise reduction]]></term>

<term><![CDATA[Stability]]></term>

<term><![CDATA[Visual system]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[525]]></spage>

<epage><![CDATA[535]]></epage>

<abstract><![CDATA[In many instances, numerical integration of space-scale PDEs is the most time consuming operation of image processing. This is because the scale step is limited by conditional stability of explicit schemes. We introduce the unconditionally stable semiimplicit linearized difference scheme that is fashioned after additive operator split (AOS) [Weickert, J. et al. (1998)], [Goldenberg, R et al., (2001)] for Beltrami and the subjective surface computation. The Beltrami flow [Kimmel, R. (1997) (1999)], [Sochen, N. et al. (1998)], is one of the most effective denoising algorithms in image processing. For gray-level images, we show that the flow equation can be arranged in an advection-diffusion form, revealing the edge-enhancing properties of this flow. This also suggests the application of AOS method for faster convergence. The subjective surface [Sarti, A. et al. (2002)] deals with constructing a perceptually meaningful interpretation from partial image data by mimicking the human visual system. However, initialization of the surface is critical for the final result and its main drawbacks are very slow convergence and the huge number of iterations required. We first show that the governing equation for the subjective surface flow can be rearranged in an AOS implementation, providing a near real-time solution to the shape completion problem in 2D and 3D. Then, we devise a new initialization paradigm where we first "condition" the viewpoint surface using the fast-marching algorithm. We compare the original method with our new algorithm on several examples of real 3D medical images, thus revealing the improvement achieved.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1310278]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.26]]></doi>

<publicationId><![CDATA[1310278]]></publicationId>

<partnum><![CDATA[1310278]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310278&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310278]]></pdf>

</document>

<document>

<rank>174</rank>

<title><![CDATA[Visual Exploration of Complex Time-Varying Graphs]]></title>

<authors><![CDATA[Kumar, G.;  Garland, M.]]></authors>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Heuristic algorithms]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Stock markets]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[805]]></spage>

<epage><![CDATA[812]]></epage>

<abstract><![CDATA[Many graph drawing and visualization algorithms, such as force-directed layout and line-dot rendering, work very well on relatively small and sparse graphs. However, they often produce extremely tangled results and exhibit impractical running times for highly non-planar graphs with large edge density. And very few graph layout algorithms support dynamic time-varying graphs; applying them independently to each frame produces distracting temporally incoherent visualizations. We have developed a new visualization technique based on a novel approach to hierarchically structuring dense graphs via stratification. Using this structure, we formulate a hierarchical force-directed layout algorithm that is both efficient and produces quality graph layouts. The stratification of the graph also allows us to present views of the data that abstract away many small details of its structure. Rather than displaying all edges and nodes at once, resulting in a convoluted rendering, we present an interactive tool that filters edges and nodes using the graph hierarchy and allows users to drill down into the graph for details. Our layout algorithm also accommodates time-varying graphs in a natural way, producing a temporally coherent animation that can be used to analyze and extract trends from dynamic graph data. For example, we demonstrate the use of our method to explore financial correlation data for the U.S. stock market in the period from 1990 to 2005. The user can easily analyze the time-varying correlation graph of the market, uncovering information such as market sector trends, representative stocks for portfolio construction, and the interrelationship of stocks over time.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015433]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.193]]></doi>

<publicationId><![CDATA[4015433]]></publicationId>

<partnum><![CDATA[4015433]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015433&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015433]]></pdf>

</document>

<document>

<rank>175</rank>

<title><![CDATA[A Study on Dual-Scale Data Charts]]></title>

<authors><![CDATA[Isenberg, P.;  Bezerianos, A.;  Dragicevic, P.;  Fekete, J.]]></authors>

<controlledterms>

<term><![CDATA[charts]]></term>

<term><![CDATA[data handling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Quantization]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Terminology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2469]]></spage>

<epage><![CDATA[2478]]></epage>

<abstract><![CDATA[We present the results of a user study that compares different ways of representing Dual-Scale data charts. Dual-Scale charts incorporate two different data resolutions into one chart in order to emphasize data in regions of interest or to enable the comparison of data from distant regions. While some design guidelines exist for these types of charts, there is currently little empirical evidence on which to base their design. We fill this gap by discussing the design space of Dual-Scale cartesian-coordinate charts and by experimentally comparing the performance of different chart types with respect to elementary graphical perception tasks such as comparing lengths and distances. Our study suggests that cut-out charts which include collocated full context and focus are the best alternative, and that superimposed charts in which focus and context overlap on top of each other should be avoided.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065014]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.160]]></doi>

<publicationId><![CDATA[6065014]]></publicationId>

<partnum><![CDATA[6065014]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065014&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065014]]></pdf>

</document>

<document>

<rank>176</rank>

<title><![CDATA[Automatic Construction of Quad-Based Subdivision Surfaces Using Fitmaps]]></title>

<authors><![CDATA[Panozzo, D.;  Puppo, E.;  Tarini, M.;  Pietroni, N.;  Cignoni, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Univ. of Genoa, Genoa, Italy]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1510]]></spage>

<epage><![CDATA[1520]]></epage>

<abstract><![CDATA[We present an automatic method to produce a Catmull-Clark subdivision surface that fits a given input mesh. Its control mesh is coarse and adaptive, and it is obtained by simplifying an initial mesh at high resolution. Simplification occurs progressively via local operators and addresses both quality of surface and faithfulness to the input shape throughout the whole process. The method is robust and performs well on rather complex shapes. Displacement mapping or normal mapping can be applied to approximate the input shape arbitrarily well.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5708143]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.28]]></doi>

<publicationId><![CDATA[5708143]]></publicationId>

<partnum><![CDATA[5708143]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5708143&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708143]]></pdf>

</document>

<document>

<rank>177</rank>

<title><![CDATA[CAVE and fishtank virtual-reality displays: a qualitative and quantitative comparison]]></title>

<authors><![CDATA[Demiralp, C.;  Jackson, C.D.;  Karelitz, D.B.;  Zhang, S.;  Laidlaw, D.H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Brown Univ., Providence, RI]]></affiliations>

<controlledterms>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[user interfaces]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brightness]]></term>

<term><![CDATA[Diffusion tensor imaging]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Head]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Object detection]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[323]]></spage>

<epage><![CDATA[330]]></epage>

<abstract><![CDATA[We present the results from a qualitative and quantitative user study comparing fishtank virtual-reality (VR) and CAVE displays. The results of the qualitative study show that users preferred the fishtank VR display to the CAVE system for our scientific visualization application because of perceived higher resolution, brightness and crispness of imagery, and comfort of use. The results of the quantitative study show that users performed an abstract visual search task significantly more quickly and more accurately on the fishtank VR display system than in the CAVE. The same study also showed that visual context had no significant effect on task performance for either of the platforms. We suggest that fishtank VR displays are more effective than CAVEs for applications in which the task occurs outside the user's reference frame, the user views and manipulates the virtual world from the outside in, and the size of the virtual object that the user interacts with is smaller than the user's body and fits into the fishtank VR display. The results of both studies support this proposition]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1608019]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.42]]></doi>

<publicationId><![CDATA[1608019]]></publicationId>

<partnum><![CDATA[1608019]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1608019&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608019]]></pdf>

</document>

<document>

<rank>178</rank>

<title><![CDATA[Comparing Four Approaches to Generalized Redirected Walking: Simulation and Live User Data]]></title>

<authors><![CDATA[Hodgson, E.;  Bachmann, E.]]></authors>

<affiliations><![CDATA[Smale Interactive Visualization Center, Miami Univ., Miami, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[navigation]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Orbits]]></term>

<term><![CDATA[Space vehicles]]></term>

<term><![CDATA[Tracking]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[634]]></spage>

<epage><![CDATA[643]]></epage>

<abstract><![CDATA[Redirected walking algorithms imperceptibly rotate a virtual scene and scale movements to guide users of immersive virtual environment systems away from tracking area boundaries. These distortions ideally permit users to explore large and potentially unbounded virtual worlds while walking naturally through a physically limited space. Estimates of the physical space required to perform effective redirected walking have been based largely on the ability of humans to perceive the distortions introduced by redirected walking and have not examined the impact the overall steering strategy used. This work compares four generalized redirected walking algorithms, including Steer-to-Center, Steer-to-Orbit, Steer-to-Multiple-Targets and Steer-to-Multiple+Center. Two experiments are presented based on simulated navigation as well as live-user navigation carried out in a large immersive virtual environment facility. Simulations were conducted with both synthetic paths and previously-logged user data. Primary comparison metrics include mean and maximum distances from the tracking area center for each algorithm, number of wall contacts, and mean rates of redirection. Results indicated that Steer-to-Center out-performed all other algorithms relative to these metrics. Steer-to-Orbit also performed well in some circumstances.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479192]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.28]]></doi>

<publicationId><![CDATA[6479192]]></publicationId>

<partnum><![CDATA[6479192]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479192&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479192]]></pdf>

</document>

<document>

<rank>179</rank>

<title><![CDATA[Designing pixel-oriented visualization techniques: theory and applications]]></title>

<authors><![CDATA[Keim, D.A.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Sci., Halle Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Artificial intelligence]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Design optimization]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Machine learning]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Statistical analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[59]]></spage>

<epage><![CDATA[78]]></epage>

<abstract><![CDATA[Visualization techniques are of increasing importance in exploring and analyzing large amounts of multidimensional information. One important class of visualization techniques which is particularly interesting for visualizing very large multidimensional data sets is the class of pixel-oriented techniques. The basic idea of pixel-oriented visualization techniques is to represent as many data objects as possible on the screen at the same time by mapping each data value to a pixel of the screen and arranging the pixels adequately. A number of different pixel-oriented visualization techniques have been proposed in recent years and it has been shown that the techniques are useful for visual data exploration in a number of different application contexts. In this paper, we discuss a number of issues which are important in developing pixel-oriented visualization techniques. The major goal of this article is to provide a formal basis of pixel-oriented visualization techniques and show that the design decisions in developing them can be seen as solutions of well-defined optimization problems. This is true for the mapping of the data values to colors, the arrangement of pixels inside the subwindows, the shape of the subwindows, and the ordering of the dimension subwindows. The paper also discusses the design issues of special variants of pixel-oriented techniques for visualizing large spatial data sets]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[841121]]></arnumber>

<doi><![CDATA[10.1109/2945.841121]]></doi>

<publicationId><![CDATA[841121]]></publicationId>

<partnum><![CDATA[841121]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=841121&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=841121]]></pdf>

</document>

<document>

<rank>180</rank>

<title><![CDATA[Signed distance computation using the angle weighted pseudonormal]]></title>

<authors><![CDATA[Baerentzen, J.A.;  Aanaes, H.]]></authors>

<affiliations><![CDATA[Informatics & Math. Modeling Dept., Tech. Univ. Denmark, Lyngby, Denmark]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Robustness]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[243]]></spage>

<epage><![CDATA[253]]></epage>

<abstract><![CDATA[The normals of closed, smooth surfaces have long been used to determine whether a point is inside or outside such a surface. It is tempting to also use this method for polyhedra represented as triangle meshes. Unfortunately, this is not possible since, at the vertices and edges of a triangle mesh, the surface is not C<sup>1</sup> continuous, hence, the normal is undefined at these loci. In this paper, we undertake to show that the angle weighted pseudonormal (originally proposed by Thurmer and Wuthrich and independently by Sequin) has the important property that it allows us to discriminate between points that are inside and points that are outside a mesh, regardless of whether a mesh vertex, edge, or face is the closest feature. This inside-outside information is usually represented as the sign in the signed distance to the mesh. In effect, our result shows that this sign can be computed as an integral part of the distance computation. Moreover, it provides an additional argument in favor of the angle weighted pseudonormals being the natural extension of the face normals. Apart from the theoretical results, we also propose a simple and efficient algorithm for computing the signed distance to a closed C<sup>0</sup> mesh. Experiments indicate that the sign computation overhead when running this algorithm is almost negligible.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1407857]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.49]]></doi>

<publicationId><![CDATA[1407857]]></publicationId>

<partnum><![CDATA[1407857]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1407857&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407857]]></pdf>

</document>

<document>

<rank>181</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1512010]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.94]]></doi>

<publicationId><![CDATA[1512010]]></publicationId>

<partnum><![CDATA[1512010]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512010&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512010]]></pdf>

</document>

<document>

<rank>182</rank>

<title><![CDATA[Interactive display of large NURBS models]]></title>

<authors><![CDATA[Subodh Kumar;  Manocha, D.;  Lastra, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Johns Hopkins Univ., Baltimore, MD, USA]]></affiliations>

<controlledterms>

<term><![CDATA[CAD]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[parallel algorithms]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[splines (mathematics)]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Coherence]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[Surface cracks]]></term>

<term><![CDATA[Surface fitting]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface topography]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[323]]></spage>

<epage><![CDATA[336]]></epage>

<abstract><![CDATA[We present algorithms for interactive rendering of large-scale NURBS models. The algorithms convert the NURBS surfaces to Bezier surfaces, tessellate each Bezier surface into triangles, and render them using the triangle-rendering capabilities common to current graphics systems. We present algorithms for computing tight bounds on surface properties in order to generate high quality tessellation of Bezier surfaces. We introduce enhanced visibility determination techniques and present methods to make efficient use of coherence between successive frames. In addition, we also discuss issues in parallelization of these techniques. The algorithm also avoids polygonization anomalies like cracks. Our algorithms work well in practice and, on high-end graphics systems, are able to display models described using thousands of Bezier surfaces at interactive frame rates]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[556501]]></arnumber>

<doi><![CDATA[10.1109/2945.556501]]></doi>

<publicationId><![CDATA[556501]]></publicationId>

<partnum><![CDATA[556501]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=556501&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556501]]></pdf>

</document>

<document>

<rank>183</rank>

<title><![CDATA[[Inside back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6238454]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.155]]></doi>

<publicationId><![CDATA[6238454]]></publicationId>

<partnum><![CDATA[6238454]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6238454&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6238454]]></pdf>

</document>

<document>

<rank>184</rank>

<title><![CDATA[Graph Visualization Techniques for Web Clustering Engines]]></title>

<authors><![CDATA[Di Giacomo, E.;  Didimo, W.;  Grilli, L.;  Liotta, G.]]></authors>

<affiliations><![CDATA[Dipt. di Ingegneria Elettronica e dell''Informazione, Univ. degli Studi di Perugia]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[information retrieval]]></term>

<term><![CDATA[search engines]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphical user interfaces]]></term>

<term><![CDATA[Organizing]]></term>

<term><![CDATA[Search engines]]></term>

<term><![CDATA[Software systems]]></term>

<term><![CDATA[Tree data structures]]></term>

<term><![CDATA[User interfaces]]></term>

<term><![CDATA[Web pages]]></term>

<term><![CDATA[Web search]]></term>

<term><![CDATA[Web sites]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[294]]></spage>

<epage><![CDATA[304]]></epage>

<abstract><![CDATA[One of the most challenging issues in mining information from the World Wide Web is the design of systems that present the data to the end user by clustering them into meaningful semantic categories. We show that the analysis of the results of a clustering engine can significantly take advantage of enhanced graph drawing and visualization techniques. We propose a graph-based user interface for Web clustering engines that makes it possible for the user to explore and visualize the different semantic categories and their relationships at the desired level of detail]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4069238]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.40]]></doi>

<publicationId><![CDATA[4069238]]></publicationId>

<partnum><![CDATA[4069238]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4069238&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069238]]></pdf>

</document>

<document>

<rank>185</rank>

<title><![CDATA[Complex character positioning based on a compatible flow model of multiple supports]]></title>

<authors><![CDATA[Boulic, R.;  Mas-Sanso, R.;  Thalmann, D.]]></authors>

<affiliations><![CDATA[Comput. Graphics Lab., Swiss Fed. Inst. of Technol., Lausanne, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[kinematics]]></term>

<term><![CDATA[position control]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[End effectors]]></term>

<term><![CDATA[Gravity]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Kinematics]]></term>

<term><![CDATA[Kinetic theory]]></term>

<term><![CDATA[Position control]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Torque control]]></term>

<term><![CDATA[Weight control]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[245]]></spage>

<epage><![CDATA[261]]></epage>

<abstract><![CDATA[We present a posture design paradigm for the positioning of complex characters. It is illustrated here on human figures. We exploit the inverse kinetics technique which allows the center of mass position control for postures with either single or multiple supports. For the multiple support case, we introduce a compatible flow model of the supporting influence. With this approach, we are able to handle continuous modification of the support distribution. By construction, inverse kinetics presents the same control architecture as inverse kinematics, and thus, it shows equivalent computing cost and similar intuitive concepts. Furthermore, inverse kinetics for the center of mass and inverse kinematics for fixed end effecters can be combined to generate a posture displaying static balance, goal oriented features, and an additional gravity optimization]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[620491]]></arnumber>

<doi><![CDATA[10.1109/2945.620491]]></doi>

<publicationId><![CDATA[620491]]></publicationId>

<partnum><![CDATA[620491]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=620491&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620491]]></pdf>

</document>

<document>

<rank>186</rank>

<title><![CDATA[Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis]]></title>

<authors><![CDATA[Dutta, S.;  Han-Wei Shen]]></authors>

<controlledterms>

<term><![CDATA[Gaussian processes]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[mixture models]]></term>

<term><![CDATA[object tracking]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Target tracking]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[837]]></spage>

<epage><![CDATA[846]]></epage>

<abstract><![CDATA[Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192664]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467436]]></doi>

<publicationId><![CDATA[7192664]]></publicationId>

<partnum><![CDATA[7192664]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192664&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192664]]></pdf>

</document>

<document>

<rank>187</rank>

<title><![CDATA[Unbiased Sampling and Meshing of Isosurfaces]]></title>

<authors><![CDATA[Dong-Ming Yan;  Wallner, J.;  Wonka, P.]]></authors>

<affiliations><![CDATA[KAUST, Thuwal, Saudi Arabia]]></affiliations>

<controlledterms>

<term><![CDATA[Monte Carlo methods]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[sampling methods]]></term>

<term><![CDATA[stochastic processes]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Density functional theory]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Monte Carlo methods]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1579]]></spage>

<epage><![CDATA[1589]]></epage>

<abstract><![CDATA[In this paper, we present a new technique to generate unbiased samples on isosurfaces. An isosurface, F(x; y; z) = c, of a function, F, is implicitly defined by trilinear interpolation of background grid points. The key idea of our approach is that of treating the isosurface within a grid cell as a graph (height) function in one of the three coordinate axis directions, restricted to where the slope is not too high, and integrating / sampling from each of these three. We use this unbiased sampling algorithm for applications in Monte Carlo integration, Poisson-disk sampling, and isosurface meshing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6811174]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2322357]]></doi>

<publicationId><![CDATA[6811174]]></publicationId>

<partnum><![CDATA[6811174]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6811174&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6811174]]></pdf>

</document>

<document>

<rank>188</rank>

<title><![CDATA[Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces]]></title>

<authors><![CDATA[Butkiewicz, T.;  Stevens, A.H.]]></authors>

<affiliations><![CDATA[Center for Coastal & Ocean Mapping, Univ. of New Hampshire, Durham, NH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Sea surface]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[926]]></spage>

<epage><![CDATA[934]]></epage>

<abstract><![CDATA[Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudo-contour lines induced by banded color scales convey the same benefits.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7194846]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467962]]></doi>

<publicationId><![CDATA[7194846]]></publicationId>

<partnum><![CDATA[7194846]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7194846&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194846]]></pdf>

</document>

<document>

<rank>189</rank>

<title><![CDATA[Interactive Visual Optimization and Analysis for RFID Benchmarking]]></title>

<authors><![CDATA[Yingcai Wu;  Ka-Kei Chung;  Huamin Qu;  Xiaoru Yuan;  Cheung, S.C.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[radiofrequency identification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data engineering]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Instruments]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[RFID tags]]></term>

<term><![CDATA[Radio frequency]]></term>

<term><![CDATA[Radiofrequency identification]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1335]]></spage>

<epage><![CDATA[1342]]></epage>

<abstract><![CDATA[Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290746]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.156]]></doi>

<publicationId><![CDATA[5290746]]></publicationId>

<partnum><![CDATA[5290746]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290746&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290746]]></pdf>

</document>

<document>

<rank>190</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5331923]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.3]]></doi>

<publicationId><![CDATA[5331923]]></publicationId>

<partnum><![CDATA[5331923]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5331923&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331923]]></pdf>

</document>

<document>

<rank>191</rank>

<title><![CDATA[Uncluttering Graph Layouts Using Anisotropic Diffusion and Mass Transport]]></title>

<authors><![CDATA[Frishman, Y.;  Tal, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Technion - Israel Inst. of Technol., Haifa, Israel]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Evolution (biology)]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Space heating]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[777]]></spage>

<epage><![CDATA[788]]></epage>

<abstract><![CDATA[Many graph layouts include very dense areas, making the layout difficult to understand. In this paper, we propose a technique for modifying an existing layout in order to reduce the clutter in dense areas. A physically inspired evolution process based on a modified heat equation is used to create an improved layout density image, making better use of available screen space. Using results from optimal mass transport problems, a warp to the improved density image is computed. The graph nodes are displaced according to the warp. The warp maintains the overall structure of the graph, thus limiting disturbances to the mental map, while reducing the clutter in dense areas of the layout. The complexity of the algorithm depends mainly on the resolution of the image visualizing the graph and is linear in the size of the graph. This allows scaling the computation according to required running times. It is demonstrated how the algorithm can be significantly accelerated using a graphics processing unit (GPU), resulting in the ability to handle large graphs in a matter of seconds. Results on several layout algorithms and applications are demonstrated.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4967578]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.55]]></doi>

<publicationId><![CDATA[4967578]]></publicationId>

<partnum><![CDATA[4967578]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4967578&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967578]]></pdf>

</document>

<document>

<rank>192</rank>

<title><![CDATA[Visibility Histograms and Visibility-Driven Transfer Functions]]></title>

<authors><![CDATA[Correa, C.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Attenuation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feedback]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Process design]]></term>

<term><![CDATA[Quality management]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[192]]></spage>

<epage><![CDATA[204]]></epage>

<abstract><![CDATA[Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating 2D images from 3D data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the general notion of visibility histograms, which are multidimensional graphical representations of the distribution of visibility in a volume-rendered image. In this paper, we explore the 1D and 2D transfer functions that result from intensity values and gradient magnitude. With the help of these histograms, users can manage a complex set of transfer function parameters that maximize the visibility of the intervals of interest and provide high quality images of volume data. We present a semiautomated method for generating transfer functions, which progressively explores the transfer function space toward the goal of maximizing visibility of important structures. Our methodology can be easily deployed in most visualization systems and can be used together with traditional 1D and 2D opacity transfer functions based on scalar values, as well as with other more sophisticated rendering algorithms.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5416704]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.35]]></doi>

<publicationId><![CDATA[5416704]]></publicationId>

<partnum><![CDATA[5416704]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5416704&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416704]]></pdf>

</document>

<document>

<rank>193</rank>

<title><![CDATA[The Helmholtz-Hodge Decomposition&amp;#x2014;A Survey]]></title>

<authors><![CDATA[Bhatia, H.;  Norgard, G.;  Pascucci, V.;  Bremer, P.-T.]]></authors>

<affiliations><![CDATA[Lawrence Livermore Nat. Lab., Univ. of Utah, Livermore, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[fluid dynamics]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Boundary conditions]]></term>

<term><![CDATA[Communities]]></term>

<term><![CDATA[Conferences]]></term>

<term><![CDATA[Physics]]></term>

<term><![CDATA[Vectors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1386]]></spage>

<epage><![CDATA[1404]]></epage>

<abstract><![CDATA[The Helmholtz-Hodge Decomposition (HHD) describes the decomposition of a flow field into its divergence-free and curl-free components. Many researchers in various communities like weather modeling, oceanology, geophysics, and computer graphics are interested in understanding the properties of flow representing physical phenomena such as incompressibility and vorticity. The HHD has proven to be an important tool in the analysis of fluids, making it one of the fundamental theorems in fluid dynamics. The recent advances in the area of flow analysis have led to the application of the HHD in a number of research communities such as flow visualization, topological analysis, imaging, and robotics. However, because the initial body of work, primarily in the physics communities, research on the topic has become fragmented with different communities working largely in isolation often repeating and sometimes contradicting each others results. Additionally, different nomenclature has evolved which further obscures the fundamental connections between fields making the transfer of knowledge difficult. This survey attempts to address these problems by collecting a comprehensive list of relevant references and examining them using a common terminology. A particular focus is the discussion of boundary conditions when computing the HHD. The goal is to promote further research in the field by creating a common repository of techniques to compute the HHD as well as a large collection of example applications in a broad range of areas.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6365629]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.316]]></doi>

<publicationId><![CDATA[6365629]]></publicationId>

<partnum><![CDATA[6365629]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6365629&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365629]]></pdf>

</document>

<document>

<rank>194</rank>

<title><![CDATA[O-buffer: a framework for sample-based graphics]]></title>

<authors><![CDATA[Qu, H.;  Kaufman, A.E.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stony Brook Univ., NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[antialiasing]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Buffer storage]]></term>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Spatial resolution]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[410]]></spage>

<epage><![CDATA[421]]></epage>

<abstract><![CDATA[We present an innovative modeling and rendering primitive, called the O-buffer, as a framework for sample-based graphics. The 2D or 3D O-buffer is, in essence, a conventional image or a volume, respectively, except that samples are not restricted to a regular grid. A sample position in the O-buffer is recorded as an offset to the nearest grid point of a regular base grid (hence the name O-buffer). The O-buffer can greatly improve the expressive power of images and volumes. Image quality can be improved by storing more spatial information with samples and by avoiding multiple resamplings. It can be exploited to represent and render unstructured primitives, such as points, particles, and curvilinear or irregular volumes. The O-buffer is therefore a unified representation for a variety of graphics primitives and supports mixing them in the same scene. It is a semiregular structure which lends itself to efficient construction and rendering. O-buffers may assume a variety of forms including 2D O-buffers, 3D O-buffers, uniform O-buffers, nonuniform O-buffers, adaptive O-buffers, layered-depth O-buffers, and O-buffer trees. We demonstrate the effectiveness of the O-buffer in a variety of applications, such as image-based rendering, point sample rendering, and volume rendering.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1298798]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.15]]></doi>

<publicationId><![CDATA[1298798]]></publicationId>

<partnum><![CDATA[1298798]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1298798&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298798]]></pdf>

</document>

<document>

<rank>195</rank>

<title><![CDATA[The Perceptual Scalability of Visualization]]></title>

<authors><![CDATA[Yost, B.;  North, C.]]></authors>

<affiliations><![CDATA[IEEE]]></affiliations>

<thesaurusterms>

<term><![CDATA[Biological information theory]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Large screen displays]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Scalability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[837]]></spage>

<epage><![CDATA[844]]></epage>

<abstract><![CDATA[Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015437]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.184]]></doi>

<publicationId><![CDATA[4015437]]></publicationId>

<partnum><![CDATA[4015437]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015437&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015437]]></pdf>

</document>

<document>

<rank>196</rank>

<title><![CDATA[Real-Time Volume Rendering in Dynamic Lighting Environments Using Precomputed Photon Mapping]]></title>

<authors><![CDATA[Yubo Zhang;  Zhao Dong;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[brightness]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Media]]></term>

<term><![CDATA[Photonics]]></term>

<term><![CDATA[Real-time systems]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scattering]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1317]]></spage>

<epage><![CDATA[1330]]></epage>

<abstract><![CDATA[We present a framework for precomputed volume radiance transfer that achieves real-time rendering of global illumination effects for volume data sets such as multiple scattering, volumetric shadows, and so on. Our approach incorporates the volumetric photon mapping method into the classical precomputed radiance transfer pipeline. We contribute several techniques for light approximation, radiance transfer precomputation, and real-time radiance estimation, which are essential to make the approach practical and to achieve high frame rates. For light approximation, we propose a new discrete spherical function that has better performance for construction and evaluation when compared with existing rotational invariant spherical functions such as spherical harmonics and spherical radial basis functions. In addition, we present a fast splatting-based radiance transfer precomputation method and an early evaluation technique for real-time radiance estimation in the clustered principal component analysis space. Our techniques are validated through comprehensive evaluations and rendering tests. We also apply our rendering approach to volume visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6461883]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.17]]></doi>

<publicationId><![CDATA[6461883]]></publicationId>

<partnum><![CDATA[6461883]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6461883&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461883]]></pdf>

</document>

<document>

<rank>197</rank>

<title><![CDATA[Personal Visualization and Personal Visual Analytics]]></title>

<authors><![CDATA[Dandan Huang;  Tory, M.;  Aseniero, B.A.;  Bartram, L.;  Bateman, S.;  Carpendale, S.;  Tang, A.;  Woodbury, R.]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Communities]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Human computer interaction]]></term>

<term><![CDATA[Taxonomy]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[420]]></spage>

<epage><![CDATA[433]]></epage>

<abstract><![CDATA[Data surrounds each and every one of us in our daily lives, ranging from exercise logs, to archives of our interactions with others on social media, to online resources pertaining to our hobbies. There is enormous potential for us to use these data to understand ourselves better and make positive changes in our lives. Visualization (Vis) and visual analytics (VA) offer substantial opportunities to help individuals gain insights about themselves, their communities and their interests; however, designing tools to support data analysis in non-professional life brings a unique set of research and design challenges. We investigate the requirements and research directions required to take full advantage of Vis and VA in a personal context. We develop a taxonomy of design dimensions to provide a coherent vocabulary for discussing personal visualization and personal visual analytics. By identifying and exploring clusters in the design space, we discuss challenges and share perspectives on future research. This work brings together research that was previously scattered across disciplines. Our goal is to call research attention to this space and engage researchers to explore the enabling techniques and technology that will support people to better understand data relevant to their personal lives, interests, and needs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6908006]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2359887]]></doi>

<publicationId><![CDATA[6908006]]></publicationId>

<partnum><![CDATA[6908006]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6908006&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6908006]]></pdf>

</document>

<document>

<rank>198</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on InfoVis]]></title>

<authors><![CDATA[North, S.C.;  Keim, D.A.;  Munzner, T.]]></authors>

<affiliations><![CDATA[IEEE]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Open source software]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[446]]></spage>

<epage><![CDATA[446]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1298801]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.12]]></doi>

<publicationId><![CDATA[1298801]]></publicationId>

<partnum><![CDATA[1298801]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1298801&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298801]]></pdf>

</document>

<document>

<rank>199</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on VRST]]></title>

<authors><![CDATA[Purgathofer, W.]]></authors>

<thesaurusterms>

<term><![CDATA[Aerodynamics]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Design for disassembly]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[4]]></spage>

<epage><![CDATA[5]]></epage>

<abstract><![CDATA[The three papers in this special section are extended versions of papers originally presented at the ACM Symposium on Virtual Reality Software and Technology (VRST) 2007.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4675193]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.7]]></doi>

<publicationId><![CDATA[4675193]]></publicationId>

<partnum><![CDATA[4675193]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4675193&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4675193]]></pdf>

</document>

<document>

<rank>200</rank>

<title><![CDATA[Distinguish yourself with the CSDP [advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1352]]></spage>

<epage><![CDATA[1352]]></epage>

<abstract><![CDATA[Advertisement: The IEEE Computer Society Certified Software Development Professional (CSDP) credential.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5946035]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.125]]></doi>

<publicationId><![CDATA[5946035]]></publicationId>

<partnum><![CDATA[5946035]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5946035&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946035]]></pdf>

</document>

<document>

<rank>201</rank>

<title><![CDATA[Feature-Based Statistical Analysis of Combustion Simulation Data]]></title>

<authors><![CDATA[Bennett, J.C.;  Krishnamoorthy, V.;  Shusen Liu;  Grout, R.W.;  Hawkes, E.R.;  Chen, J.H.;  Shepherd, J.;  Pascucci, V.;  Bremer, P.-T.]]></authors>

<affiliations><![CDATA[Sandia Nat. Labs., Albuquerque, NM, USA]]></affiliations>

<controlledterms>

<term><![CDATA[chemically reactive flow]]></term>

<term><![CDATA[combustion]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[meta data]]></term>

<term><![CDATA[mixing]]></term>

<term><![CDATA[numerical analysis]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[turbulence]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Statistical analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1822]]></spage>

<epage><![CDATA[1831]]></epage>

<abstract><![CDATA[We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion s- ience; however, it is applicable to many other science domains.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064945]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.199]]></doi>

<publicationId><![CDATA[6064945]]></publicationId>

<partnum><![CDATA[6064945]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064945&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064945]]></pdf>

</document>

<document>

<rank>202</rank>

<title><![CDATA[Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles]]></title>

<authors><![CDATA[Kothur, P.;  Sips, M.;  Dobslaw, H.;  Dransch, D.]]></authors>

<affiliations><![CDATA[GFZ German Res. Centre for Geosci., Potsdam, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[expert systems]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[ocean waves]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[tides]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Geospatial analysis]]></term>

<term><![CDATA[Oceans]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1893]]></spage>

<epage><![CDATA[1902]]></epage>

<abstract><![CDATA[Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876007]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346751]]></doi>

<publicationId><![CDATA[6876007]]></publicationId>

<partnum><![CDATA[6876007]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876007&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876007]]></pdf>

</document>

<document>

<rank>203</rank>

<title><![CDATA[In Situ Exploration of Large Dynamic Networks]]></title>

<authors><![CDATA[Hadlak, S.;  Schulz, H.;  Schumann, H.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[network theory (graphs)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2334]]></spage>

<epage><![CDATA[2343]]></epage>

<abstract><![CDATA[The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065000]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.213]]></doi>

<publicationId><![CDATA[6065000]]></publicationId>

<partnum><![CDATA[6065000]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065000&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065000]]></pdf>

</document>

<document>

<rank>204</rank>

<title><![CDATA[Editor's Note]]></title>

<authors><![CDATA[Lin, Ming C.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[897]]></spage>

<epage><![CDATA[897]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6494563]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.69]]></doi>

<publicationId><![CDATA[6494563]]></publicationId>

<partnum><![CDATA[6494563]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6494563&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6494563]]></pdf>

</document>

<document>

<rank>205</rank>

<title><![CDATA[Efficient Surface Reconstruction using Generalized Coulomb Potentials]]></title>

<authors><![CDATA[Jalba, A.C.;  Roerdink, J.B.T.]]></authors>

<affiliations><![CDATA[Univ. of Groningen, Groningen]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[electric potential]]></term>

<term><![CDATA[octrees]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[Noise level]]></term>

<term><![CDATA[Noise robustness]]></term>

<term><![CDATA[Surface contamination]]></term>

<term><![CDATA[Surface fitting]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Tagging]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1512]]></spage>

<epage><![CDATA[1519]]></epage>

<abstract><![CDATA[We propose a novel, geometrically adaptive method for surface reconstruction from noisy and sparse point clouds, without orientation information. The method employs a fast convection algorithm to attract the evolving surface towards the data points. The force field in which the surface is convected is based on generalized Coulomb potentials evaluated on an adaptive grid (i.e., an octree) using a fast, hierarchical algorithm. Formulating reconstruction as a convection problem in a velocity field generated by Coulomb potentials offers a number of advantages. Unlike methods which compute the distance from the data set to the implicit surface, which are sensitive to noise due to the very reliance on the distance transform, our method is highly resilient to shot noise since global, generalized Coulomb potentials can be used to disregard the presence of outliers due to noise. Coulomb potentials represent long-range interactions that consider all data points at once, and thus they convey global information which is crucial in the fitting process. Both the spatial and temporal complexities of our spatially-adaptive method are proportional to the size of the reconstructed object, which makes our method compare favorably with respect to previous approaches in terms of speed and flexibility. Experiments with sparse as well as noisy data sets show that the method is capable of delivering crisp and detailed yet smooth surfaces.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376181]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70553]]></doi>

<publicationId><![CDATA[4376181]]></publicationId>

<partnum><![CDATA[4376181]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376181&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376181]]></pdf>

</document>

<document>

<rank>206</rank>

<title><![CDATA[An Interaction Model for Visualizations Beyond The Desktop]]></title>

<authors><![CDATA[Jansen, Y.;  Dragicevic, P.]]></authors>

<affiliations><![CDATA[Inria & Univ. Paris Sud, Paris, France]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2396]]></spage>

<epage><![CDATA[2405]]></epage>

<abstract><![CDATA[We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6634126]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.134]]></doi>

<publicationId><![CDATA[6634126]]></publicationId>

<partnum><![CDATA[6634126]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634126&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634126]]></pdf>

</document>

<document>

<rank>207</rank>

<title><![CDATA[Attributes of Subtle Cues for Facilitating Visual Search in Augmented Reality]]></title>

<authors><![CDATA[Weiquan Lu;  Duh, H.B.-L.;  Feiner, S.;  Qi Zhao]]></authors>

<affiliations><![CDATA[Interactive Digital Media Inst., Nat. Univ. of Singapore, Singapore, Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[image enhancement]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clutter]]></term>

<term><![CDATA[Computers]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Error analysis]]></term>

<term><![CDATA[Protocols]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[404]]></spage>

<epage><![CDATA[412]]></epage>

<abstract><![CDATA[Goal-oriented visual search is performed when a person intentionally seeks a target in the visual environment. In augmented reality (AR) environments, visual search can be facilitated by augmenting virtual cues in the person's field of view. Traditional use of explicit AR cues can potentially degrade visual search performance due to the creation of distortions in the scene. An alternative to explicit cueing, known as subtle cueing, has been proposed as a clutter-neutral method to enhance visual search in video-see-through AR. However, the effects of subtle cueing are still not well understood, and more research is required to determine the optimal methods of applying subtle cueing in AR. We performed two experiments to investigate the variables of scene clutter, subtle cue opacity, size, and shape on visual search performance. We introduce a novel method of experimentally manipulating the scene clutter variable in a natural scene while controlling for other variables. The findings provide supporting evidence for the subtlety of the cue, and show that the clutter conditions of the scene can be used both as a global classifier, as well as a local performance measure.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6620869]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.241]]></doi>

<publicationId><![CDATA[6620869]]></publicationId>

<partnum><![CDATA[6620869]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6620869&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620869]]></pdf>

</document>

<document>

<rank>208</rank>

<title><![CDATA[Distance Visualization for Interactive 3D Implant Planning]]></title>

<authors><![CDATA[Dick, C.;  Burgkart, R.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[medical computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical image processing]]></term>

<term><![CDATA[Distance measurement]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Implants]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2173]]></spage>

<epage><![CDATA[2182]]></epage>

<abstract><![CDATA[An instant and quantitative assessment of spatial distances between two objects plays an important role in interactive applications such as virtual model assembly, medical operation planning, or computational steering. While some research has been done on the development of distance-based measures between two objects, only very few attempts have been reported to visualize such measures in interactive scenarios. In this paper we present two different approaches for this purpose, and we investigate the effectiveness of these approaches for intuitive 3D implant positioning in a medical operation planning system. The first approach uses cylindrical glyphs to depict distances, which smoothly adapt their shape and color to changing distances when the objects are moved. This approach computes distances directly on the polygonal object representations by means of ray/triangle mesh intersection. The second approach introduces a set of slices as additional geometric structures, and uses color coding on surfaces to indicate distances. This approach obtains distances from a precomputed distance field of each object. The major findings of the performed user study indicate that a visualization that can facilitate an instant and quantitative analysis of distances between two objects in interactive 3D scenarios is demanding, yet can be achieved by including additional monocular cues into the visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6064982]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.189]]></doi>

<publicationId><![CDATA[6064982]]></publicationId>

<partnum><![CDATA[6064982]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064982&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064982]]></pdf>

</document>

<document>

<rank>209</rank>

<title><![CDATA[Topology simplification for polygonal virtual environments]]></title>

<authors><![CDATA[El-Sana, J.;  Varshney, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[topology]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[133]]></spage>

<epage><![CDATA[144]]></epage>

<abstract><![CDATA[We present a topology simplifying approach that can be used for genus reductions, removal of protuberances, and repair of cracks in polygonal models in a unified framework. Our work is complementary to the existing work on geometry simplification of polygonal datasets and we demonstrate that using topology and geometry simplifications together yields superior multiresolution hierarchies than is possible by using either of them alone. Our approach can also address the important issue of repair of cracks in polygonal models, as well as for rapid identification and removal of protuberances based on internal accessibility in polygonal models. Our approach is based on identifying holes and cracks by extending the concept of &alpha;-shapes to polygonal meshes under the L<sub>&infin;</sub> distance metric. We then generate valid triangulations to fill them using the intuitive notion of sweeping an L<sub>&infin;</sub> cube over the identified regions]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[694955]]></arnumber>

<doi><![CDATA[10.1109/2945.694955]]></doi>

<publicationId><![CDATA[694955]]></publicationId>

<partnum><![CDATA[694955]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=694955&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=694955]]></pdf>

</document>

<document>

<rank>210</rank>

<title><![CDATA[Relation-Aware Isosurface Extraction in Multifield Data]]></title>

<authors><![CDATA[Nagaraj, Suthambhara;  Natarajan, V.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bengaluru, India]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data handling]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[182]]></spage>

<epage><![CDATA[191]]></epage>

<abstract><![CDATA[We introduce a variation density function that profiles the relationship between multiple scalar fields over isosurfaces of a given scalar field. This profile serves as a valuable tool for multifield data exploration because it provides the user with cues to identify interesting isovalues of scalar fields. Existing isosurface-based techniques for scalar data exploration like Reeb graphs, contour spectra, isosurface statistics, etc., study a scalar field in isolation. We argue that the identification of interesting isovalues in a multifield data set should necessarily be based on the interaction between the different fields. We demonstrate the effectiveness of our approach by applying it to explore data from a wide variety of applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5453366]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.64]]></doi>

<publicationId><![CDATA[5453366]]></publicationId>

<partnum><![CDATA[5453366]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5453366&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453366]]></pdf>

</document>

<document>

<rank>211</rank>

<title><![CDATA[Ribbon networks for modeling navigable paths of autonomous agents in virtual environments]]></title>

<authors><![CDATA[Willemsen, P.;  Kearney, J.K.;  Wang, H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Minnesota Univ., Duluth, MN]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[software agents]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Autonomous agents]]></term>

<term><![CDATA[Complex networks]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Intelligent networks]]></term>

<term><![CDATA[Remotely operated vehicles]]></term>

<term><![CDATA[Road vehicles]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[331]]></spage>

<epage><![CDATA[342]]></epage>

<abstract><![CDATA[This paper presents the environment description framework (EOF) for modeling complex networks of intersecting roads and pathways in virtual environments. EOF represents information about the layout of streets and sidewalks, the rules that govern behavior on roads and walkways, and the locations of agents with respect to navigable structures. The framework serves as the substrate on which behavior programs for autonomous vehicles and pedestrians are built. Pathways are modeled as ribbons in space. The ribbon structure provides a natural coordinate frame for defining the local geometry of navigable surfaces. EOF includes a powerful runtime interface supported by robust and efficient code for locating objects on the ribbon network, for mapping between Cartesian and ribbon coordinates, and for determining behavioral constraints imposed by the environment]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1608020]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.53]]></doi>

<publicationId><![CDATA[1608020]]></publicationId>

<partnum><![CDATA[1608020]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1608020&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608020]]></pdf>

</document>

<document>

<rank>212</rank>

<title><![CDATA[Transpost: a novel approach to the display and transmission of 360 degrees-viewable 3D solid images]]></title>

<authors><![CDATA[Otsuka, R.;  Hoshino, T.;  Horry, Y.]]></authors>

<affiliations><![CDATA[Adv. Res. Lab., Hitachi Ltd., Tokyo, Japan]]></affiliations>

<controlledterms>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[three-dimensional displays]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Laser modes]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Motion pictures]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Solids]]></term>

<term><![CDATA[Spinning]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[178]]></spage>

<epage><![CDATA[185]]></epage>

<abstract><![CDATA[Three-dimensional displays are drawing attention as next-generation devices. Some techniques which can reproduce three-dimensional images prepared in advance have already been developed. However, technology for the transmission of 3D moving pictures in real-time is yet to be achieved. In this paper, we present a novel method for 360-degrees viewable 3D displays and the Transpost system in which we implement the method. The basic concept of our system is to project multiple images of the object, taken from different angles, onto a spinning screen. The key to the method is projection of the images onto a directionally reflective screen with a limited viewing angle. The images are reconstructed to give the viewer a three-dimensional image of the object displayed on the screen. The display system can present images of computer-graphics pictures, live pictures, and movies. Furthermore, the reverse optical process of that in the display system can be used to record images of the subject from multiple directions. The images can then be transmitted to the display in real-time. We have developed prototypes of a 3D display and a 3D human-image transmission system. Our preliminary working prototypes demonstrate new possibilities of expression and forms of communication.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1580452]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.38]]></doi>

<publicationId><![CDATA[1580452]]></publicationId>

<partnum><![CDATA[1580452]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580452&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580452]]></pdf>

</document>

<document>

<rank>213</rank>

<title><![CDATA[Enterprise Data Analysis and Visualization: An Interview Study]]></title>

<authors><![CDATA[Kandel, S.;  Paepcke, A.;  Hellerstein, J.M.;  Heer, J.]]></authors>

<affiliations><![CDATA[Stanford Univ., Stanford, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[business data processing]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision making]]></term>

<term><![CDATA[organisational aspects]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Computer hacking]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed databases]]></term>

<term><![CDATA[Organizations]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2917]]></spage>

<epage><![CDATA[2926]]></epage>

<abstract><![CDATA[Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327298]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.219]]></doi>

<publicationId><![CDATA[6327298]]></publicationId>

<partnum><![CDATA[6327298]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327298&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327298]]></pdf>

</document>

<document>

<rank>214</rank>

<title><![CDATA[Online Dynamic Graph Drawing]]></title>

<authors><![CDATA[Frishman, Y.;  Tal, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Israel Inst. of Technol., Haifa]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[727]]></spage>

<epage><![CDATA[740]]></epage>

<abstract><![CDATA[This paper presents an algorithm for drawing a sequence of graphs online. The algorithm strives to maintain the global structure of the graph and, thus, the user's mental map while allowing arbitrary modifications between consecutive layouts. The algorithm works online and uses various execution culling methods in order to reduce the layout time and handle large dynamic graphs. Techniques for representing graphs on the GPU allow a speedup by a factor of up to 17 compared to the CPU implementation. The scalability of the algorithm across GPU generations is demonstrated. Applications of the algorithm to the visualization of discussion threads in Internet sites and to the visualization of social networks are provided.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4433990]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.11]]></doi>

<publicationId><![CDATA[4433990]]></publicationId>

<partnum><![CDATA[4433990]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4433990&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4433990]]></pdf>

</document>

<document>

<rank>215</rank>

<title><![CDATA[Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease]]></title>

<authors><![CDATA[Meyer-Spradow, J.;  Stegger, L.;  Doring, C.;  Ropinski, T.;  Hinrichs, K.]]></authors>

<affiliations><![CDATA[Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster]]></affiliations>

<controlledterms>

<term><![CDATA[cardiology]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diseases]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[single photon emission computed tomography]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Arteries]]></term>

<term><![CDATA[Blood]]></term>

<term><![CDATA[Coronary arteriosclerosis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Heart]]></term>

<term><![CDATA[Myocardium]]></term>

<term><![CDATA[Positron emission tomography]]></term>

<term><![CDATA[Single photon emission computed tomography]]></term>

<term><![CDATA[Stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1499]]></spage>

<epage><![CDATA[1506]]></epage>

<abstract><![CDATA[Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658168]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.136]]></doi>

<publicationId><![CDATA[4658168]]></publicationId>

<partnum><![CDATA[4658168]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658168&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658168]]></pdf>

</document>

<document>

<rank>216</rank>

<title><![CDATA[Towards Robust Topology of Sparsely Sampled Data]]></title>

<authors><![CDATA[Correa, C.;  Lindstrom, P.]]></authors>

<affiliations><![CDATA[Center for Appl. Sci. Comput. (CASC), Lawrence Livermore Nat. Lab., Livermore, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[sampling methods]]></term>

<term><![CDATA[set theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Noise measurement]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1852]]></spage>

<epage><![CDATA[1861]]></epage>

<abstract><![CDATA[Sparse, irregular sampling is becoming a necessity for reconstructing large and high-dimensional signals. However, the analysis of this type of data remains a challenge. One issue is the robust selection of neighborhoods - a crucial part of analytic tools such as topological decomposition, clustering and gradient estimation. When extracting the topology of sparsely sampled data, common neighborhood strategies such as k-nearest neighbors may lead to inaccurate results, either due to missing neighborhood connections, which introduce false extrema, or due to spurious connections, which conceal true extrema. Other neighborhoods, such as the Delaunay triangulation, are costly to compute and store even in relatively low dimensions. In this paper, we address these issues. We present two new types of neighborhood graphs: a variation on and a generalization of empty region graphs, which considerably improve the robustness of neighborhood-based analysis tools, such as topological decomposition. Our findings suggest that these neighborhood graphs lead to more accurate topological representations of low- and high- dimensional data sets at relatively low cost, both in terms of storage and computation time. We describe the implications of our work in the analysis and visualization of scalar functions, and provide general strategies for computing and applying our neighborhood graphs towards robust data analysis.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064948]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.245]]></doi>

<publicationId><![CDATA[6064948]]></publicationId>

<partnum><![CDATA[6064948]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064948&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064948]]></pdf>

</document>

<document>

<rank>217</rank>

<title><![CDATA[Real-Time Simulation of Brittle Fracture Using Modal Analysis]]></title>

<authors><![CDATA[Glondu, L.;  Marchal, M.;  Dumont, G.]]></authors>

<affiliations><![CDATA[orange IRISA, INRIA Rennes, Rennes, France]]></affiliations>

<controlledterms>

<term><![CDATA[brittle fracture]]></term>

<term><![CDATA[damping]]></term>

<term><![CDATA[mechanical contact]]></term>

<term><![CDATA[modal analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Force]]></term>

<term><![CDATA[Materials]]></term>

<term><![CDATA[Modal analysis]]></term>

<term><![CDATA[Real time systems]]></term>

<term><![CDATA[Stress]]></term>

<term><![CDATA[Surface cracks]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[201]]></spage>

<epage><![CDATA[209]]></epage>

<abstract><![CDATA[We present a novel physically based approach for simulating realistic brittle fracture of impacting bodies in real time. Our method is mainly composed of two novel parts: 1) a fracture initiation method based on modal analysis, and 2) a fast energy-based fracture propagation algorithm. We propose a way to compute the contact durations and the contact forces between stiff bodies to simulate the damped deformation wave that is responsible for fracture initiation. As a consequence, our method naturally takes into account the damping properties of the bodies as well as the contact properties to simulate the fracture. To obtain a complete fracture pipeline, we present an efficient way to generate the fragments and their geometric surfaces. These surfaces are sampled on the edges of the physical mesh, to visually represent the actual fracture surface computed. As shown in our results, the computation time performances and realism of our method are well suited for physically based interactive applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6197190]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.121]]></doi>

<publicationId><![CDATA[6197190]]></publicationId>

<partnum><![CDATA[6197190]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6197190&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197190]]></pdf>

</document>

<document>

<rank>218</rank>

<title><![CDATA[An Information-theoretic Framework for Visualization]]></title>

<authors><![CDATA[Chen, M.;  Ja&#x0308; enicke, H.]]></authors>

<controlledterms>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[information theory]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1206]]></spage>

<epage><![CDATA[1215]]></epage>

<abstract><![CDATA[In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613460]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.132]]></doi>

<publicationId><![CDATA[5613460]]></publicationId>

<partnum><![CDATA[5613460]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613460&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613460]]></pdf>

</document>

<document>

<rank>219</rank>

<title><![CDATA[Lark: Coordinating Co-located Collaboration with Information Visualization]]></title>

<authors><![CDATA[Tobiasz, M.;  Isenberg, P.;  Carpendale, S.]]></authors>

<affiliations><![CDATA[Univ. of Calgary, Calgary, AB, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[touch sensitive screens]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Switches]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1065]]></spage>

<epage><![CDATA[1072]]></epage>

<abstract><![CDATA[Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290713]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.162]]></doi>

<publicationId><![CDATA[5290713]]></publicationId>

<partnum><![CDATA[5290713]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290713&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290713]]></pdf>

</document>

<document>

<rank>220</rank>

<title><![CDATA[Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data]]></title>

<authors><![CDATA[Xiaoru Yuan;  Donghao Ren;  Zuchao Wang;  Cong Guo]]></authors>

<affiliations><![CDATA[Key Lab. of Machine Perception (Minist. of Educ.) & Sch. of EECS, Peking Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[merging]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2625]]></spage>

<epage><![CDATA[2633]]></epage>

<abstract><![CDATA[For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634155]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.150]]></doi>

<publicationId><![CDATA[6634155]]></publicationId>

<partnum><![CDATA[6634155]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634155&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634155]]></pdf>

</document>

<document>

<rank>221</rank>

<title><![CDATA[The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking]]></title>

<authors><![CDATA[Chevalier, F.;  Dragicevic, P.;  Franconeri, S.]]></authors>

<affiliations><![CDATA[Inria, Sophia-Antipolis, France]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[object tracking]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Target tracking]]></term>

<term><![CDATA[Tracking]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2241]]></spage>

<epage><![CDATA[2250]]></epage>

<abstract><![CDATA[Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876010]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346424]]></doi>

<publicationId><![CDATA[6876010]]></publicationId>

<partnum><![CDATA[6876010]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876010&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876010]]></pdf>

</document>

<document>

<rank>222</rank>

<title><![CDATA[Spatial-temporal antialiasing]]></title>

<authors><![CDATA[Sung, K.;  Pearce, A.;  Changyaw Wang]]></authors>

<affiliations><![CDATA[Washington Univ., Bothell, WA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[antialiasing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive algorithm]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Production]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[144]]></spage>

<epage><![CDATA[153]]></epage>

<abstract><![CDATA[A framework for discussing the motion blur image generation process is formulated. Previous work is studied in the context of this framework. Due to the implicit assumptions on low temporal frequencies in most motion blur algorithms, issues involved in large screen space movements and fast illumination changes in time have not been adequately addressed so far. A new approach that does not make these assumptions is introduced to solve the spatial-temporal geometric and shading aliasing problems separately. Based on newly developed adaptive algorithms in the spatial-temporal domain, an implementation of the new approach is developed to efficiently deliver high-quality motion blurred images in general computer graphics production environments]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[998667]]></arnumber>

<doi><![CDATA[10.1109/2945.998667]]></doi>

<publicationId><![CDATA[998667]]></publicationId>

<partnum><![CDATA[998667]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=998667&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998667]]></pdf>

</document>

<document>

<rank>223</rank>

<title><![CDATA[Concurrent Visualization in a Production Supercomputing Environment]]></title>

<authors><![CDATA[Ellsworth, D.;  Green, B.;  Henze, C.;  Moran, P.;  Sandstrom, T.]]></authors>

<affiliations><![CDATA[AMTl, NASA Ames Res. Center, Moffett Field, CA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data compression]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[image coding]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[parallel machines]]></term>

<term><![CDATA[pipeline processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[storms]]></term>

<term><![CDATA[weather forecasting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Atmospheric modeling]]></term>

<term><![CDATA[Hurricanes]]></term>

<term><![CDATA[NASA]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Production]]></term>

<term><![CDATA[Supercomputers]]></term>

<term><![CDATA[Time factors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[997]]></spage>

<epage><![CDATA[1004]]></epage>

<abstract><![CDATA[We describe a concurrent visualization pipeline designed for operation in a production supercomputing environment. The facility was initially developed on the NASA Ames "Columbia" supercomputer for a massively parallel forecast model (GEOS4). During the 2005 Atlantic hurricane season, GEOS4 was run 4 times a day under tight time constraints so that its output could be included in an ensemble prediction that was made available to forecasters at the National Hurricane Center. Given this time-critical context, we designed a configurable concurrent pipeline to visualize multiple global fields without significantly affecting the runtime model performance or reliability. We use MPEG compression of the accruing images to facilitate live low-bandwidth distribution of multiple visualization streams to remote sites. We also describe the use of our concurrent visualization framework with a global ocean circulation model, which provides a 864-fold increase in the temporal resolution of practically achievable animations. In both the atmospheric and oceanic circulation models, the application scientists gained new insights into their model dynamics, due to the high temporal resolution animations attainable]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015457]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.128]]></doi>

<publicationId><![CDATA[4015457]]></publicationId>

<partnum><![CDATA[4015457]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015457&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015457]]></pdf>

</document>

<document>

<rank>224</rank>

<title><![CDATA[Wavelet-based progressive compression scheme for triangle meshes: wavemesh]]></title>

<authors><![CDATA[Valette, S.;  Prost, R.]]></authors>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data compression]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Bit rate]]></term>

<term><![CDATA[Context modeling]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Design automation]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Inverse problems]]></term>

<term><![CDATA[Propagation losses]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[123]]></spage>

<epage><![CDATA[129]]></epage>

<abstract><![CDATA[We propose a new lossy to lossless progressive compression scheme for triangular meshes, based on a wavelet multiresolution theory for irregular 3D meshes. Although remeshing techniques obtain better compression ratios for geometric compression, this approach can be very effective when one wants to keep the connectivity and geometry of the processed mesh completely unchanged. The simplification is based on the solving of an inverse problem. Optimization of both the connectivity and geometry of the processed mesh improves the approximation quality and the compression ratio of the scheme at each resolution level. We show why this algorithm provides an efficient means of compression for both connectivity and geometry of 3D meshes and it is illustrated by experimental results on various sets of reference meshes, where our algorithm performs better than previously published approaches for both lossless and progressive compression.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1260764]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1260764]]></doi>

<publicationId><![CDATA[1260764]]></publicationId>

<partnum><![CDATA[1260764]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260764&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260764]]></pdf>

</document>

<document>

<rank>225</rank>

<title><![CDATA[TripAdvisor^{N-D}: A Tourism-Inspired High-Dimensional Space Exploration Framework with Overview and Detail]]></title>

<authors><![CDATA[Nam, J.E.;  Mueller, K.]]></authors>

<affiliations><![CDATA[Microsoft Corp., Redmond, WA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[travel industry]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Space exploration]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[291]]></spage>

<epage><![CDATA[305]]></epage>

<abstract><![CDATA[Gaining a true appreciation of high-dimensional space remains difficult since all of the existing high-dimensional space exploration techniques serialize the space travel in some way. This is not so foreign to us since we, when traveling, also experience the world in a serial fashion. But we typically have access to a map to help with positioning, orientation, navigation, and trip planning. Here, we propose a multivariate data exploration tool that compares high-dimensional space navigation with a sightseeing trip. It decomposes this activity into five major tasks: 1) Identify the sights: use a map to identify the sights of interest and their location; 2) Plan the trip: connect the sights of interest along a specifyable path; 3) Go on the trip: travel along the route; 4) Hop off the bus: experience the location, look around, zoom into detail; and 5) Orient and localize: regain bearings in the map. We describe intuitive and interactive tools for all of these tasks, both global navigation within the map and local exploration of the data distributions. For the latter, we describe a polygonal touchpad interface which enables users to smoothly tilt the projection plane in high-dimensional space to produce multivariate scatterplots that best convey the data relationships under investigation. Motion parallax and illustrative motion trails aid in the perception of these transient patterns. We describe the use of our system within two applications: 1) the exploratory discovery of data configurations that best fit a personal preference in the presence of tradeoffs and 2) interactive cluster analysis via cluster sculpting in N-D.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6155716]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.65]]></doi>

<publicationId><![CDATA[6155716]]></publicationId>

<partnum><![CDATA[6155716]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6155716&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155716]]></pdf>

</document>

<document>

<rank>226</rank>

<title><![CDATA[VIS Conference Committee]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xvi]]></spage>

<epage><![CDATA[xvi]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634114]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.218]]></doi>

<publicationId><![CDATA[6634114]]></publicationId>

<partnum><![CDATA[6634114]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634114&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634114]]></pdf>

</document>

<document>

<rank>227</rank>

<title><![CDATA[Scattered data interpolation with multilevel B-splines]]></title>

<authors><![CDATA[Seungyong Lee;  Wolberg, G.;  Sung Yong Shin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Pohang Inst. of Sci. & Technol., South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Geologic measurements]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Sea measurements]]></term>

<term><![CDATA[Sea surface]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[Surface fitting]]></term>

<term><![CDATA[Surface reconstruction]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[228]]></spage>

<epage><![CDATA[244]]></epage>

<abstract><![CDATA[The paper describes a fast algorithm for scattered data interpolation and approximation. Multilevel B-splines are introduced to compute a C<sup>2</sup> continuous surface through a set of irregularly spaced points. The algorithm makes use of a coarse to fine hierarchy of control lattices to generate a sequence of bicubic B-spline functions whose sum approaches the desired interpolation function. Large performance gains are realized by using B-spline refinement to reduce the sum of these functions into one equivalent B-spline function. Experimental results demonstrate that high fidelity reconstruction is possible from a selected set of sparse and irregular samples]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[620490]]></arnumber>

<doi><![CDATA[10.1109/2945.620490]]></doi>

<publicationId><![CDATA[620490]]></publicationId>

<partnum><![CDATA[620490]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=620490&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620490]]></pdf>

</document>

<document>

<rank>228</rank>

<title><![CDATA[The lazy sweep ray casting algorithm for rendering irregular grids]]></title>

<authors><![CDATA[Silva, Claudio T.;  Mitchell, J.S.B.]]></authors>

<affiliations><![CDATA[Dept. of Appl. Math. & Stat., State Univ. of New York, Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Software algorithms]]></term>

<term><![CDATA[Spatial coherence]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Upper bound]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[142]]></spage>

<epage><![CDATA[157]]></epage>

<abstract><![CDATA[Lazy sweep ray casting is a fast algorithm for rendering general irregular grids. It is based on the sweep-plane paradigm, and it is able to accelerate ray casting for rendering irregular grids, including disconnected and nonconvex unstructured irregular grids (even with holes) with a rendering cost that decreases as the &ldquo;disconnectedness&rdquo; decreases. The algorithm is carefully tailored to exploit spatial coherence even if the image resolution differs substantially from the object space resolution. Lazy sweep ray casting has several desirable properties, including its generality, (depth-sorting) accuracy, low memory consumption, speed, simplicity of implementation and portability (e.g. no hardware dependencies). We establish the practicality of our method through experimental results based on our implementation, which is shown to be substantially faster (by up to two orders of magnitude) than other algorithms implemented in software. We also provide theoretical results, both lower and upper bounds, on the complexity of ray casting of irregular grids]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[597797]]></arnumber>

<doi><![CDATA[10.1109/2945.597797]]></doi>

<publicationId><![CDATA[597797]]></publicationId>

<partnum><![CDATA[597797]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=597797&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=597797]]></pdf>

</document>

<document>

<rank>229</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on the ACM Symposium on Virtual Reality Software and Technology]]></title>

<authors><![CDATA[Hachet, Martin;  Kruijff, E.]]></authors>

<thesaurusterms>

<term><![CDATA[Augmented reality]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Face detection]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Optical control]]></term>

<term><![CDATA[Optical design]]></term>

<term><![CDATA[Sections]]></term>

<term><![CDATA[User interfaces]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[2]]></spage>

<epage><![CDATA[3]]></epage>

<abstract><![CDATA[This special section contains the best three full papers from the ACM Symposium on Virtual Reality Software and Technology (VRST) 2008, held in Bordeaux, France.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5331926]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.8]]></doi>

<publicationId><![CDATA[5331926]]></publicationId>

<partnum><![CDATA[5331926]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5331926&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331926]]></pdf>

</document>

<document>

<rank>230</rank>

<title><![CDATA[2013 reviewers list]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[IEEE publishing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[155]]></spage>

<epage><![CDATA[158]]></epage>

<abstract><![CDATA[The publication offers a note of thanks and lists its reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6674935]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2]]></doi>

<publicationId><![CDATA[6674935]]></publicationId>

<partnum><![CDATA[6674935]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6674935&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6674935]]></pdf>

</document>

<document>

<rank>231</rank>

<title><![CDATA[Temporal Coherence in Image-Based Visual Hull Rendering]]></title>

<authors><![CDATA[Hauswiesner, S.;  Straka, M.;  Reitmayr, G.]]></authors>

<affiliations><![CDATA[Inst. for Comput. Graphics & Vision, Graz Univ. of Technol., Graz, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[calibration]]></term>

<term><![CDATA[cameras]]></term>

<term><![CDATA[coherence]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Coherence]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sensors]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1758]]></spage>

<epage><![CDATA[1767]]></epage>

<abstract><![CDATA[Image-based visual hull rendering is a method for generating depth maps of a desired viewpoint from a set of silhouette images captured by calibrated cameras. It does not compute a view-independent data representation, such as a voxel grid or a mesh, which makes it particularly efficient for dynamic scenes. When users are captured, the scene is usually dynamic, but does not change rapidly because people move smoothly within a subsecond time frame. Exploiting this temporal coherence to avoid redundant calculations is challenging because of the lack of an explicit data representation. This paper analyzes the image-based visual hull algorithm to find intermediate information that stays valid over time and is, therefore, worth to make explicit. We then derive methods that exploit this information to improve the rendering performance. Our methods reduce the execution time by up to 25 percent. When the user's motions are very slow, reductions of up to 50 percent are achieved.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6517186]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.85]]></doi>

<publicationId><![CDATA[6517186]]></publicationId>

<partnum><![CDATA[6517186]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6517186&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6517186]]></pdf>

</document>

<document>

<rank>232</rank>

<title><![CDATA[Designing Serious Games for Safety Education: &#x201C;Learn to Brace&#x201D; vs. Traditional Pictorials for Aircraft Passengers]]></title>

<authors><![CDATA[Chittaro, L.]]></authors>

<affiliations><![CDATA[Luca Chittaro is with the Human-Computer Ineraction Lab, Department of Mathematics and Computer Science, University of Udine, via delle Scienze, 206, 33100 Udine, Italy.(email:luca.chittaro@uniud.it)]]></affiliations>

<thesaurusterms>

<term><![CDATA[Accidents]]></term>

<term><![CDATA[Aircraft]]></term>

<term><![CDATA[Avatars]]></term>

<term><![CDATA[Education]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Safety]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Serious games for safety education (SGSE) are a novel tool for preparing people to prevent and/or handle risky situations. Although several SGSE have been developed, design and evaluation methods for SGSE need to be better grounded in and guided by safety-relevant psychological theories. In particular, this paper focuses on threat appeals and the assessment of variables, such as safety locus of control, that influence human behavior in real risky situations. It illustrates how we took into account such models in the design and evaluation of &#x201C;Learn to Brace&#x201D;, a first-of-its-kind serious game that deals with a major problem in aviation safety, i.e. the scarce effectiveness of the safety cards used by airlines. The study considered a sample of 48 users: half of them received instructions about the brace position through the serious game, the other half through a traditional safety card pictorial. Results showed that the serious game was much more effective than the traditional instructions both in terms of learning and of changing safety-relevant perceptions, especially safety locus of control and recommendation perception.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7122340]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2443787]]></doi>

<publicationId><![CDATA[7122340]]></publicationId>

<partnum><![CDATA[7122340]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7122340&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7122340]]></pdf>

</document>

<document>

<rank>233</rank>

<title><![CDATA[Wellformedness Properties in Euler Diagrams: Which Should Be Used?]]></title>

<authors><![CDATA[Rodgers, P.;  Leishi Zhang;  Purchase, H.]]></authors>

<affiliations><![CDATA[Sch. of Comput., Univ. of Kent, Canterbury, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Decision support systems]]></term>

<term><![CDATA[Handheld computers]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1089]]></spage>

<epage><![CDATA[1100]]></epage>

<abstract><![CDATA[Euler diagrams are often used to visualize intersecting data sets in applications such as criminology; genetics, medicine, and computer file systems. One interesting aspect of these diagrams is that some data sets cannot be drawn without breaking one or more "wellformedness properties,&#x201D; which are considered to reduce the user comprehension of the diagrams. However, it is possible to draw the same data with different diagrams, each of which breaks different wellformedness properties. Hence, some properties are "swappable,&#x201D; so motivating the study of which of the alternatives would be best to use. This paper reports on the two empirical studies to determine how wellformedness properties affect comprehension. One study was with abstract data, the other was with concrete data that visualized students' enrollment on university modules. We have results from both studies that imply that diagrams with concurrency or disconnected zones perform less well than other some other properties. Further, we have no results that imply that diagrams with brushing points adversely affect performance. Our data also indicate that nonsimple curves are preferred less than diagrams with other properties. These results will inform both human diagram designers and the developers of automated drawing systems on the best way to visualize data using Euler diagrams.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5999665]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.143]]></doi>

<publicationId><![CDATA[5999665]]></publicationId>

<partnum><![CDATA[5999665]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5999665&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999665]]></pdf>

</document>

<document>

<rank>234</rank>

<title><![CDATA[The Visual Causality Analyst: An Interactive Interface for Causal Reasoning]]></title>

<authors><![CDATA[Jun Wang;  Mueller, K.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[inference mechanisms]]></term>

<term><![CDATA[statistical testing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Inference algorithms]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Linear regression]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[230]]></spage>

<epage><![CDATA[239]]></epage>

<abstract><![CDATA[Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192729]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467931]]></doi>

<publicationId><![CDATA[7192729]]></publicationId>

<partnum><![CDATA[7192729]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192729&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192729]]></pdf>

</document>

<document>

<rank>235</rank>

<title><![CDATA[Disambiguating Stereoscopic Transparency Using a Thaumatrope Approach]]></title>

<authors><![CDATA[Yan-Jen Su;  Yung-Yu Chuang]]></authors>

<affiliations><![CDATA[Grad. Inst. of Networking & Multimedia, Nat. Taiwan Univ., Taipei, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[stereo image processing]]></term>

<term><![CDATA[three-dimensional displays]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Stereo image processing]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[959]]></spage>

<epage><![CDATA[969]]></epage>

<abstract><![CDATA[Volume rendering is a popular visualization technique for scientific computing and medical imaging. By assigning proper transparency, it allows us to see more information inside the volume. However, because volume rendering projects complex 3D structures into the 2D domain, the resultant visualization often suffers from ambiguity and its spatial relationship could be difficult to recognize correctly, especially when the scene or setting is highly transparent. Stereoscopic displays are not the rescue to the problem even though they add an additional dimension which seems helpful for resolving the ambiguity. This paper proposes a thaumatrope method to enhance 3D understanding with stereoscopic transparency for volume rendering. Our method first generates an additional cue with less spatial ambiguity by using a high opacity setting. To avoid cluttering the actual content, we only select its prominent feature for displaying. By alternating the actual content and the selected feature quickly, the viewer only perceives a whole volume while its spatial understanding has been enhanced. A user study was performed to compare the proposed method with the original stereoscopic volume rendering and the static combination of the actual content and the selected feature using a 3D display. Results show that the proposed thaumatrope approach provides better spatial understanding than compared approaches.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7055322]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2410273]]></doi>

<publicationId><![CDATA[7055322]]></publicationId>

<partnum><![CDATA[7055322]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7055322&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7055322]]></pdf>

</document>

<document>

<rank>236</rank>

<title><![CDATA[Multiscale visualization using data cubes]]></title>

<authors><![CDATA[Stolte, C.;  Tang, D.;  Hanrahan, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stanford Univ., CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[visual databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Polarization]]></term>

<term><![CDATA[Relational databases]]></term>

<term><![CDATA[Switches]]></term>

<term><![CDATA[Visual databases]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[176]]></spage>

<epage><![CDATA[187]]></epage>

<abstract><![CDATA[Most analysts start with an overview of the data before gradually refining their view to be more focused and detailed. Multiscale pan-and-zoom systems are effective because they directly support this approach. However, generating abstract overviews of large data sets is difficult and most systems take advantage of only one type of abstraction: visual abstraction. Furthermore, these existing systems limit the analyst to a single zooming path on their data and thus to a single set of abstract views. This paper presents: 1) a formalism for describing multiscale visualizations of data cubes with both data and visual abstraction and 2) a method for independently zooming along one or more dimensions by traversing a zoom graph with nodes at different levels of detail. As an example of how to design multiscale visualizations using our system, we describe four design patterns using our formalism. These design patterns show the effectiveness of multiscale visualization of general relational databases.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1196005]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1196005]]></doi>

<publicationId><![CDATA[1196005]]></publicationId>

<partnum><![CDATA[1196005]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1196005&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196005]]></pdf>

</document>

<document>

<rank>237</rank>

<title><![CDATA[Improving the robustness and accuracy of the marching cubes algorithm for isosurfacing]]></title>

<authors><![CDATA[Lopes, A.;  Brodlie, K.]]></authors>

<affiliations><![CDATA[Dept. de Matematica, Coimbra Univ., Portugal]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Visualization]]></term>

<term><![CDATA[Yield estimation]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[16]]></spage>

<epage><![CDATA[29]]></epage>

<abstract><![CDATA[This paper proposes a modification of the Marching Cubes algorithm for isosurfacing, with the intent of improving the representation of the surface in the interior of each grid cell. Our objective is to create a representation which correctly models the topology of the trilinear interpolant within the cell and which is robust under perturbations of the data and threshold value. To achieve this, we identify a small number of key points in the cell interior that are critical to the surface definition. This allows us to efficiently represent the different topologies that can occur, including the possibility of "tunnels." The representation is robust in the sense that the surface is visually continuous as the data and threshold change in value. Each interior point lies on the isosurface. Finally, a major feature of our new approach is the systematic method of triangulating the polygon in the cell interior.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1175094]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1175094]]></doi>

<publicationId><![CDATA[1175094]]></publicationId>

<partnum><![CDATA[1175094]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1175094&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1175094]]></pdf>

</document>

<document>

<rank>238</rank>

<title><![CDATA[Projection-Based Metal-Artifact Reduction for Industrial 3D X-ray Computed Tomography]]></title>

<authors><![CDATA[Amirkhanov, A.;  Heinzl, C.;  Reiter, M.;  Kastner, J.;  Groller, E.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interpolation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2193]]></spage>

<epage><![CDATA[2202]]></epage>

<abstract><![CDATA[Multi-material components, which contain metal parts surrounded by plastic materials, are highly interesting for inspection using industrial 3D X-ray computed tomography (3DXCT). Examples of this application scenario are connectors or housings with metal inlays in the electronic or automotive industry. A major problem of this type of components is the presence of metal, which causes streaking artifacts and distorts the surrounding media in the reconstructed volume. Streaking artifacts and dark-band artifacts around metal components significantly influence the material characterization (especially for the plastic components). In specific cases these artifacts even prevent a further analysis. Due to the nature and the different characteristics of artifacts, the development of an efficient artifact-reduction technique in reconstruction-space is rather complicated. In this paper we present a projection-space pipeline for metal-artifacts reduction. The proposed technique first segments the metal in the spatial domain of the reconstructed volume in order to separate it from the other materials. Then metal parts are forward-projected on the set of projections in a way that metal-projection regions are treated as voids. Subsequently the voids, which are left by the removed metal, are interpolated in the 2D projections. Finally, the metal is inserted back into the reconstructed 3D volume during the fusion stage. We present a visual analysis tool, allowing for interactive parameter estimation of the metal segmentation. The results of the proposed artifact-reduction technique are demonstrated on a test part as well as on real world components. For these specimens we achieve a significant reduction of metal artifacts, allowing an enhanced material characterization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064984]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.228]]></doi>

<publicationId><![CDATA[6064984]]></publicationId>

<partnum><![CDATA[6064984]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064984&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064984]]></pdf>

</document>

<document>

<rank>239</rank>

<title><![CDATA[Exploring the Millennium Run - Scalable Rendering of Large-Scale Cosmological Datasets]]></title>

<authors><![CDATA[Fraedrich, R.;  Schneider, J.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[astronomy computing]]></term>

<term><![CDATA[cosmology]]></term>

<term><![CDATA[dark matter]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[vector quantisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Vector quantization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1251]]></spage>

<epage><![CDATA[1258]]></epage>

<abstract><![CDATA[In this paper we investigate scalability limitations in the visualization of large-scale particle-based cosmological simulations, and we present methods to reduce these limitations on current PC architectures. To minimize the amount of data to be streamed from disk to the graphics subsystem, we propose a visually continuous level-of-detail (LOD) particle representation based on a hierarchical quantization scheme for particle coordinates and rules for generating coarse particle distributions. Given the maximal world space error per level, our LOD selection technique guarantees a sub-pixel screen space error during rendering. A brick-based page-tree allows to further reduce the number of disk seek operations to be performed. Additional particle quantities like density, velocity dispersion, and radius are compressed at no visible loss using vector quantization of logarithmically encoded floating point values. By fine-grain view-frustum culling and presence acceleration in a geometry shader the required geometry throughput on the GPU can be significantly reduced. We validate the quality and scalability of our method by presenting visualizations of a particle-based cosmological dark-matter simulation exceeding 10 billion elements.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290736]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.142]]></doi>

<publicationId><![CDATA[5290736]]></publicationId>

<partnum><![CDATA[5290736]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290736&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290736]]></pdf>

</document>

<document>

<rank>240</rank>

<title><![CDATA[Memory-Efficient Single-Pass GPU Rendering of Multifragment Effects]]></title>

<authors><![CDATA[Wencheng Wang;  Guofu Xie]]></authors>

<affiliations><![CDATA[State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Data communication]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Ellipsoids]]></term>

<term><![CDATA[Graphics processing units]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Slabs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1307]]></spage>

<epage><![CDATA[1316]]></epage>

<abstract><![CDATA[Rendering multifragment effects using graphics processing units (GPUs) is attractive for high speed. However, the efficiency is seriously compromised, because ordering fragments on GPUs is not easy and the GPU's memory may not be large enough to store the whole scene geometry. Hitherto, existing methods have been unsuitable for large models or have required many passes for data transmission from CPU to GPU, resulting in a bottleneck for speedup. This paper presents a stream method for accurate rendering of multifragment effects. It decomposes the model into parts and manages these in an efficient manner, guaranteeing that the parts can easily be ordered with respect to any viewpoint, and that each part can be rendered correctly on the GPU. Thus, we can transmit the model data part by part, and once a part has been loaded onto the GPU, we immediately render it and composite its result with the results of the processed parts. In this way, we need only a single pass for data access with a very low bounded memory requirement. Moreover, we treat parts in packs for further acceleration. Results show that our method is much faster than existing methods and can easily handle large models of any size.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6381406]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.320]]></doi>

<publicationId><![CDATA[6381406]]></publicationId>

<partnum><![CDATA[6381406]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6381406&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381406]]></pdf>

</document>

<document>

<rank>241</rank>

<title><![CDATA[Real-Time Evaluation and Visualization of Learner Performance in a Mixed-Reality Environment for Clinical Breast Examination]]></title>

<authors><![CDATA[Kotranza, A.;  Lind, D.S.;  Lok, Benjamin]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical education]]></term>

<term><![CDATA[computer based training]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[patient diagnosis]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Breast]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Real time systems]]></term>

<term><![CDATA[Sensors]]></term>

<term><![CDATA[Training]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1101]]></spage>

<epage><![CDATA[1114]]></epage>

<abstract><![CDATA[We investigate the efficacy of incorporating real-time feedback of user performance within mixed-reality environments (MREs) for training real-world tasks with tightly coupled cognitive and psychomotor components. This paper presents an approach to providing real-time evaluation and visual feedback of learner performance in an MRE for training clinical breast examination (CBE). In a user study of experienced and novice CBE practitioners (n = 69), novices receiving real-time feedback performed equivalently or better than more experienced practitioners in the completeness and correctness of the exam. A second user study (n = 8) followed novices through repeated practice of CBE in the MRE. Results indicate that skills improvement in the MRE transfers to the real-world task of CBE of human patients. This initial case study demonstrates the efficacy of MREs incorporating real-time feedback for training real-world cognitive-psychomotor tasks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5963665]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.132]]></doi>

<publicationId><![CDATA[5963665]]></publicationId>

<partnum><![CDATA[5963665]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5963665&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963665]]></pdf>

</document>

<document>

<rank>242</rank>

<title><![CDATA[An RBF-Based Reparameterization Method for Constrained Texture Mapping]]></title>

<authors><![CDATA[Hongchuan Yu;  Tong-Yee Lee;  I-Cheng Yeh;  Xiaosong Yang;  Wenxi Li;  Zhang, J.J.]]></authors>

<affiliations><![CDATA[Nat. Centre for Comput. Animation, Bournemouth Univ., Poole, UK]]></affiliations>

<controlledterms>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image enhancement]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[radial basis function networks]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1115]]></spage>

<epage><![CDATA[1124]]></epage>

<abstract><![CDATA[Texture mapping has long been used in computer graphics to enhance the realism of virtual scenes. However, to match the 3D model feature points with the corresponding pixels in a texture image, surface parameterization must satisfy specific positional constraints. However, despite numerous research efforts, the construction of a mathematically robust, foldover-free parameterization that is subject to positional constraints continues to be a challenge. In the present paper, this foldover problem is addressed by developing radial basis function (RBF)-based reparameterization. Given initial 2D embedding of a 3D surface, the proposed method can reparameterize 2D embedding into a foldover-free 2D mesh, satisfying a set of user-specified constraint points. In addition, this approach is mesh free. Therefore, generating smooth texture mapping results is possible without extra smoothing optimization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5928343]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.117]]></doi>

<publicationId><![CDATA[5928343]]></publicationId>

<partnum><![CDATA[5928343]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5928343&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928343]]></pdf>

</document>

<document>

<rank>243</rank>

<title><![CDATA[Trajectory Optimization for Full-Body Movements with Complex Contacts]]></title>

<authors><![CDATA[Al Borno, M.;  de Lasa, M.;  Hertzmann, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Toronto, Toronto, ON, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Linear programming]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1405]]></spage>

<epage><![CDATA[1414]]></epage>

<abstract><![CDATA[This paper presents the first method for full-body trajectory optimization of physics-based human motion that does not rely on motion capture, specified key-poses, or periodic motion. Optimization is performed using a small set of simple goals, for example, one hand should be on the ground, or the center-of-mass should be above a particular height. These objectives are applied to short spacetime windows which can be composed to express goals over an entire animation. Specific contact locations needed to achieve objectives are not required by our method. We show that the method can synthesize many different kinds of movement, including walking, hand walking, breakdancing, flips, and crawling. Most of these movements have never been previously synthesized by physics-based methods.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6392834]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.325]]></doi>

<publicationId><![CDATA[6392834]]></publicationId>

<partnum><![CDATA[6392834]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6392834&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392834]]></pdf>

</document>

<document>

<rank>244</rank>

<title><![CDATA[Robust creation of implicit surfaces from polygonal meshes]]></title>

<authors><![CDATA[Yngve, G.;  Turk, G.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Washington Univ., Seattle, WA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[matrix algebra]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Computer errors]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Object detection]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[346]]></spage>

<epage><![CDATA[359]]></epage>

<abstract><![CDATA[Implicit surfaces are used for a number of tasks in computer graphics, including modeling soft or organic objects, morphing, collision detection, and constructive solid geometry. Although operating on implicit surfaces is usually straightforward, creating them is not. We introduce a practical method for creating implicit surfaces from polygonal models that produces high-quality results for complex surfaces. Whereas much previous work in implicit surfaces has been done with primitives such as "blobbies," we use implicit surfaces based on a variational interpolation technique (the three-dimensional generalization of thin-plate interpolation). Given a polygonal mesh, we convert the data to a volumetric representation to use as a guide for creating the implicit surface iteratively. We begin by seeding the surface with a number of constraint points through which the surface must pass. Iteratively, additional constraints are added; the resulting surfaces are evaluated, and the errors guide the placement of subsequent constraints. We have applied our method successfully to a variety of polygonal meshes and consider it to be robust]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1044520]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2002.1044520]]></doi>

<publicationId><![CDATA[1044520]]></publicationId>

<partnum><![CDATA[1044520]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1044520&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044520]]></pdf>

</document>

<document>

<rank>245</rank>

<title><![CDATA[The Natural Helmholtz-Hodge Decomposition for Open-Boundary Flow Analysis]]></title>

<authors><![CDATA[Bhatia, H.;  Pascucci, V.;  Bremer, P.-T.]]></authors>

<affiliations><![CDATA[Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[flow simulation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Boundary conditions]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Green's function methods]]></term>

<term><![CDATA[Harmonic analysis]]></term>

<term><![CDATA[Poisson equations]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1566]]></spage>

<epage><![CDATA[1578]]></epage>

<abstract><![CDATA[The Helmholtz-Hodge decomposition (HHD), which describes a flow as the sum of an incompressible, an irrotational, and a harmonic flow, is a fundamental tool for simulation and analysis. Unfortunately, for bounded domains, the HHD is not uniquely defined, traditionally, boundary conditions are imposed to obtain a unique solution. However, in general, the boundary conditions used during the simulation may not be known known, or the simulation may use open boundary conditions. In these cases, the flow imposed by traditional boundary conditions may not be compatible with the given data, which leads to sometimes drastic artifacts and distortions in all three components, hence producing unphysical results. This paper proposes the natural HHD, which is defined by separating the flow into internal and external components. Using a completely data-driven approach, the proposed technique obtains uniqueness without assuming boundary conditions a priori. As a result, it enables a reliable and artifact-free analysis for flows with open boundaries or unknown boundary conditions. Furthermore, our approach computes the HHD on a point-wise basis in contrast to the existing global techniques, and thus supports computing inexpensive local approximations for any subset of the domain. Finally, the technique is easy to implement for a variety of spatial discretizations and interpolated fields in both two and three dimensions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6774477]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2312012]]></doi>

<publicationId><![CDATA[6774477]]></publicationId>

<partnum><![CDATA[6774477]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6774477&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774477]]></pdf>

</document>

<document>

<rank>246</rank>

<title><![CDATA[Extended Overview Techniques for Outdoor Augmented Reality]]></title>

<authors><![CDATA[Veas, E.;  Grasset, R.;  Kruijff, E.;  Schmalstieg, D.]]></authors>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Mobile communication]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[565]]></spage>

<epage><![CDATA[572]]></epage>

<abstract><![CDATA[In this paper, we explore techniques that aim to improve site understanding for outdoor Augmented Reality (AR) applications. While the first person perspective in AR is a direct way of filtering and zooming on a portion of the data set, it severely narrows overview of the situation, particularly over large areas. We present two interactive techniques to overcome this problem: multi-view AR and variable perspective view. We describe in details the conceptual, visualization and interaction aspects of these techniques and their evaluation through a comparative user study. The results we have obtained strengthen the validity of our approach and the applicability of our methods to a large range of application domains.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6165137]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.44]]></doi>

<publicationId><![CDATA[6165137]]></publicationId>

<partnum><![CDATA[6165137]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165137&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165137]]></pdf>

</document>

<document>

<rank>247</rank>

<title><![CDATA[Digital marbling: a multiscale fluid model]]></title>

<authors><![CDATA[Acar, R.;  Boulanger, P.]]></authors>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[laminar flow]]></term>

<term><![CDATA[stochastic processes]]></term>

<term><![CDATA[turbulent diffusion]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Fluctuations]]></term>

<term><![CDATA[Fluid dynamics]]></term>

<term><![CDATA[Fluid flow]]></term>

<term><![CDATA[Fluid flow control]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Microscopy]]></term>

<term><![CDATA[Pattern matching]]></term>

<term><![CDATA[Stochastic processes]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[600]]></spage>

<epage><![CDATA[614]]></epage>

<abstract><![CDATA[This paper presents a multiscale fluid model based on mesoscale dynamics and viscous fluid equations as a generic tool for digital marbling purposes. The model uses an averaging technique on the adaptation of a stochastic mesoscale model to obtain the effect of fluctuations at different levels. It allows various user controls to simulate complex flow behaviors as in traditional marbling techniques, as well as laminar and turbulent flows. Material transport is based on an improved advection solution to be able to match the highly detailed, sharp fluid interfaces in marbling patterns. In the transport model, two reaction models are introduced to create different effects and to simulate density fluctuations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634324]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.66]]></doi>

<publicationId><![CDATA[1634324]]></publicationId>

<partnum><![CDATA[1634324]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634324&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634324]]></pdf>

</document>

<document>

<rank>248</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4297681]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1037]]></doi>

<publicationId><![CDATA[4297681]]></publicationId>

<partnum><![CDATA[4297681]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297681&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297681]]></pdf>

</document>

<document>

<rank>249</rank>

<title><![CDATA[GPU-Assisted Computation of Centroidal Voronoi Tessellation]]></title>

<authors><![CDATA[Guodong Rong;  Yang Liu;  Wenping Wang;  Xiaotian Yin;  Gu, X.D.;  Guo, Xiaohu]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Texas at Dallas, Richardson, TX, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[coprocessors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Art]]></term>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Pattern recognition]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[345]]></spage>

<epage><![CDATA[356]]></epage>

<abstract><![CDATA[Centroidal Voronoi tessellations (CVT) are widely used in computational science and engineering. The most commonly used method is Lloyd's method, and recently the L-BFGS method is shown to be faster than Lloyd's method for computing the CVT. However, these methods run on the CPU and are still too slow for many practical applications. We present techniques to implement these methods on the GPU for computing the CVT on 2D planes and on surfaces, and demonstrate significant speedup of these GPU-based methods over their CPU counterparts. For CVT computation on a surface, we use a geometry image stored in the GPU to represent the surface for computing the Voronoi diagram on it. In our implementation a new technique is proposed for parallel regional reduction on the GPU for evaluating integrals over Voronoi cells.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5438988]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.53]]></doi>

<publicationId><![CDATA[5438988]]></publicationId>

<partnum><![CDATA[5438988]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5438988&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5438988]]></pdf>

</document>

<document>

<rank>250</rank>

<title><![CDATA[Front Cover]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[i]]></spage>

<epage><![CDATA[Bii]]></epage>

<abstract><![CDATA[Presents the front cover for this issue of the publication.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7064839]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2399732]]></doi>

<publicationId><![CDATA[7064839]]></publicationId>

<partnum><![CDATA[7064839]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7064839&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064839]]></pdf>

</document>

<document>

<rank>251</rank>

<title><![CDATA[MovExp: A Versatile Visualization Tool for Human-Computer Interaction Studies with 3D Performance and Biomechanical Data]]></title>

<authors><![CDATA[Palmas, G.;  Bachynskyi, M.;  Oulasvirta, A.;  Seidel, H.-P.;  Weinkauf, T.]]></authors>

<affiliations><![CDATA[Max Planck Inst. for Inf., Saarbrucken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human computer interaction]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Biomechanics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Ergonomics]]></term>

<term><![CDATA[Human computer interaction]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2359]]></spage>

<epage><![CDATA[2368]]></epage>

<abstract><![CDATA[In Human-Computer Interaction (HCI), experts seek to evaluate and compare the performance and ergonomics of user interfaces. Recently, a novel cost-efficient method for estimating physical ergonomics and performance has been introduced to HCI. It is based on optical motion capture and biomechanical simulation. It provides a rich source for analyzing human movements summarized in a multidimensional data set. Existing visualization tools do not sufficiently support the HCI experts in analyzing this data. We identified two shortcomings. First, appropriate visual encodings are missing particularly for the biomechanical aspects of the data. Second, the physical setup of the user interface cannot be incorporated explicitly into existing tools. We present MovExp, a versatile visualization tool that supports the evaluation of user interfaces. In particular, it can be easily adapted by the HCI experts to include the physical setup that is being evaluated, and visualize the data on top of it. Furthermore, it provides a variety of visual encodings to communicate muscular loads, movement directions, and other specifics of HCI studies that employ motion capture and biomechanical simulation. In this design study, we follow a problem-driven research approach. Based on a formalization of the visualization needs and the data structure, we formulate technical requirements for the visualization tool and present novel solutions to the analysis needs of the HCI experts. We show the utility of our tool with four case studies from the daily work of our HCI experts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876050]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346311]]></doi>

<publicationId><![CDATA[6876050]]></publicationId>

<partnum><![CDATA[6876050]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876050&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876050]]></pdf>

</document>

<document>

<rank>252</rank>

<title><![CDATA[Guest Editor&#x0027;s Introduction to the Special Section on the International Symposium on Mixed and Augmented Reality 2013]]></title>

<authors><![CDATA[Gandy, M.;  Julier, S.;  Kiyokawa, K.]]></authors>

<affiliations><![CDATA[Interactive Media Technology Center, Georgia Institute of Technology, Technology Square Research Building #313, 85 5th St NW, Atlanta, GA]]></affiliations>

<thesaurusterms>

<term><![CDATA[Augmented reality]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[555]]></spage>

<epage><![CDATA[556]]></epage>

<abstract><![CDATA[The articles in this special section were presented at the 2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR).]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7067526]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2410051]]></doi>

<publicationId><![CDATA[7067526]]></publicationId>

<partnum><![CDATA[7067526]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7067526&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7067526]]></pdf>

</document>

<document>

<rank>253</rank>

<title><![CDATA[Direct Isosurface Visualization of Hex-Based High-Order Geometry and Attribute Representations]]></title>

<authors><![CDATA[Martin, T.;  Cohen, E.;  Kirby, R.M.]]></authors>

<affiliations><![CDATA[Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Splines (mathematics)]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface topography]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[753]]></spage>

<epage><![CDATA[766]]></epage>

<abstract><![CDATA[In this paper, we present a novel isosurface visualization technique that guarantees the accurate visualization of isosurfaces with complex attribute data defined on (un)structured (curvi)linear hexahedral grids. Isosurfaces of high-order hexahedral-based finite element solutions on both uniform grids (including MRI and CT scans) and more complex geometry representing a domain of interest that can be rendered using our algorithm. Additionally, our technique can be used to directly visualize solutions and attributes in isogeometric analysis, an area based on trivariate high-order NURBS (Non-Uniform Rational B-splines) geometry and attribute representations for the analysis. Furthermore, our technique can be used to visualize isosurfaces of algebraic functions. Our approach combines subdivision and numerical root finding to form a robust and efficient isosurface visualization algorithm that does not miss surface features, while finding all intersections between a view frustum and desired isosurfaces. This allows the use of view-independent transparency in the rendering process. We demonstrate our technique through a straightforward CPU implementation on both complex-structured and complex-unstructured geometries with high-order simulation solutions, isosurfaces of medical data sets, and isosurfaces of algebraic functions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5887330]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.103]]></doi>

<publicationId><![CDATA[5887330]]></publicationId>

<partnum><![CDATA[5887330]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5887330&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887330]]></pdf>

</document>

<document>

<rank>254</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4472711]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.43]]></doi>

<publicationId><![CDATA[4472711]]></publicationId>

<partnum><![CDATA[4472711]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4472711&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4472711]]></pdf>

</document>

<document>

<rank>255</rank>

<title><![CDATA[Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists]]></title>

<authors><![CDATA[Brehmer, M.;  Ingram, S.;  Stray, J.;  Munzner, T.]]></authors>

<affiliations><![CDATA[Univ. of British Columbia, Vancouver, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Document handling]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Text analysis]]></term>

<term><![CDATA[Text mining]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2271]]></spage>

<epage><![CDATA[2280]]></epage>

<abstract><![CDATA[For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system &#x201C;in the wild&#x201D;, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of &#x201C;exploring&#x201D; a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875900]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346431]]></doi>

<publicationId><![CDATA[6875900]]></publicationId>

<partnum><![CDATA[6875900]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875900&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875900]]></pdf>

</document>

<document>

<rank>256</rank>

<title><![CDATA[Visual Mementos: Reflecting Memories with Personal Data]]></title>

<authors><![CDATA[Thudt, A.;  Baur, D.;  Huron, S.;  Carpendale, S.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data privacy]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Global Positioning System]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Loading]]></term>

<term><![CDATA[Privacy]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[369]]></spage>

<epage><![CDATA[378]]></epage>

<abstract><![CDATA[In this paper we discuss the creation of visual mementos as a new application area for visualization. We define visual mementos as visualizations of personally relevant data for the purpose of reminiscing, and sharing of life experiences. Today more people collect digital information about their life than ever before. The shift from physical to digital archives poses new challenges and opportunities for self-reflection and self-representation. Drawing on research on autobiographical memory and on the role of artifacts in reminiscing, we identified design challenges for visual mementos: mapping data to evoke familiarity, expressing subjectivity, and obscuring sensitive details for sharing. Visual mementos can make use of the known strengths of visualization in revealing patterns to show the familiar instead of the unexpected, and extend representational mappings beyond the objective to include the more subjective. To understand whether people's subjective views on their past can be reflected in a visual representation, we developed, deployed and studied a technology probe that exemplifies our concept of visual mementos. Our results show how reminiscing has been supported and reveal promising new directions for self-reflection and sharing through visual mementos of personal experiences.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192708]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467831]]></doi>

<publicationId><![CDATA[7192708]]></publicationId>

<partnum><![CDATA[7192708]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192708&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192708]]></pdf>

</document>

<document>

<rank>257</rank>

<title><![CDATA[Segmentation of discrete vector fields]]></title>

<authors><![CDATA[Hongyu Li;  Wenbin Chen;  I-Fan Shen]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Fudan Univ., Shanghai]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering methods]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Green function]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Merging]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Shape measurement]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[289]]></spage>

<epage><![CDATA[300]]></epage>

<abstract><![CDATA[In this paper, we propose an approach for 2D discrete vector field segmentation based on the Green function and normalized cut. The method is inspired by discrete Hodge decomposition such that a discrete vector field can be broken down into three simpler components, namely, curl-free, divergence-free, and harmonic components. We show that the Green function method (GFM) can be used to approximate the curl-free and the divergence-free components to achieve our goal of the vector field segmentation. The final segmentation curves that represent the boundaries of the influence region of singularities are obtained from the optimal vector field segmentations. These curves are composed of piecewise smooth contours or streamlines. Our method is applicable to both linear and nonlinear discrete vector fields. Experiments show that the segmentations obtained using our approach essentially agree with human perceptual judgement]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1608016]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.54]]></doi>

<publicationId><![CDATA[1608016]]></publicationId>

<partnum><![CDATA[1608016]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1608016&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608016]]></pdf>

</document>

<document>

<rank>258</rank>

<title><![CDATA[Network Visualization by Semantic Substrates]]></title>

<authors><![CDATA[Shneiderman, B.;  Aris, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Maryland Univ., College Park, MD]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Automatic control]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Graphical user interfaces]]></term>

<term><![CDATA[Law]]></term>

<term><![CDATA[Legal factors]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Terminology]]></term>

<term><![CDATA[Tunneling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[733]]></spage>

<epage><![CDATA[740]]></epage>

<abstract><![CDATA[Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015424]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.166]]></doi>

<publicationId><![CDATA[4015424]]></publicationId>

<partnum><![CDATA[4015424]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015424&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015424]]></pdf>

</document>

<document>

<rank>259</rank>

<title><![CDATA[Direct Feature Visualization Using Morse-Smale Complexes]]></title>

<authors><![CDATA[Gyulassy, A.;  Kotava, N.;  Kim, M.;  Hansen, C.D.;  Hagen, H.;  Pascucci, V.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[dictionaries]]></term>

<term><![CDATA[query languages]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Vectors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1549]]></spage>

<epage><![CDATA[1562]]></epage>

<abstract><![CDATA[In this paper, we characterize the range of features that can be extracted from an Morse-Smale complex and describe a unified query language to extract them. We provide a visual dictionary to guide users when defining features in terms of these queries. We demonstrate our topology-rich visualization pipeline in a tool that interactively queries the MS complex to extract features at multiple resolutions, assigns rendering attributes, and combines traditional volume visualization with the extracted features. The flexibility and power of this approach is illustrated with examples showing novel features.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065731]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.272]]></doi>

<publicationId><![CDATA[6065731]]></publicationId>

<partnum><![CDATA[6065731]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065731&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065731]]></pdf>

</document>

<document>

<rank>260</rank>

<title><![CDATA[Mesh Layouts for Block-Based Caches]]></title>

<authors><![CDATA[Yoon, S.-E.;  Lindstrom, P.]]></authors>

<affiliations><![CDATA[Lawrence Livermore Nat. Lab., Berkeley, CA]]></affiliations>

<controlledterms>

<term><![CDATA[cache storage]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Delay]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Optimizing compilers]]></term>

<term><![CDATA[Pattern matching]]></term>

<term><![CDATA[Spatial coherence]]></term>

<term><![CDATA[Strips]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1213]]></spage>

<epage><![CDATA[1220]]></epage>

<abstract><![CDATA[Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015484]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.162]]></doi>

<publicationId><![CDATA[4015484]]></publicationId>

<partnum><![CDATA[4015484]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015484&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015484]]></pdf>

</document>

<document>

<rank>261</rank>

<title><![CDATA[Exploring Brain Connectivity with Two-Dimensional Neural Maps]]></title>

<authors><![CDATA[Jianu, R.;  Demiralp, C.;  Laidlaw, D.H.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Brown Univ., Providence, RI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[biodiffusion]]></term>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[brain models]]></term>

<term><![CDATA[brain-computer interfaces]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[neural nets]]></term>

<term><![CDATA[neurophysiology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Diffusion tensor imaging]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Splines (mathematics)]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[978]]></spage>

<epage><![CDATA[987]]></epage>

<abstract><![CDATA[We introduce two-dimensional neural maps for exploring connectivity in the brain. For this, we create standard streamtube models from diffusion-weighted brain imaging data sets along with neural paths hierarchically projected into the plane. These planar neural maps combine desirable properties of low-dimensional representations, such as visual clarity and ease of tract-of-interest selection, with the anatomical familiarity of 3D brain models and planar sectional views. We distribute this type of visualization both in a traditional stand-alone interactive application and as a novel, lightweight web-accessible system. The web interface integrates precomputed neural-path representations into a geographical digital-maps framework with associated labels, metrics, statistics, and linkouts. Anecdotal and quantitative comparisons of the present method with a recently proposed 2D point representation suggest that our representation is more intuitive and easier to use and learn. Similarly, users are faster and more accurate in selecting bundles using the 2D path representation than the 2D point representation. Finally, expert feedback on the web interface suggests that it can be useful for collaboration as well as quick exploration of data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5753898]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.82]]></doi>

<publicationId><![CDATA[5753898]]></publicationId>

<partnum><![CDATA[5753898]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5753898&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753898]]></pdf>

</document>

<document>

<rank>262</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1541992]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.3]]></doi>

<publicationId><![CDATA[1541992]]></publicationId>

<partnum><![CDATA[1541992]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1541992&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1541992]]></pdf>

</document>

<document>

<rank>263</rank>

<title><![CDATA[Full Body Virtual Autopsies using a State-of-the-art Volume Rendering Pipeline]]></title>

<authors><![CDATA[Ljung, P.;  Winskog, C.;  Persson, A.;  Lundstrom, C.;  Ynnerman, A.]]></authors>

<affiliations><![CDATA[Div. for Visual Inf. Technol. & Applications, Linkoping Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Autopsy]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Cadaver]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Forensics]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[869]]></spage>

<epage><![CDATA[876]]></epage>

<abstract><![CDATA[This paper presents a procedure for virtual autopsies based on interactive 3D visualizations of large scale, high resolution data from CT-scans of human cadavers. The procedure is described using examples from forensic medicine and the added value and future potential of virtual autopsies is shown from a medical and forensic perspective. Based on the technical demands of the procedure state-of-the-art volume rendering techniques are applied and refined to enable real-time, full body virtual autopsies involving gigabyte sized data on standard GPUs. The techniques applied include transfer function based data reduction using level-of-detail selection and multi-resolution rendering techniques. The paper also describes a data management component for large, out-of-core data sets and an extension to the GPU-based raycaster for efficient dual TF rendering. Detailed benchmarks of the pipeline are presented using data sets from forensic cases]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015441]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.146]]></doi>

<publicationId><![CDATA[4015441]]></publicationId>

<partnum><![CDATA[4015441]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015441&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015441]]></pdf>

</document>

<document>

<rank>264</rank>

<title><![CDATA[Visualizing Tensor Normal Distributions at Multiple Levels of Detail]]></title>

<authors><![CDATA[Abbasloo, A.;  Wiens, V.;  Hermann, M.;  Schultz, T.]]></authors>

<affiliations><![CDATA[Univ. of Bonn, Bonn, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Covariance matrices]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Eigenvalues and eigenfunctions]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[975]]></spage>

<epage><![CDATA[984]]></epage>

<abstract><![CDATA[Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192624]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467031]]></doi>

<publicationId><![CDATA[7192624]]></publicationId>

<partnum><![CDATA[7192624]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192624&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192624]]></pdf>

</document>

<document>

<rank>265</rank>

<title><![CDATA[Guest Editors&#146; Introduction: Special Section on InfoVis]]></title>

<authors><![CDATA[Ward, M.O.;  Munzner, T.]]></authors>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Failure analysis]]></term>

<term><![CDATA[Robots]]></term>

<term><![CDATA[Software tools]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[431]]></spage>

<epage><![CDATA[431]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1432688]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.61]]></doi>

<publicationId><![CDATA[1432688]]></publicationId>

<partnum><![CDATA[1432688]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1432688&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1432688]]></pdf>

</document>

<document>

<rank>266</rank>

<title><![CDATA[Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping]]></title>

<authors><![CDATA[Jonsson, D.;  Kronander, J.;  Ropinski, T.;  Ynnerman, A.]]></authors>

<affiliations><![CDATA[Linkoping Univ., Linkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Photonics]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Volume measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2364]]></spage>

<epage><![CDATA[2371]]></epage>

<abstract><![CDATA[In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327241]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.232]]></doi>

<publicationId><![CDATA[6327241]]></publicationId>

<partnum><![CDATA[6327241]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327241&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327241]]></pdf>

</document>

<document>

<rank>267</rank>

<title><![CDATA[Efficient implementation of real-time view-dependent multiresolution meshing]]></title>

<authors><![CDATA[Pajarola, Renato;  DeCoro, C.]]></authors>

<affiliations><![CDATA[Comput. Graphics Lab, California Univ., Irvine, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[spatial data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Error correction]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[353]]></spage>

<epage><![CDATA[368]]></epage>

<abstract><![CDATA[In this paper, we present an efficient (topology preserving) multiresolution meshing framework for interactive level-of-detail (LOD) generation and rendering of large triangle meshes. More specifically, the presented approach, called FastMesh, provides view-dependent LOD generation and real-time mesh simplification that minimizes visual artifacts. Multiresolution triangle mesh representations are an important tool for reducing triangle mesh complexity in interactive rendering environments. Ideally, for interactive visualization, a triangle mesh is simplified to the maximal tolerated visible error and, thus, mesh simplification is view-dependent. This paper introduces an efficient hierarchical multiresolution triangulation framework based on a half-edge triangle mesh data structure and presents optimized implementations of several view-dependent or visual mesh simplification heuristics within that framework. Despite being optimized for performance, these error heuristics provide conservative error bounds. The presented framework is highly efficient both in space and time cost and needs only a fraction of the time required for rendering to perform the error calculations and dynamic mesh updates.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1272735]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1272735]]></doi>

<publicationId><![CDATA[1272735]]></publicationId>

<partnum><![CDATA[1272735]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1272735&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272735]]></pdf>

</document>

<document>

<rank>268</rank>

<title><![CDATA[Spatial domain wavelet design for feature preservation in computational data sets]]></title>

<authors><![CDATA[Craciun, G.;  Jiang, M.;  Thompson, D.;  Machiraju, R.]]></authors>

<affiliations><![CDATA[Math. Biosciences Inst., Ohio State Univ., Columbus, OH]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[low-pass filters]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Discrete wavelet transforms]]></term>

<term><![CDATA[Frequency domain analysis]]></term>

<term><![CDATA[Low pass filters]]></term>

<term><![CDATA[Wavelet domain]]></term>

<term><![CDATA[Wavelet transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[149]]></spage>

<epage><![CDATA[159]]></epage>

<abstract><![CDATA[High-fidelity wavelet transforms can facilitate visualization and analysis of large scientific data sets. However, it is important that salient characteristics of the original features be preserved under the transformation. We present a set of filter design axioms in the spatial domain which ensure that certain feature characteristics are preserved from scale to scale and that the resulting filters correspond to wavelet transforms admitting in-place implementation. We demonstrate how the axioms can be used to design linear feature-preserving filters that are optimal in the sense that they are closest in L<sup>2</sup> to the ideal low pass filter. We are particularly interested in linear wavelet transforms for large data sets generated by computational fluid dynamics simulations. Our effort is different from classical filter design approaches which focus solely on performance in the frequency domain. Results are included that demonstrate the feature-preservation characteristics of our filters]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1388226]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.35]]></doi>

<publicationId><![CDATA[1388226]]></publicationId>

<partnum><![CDATA[1388226]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1388226&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1388226]]></pdf>

</document>

<document>

<rank>269</rank>

<title><![CDATA[Multivariate Data Analysis Using Persistence-Based Filtering and Topological Signatures]]></title>

<authors><![CDATA[Rieck, B.;  Mara, H.;  Leitte, H.]]></authors>

<affiliations><![CDATA[Interdiscipl. Center for Sci. Comput. (IWR), Heidelberg Univ., Heidelberg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[history]]></term>

<term><![CDATA[information filtering]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering methods]]></term>

<term><![CDATA[Multivariate data sets]]></term>

<term><![CDATA[Network topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2382]]></spage>

<epage><![CDATA[2391]]></epage>

<abstract><![CDATA[The extraction of significant structures in arbitrary high-dimensional data sets is a challenging task. Moreover, classifying data points as noise in order to reduce a data set bears special relevance for many application domains. Standard methods such as clustering serve to reduce problem complexity by providing the user with classes of similar entities. However, they usually do not highlight relations between different entities and require a stopping criterion, e.g. the number of clusters to be detected. In this paper, we present a visualization pipeline based on recent advancements in algebraic topology. More precisely, we employ methods from persistent homology that enable topological data analysis on high-dimensional data sets. Our pipeline inherently copes with noisy data and data sets of arbitrary dimensions. It extracts central structures of a data set in a hierarchical manner by using a persistence-based filtering algorithm that is theoretically well-founded. We furthermore introduce persistence rings, a novel visualization technique for a class of topological features-the persistence intervals-of large data sets. Persistence rings provide a unique topological signature of a data set, which helps in recognizing similarities. In addition, we provide interactive visualization techniques that assist the user in evaluating the parameter space of our method in order to extract relevant structures. We describe and evaluate our analysis pipeline by means of two very distinct classes of data sets: First, a class of synthetic data sets containing topological objects is employed to highlight the interaction capabilities of our method. Second, in order to affirm the utility of our technique, we analyse a class of high-dimensional real-world data sets arising from current research in cultural heritage.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327243]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.248]]></doi>

<publicationId><![CDATA[6327243]]></publicationId>

<partnum><![CDATA[6327243]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327243&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327243]]></pdf>

</document>

<document>

<rank>270</rank>

<title><![CDATA[Efficient Computation of Combinatorial Feature Flow Fields]]></title>

<authors><![CDATA[Reininghaus, J.;  Kasten, J.;  Weinkauf, T.;  Hotz, I.]]></authors>

<affiliations><![CDATA[Konrad-Zuse-Zentrum fuer Informationstechnik, Zuse Inst., Berlin, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[combinatorial mathematics]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[numerical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Jacobian matrices]]></term>

<term><![CDATA[Joining processes]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Noise measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1563]]></spage>

<epage><![CDATA[1573]]></epage>

<abstract><![CDATA[We propose a combinatorial algorithm to track critical points of 2D time-dependent scalar fields. Existing tracking algorithms such as Feature Flow Fields apply numerical schemes utilizing derivatives of the data, which makes them prone to noise and involve a large number of computational parameters. In contrast, our method is robust against noise since it does not require derivatives, interpolation, and numerical integration. Furthermore, we propose an importance measure that combines the spatial persistence of a critical point with its temporal evolution. This leads to a time-aware feature hierarchy, which allows us to discriminate important from spurious features. Our method requires only a single, easy-to-tune computational parameter and is naturally formulated in an out-of-core fashion, which enables the analysis of large data sets. We apply our method to synthetic data and data sets from computational fluid dynamics and compare it to the stabilized continuous Feature Flow Field tracking algorithm.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6060947]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.269]]></doi>

<publicationId><![CDATA[6060947]]></publicationId>

<partnum><![CDATA[6060947]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6060947&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060947]]></pdf>

</document>

<document>

<rank>271</rank>

<title><![CDATA[Visualizing Business Data with Generalized Treemaps]]></title>

<authors><![CDATA[Vliegen, R.;  van Wijk, J.J.;  van der Linden, E.-J.]]></authors>

<affiliations><![CDATA[MagnaView]]></affiliations>

<controlledterms>

<term><![CDATA[business data processing]]></term>

<term><![CDATA[business graphics]]></term>

<term><![CDATA[data models]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[tree data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[789]]></spage>

<epage><![CDATA[796]]></epage>

<abstract><![CDATA[Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015431]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.200]]></doi>

<publicationId><![CDATA[4015431]]></publicationId>

<partnum><![CDATA[4015431]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015431&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015431]]></pdf>

</document>

<document>

<rank>272</rank>

<title><![CDATA[A Taxonomy of Clutter Reduction for Information Visualisation]]></title>

<authors><![CDATA[Ellis, G.;  Dix, A.]]></authors>

<affiliations><![CDATA[Lancaster Univ, Lancaster]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Government]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Software]]></term>

<term><![CDATA[Taxonomy]]></term>

<term><![CDATA[Usability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1216]]></spage>

<epage><![CDATA[1223]]></epage>

<abstract><![CDATA[Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376143]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70535]]></doi>

<publicationId><![CDATA[4376143]]></publicationId>

<partnum><![CDATA[4376143]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376143&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376143]]></pdf>

</document>

<document>

<rank>273</rank>

<title><![CDATA[Zometool Rationalization of Freeform Surfaces]]></title>

<authors><![CDATA[Zimmer, H.;  Kobbelt, L.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Graphics & Multimedia, RWTH Aachen Univ., Aachen, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Harmonic analysis]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1461]]></spage>

<epage><![CDATA[1473]]></epage>

<abstract><![CDATA[An ever broader availability of freeform designs together with an increasing demand for product customization has lead to a rising interest in efficient physical realization of such designs, the trend toward personal fabrication. Not only large-scale architectural applications are (becoming increasingly) popular but also different consumer-level rapid-prototyping applications, including toy and 3D puzzle creation. In this work we present a method for do-it-yourself reproduction of freeform designs without the typical limitation of state-of-the-art approaches requiring manufacturing custom parts using semi-professional laser cutters or 3D printers. Our idea is based on a popular mathematical modeling system (Zometool) commonly used for modeling higher dimensional polyhedra and symmetric structures such as molecules and crystal lattices. The proposed method extends the scope of Zometool modeling to freeform, disk-topology surfaces. While being an efficient construction system on the one hand (consisting only of a single node type and nine different edge types), this inherent discreteness of the Zometool system, on the other hand gives rise to a hard approximation problem. We base our method on a marching front approach, where elements are not added in a greedy sense, but rather whole regions on the front are filled optimally, using a set of problem specific heuristics to keep complexity under control.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6747390]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2307885]]></doi>

<publicationId><![CDATA[6747390]]></publicationId>

<partnum><![CDATA[6747390]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6747390&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6747390]]></pdf>

</document>

<document>

<rank>274</rank>

<title><![CDATA[Exploring Curved Schematization of Territorial Outlines]]></title>

<authors><![CDATA[van Goethem, A.;  Meulemans, W.;  Speckmann, B.;  Wood, J.]]></authors>

<affiliations><![CDATA[Dept. of Math. & Comput. Sci., Tech. Univ. Eindhoven, Eindhoven, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computational geometry]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Clocks]]></term>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[889]]></spage>

<epage><![CDATA[902]]></epage>

<abstract><![CDATA[Hand-drawn schematized maps traditionally make extensive use of curves. However, there are few automated approaches for curved schematization; most previous work focuses on straight lines. We present a new algorithm for area-preserving curved schematization of territorial outlines. Our algorithm converts a simple polygon into a schematic crossing-free representation using circular arcs. We use two basic operations to iteratively replace consecutive arcs until the desired complexity is reached. Our results are not restricted to arcs ending at input vertices. The method can be steered towards different degrees of &#x201C;curviness&#x201D;: we can encourage or discourage the use of arcs with a large central angle via a single parameter. Our method creates visually pleasing results even for very low output complexities. To evaluate the effectiveness of our design choices, we present a geometric evaluation of the resulting schematizations. Besides the geometric qualities of our algorithm, we also investigate the potential of curved schematization as a concept. We conducted an online user study investigating the effectiveness of curved schematizations compared to straight-line schematizations. While the visual complexity of curved shapes was judged higher than that of straight-line shapes, users generally preferred curved schematizations. We observed that curves significantly improved the ability of users to match schematized shapes of moderate complexity to their unschematized equivalents.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7035078]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2401025]]></doi>

<publicationId><![CDATA[7035078]]></publicationId>

<partnum><![CDATA[7035078]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7035078&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7035078]]></pdf>

</document>

<document>

<rank>275</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on the Eurographics Symposium on Parallel Graphics and Visualization (EGPGV)]]></title>

<authors><![CDATA[Comba, J.;  Weiskopf, D.]]></authors>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[130]]></spage>

<epage><![CDATA[131]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5665271]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.14]]></doi>

<publicationId><![CDATA[5665271]]></publicationId>

<partnum><![CDATA[5665271]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5665271&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5665271]]></pdf>

</document>

<document>

<rank>276</rank>

<title><![CDATA[2010 Reviewers List]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[IEEE]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[125]]></spage>

<epage><![CDATA[128]]></epage>

<abstract><![CDATA[Lists the reviewers who contributed to the IEEE Transactions on Visualization and Computer Graphics for 2010.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5629315]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.2]]></doi>

<publicationId><![CDATA[5629315]]></publicationId>

<partnum><![CDATA[5629315]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5629315&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5629315]]></pdf>

</document>

<document>

<rank>277</rank>

<title><![CDATA[Table of contents]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[iii]]></spage>

<epage><![CDATA[iv]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6777446]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.41]]></doi>

<publicationId><![CDATA[6777446]]></publicationId>

<partnum><![CDATA[6777446]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777446&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777446]]></pdf>

</document>

<document>

<rank>278</rank>

<title><![CDATA[Haptics-based dynamic implicit solid modeling]]></title>

<authors><![CDATA[Hua, J.;  Hong Qin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[deformation]]></term>

<term><![CDATA[haptic interfaces]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Manipulator dynamics]]></term>

<term><![CDATA[Power system modeling]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[574]]></spage>

<epage><![CDATA[586]]></epage>

<abstract><![CDATA[We systematically present a novel, interactive solid modeling framework, haptics-based dynamic implicit solid modeling, which is founded upon volumetric implicit functions and powerful physics-based modeling. In particular, we augment our modeling framework with a haptic mechanism in order to take advantage of additional realism associated with a 3D haptic interface. Our dynamic implicit solids are semialgebraic sets of volumetric implicit functions and are governed by the principles of dynamics, hence responding to sculpting forces in a natural and predictable manner. In order to directly manipulate existing volumetric data sets as well as point clouds, we develop a hierarchical fitting algorithm to reconstruct and represent discrete data sets using our continuous implicit functions, which permit users to further design and edit those existing 3D models in real-time using a large variety of haptic and geometric toolkits, and visualize their interactive deformation at arbitrary resolution. The additional geometric and physical constraints afford more sophisticated control of the dynamic implicit solids. The versatility of our dynamic implicit modeling enables the user to easily modify both the geometry and the topology of modeled objects, while the inherent physical properties can offer an intuitive haptic interface for direct manipulation with force feedback.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1310283]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.28]]></doi>

<publicationId><![CDATA[1310283]]></publicationId>

<partnum><![CDATA[1310283]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310283&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310283]]></pdf>

</document>

<document>

<rank>279</rank>

<title><![CDATA[Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis]]></title>

<authors><![CDATA[Brehmer, M.;  Ng, J.;  Tate, K.;  Munzner, T.]]></authors>

<controlledterms>

<term><![CDATA[building management systems]]></term>

<term><![CDATA[buildings (structures)]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern matching]]></term>

<term><![CDATA[power engineering computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aggregates]]></term>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Portfolios]]></term>

<term><![CDATA[Time series analysis]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[449]]></spage>

<epage><![CDATA[458]]></epage>

<abstract><![CDATA[The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7225156]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2466971]]></doi>

<publicationId><![CDATA[7225156]]></publicationId>

<partnum><![CDATA[7225156]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7225156&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225156]]></pdf>

</document>

<document>

<rank>280</rank>

<title><![CDATA[Visualization and Exploration of Temporal Trend Relationships in Multivariate Time-Varying Data]]></title>

<authors><![CDATA[Teng-Yok Lee;  Han-Wei Shen]]></authors>

<affiliations><![CDATA[Ohio State Univ., Columbus, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Hurricanes]]></term>

<term><![CDATA[Temperature]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[User interfaces]]></term>

<term><![CDATA[Wind]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1359]]></spage>

<epage><![CDATA[1366]]></epage>

<abstract><![CDATA[We present a new algorithm to explore and visualize multivariate time-varying data sets. We identify important trend relationships among the variables based on how the values of the variables change over time and how those changes are related to each other in different spatial regions and time intervals. The trend relationships can be used to describe the correlation and causal effects among the different variables. To identify the temporal trends from a local region, we design a new algorithm called SUBDTW to estimate when a trend appears and vanishes in a given time series. Based on the beginning and ending times of the trends, their temporal relationships can be modeled as a state machine representing the trend sequence. Since a scientific data set usually contains millions of data points, we propose an algorithm to extract important trend relationships in linear time complexity. We design novel user interfaces to explore the trend relationships, to visualize their temporal characteristics, and to display their spatial distributions. We use several scientific data sets to test our algorithm and demonstrate its utilities.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290749]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.200]]></doi>

<publicationId><![CDATA[5290749]]></publicationId>

<partnum><![CDATA[5290749]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290749&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290749]]></pdf>

</document>

<document>

<rank>281</rank>

<title><![CDATA[An Enhanced Visualization Process Model for Incremental Visualization]]></title>

<authors><![CDATA[Schulz, Hans-Jorg;  Angelini, M.;  Santucci, G.;  Schumann, H.]]></authors>

<affiliations><![CDATA[Hans-Jorg Schulz is with the Fraunhofer IGD Rostock, Rostock, Germany.(Email: hjschulz@informatik.uni-rostock.de)]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[With today&#x2019;s technical possibilities, a stable visualization scenario can no longer be assumed as a matter of course, as underlying data and targeted display setup are much more in flux than in traditional scenarios. Incremental visualization approaches are a means to address this challenge, as they permit the user to interact with, steer, and change the visualization at intermediate time points and not just after it has been completed. In this paper, we put forward a model for incremental visualizations that is based on the established Data State Reference Model, but extends it in ways to also represent partitioned data and visualization operators to facilitate intermediate visualization updates. In combination, partitioned data and operators can be used independently and in combination to strike tailored compromises between output quality, shown data quantity, and responsiveness&#x2014;i.e., frame rates. We showcase the new expressive power of this model by discussing the opportunities and challenges of incremental visualization in general and its usage in a real world scenario in particular.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7172541]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2462356]]></doi>

<publicationId><![CDATA[7172541]]></publicationId>

<partnum><![CDATA[7172541]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7172541&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7172541]]></pdf>

</document>

<document>

<rank>282</rank>

<title><![CDATA[Optimal Sets of Projections of High-Dimensional Data]]></title>

<authors><![CDATA[Lehmann, D.J.;  Theisel, H.]]></authors>

<affiliations><![CDATA[Univ. of Magdeburg, Magdeburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[matrix algebra]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Benchmark testing]]></term>

<term><![CDATA[Convergence]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Iris]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[609]]></spage>

<epage><![CDATA[618]]></epage>

<abstract><![CDATA[Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192684]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467132]]></doi>

<publicationId><![CDATA[7192684]]></publicationId>

<partnum><![CDATA[7192684]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192684&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192684]]></pdf>

</document>

<document>

<rank>283</rank>

<title><![CDATA[Author index]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[380]]></spage>

<epage><![CDATA[381]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the coauthors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under he primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[965351]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2001.965351]]></doi>

<publicationId><![CDATA[965351]]></publicationId>

<partnum><![CDATA[965351]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=965351&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965351]]></pdf>

</document>

<document>

<rank>284</rank>

<title><![CDATA[An Energy-Driven Motion Planning Method for Two Distant Postures]]></title>

<authors><![CDATA[He Wang;  Ho, E.S.L.;  Komura, T.]]></authors>

<affiliations><![CDATA[Sch. of Inf., Univ. of Edinburgh, Edinburgh, UK]]></affiliations>

<controlledterms>

<term><![CDATA[boundary-value problems]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Couplings]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Planning]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[18]]></spage>

<epage><![CDATA[30]]></epage>

<abstract><![CDATA[In this paper, we present a local motion planning algorithm for character animation. We focus on motion planning between two distant postures where linear interpolation leads to penetrations. Our framework has two stages. The motion planning problem is first solved as a Boundary Value Problem (BVP) on an energy graph which encodes penetrations, motion smoothness and user control. Having established a mapping from the configuration space to the energy graph, a fast and robust local motion planning algorithm is introduced to solve the BVP to generate motions that could only previously be computed by global planning methods. In the second stage, a projection of the solution motion onto a constraint manifold is proposed for more user control. Our method can be integrated into current keyframing techniques. It also has potential applications in motion planning problems in robotics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6824787]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2327976]]></doi>

<publicationId><![CDATA[6824787]]></publicationId>

<partnum><![CDATA[6824787]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6824787&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824787]]></pdf>

</document>

<document>

<rank>285</rank>

<title><![CDATA[International Program Committee and Steering Committee]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[ix]]></spage>

<epage><![CDATA[ix]]></epage>

<abstract><![CDATA[Provides a listing of current committee members.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479165]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.49]]></doi>

<publicationId><![CDATA[6479165]]></publicationId>

<partnum><![CDATA[6479165]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479165&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479165]]></pdf>

</document>

<document>

<rank>286</rank>

<title><![CDATA[Animated Transitions in Statistical Data Graphics]]></title>

<authors><![CDATA[Heer, J.;  Robertson, G.G.]]></authors>

<affiliations><![CDATA[Univ. of California at Berkeley, Berkeley]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Drilling]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Guidelines]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Marketing and sales]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Taxonomy]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1240]]></spage>

<epage><![CDATA[1247]]></epage>

<abstract><![CDATA[In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in <i>DynaVis</i>, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376146]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70539]]></doi>

<publicationId><![CDATA[4376146]]></publicationId>

<partnum><![CDATA[4376146]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376146&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376146]]></pdf>

</document>

<document>

<rank>287</rank>

<title><![CDATA[Closed-Loop Feedback Illumination for Optical Inverse Tone-Mapping in Light Microscopy]]></title>

<authors><![CDATA[Bimber, O.;  Kloeck, D.;  Amano, T.;  Grundhoefer, A.;  Kurz, D.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Graphics, Johannes Kepler Univ. Linz, Linz, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[image enhancement]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[optical computing]]></term>

<term><![CDATA[optical images]]></term>

<term><![CDATA[optical microscopy]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical optical imaging]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Fluorescence]]></term>

<term><![CDATA[Interference]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Optical feedback]]></term>

<term><![CDATA[Optical microscopy]]></term>

<term><![CDATA[Optical modulation]]></term>

<term><![CDATA[Optical recording]]></term>

<term><![CDATA[Optical refraction]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[857]]></spage>

<epage><![CDATA[870]]></epage>

<abstract><![CDATA[In this paper, we show that optical inverse tone-mapping (OITM) in light microscopy can improve the visibility of specimens, both when observed directly through the oculars and when imaged with a camera. In contrast to previous microscopy techniques, we premodulate the illumination based on the local modulation properties of the specimen itself. We explain how the modulation of uniform white light by a specimen can be estimated in real time, even though the specimen is continuously but not uniformly illuminated. This information is processed and back-projected constantly, allowing the illumination to be adjusted on the fly if the specimen is moved or the focus or magnification of the microscope is changed. The contrast of the specimen's optical image can be enhanced, and high-intensity highlights can be suppressed. A formal pilot study with users indicates that this optimizes the visibility of spatial structures when observed through the oculars. We also demonstrate that the signal-to-noise (S/N) ratio in digital images of the specimen is higher if captured under an optimized rather than a uniform illumination. In contrast to advanced scanning techniques that maximize the S/N ratio using multiple measurements, our approach is fast because it requires only two images. This can improve image analysis in digital microscopy applications with real-time capturing requirements.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5539757]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.104]]></doi>

<publicationId><![CDATA[5539757]]></publicationId>

<partnum><![CDATA[5539757]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5539757&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5539757]]></pdf>

</document>

<document>

<rank>288</rank>

<title><![CDATA[Scattering Points in Parallel Coordinates]]></title>

<authors><![CDATA[Xiaoru Yuan;  Peihong Guo;  He Xiao;  Hong Zhou;  Huamin Qu]]></authors>

<affiliations><![CDATA[Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Explosions]]></term>

<term><![CDATA[Interference]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[System performance]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1001]]></spage>

<epage><![CDATA[1008]]></epage>

<abstract><![CDATA[In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290705]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.179]]></doi>

<publicationId><![CDATA[5290705]]></publicationId>

<partnum><![CDATA[5290705]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290705&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290705]]></pdf>

</document>

<document>

<rank>289</rank>

<title><![CDATA[Mesh-Guided Optimized Retexturing for Image and Video]]></title>

<authors><![CDATA[Yanwen Guo;  Hanqiu Sun;  Qunsheng Peng;  Zhongding Jiang]]></authors>

<affiliations><![CDATA[Nanjing Univ., Nanjing]]></affiliations>

<controlledterms>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[stochastic processes]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[426]]></spage>

<epage><![CDATA[439]]></epage>

<abstract><![CDATA[This paper presents a novel approach for replacing textures of specified regions in the input image and video using stretch-based mesh optimization. The retexturing results have the similar distortion and shading effect conforming to the unknown underlying geometry and lighting conditions. For replacing textures in a single image, two important steps are developed: The stretch-based mesh parameterization incorporating the recovered normal information is deduced to imitate perspective distortion of the region of interest; the Poisson-based refinement process is exploited to account for texture distortion at fine scale. The luminance of the input image is preserved through color transfer in YCbCr color space. Our approach is independent of the replaced textures. Once the input image is processed, any new textures can be applied to efficiently generate the retexturing results. For video retexturing, we propose key-frame-based texture replacement extended and generalized from the image retexturing. Our approach repeatedly propagates the replacement results of key frames to the rest of the frames. We develop the local motion optimization scheme to deal with the inaccuracies and errors of robust optical flow when tracking moving objects. Visibility shifting and texture drifting are effectively alleviated using graphcut segmentation algorithm and the global optimization to smooth trajectories of the tracked points over temporal domain. Our experimental results showed that the proposed approach can generate visually pleasing results for retextured images and video.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359506]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70438]]></doi>

<publicationId><![CDATA[4359506]]></publicationId>

<partnum><![CDATA[4359506]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359506&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359506]]></pdf>

</document>

<document>

<rank>290</rank>

<title><![CDATA[Query2Question: Translating Visualization Interaction into Natural Language]]></title>

<authors><![CDATA[Nafari, M.;  Weaver, C.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci., Univ. of Oklahoma, Norman, OK, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[natural language processing]]></term>

<term><![CDATA[query processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Manuals]]></term>

<term><![CDATA[Natural languages]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[756]]></spage>

<epage><![CDATA[769]]></epage>

<abstract><![CDATA[Richly interactive visualization tools are increasingly popular for data exploration and analysis in a wide variety of domains. Existing systems and techniques for recording provenance of interaction focus either on comprehensive automated recording of low-level interaction events or on idiosyncratic manual transcription of high-level analysis activities. In this paper, we present the architecture and translation design of a query-to-question (Q2Q) system that automatically records user interactions and presents them semantically using natural language (written English). Q2Q takes advantage of domain knowledge and uses natural language generation (NLG) techniques to translate and transcribe a progression of interactive visualization states into a visual log of styled text that complements and effectively extends the functionality of visualization tools. We present Q2Q as a means to support a cross-examination process in which questions rather than interactions are the focus of analytic reasoning and action. We describe the architecture and implementation of the Q2Q system, discuss key design factors and variations that effect question generation, and present several visualizations that incorporate Q2Q for analysis in a variety of knowledge domains.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7018997]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2396062]]></doi>

<publicationId><![CDATA[7018997]]></publicationId>

<partnum><![CDATA[7018997]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7018997&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7018997]]></pdf>

</document>

<document>

<rank>291</rank>

<title><![CDATA[Interactive Volume Visualization of General Polyhedral Grids]]></title>

<authors><![CDATA[Muigg, P.;  Hadwiger, M.;  Doleisch, H.;  Groller, E.]]></authors>

<affiliations><![CDATA[Vienna Univ. of Technol., Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[simulation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2115]]></spage>

<epage><![CDATA[2124]]></epage>

<abstract><![CDATA[This paper presents a novel framework for visualizing volumetric data specified on complex polyhedral grids, without the need to perform any kind of a priori tetrahedralization. These grids are composed of polyhedra that often are non-convex and have an arbitrary number of faces, where the faces can be non-planar with an arbitrary number of vertices. The importance of such grids in state-of-the-art simulation packages is increasing rapidly. We propose a very compact, face-based data structure for representing such meshes for visualization, called two-sided face sequence lists (TSFSL), as well as an algorithm for direct GPU-based ray-casting using this representation. The TSFSL data structure is able to represent the entire mesh topology in a 1D TSFSL data array of face records, which facilitates the use of efficient 1D texture accesses for visualization. In order to scale to large data sizes, we employ a mesh decomposition into bricks that can be handled independently, where each brick is then composed of its own TSFSL array. This bricking enables memory savings and performance improvements for large meshes. We illustrate the feasibility of our approach with real-world application results, by visualizing highly complex polyhedral data from commercial state-of-the-art simulation packages.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064976]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.216]]></doi>

<publicationId><![CDATA[6064976]]></publicationId>

<partnum><![CDATA[6064976]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064976&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064976]]></pdf>

</document>

<document>

<rank>292</rank>

<title><![CDATA[Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study]]></title>

<authors><![CDATA[Lloyd, D.;  Dykes, J.]]></authors>

<affiliations><![CDATA[giCentre, City Univ. London, London, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[knowledge acquisition]]></term>

<term><![CDATA[prototypes]]></term>

<term><![CDATA[user centred design]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Domain specific languages]]></term>

<term><![CDATA[Human factors]]></term>

<term><![CDATA[Taxonomy]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2498]]></spage>

<epage><![CDATA[2507]]></epage>

<abstract><![CDATA[Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065017]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.209]]></doi>

<publicationId><![CDATA[6065017]]></publicationId>

<partnum><![CDATA[6065017]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065017&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065017]]></pdf>

</document>

<document>

<rank>293</rank>

<title><![CDATA[Splatterplots: Overcoming Overdraw in Scatter Plots]]></title>

<authors><![CDATA[Mayorga, A.;  Gleicher, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphics processing units]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clutter]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1526]]></spage>

<epage><![CDATA[1538]]></epage>

<abstract><![CDATA[We introduce Splatterplots, a novel presentation of scattered data that enables visualizations that scale beyond standard scatter plots. Traditional scatter plots suffer from overdraw (overlapping glyphs) as the number of points per unit area increases. Overdraw obscures outliers, hides data distributions, and makes the relationship among subgroups of the data difficult to discern. To address these issues, Splatterplots abstract away information such that the density of data shown in any unit of screen space is bounded, while allowing continuous zoom to reveal abstracted details. Abstraction automatically groups dense data points into contours and samples remaining points. We combine techniques for abstraction with perceptually based color blending to reveal the relationship between data subgroups. The resulting visualizations represent the dense regions of each subgroup of the data set as smooth closed shapes and show representative outliers explicitly. We present techniques that leverage the GPU for Splatterplot computation and rendering, enabling interaction with massive data sets. We show how Splatterplots can be an effective alternative to traditional methods of displaying scatter data communicating data trends, outliers, and data set relationships much like traditional scatter plots, but scaling to data sets of higher density and up to millions of points on the screen.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6484064]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.65]]></doi>

<publicationId><![CDATA[6484064]]></publicationId>

<partnum><![CDATA[6484064]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6484064&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6484064]]></pdf>

</document>

<document>

<rank>294</rank>

<title><![CDATA[Modality-driven Classification and Visualization of Ensemble Variance]]></title>

<authors><![CDATA[Bensema, K.;  Gosink, L.;  Obermaier, H.;  Joy, K.]]></authors>

<affiliations><![CDATA[Kevin Bensema is with the Department of Com- puter Science at the University of California at Davis.(email:kbensema@ucdavis.edu)]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Advances in computational power now enable domain scientists to address conceptual and parametric uncertainty by running simulations multiple times in order to sufficiently sample the uncertain input space. While this approach helps address conceptual and parametric uncertainties, the ensemble datasets produced by this technique present a special challenge to visualization researchers as the ensemble dataset records a distribution of possible values for each location in the domain. Contemporary visualization approaches that rely solely on summary statistics (e.g., mean and variance) cannot convey the detailed information encoded in ensemble distributions that are paramount to ensemble analysis; summary statistics provide no information about modality classification and modality persistence. To address this problem, we propose a novel technique that classifies high-variance locations based on the modality of the distribution of ensemble predictions. Additionally, we develop a set of confidence metrics to inform the end-user of the quality of fit between the distribution at a given location and its assigned class. Finally, for the special application of evaulating the stability of bimodal regions, we develop local and regional metrics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7352364]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2507569]]></doi>

<publicationId><![CDATA[7352364]]></publicationId>

<partnum><![CDATA[7352364]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7352364&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352364]]></pdf>

</document>

<document>

<rank>295</rank>

<title><![CDATA[Analysis of head pose accuracy in augmented reality]]></title>

<authors><![CDATA[Hoff, W.;  Vincent, T.]]></authors>

<affiliations><![CDATA[Div. of Eng., Colorado Sch. of Mines, Golden, CO, USA]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[covariance matrices]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[optical sensors]]></term>

<term><![CDATA[optical tracking]]></term>

<term><![CDATA[sensor fusion]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Augmented reality]]></term>

<term><![CDATA[Covariance matrix]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Ellipsoids]]></term>

<term><![CDATA[Fuses]]></term>

<term><![CDATA[Optical computing]]></term>

<term><![CDATA[Optical sensors]]></term>

<term><![CDATA[Sensor fusion]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[319]]></spage>

<epage><![CDATA[334]]></epage>

<abstract><![CDATA[A method is developed to analyze the accuracy of the relative head-to-object position and orientation (pose) in augmented reality systems with head-mounted displays. From probabilistic estimates of the errors in optical tracking sensors, the uncertainty in head-to-object pose can be computed in the form of a covariance matrix. The positional uncertainty can be visualized as a 3D ellipsoid. One useful benefit of having an explicit representation of uncertainty is that we can fuse sensor data from a combination of fixed and head-mounted sensors in order to improve the overall registration accuracy. The method was applied to the analysis of an experimental augmented reality system, incorporating an optical see-through head-mounted display, a head-mounted CCD camera, and a fixed optical tracking sensor. The uncertainty of the pose of a movable object with respect to the head-mounted display was analyzed. By using both fixed and head mounted sensors, we produced a pose estimate that is significantly more accurate than that produced by either sensor acting alone]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[895877]]></arnumber>

<doi><![CDATA[10.1109/2945.895877]]></doi>

<publicationId><![CDATA[895877]]></publicationId>

<partnum><![CDATA[895877]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=895877&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=895877]]></pdf>

</document>

<document>

<rank>296</rank>

<title><![CDATA[The 2012 VGTC Visualization Career Award:Ben Shneiderman]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Awards]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xxiii]]></spage>

<epage><![CDATA[xxiii]]></epage>

<abstract><![CDATA[The 2012 VGTC Visualization Career Award was presented to Ben Shneiderman.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634147]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.201]]></doi>

<publicationId><![CDATA[6634147]]></publicationId>

<partnum><![CDATA[6634147]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634147&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634147]]></pdf>

</document>

<document>

<rank>297</rank>

<title><![CDATA[Cover3]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6168457]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.83]]></doi>

<publicationId><![CDATA[6168457]]></publicationId>

<partnum><![CDATA[6168457]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6168457&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168457]]></pdf>

</document>

<document>

<rank>298</rank>

<title><![CDATA[VR Conference Committee]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[x]]></spage>

<epage><![CDATA[x]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6777451]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.46]]></doi>

<publicationId><![CDATA[6777451]]></publicationId>

<partnum><![CDATA[6777451]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777451&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777451]]></pdf>

</document>

<document>

<rank>299</rank>

<title><![CDATA[A Scale Space Based Persistence Measure for Critical Points in 2D Scalar Fields]]></title>

<authors><![CDATA[Reininghaus, J.;  Kotava, N.;  Gunther, D.;  Kasten, J.;  Hagen, H.;  Hotz, I.]]></authors>

<affiliations><![CDATA[Zuse Inst. Berlin, Berlin, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Laplace equations]]></term>

<term><![CDATA[Noise measurement]]></term>

<term><![CDATA[Noise robustness]]></term>

<term><![CDATA[Scalability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2045]]></spage>

<epage><![CDATA[2052]]></epage>

<abstract><![CDATA[This paper introduces a novel importance measure for critical points in 2D scalar fields. This measure is based on a combination of the deep structure of the scale space with the well-known concept of homological persistence. We enhance the noise robust persistence measure by implicitly taking the hill-, ridge- and outlier-like spatial extent of maxima and minima into account. This allows for the distinction between different types of extrema based on their persistence at multiple scales. Our importance measure can be computed efficiently in an out-of-core setting. To demonstrate the practical relevance of our method we apply it to a synthetic and a real-world data set and evaluate its performance and scalability.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064968]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.159]]></doi>

<publicationId><![CDATA[6064968]]></publicationId>

<partnum><![CDATA[6064968]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064968&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064968]]></pdf>

</document>

<document>

<rank>300</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4917478]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.51]]></doi>

<publicationId><![CDATA[4917478]]></publicationId>

<partnum><![CDATA[4917478]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4917478&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4917478]]></pdf>

</document>

<document>

<rank>301</rank>

<title><![CDATA[Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards]]></title>

<authors><![CDATA[Walny, J.;  Bongshin Lee;  Johns, P.;  Riche, N.H.;  Carpendale, S.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Sociology]]></term>

<term><![CDATA[Statistical analysis]]></term>

<term><![CDATA[Writing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2779]]></spage>

<epage><![CDATA[2788]]></epage>

<abstract><![CDATA[Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327284]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.275]]></doi>

<publicationId><![CDATA[6327284]]></publicationId>

<partnum><![CDATA[6327284]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327284&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327284]]></pdf>

</document>

<document>

<rank>302</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5165584]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.79]]></doi>

<publicationId><![CDATA[5165584]]></publicationId>

<partnum><![CDATA[5165584]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5165584&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5165584]]></pdf>

</document>

<document>

<rank>303</rank>

<title><![CDATA[Almost Isometric Mesh Parameterization through Abstract Domains]]></title>

<authors><![CDATA[Pietroni, N.;  Tarini, M.;  Cignoni, P.]]></authors>

<affiliations><![CDATA[Visual Comput. Lab., CNR-Nat. Res. Council, Pisa, Italy]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[distortion]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Distortion measurement]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Open source software]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[621]]></spage>

<epage><![CDATA[635]]></epage>

<abstract><![CDATA[In this paper, we propose a robust, automatic technique to build a global hi-quality parameterization of a two-manifold triangular mesh. An adaptively chosen 2D domain of the parameterization is built as part of the process. The produced parameterization exhibits very low isometric distortion, because it is globally optimized to preserve both areas and angles. The domain is a collection of equilateral triangular 2D regions enriched with explicit adjacency relationships (it is abstract in the sense that no 3D embedding is necessary). It is tailored to minimize isometric distortion, resulting in excellent parameterization qualities, even when meshes with complex shape and topology are mapped into domains composed of a small number of large continuous regions. Moreover, this domain is, in turn, remapped into a collection of 2D square regions, unlocking many advantages found in quad-based domains (e.g., ease of packing). The technique is tested on a variety of cases, including challenging ones, and compares very favorably with known approaches. An open-source implementation is made available.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5204086]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.96]]></doi>

<publicationId><![CDATA[5204086]]></publicationId>

<partnum><![CDATA[5204086]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5204086&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5204086]]></pdf>

</document>

<document>

<rank>304</rank>

<title><![CDATA[VisOHC: Designing Visual Analytics for Online Health Communities]]></title>

<authors><![CDATA[Bum Chul Kwon;  Sung-Hee Kim;  Sukwon Lee;  Jaegul Choo;  Jina Huh;  Ji Soo Yi]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[health care]]></term>

<term><![CDATA[medical administrative data processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atmospheric measurements]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Message systems]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[71]]></spage>

<epage><![CDATA[80]]></epage>

<abstract><![CDATA[Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192683]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467555]]></doi>

<publicationId><![CDATA[7192683]]></publicationId>

<partnum><![CDATA[7192683]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192683&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192683]]></pdf>

</document>

<document>

<rank>305</rank>

<title><![CDATA[GPU-Based Multilevel Clustering]]></title>

<authors><![CDATA[Chiosa, I.;  Kolb, A.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Multimedia Syst. Group, Univ. of Siegen, Siegen, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[parallel algorithms]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[132]]></spage>

<epage><![CDATA[145]]></epage>

<abstract><![CDATA[The processing power of parallel coprocessors like the Graphics Processing Unit (GPU) is dramatically increasing. However, until now only a few approaches have been presented to utilize this kind of hardware for mesh clustering purposes. In this paper, we introduce a Multilevel clustering technique designed as a parallel algorithm and solely implemented on the GPU. Our formulation uses the spatial coherence present in the cluster optimization and hierarchical cluster merging to significantly reduce the number of comparisons in both parts. Our approach provides a fast, high-quality, and complete clustering analysis. Furthermore, based on the original concept, we present a generalization of the method to data clustering. All advantages of the mesh-based techniques smoothly carry over to the generalized clustering approach. Additionally, this approach solves the problem of the missing topological information inherent to general data clustering and leads to a Local Neighbors k-means algorithm. We evaluate both techniques by applying them to Centroidal Voronoi Diagram (CVD)-based clustering. Compared to classical approaches, our techniques generate results with at least the same clustering quality. Our technique proves to scale very well, currently being limited only by the available amount of graphics memory.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5453357]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.55]]></doi>

<publicationId><![CDATA[5453357]]></publicationId>

<partnum><![CDATA[5453357]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5453357&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453357]]></pdf>

</document>

<document>

<rank>306</rank>

<title><![CDATA[Variant View: Visualizing Sequence Variants in their Gene Context]]></title>

<authors><![CDATA[Ferstay, J.A.;  Nielsen, C.B.;  Munzner, T.]]></authors>

<controlledterms>

<term><![CDATA[DNA]]></term>

<term><![CDATA[bioinformatics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diseases]]></term>

<term><![CDATA[genomics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Browsers]]></term>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Databases]]></term>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Genomics]]></term>

<term><![CDATA[Sequential analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2546]]></spage>

<epage><![CDATA[2555]]></epage>

<abstract><![CDATA[Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6634170]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.214]]></doi>

<publicationId><![CDATA[6634170]]></publicationId>

<partnum><![CDATA[6634170]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634170&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634170]]></pdf>

</document>

<document>

<rank>307</rank>

<title><![CDATA[1998 Index - IEEE Transactions on Visualization and Computer Gaphics - Vol. 4]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[379]]></spage>

<epage><![CDATA[382]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[765330]]></arnumber>

<doi><![CDATA[10.1109/TVCG.1998.765330]]></doi>

<publicationId><![CDATA[765330]]></publicationId>

<partnum><![CDATA[765330]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=765330&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=765330]]></pdf>

</document>

<document>

<rank>308</rank>

<title><![CDATA[Octree-R: an adaptive octree for efficient ray tracing]]></title>

<authors><![CDATA[Kyu-Young Whang;  Ju-Won Song;  Ji-Woong Chang;  Ji-Yun Kim;  Wan-Sup Cho;  Chong-Mok Park;  Il-Yeol Song]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Seoul, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[octrees]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Partitioning algorithms]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Performance gain]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[343]]></spage>

<epage><![CDATA[349]]></epage>

<abstract><![CDATA[Ray tracing requires many ray-object intersection tests. A way of reducing the number of ray-object intersection tests is to subdivide the space occupied by objects into many nonoverlapping subregions, called voxels, and to construct an octree for the subdivided space. We propose the Octree-R, an octree-variant data structure for efficient ray tracing. The algorithm for constructing the Octree-R first estimates the number of ray-object intersection tests. Then, it partitions the space along the plane that minimizes the estimated number of ray-object intersection tests. We present the results of experiments for verifying the effectiveness of the Octree-R. In the experiment, the Octree-R provides a 4% to 47% performance gain over the conventional octree. The result shows the more skewed the object distribution (as is typical for real data), the more performance gain the Octree-R achieves]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[485621]]></arnumber>

<doi><![CDATA[10.1109/2945.485621]]></doi>

<publicationId><![CDATA[485621]]></publicationId>

<partnum><![CDATA[485621]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=485621&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485621]]></pdf>

</document>

<document>

<rank>309</rank>

<title><![CDATA[Comparative Visualization for Parameter Studies of Dataset Series]]></title>

<authors><![CDATA[Malik, M.M.;  Heinzl, C.;  Groeller, M.E.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[X-ray imaging]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[edge detection]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[829]]></spage>

<epage><![CDATA[840]]></epage>

<abstract><![CDATA[This paper proposes comparison and visualization techniques to carry out parameter studies for the special application area of dimensional measurement using 3D X-ray computed tomography (3DCT). A dataset series is generated by scanning a specimen multiple times by varying parameters of an industrial 3DCT device. A high-resolution series is explored using our planar-reformatting-based visualization system. We present a novel multi-image view and an edge explorer for comparing and visualizing gray values and edges of several datasets simultaneously. Visualization results and quantitative data are displayed side by side. Our technique is scalable and generic. It can be effective in various application areas like parameter studies of imaging modalities and dataset artifact detection. For fast data retrieval and convenient usability, we use bricking of the datasets and efficient data structures. We evaluate the applicability of the proposed techniques in collaboration with our company partners.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5401158]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.20]]></doi>

<publicationId><![CDATA[5401158]]></publicationId>

<partnum><![CDATA[5401158]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5401158&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401158]]></pdf>

</document>

<document>

<rank>310</rank>

<title><![CDATA[Visualization by Proxy: A Novel Framework for Deferred Interaction with Volume Data]]></title>

<authors><![CDATA[Tikhonova, A.;  Correa, C.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Univ. of California, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Attenuation]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1551]]></spage>

<epage><![CDATA[1559]]></epage>

<abstract><![CDATA[Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613497]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.215]]></doi>

<publicationId><![CDATA[5613497]]></publicationId>

<partnum><![CDATA[5613497]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613497&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613497]]></pdf>

</document>

<document>

<rank>311</rank>

<title><![CDATA[FaceWarehouse: A 3D Facial Expression Database for Visual Computing]]></title>

<authors><![CDATA[Chen Cao;  Yanlin Weng;  Shun Zhou;  Yiying Tong;  Kun Zhou]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[emotion recognition]]></term>

<term><![CDATA[face recognition]]></term>

<term><![CDATA[visual databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Databases]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Mouth]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[413]]></spage>

<epage><![CDATA[425]]></epage>

<abstract><![CDATA[We present FaceWarehouse, a database of 3D facial expressions for visual computing applications. We use Kinect, an off-the-shelf RGBD camera, to capture 150 individuals aged 7-80 from various ethnic backgrounds. For each person, we captured the RGBD data of her different expressions, including the neutral expression and 19 other expressions such as mouth-opening, smile, kiss, etc. For every RGBD raw data record, a set of facial feature points on the color image such as eye corners, mouth contour, and the nose tip are automatically localized, and manually adjusted if better accuracy is required. We then deform a template facial mesh to fit the depth data as closely as possible while matching the feature points on the color image to their corresponding points on the mesh. Starting from these fitted face meshes, we construct a set of individual-specific expression blendshapes for each person. These meshes with consistent topology are assembled as a rank-3 tensor to build a bilinear face model with two attributes: identity and expression. Compared with previous 3D facial databases, for every person in our database, there is a much richer matching collection of expressions, enabling depiction of most human facial actions. We demonstrate the potential of FaceWarehouse for visual computing with four applications: facial image manipulation, face component transfer, real-time performance-based facial image animation, and facial animation retargeting from video to image.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6654137]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.249]]></doi>

<publicationId><![CDATA[6654137]]></publicationId>

<partnum><![CDATA[6654137]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6654137&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654137]]></pdf>

</document>

<document>

<rank>312</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1333658]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.40]]></doi>

<publicationId><![CDATA[1333658]]></publicationId>

<partnum><![CDATA[1333658]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1333658&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333658]]></pdf>

</document>

<document>

<rank>313</rank>

<title><![CDATA[Authalic Parameterization of General Surfaces Using Lie Advection]]></title>

<authors><![CDATA[Guangyu Zou;  Jiaxi Hu;  Xianfeng Gu;  Jing Hua]]></authors>

<affiliations><![CDATA[Wayne State Univ., Detroit, MI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Boundary conditions]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2005]]></spage>

<epage><![CDATA[2014]]></epage>

<abstract><![CDATA[Parameterization of complex surfaces constitutes a major means of visualizing highly convoluted geometric structures as well as other properties associated with the surface. It also enables users with the ability to navigate, orient, and focus on regions of interest within a global view and overcome the occlusions to inner concavities. In this paper, we propose a novel area-preserving surface parameterization method which is rigorous in theory, moderate in computation, yet easily extendable to surfaces of non-disc and closed-boundary topologies. Starting from the distortion induced by an initial parameterization, an area restoring diffeomorphic flow is constructed as a Lie advection of differential 2-forms along the manifold, which yields equality of the area elements between the domain and the original surface at its final state. Existence and uniqueness of result are assured through an analytical derivation. Based upon a triangulated surface representation, we also present an efficient algorithm in line with discrete differential modeling. As an exemplar application, the utilization of this method for the effective visualization of brain cortical imaging modalities is presented. Compared with conformal methods, our method can reveal more subtle surface patterns in a quantitative manner. It, therefore, provides a competitive alternative to the existing parameterization techniques for better surface-based analysis in various scenarios.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064964]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.171]]></doi>

<publicationId><![CDATA[6064964]]></publicationId>

<partnum><![CDATA[6064964]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064964&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064964]]></pdf>

</document>

<document>

<rank>314</rank>

<title><![CDATA[Physically-Based Feature Tracking for CFD Data]]></title>

<authors><![CDATA[Clyne, J.;  Mininni, P.;  Norton, A.]]></authors>

<affiliations><![CDATA[Nat. Center for Atmos. Res., Boulder, CO, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[turbulence]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aerodynamics]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Tracking]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1020]]></spage>

<epage><![CDATA[1033]]></epage>

<abstract><![CDATA[Numerical simulations of turbulent fluid flow in areas ranging from solar physics to aircraft design are dominated by the presence of repeating patterns known as coherent structures. These persistent features are not yet well understood, but are believed to play an important role in the dynamics of turbulent fluid motion, and are the subject of study across numerous scientific and engineering disciplines. To facilitate their investigation a variety of techniques have been devised to track the paths of these structures as they evolve through time. Heretofore, all such feature tracking methods have largely ignored the physics governing the motion of these objects at the expense of error prone and often computationally expensive solutions. In this paper, we present a feature path prediction method that is based on the physics of the underlying solutions to the equations of fluid motion. To the knowledge of the authors the accuracy of these predictions is superior to methods reported elsewhere. Moreover, the precision of these forecasts for many applications is sufficiently high to enable the use of only the most rudimentary and inexpensive forms of correspondence matching. We also provide insight on the relationship between the internal time stepping used in a CFD simulation, and the evolution of coherent structures, that we believe is of benefit to any feature tracking method applicable to CFD. Finally, our method is easy to implement, and computationally inexpensive to execute, making it well suited for very high-resolution simulations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6269875]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.171]]></doi>

<publicationId><![CDATA[6269875]]></publicationId>

<partnum><![CDATA[6269875]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6269875&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269875]]></pdf>

</document>

<document>

<rank>315</rank>

<title><![CDATA[Tuning Self-Motion Perception in Virtual Reality with Visual Illusions]]></title>

<authors><![CDATA[Bruder, G.;  Steinicke, F.;  Wieland, P.;  Lappe, M.]]></authors>

<affiliations><![CDATA[Depts. of Human-Comput. Media & Comput. Sci., Univ. of Wurzburg, Wurzburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[image sensors]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[motion estimation]]></term>

<term><![CDATA[virtual reality]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Blindness]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Detectors]]></term>

<term><![CDATA[Optical distortion]]></term>

<term><![CDATA[Optical sensors]]></term>

<term><![CDATA[Stimulated emission]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1068]]></spage>

<epage><![CDATA[1078]]></epage>

<abstract><![CDATA[Motion perception in immersive virtual environments significantly differs from the real world. For example, previous work has shown that users tend to underestimate travel distances in virtual environments (VEs). As a solution to this problem, researchers proposed to scale the mapped virtual camera motion relative to the tracked real-world movement of a user until real and virtual motion are perceived as equal, i.e., real-world movements could be mapped with a larger gain to the VE in order to compensate for the underestimation. However, introducing discrepancies between real and virtual motion can become a problem, in particular, due to misalignments of both worlds and distorted space cognition. In this paper, we describe a different approach that introduces apparent self-motion illusions by manipulating optic flow fields during movements in VEs. These manipulations can affect self-motion perception in VEs, but omit a quantitative discrepancy between real and virtual motions. In particular, we consider to which regions of the virtual view these apparent self-motion illusions can be applied, i.e., the ground plane or peripheral vision. Therefore, we introduce four illusions and show in experiments that optic flow manipulation can significantly affect users' self-motion judgments. Furthermore, we show that with such manipulations of optic flow fields the underestimation of travel distances can be compensated.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6081857]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.274]]></doi>

<publicationId><![CDATA[6081857]]></publicationId>

<partnum><![CDATA[6081857]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6081857&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081857]]></pdf>

</document>

<document>

<rank>316</rank>

<title><![CDATA[Multiresolution indexing of triangulated irregular networks]]></title>

<authors><![CDATA[Bartholdi, J.J., III;  Goldsman, P.]]></authors>

<affiliations><![CDATA[Sch. of Ind. & Syst. Eng., Georgia Inst. of Technol., Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Filling]]></term>

<term><![CDATA[Geographic Information Systems]]></term>

<term><![CDATA[Indexing]]></term>

<term><![CDATA[Information retrieval]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Spatial indexes]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Strips]]></term>

<term><![CDATA[Tin]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[484]]></spage>

<epage><![CDATA[495]]></epage>

<abstract><![CDATA[We show how to build a continuous, one-dimensional index of the points on a triangulated irregular network (TIN). The index is constructed by first finding an ordering of the triangles in which consecutive triangles share a vertex or an edge. Then, the space within each triangle is continuously indexed with a space-filling curve that begins at one vertex of the triangle and ends at another. The space-filling curve is oriented such that the first point in each triangle is a vertex shared with the previous triangle and the last point is a vertex shared with the next triangle. Furthermore, our index can be refined locally and, therefore, efficiently when the TIN is augmented by filling any face with another TIN (to make a hierarchical TIN). Such processes arise, for example, in the elaboration of detail on a graphical surface.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1298805]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.14]]></doi>

<publicationId><![CDATA[1298805]]></publicationId>

<partnum><![CDATA[1298805]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1298805&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298805]]></pdf>

</document>

<document>

<rank>317</rank>

<title><![CDATA[&#x0023;FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media]]></title>

<authors><![CDATA[Jian Zhao;  Nan Cao;  Zhen Wen;  Yale Song;  Yu-Ru Lin;  Collins, C.]]></authors>

<affiliations><![CDATA[Univ. of Toronto, Toronto, ON, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision making]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[social networking (online)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Instruction sets]]></term>

<term><![CDATA[Media]]></term>

<term><![CDATA[Message systems]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Twitter]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1773]]></spage>

<epage><![CDATA[1782]]></epage>

<abstract><![CDATA[We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876013]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346922]]></doi>

<publicationId><![CDATA[6876013]]></publicationId>

<partnum><![CDATA[6876013]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876013&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876013]]></pdf>

</document>

<document>

<rank>318</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4917479]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.52]]></doi>

<publicationId><![CDATA[4917479]]></publicationId>

<partnum><![CDATA[4917479]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4917479&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4917479]]></pdf>

</document>

<document>

<rank>319</rank>

<title><![CDATA[Smooth Graphs for Visual Exploration of Higher-Order State Transitions]]></title>

<authors><![CDATA[Blaas, J.;  Botha, C.P.;  Grundy, E.;  Jones, M.;  Laramee, R.S.;  Post, F.H.]]></authors>

<affiliations><![CDATA[Visualization Group, Delft Univ. of Technol., Delft, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[splines (mathematics)]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Frequency]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[969]]></spage>

<epage><![CDATA[976]]></epage>

<abstract><![CDATA[In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290701]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.181]]></doi>

<publicationId><![CDATA[5290701]]></publicationId>

<partnum><![CDATA[5290701]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290701&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290701]]></pdf>

</document>

<document>

<rank>320</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on the ACM Symposium on Virtual Reality and Software Technology (VRST 2009)]]></title>

<authors><![CDATA[Thalmann, D.;  Lok, Benjamin]]></authors>

<thesaurusterms>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Software architecture]]></term>

<term><![CDATA[Software development]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[873]]></spage>

<epage><![CDATA[874]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5762831]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.87]]></doi>

<publicationId><![CDATA[5762831]]></publicationId>

<partnum><![CDATA[5762831]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5762831&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5762831]]></pdf>

</document>

<document>

<rank>321</rank>

<title><![CDATA[Volume Ray Casting with Peak Finding and Differential Sampling]]></title>

<authors><![CDATA[Knoll, A.;  Hijazi, Y.;  Westerteiger, R.;  Schott, M.;  Hansen, C.;  Hagen, H.]]></authors>

<affiliations><![CDATA[Univ. of Kaiserslautern, Kaiserslautern, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1571]]></spage>

<epage><![CDATA[1578]]></epage>

<abstract><![CDATA[Direct volume rendering and isosurfacing are ubiquitous rendering techniques in scientific visualization, commonly employed in imaging 3D data from simulation and scan sources. Conventionally, these methods have been treated as separate modalities, necessitating different sampling strategies and rendering algorithms. In reality, an isosurface is a special case of a transfer function, namely a Dirac impulse at a given isovalue. However, artifact-free rendering of discrete isosurfaces in a volume rendering framework is an elusive goal, requiring either infinite sampling or smoothing of the transfer function. While preintegration approaches solve the most obvious deficiencies in handling sharp transfer functions, artifacts can still result, limiting classification. In this paper, we introduce a method for rendering such features by explicitly solving for isovalues within the volume rendering integral. In addition, we present a sampling strategy inspired by ray differentials that automatically matches the frequency of the image plane, resulting in fewer artifacts near the eye and better overall performance. These techniques exhibit clear advantages over standard uniform ray casting with and without preintegration, and allow for high-quality interactive volume rendering with sharp C<sup>0</sup> transfer functions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290775]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.204]]></doi>

<publicationId><![CDATA[5290775]]></publicationId>

<partnum><![CDATA[5290775]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290775&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290775]]></pdf>

</document>

<document>

<rank>322</rank>

<title><![CDATA[Edge Aware Anisotropic Diffusion for 3D Scalar Data]]></title>

<authors><![CDATA[Hosssain, Z.;  Moller, T.]]></authors>

<affiliations><![CDATA[Graphics, Usability, & Visualization (GrUVi) Lab., Simon Fraser Univ., Burnaby, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[edge detection]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[image denoising]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Noise reduction]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1376]]></spage>

<epage><![CDATA[1385]]></epage>

<abstract><![CDATA[In this paper we present a novel anisotropic diffusion model targeted for 3D scalar field data. Our model preserves material boundaries as well as fine tubular structures while noise is smoothed out. One of the major novelties is the use of the directional second derivative to define material boundaries instead of the gradient magnitude for thresholding. This results in a diffusion model that has much lower sensitivity to the diffusion parameter and smoothes material boundaries consistently compared to gradient magnitude based techniques. We empirically analyze the stability and convergence of the proposed diffusion and demonstrate its de-noising capabilities for both analytic and real data. We also discuss applications in the context of volume rendering.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613478]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.147]]></doi>

<publicationId><![CDATA[5613478]]></publicationId>

<partnum><![CDATA[5613478]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613478&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613478]]></pdf>

</document>

<document>

<rank>323</rank>

<title><![CDATA[Feature Aligned Volume Manipulation for Illustration and Visualization]]></title>

<authors><![CDATA[Correa, C.;  Silver, D.;  Chen, M.]]></authors>

<affiliations><![CDATA[Dept. of Electr. & Comput. Eng., State Univ. of New Jersey, NJ]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Biology computing]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Silver]]></term>

<term><![CDATA[Skin]]></term>

<term><![CDATA[Surgery]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1069]]></spage>

<epage><![CDATA[1076]]></epage>

<abstract><![CDATA[In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015466]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.144]]></doi>

<publicationId><![CDATA[4015466]]></publicationId>

<partnum><![CDATA[4015466]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015466&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015466]]></pdf>

</document>

<document>

<rank>324</rank>

<title><![CDATA[A High-Quality High-Fidelity Visualization of the September 11 Attack on the World Trade Center]]></title>

<authors><![CDATA[Rosen, P.;  Popescu, V.;  Hoffmann, C.;  Irfanoglu, A.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Purdue Univ., West Lafayette, IN]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[finite element analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aircraft manufacture]]></term>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Physics]]></term>

<term><![CDATA[Poles and towers]]></term>

<term><![CDATA[Terrorism]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[937]]></spage>

<epage><![CDATA[947]]></epage>

<abstract><![CDATA[In this application paper, we describe the efforts of a multidisciplinary team toward producing a visualization of the September 11 attack on the North Tower of New York's World Trade Center. The visualization was designed to meet two requirements. First, the visualization had to depict the impact with high fidelity by closely following the laws of physics. Second, the visualization had to be eloquent to a nonexpert user. This was achieved by first designing and computing a finite-element analysis (FEA) simulation of the impact between the aircraft and the top 20 stories of the building and then by visualizing the FEA results with a state-of-the-art commercial animation system. The visualization was enabled by an automatic translator that converts the simulation data into an animation system 3D scene. We built upon a previously developed translator. The translator was substantially extended to enable and control visualization of fire and of disintegrating elements to better scale with the number of nodes and the number of states to handle beam elements with complex profiles and to handle smoothed particle hydrodynamics liquid representation. The resulting translator is a powerful automatic and scalable tool for high-quality visualization of FEA results.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4530420]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.41]]></doi>

<publicationId><![CDATA[4530420]]></publicationId>

<partnum><![CDATA[4530420]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4530420&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4530420]]></pdf>

</document>

<document>

<rank>325</rank>

<title><![CDATA[Direct Interval Volume Visualization]]></title>

<authors><![CDATA[Ament, M.;  Weiskopf, D.;  Carr, H.]]></authors>

<affiliations><![CDATA[VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1505]]></spage>

<epage><![CDATA[1514]]></epage>

<abstract><![CDATA[We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613492]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.145]]></doi>

<publicationId><![CDATA[5613492]]></publicationId>

<partnum><![CDATA[5613492]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613492&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613492]]></pdf>

</document>

<document>

<rank>326</rank>

<title><![CDATA[SpicyNodes: Radial Layout Authoring for the General Public]]></title>

<authors><![CDATA[Douma, M.;  Ligierko, G.;  Ancuta, O.;  Gritsai, P.;  Liu, S.]]></authors>

<controlledterms>

<term><![CDATA[authoring systems]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Catalogs]]></term>

<term><![CDATA[Graphical user interfaces]]></term>

<term><![CDATA[Information management]]></term>

<term><![CDATA[Portals]]></term>

<term><![CDATA[Semantic Web]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Software libraries]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1089]]></spage>

<epage><![CDATA[1096]]></epage>

<abstract><![CDATA[Trees and graphs are relevant to many online tasks such as visualizing social networks, product catalogs, educational portals, digital libraries, the semantic web, concept maps and personalized information management. SpicyNodes is an information-visualization technology that builds upon existing research on radial tree layouts and graph structures. Users can browse a tree, clicking from node to node, as well as successively viewing a node, immediately related nodes and the path back to the ldquohomerdquo nodes. SpicyNodes' layout algorithms maintain balanced layouts using a hybrid mixture of a geometric layout (a succession of spanning radial trees) and force-directed layouts to minimize overlapping nodes, plus several other improvements over prior art. It provides XML-based API and GUI authoring tools. The goal of the SpicyNodes project is to implement familiar principles of radial maps and focus+context with an attractive and inviting look and feel in an open system that is accessible to virtually any Internet user.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290716]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.183]]></doi>

<publicationId><![CDATA[5290716]]></publicationId>

<partnum><![CDATA[5290716]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290716&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290716]]></pdf>

</document>

<document>

<rank>327</rank>

<title><![CDATA[Texture-Based Visualization of Unsteady 3D Flow by Real-Time Advection and Volumetric Illumination]]></title>

<authors><![CDATA[Weiskopf, D.;  Schafhitzel, T.;  Ertl, T.]]></authors>

<affiliations><![CDATA[Graphics, Visualization, & Usability Lab, Simon Fraser Univ., Burnaby, BC]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Read-write memory]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Visual perception]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[569]]></spage>

<epage><![CDATA[582]]></epage>

<abstract><![CDATA[This paper presents an interactive technique for the dense texture-based visualization of unsteady 3D flow, taking into account issues of computational efficiency and visual perception. High efficiency is achieved by a 3D graphics processing unit (GPU)-based texture advection mechanism that implements logical 3D grid structures by physical memory in the form of 2D textures. This approach results in fast read and write access to physical memory, independent of GPU architecture. Slice-based direct volume rendering is used for the final display. We investigate two alternative methods for the volumetric illumination of the result of texture advection: First, gradient-based illumination that employs a real-time computation of gradients, and, second, line-based lighting based on illumination in codimension 2. In addition to the Phong model, perception-guided rendering methods are considered, such as cool/warm shading, halo rendering, or color-based depth cueing. The problems of clutter and occlusion are addressed by supporting a volumetric importance function that enhances features of the flow and reduces visual complexity in less interesting regions. GPU implementation aspects, performance measurements, and a discussion of results are included to demonstrate our visualization approach]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4135661]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1045]]></doi>

<publicationId><![CDATA[4135661]]></publicationId>

<partnum><![CDATA[4135661]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4135661&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4135661]]></pdf>

</document>

<document>

<rank>328</rank>

<title><![CDATA[Constraint Fluids]]></title>

<authors><![CDATA[Bodin, K.;  Lacoursiere, C.;  Servin, M.]]></authors>

<affiliations><![CDATA[Umed Univ., Umea, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[hydrodynamics]]></term>

<term><![CDATA[iterative methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Force]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Stability analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[516]]></spage>

<epage><![CDATA[526]]></epage>

<abstract><![CDATA[We present a fluid simulation method based on Smoothed Particle Hydrodynamics (SPH) in which incompressibility and boundary conditions are enforced using holonomic kinematic constraints on the density. This formulation enables systematic multiphysics integration in which interactions are modeled via similar constraints between the fluid pseudoparticles and impenetrable surfaces of other bodies. These conditions embody Archimede's principle for solids and thus buoyancy results as a direct consequence. We use a variational time stepping scheme suitable for general constrained multibody systems we call SPOOK. Each step requires the solution of only one Mixed Linear Complementarity Problem (MLCP) with very few inequalities, corresponding to solid boundary conditions. We solve this MLCP with a fast iterative method. Overall stability is vastly improved in comparison to the unconstrained version of SPH, and this allows much larger time steps, and an increase in overall performance by two orders of magnitude. Proof of concept is given for computer graphics applications and interactive simulations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5708198]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.29]]></doi>

<publicationId><![CDATA[5708198]]></publicationId>

<partnum><![CDATA[5708198]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5708198&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708198]]></pdf>

</document>

<document>

<rank>329</rank>

<title><![CDATA[Hypothesis Generation in Climate Research with Interactive Visual Data Exploration]]></title>

<authors><![CDATA[Kehrer, J.;  Ladstadter, F.;  Muigg, P.;  Doleisch, H.;  Steiner, A.;  Hauser, H.]]></authors>

<affiliations><![CDATA[Dept. of Inf., Bergen Univ., Bergen]]></affiliations>

<controlledterms>

<term><![CDATA[climatology]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[geophysics computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atmosphere]]></term>

<term><![CDATA[Atmospheric measurements]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Extraterrestrial measurements]]></term>

<term><![CDATA[Geophysical measurements]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Satellites]]></term>

<term><![CDATA[Signal to noise ratio]]></term>

<term><![CDATA[Weather forecasting]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1579]]></spage>

<epage><![CDATA[1586]]></epage>

<abstract><![CDATA[One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658178]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.139]]></doi>

<publicationId><![CDATA[4658178]]></publicationId>

<partnum><![CDATA[4658178]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658178&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658178]]></pdf>

</document>

<document>

<rank>330</rank>

<title><![CDATA[Stack Zooming for Multifocus Interaction in Skewed-Aspect Visual Spaces]]></title>

<authors><![CDATA[Javed, W.;  Elmqvist, N.]]></authors>

<affiliations><![CDATA[Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Nonlinear distortion]]></term>

<term><![CDATA[Strips]]></term>

<term><![CDATA[Vegetation]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1362]]></spage>

<epage><![CDATA[1374]]></epage>

<abstract><![CDATA[Many 2D visual spaces have a virtually one-dimensional nature with very high aspect ratio between the dimensions: examples include time-series data, multimedia data such as sound or video, text documents, and bipartite graphs. Common among these is that the space can become very large, e.g., temperature measurements could span a long time period, surveillance video could cover entire days or weeks, and documents can have thousands of pages. Many analysis tasks for such spaces require several foci while retaining context and distance awareness. In this extended version of our IEEE PacificVis 2010 paper, we introduce a method for supporting this kind of multifocus interaction that we call stack zooming. The approach is based on building hierarchies of 1D strips stacked on top of each other, where each subsequent stack represents a higher zoom level, and sibling strips represent branches in the exploration. Correlation graphics show the relation between stacks and strips of different levels, providing context and distance awareness for the foci. The zoom hierarchies can also be used as graphical histories and for communicating insights to stakeholders and can be further extended with annotation and integrated statistics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6392832]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.323]]></doi>

<publicationId><![CDATA[6392832]]></publicationId>

<partnum><![CDATA[6392832]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6392832&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392832]]></pdf>

</document>

<document>

<rank>331</rank>

<title><![CDATA[Effects of Approximate Filtering on the Appearance of Bidirectional Texture Functions]]></title>

<authors><![CDATA[Jarabo, A.;  Wu, H.;  Dorsey, J.;  Rushmeier, H.;  Gutierrez, D.]]></authors>

<affiliations><![CDATA[Univ. de Zaragoza, Zaragoza, Spain]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[image coding]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Materials]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[880]]></spage>

<epage><![CDATA[892]]></epage>

<abstract><![CDATA[The BTF data structure was a breakthrough for appearance modeling in computer graphics. More research is needed though to make BTFs practical in rendering applications. We present the first systematic study of the effects of Approximate filtering on the appearance of BTFs, by exploring the spatial, angular and temporal domains over a varied set of stimuli. We perform our initial experiments on simple geometry and lighting, and verify our observations on more complex settings. We consider multi-dimensional filtering versus conventional mipmapping, and find that multi-dimensional filtering produces superior results. We examine the tradeoff between under- and oversampling, and find that different filtering strategies can be applied in each domain, while maintaining visual equivalence with respect to a ground truth. For example, we find that preserving contrast is more important in static than dynamic images, indicating greater levels of spatial filtering are possible for animations. We find that filtering can be performed more aggressively in the angular domain than in the spatial. Additionally, we find that high-level visual descriptors of the BTF are linked to the perceptual performance of pre-filtered approximations. In turn, some of these high-level descriptors correlate with low level statistics of the BTF. We show six different practical applications of applying our findings to improving filtering, rendering and compression strategies.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6767158]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2312016]]></doi>

<publicationId><![CDATA[6767158]]></publicationId>

<partnum><![CDATA[6767158]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6767158&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6767158]]></pdf>

</document>

<document>

<rank>332</rank>

<title><![CDATA[Pairwise Harmonics for Shape Analysis]]></title>

<authors><![CDATA[Youyi Zheng;  Chiew-Lan Tai;  Zhang, E.;  Pengfei Xu]]></authors>

<affiliations><![CDATA[Geometric Modeling & Sci. Visualization Center, King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia]]></affiliations>

<controlledterms>

<term><![CDATA[geometry]]></term>

<term><![CDATA[harmonics]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[shape recognition]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Harmonic analysis]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Shape measurement]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1172]]></spage>

<epage><![CDATA[1184]]></epage>

<abstract><![CDATA[This paper introduces a simple yet effective shape analysis mechanism for geometry processing. Unlike traditional shape analysis techniques which compute descriptors per surface point up to certain neighborhoods, we introduce a shape analysis framework in which the descriptors are based on pairs of surface points. Such a pairwise analysis approach leads to a new class of shape descriptors that are more global, discriminative, and can effectively capture the variations in the underlying geometry. Specifically, we introduce new shape descriptors based on the isocurves of harmonic functions whose global maximum and minimum occur at the point pair. We show that these shape descriptors can infer shape structures and consistently lead to simpler and more efficient algorithms than the state-of-the-art methods for three applications: intrinsic reflectional symmetry axis computation, matching shape extremities, and simultaneous surface segmentation and skeletonization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6361386]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.309]]></doi>

<publicationId><![CDATA[6361386]]></publicationId>

<partnum><![CDATA[6361386]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6361386&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6361386]]></pdf>

</document>

<document>

<rank>333</rank>

<title><![CDATA[Exploiting triangulated surface extraction using tetrahedral decomposition]]></title>

<authors><![CDATA[Gueziec, A.;  Hummel, R.]]></authors>

<affiliations><![CDATA[IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[interpolation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Parallel processing]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[328]]></spage>

<epage><![CDATA[342]]></epage>

<abstract><![CDATA[Beginning with digitized volumetric data, we wish to rapidly and efficiently extract and represent surfaces defined as isosurfaces in the interpolated data. The Marching Cubes algorithm is a standard approach to this problem. We instead perform a decomposition of each 8-cell associated with a voxel into five tetrahedra. We guarantee the resulting surface representation to be closed and oriented, defined by a valid triangulation of the surface of the body, which in turn is presented as a collection of tetrahedra. The entire surface is &ldquo;wrapped&rdquo; by a collection of triangles, which form a graph structure, and where each triangle is contained within a single tetrahedron. The representation is similar to the homology theory that uses simplices embedded in a manifold to define a closed curve within each tetrahedron. We introduce data structures based upon a new encoding of the tetrahedra that are at least four times more compact than the standard data structures using vertices and triangles. For parallel computing and improved cache performance, the vertex information is stored local to the tetrahedra. We can distribute the vertices in such a way that no tetrahedron ever contains more than one vertex, We give methods to evaluate surface curvatures and principal directions at each vertex, whenever these quantities are defined. Finally, we outline a method for simplifying the surface, that is reducing the vertex count while preserving the geometry. We compare the characteristics of our methods with an 8-cell based method, and show results of surface extractions from CT-scans and MR-scans at full resolution]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[485620]]></arnumber>

<doi><![CDATA[10.1109/2945.485620]]></doi>

<publicationId><![CDATA[485620]]></publicationId>

<partnum><![CDATA[485620]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=485620&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485620]]></pdf>

</document>

<document>

<rank>334</rank>

<title><![CDATA[A Radial Adaptation of the Sugiyama Framework for Visualizing Hierarchical Information]]></title>

<authors><![CDATA[Bachmaier, C.]]></authors>

<affiliations><![CDATA[Fakultat fur Mathematik und Informatik, Passau Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Routing]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Spirals]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Web pages]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[583]]></spage>

<epage><![CDATA[594]]></epage>

<abstract><![CDATA[In radial drawings of hierarchical graphs, the vertices are placed on concentric circles rather than on horizontal lines and the edges are drawn as outward monotone segments of spirals rather than straight lines as it is done in the standard Sugiyama framework. This drawing style is well suited for the visualization of centrality in social networks and similar concepts. Radial drawings also allow a more flexible edge routing than horizontal drawings, as edges can be routed around the center in two directions. In experimental results, this reduces the number of crossings by approximately 30 percent on average. Few crossings are one of the major criteria for human readability. This paper is a detailed description of a complete framework for visualizing hierarchical information in a new radial fashion. Particularly, we briefly cover extensions of the level assignment step to benefit from the increasing perimeters of the circles, present three heuristics for crossing reduction in radial level drawings, and also show how to visualize the results]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4297689]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1000]]></doi>

<publicationId><![CDATA[4297689]]></publicationId>

<partnum><![CDATA[4297689]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297689&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297689]]></pdf>

</document>

<document>

<rank>335</rank>

<title><![CDATA[I3D 2014 Guest Editor&#x2019;s Introduction]]></title>

<authors><![CDATA[Olano, M.;  Otaduy, M.]]></authors>

<affiliations><![CDATA[Computer Science and Electrical Engineering Department, University of Maryland, Baltimore County]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[686]]></spage>

<epage><![CDATA[687]]></epage>

<abstract><![CDATA[The papers in this special section were presented at the ACM Symposium on Interactive 3D Graphics and Games (I3D) in 2014 that was held from March 14-16 in San Francisco, California. I3D focuses on real-time rendering, animation, and interaction techniques. Games are not the only application for these kinds of interactive methods, but are certainly a significant user of them. Consequently, the quality, time, space, stability, and predictability constraints faced by game development are an important factor in much of the work presented at I3D.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7097769]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2422231]]></doi>

<publicationId><![CDATA[7097769]]></publicationId>

<partnum><![CDATA[7097769]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7097769&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097769]]></pdf>

</document>

<document>

<rank>336</rank>

<title><![CDATA[Graphical inference for infovis]]></title>

<authors><![CDATA[Wickham, H.;  Cook, D.;  Hofmann, H.;  Buja, Andreas]]></authors>

<affiliations><![CDATA[Rice Univ., Houston, TX, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Protocols]]></term>

<term><![CDATA[Tag clouds]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[973]]></spage>

<epage><![CDATA[979]]></epage>

<abstract><![CDATA[How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The "Rorschach" helps the analyst calibrate their understanding of uncertainty and "line-up" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613434]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.161]]></doi>

<publicationId><![CDATA[5613434]]></publicationId>

<partnum><![CDATA[5613434]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613434&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613434]]></pdf>

</document>

<document>

<rank>337</rank>

<title><![CDATA[Smelling Screen: Development and Evaluation of an Olfactory Display System for Presenting a Virtual Odor Source]]></title>

<authors><![CDATA[Matsukura, H.;  Yoneda, T.;  Ishida, H.]]></authors>

<affiliations><![CDATA[Tokyo Univ. of Agric. & Technol., Koganei, Japan]]></affiliations>

<controlledterms>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Fans]]></term>

<term><![CDATA[Gas detectors]]></term>

<term><![CDATA[Olfactory]]></term>

<term><![CDATA[Position measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[606]]></spage>

<epage><![CDATA[615]]></epage>

<abstract><![CDATA[We propose a new olfactory display system that can generate an odor distribution on a two-dimensional display screen. The proposed system has four fans on the four corners of the screen. The airflows that are generated by these fans collide multiple times to create an airflow that is directed towards the user from a certain position on the screen. By introducing odor vapor into the airflows, the odor distribution is as if an odor source had been placed onto the screen. The generated odor distribution leads the user to perceive the odor as emanating from a specific region of the screen. The position of this virtual odor source can be shifted to an arbitrary position on the screen by adjusting the balance of the airflows from the four fans. Most users do not immediately notice the odor presentation mechanism of the proposed olfactory display system because the airflow and perceived odor come from the display screen rather than the fans. The airflow velocity can even be set below the threshold for airflow sensation, such that the odor alone is perceived by the user. We present experimental results that show the airflow field and odor distribution that are generated by the proposed system. We also report sensory test results to show how the generated odor distribution is perceived by the user and the issues that must be considered in odor presentation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6479189]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.40]]></doi>

<publicationId><![CDATA[6479189]]></publicationId>

<partnum><![CDATA[6479189]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479189&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479189]]></pdf>

</document>

<document>

<rank>338</rank>

<title><![CDATA[Interactive volume navigation]]></title>

<authors><![CDATA[Brady, M.L.;  Jung, K.K.;  Nguyen, H.T.;  Nguyen, T.P.Q.]]></authors>

<affiliations><![CDATA[Microcomput. Res. Labs., Intel Corp., Santa Clara, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Gray-scale]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Heart]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[243]]></spage>

<epage><![CDATA[256]]></epage>

<abstract><![CDATA[Volume navigation is the interactive exploration of volume data sets by &ldquo;flying&rdquo; the viewpoint through the data, producing a volume rendered view at each frame. We present an inexpensive perspective volume navigation method designed to be run on a PC platform with accelerated 3D graphics hardware. The heart of the method is a two-phase perspective ray casting algorithm that takes advantage of the coherence inherent in adjacent frames during navigation. The algorithm generates a sequence of approximate volume-rendered views in a fraction of the time that would be required to compute them individually. The algorithm handles arbitrarily large volumes by dynamically swapping data within the current view frustum into main memory as the viewpoint moves through the volume. We also describe an interactive volume navigation application based on this algorithm. The application renders gray-scale, RGB, and labeled RGB volumes by volumetric compositing, allows trilinear interpolation of sample points, and implements progressive refinement during pauses in user input]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[722298]]></arnumber>

<doi><![CDATA[10.1109/2945.722298]]></doi>

<publicationId><![CDATA[722298]]></publicationId>

<partnum><![CDATA[722298]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=722298&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722298]]></pdf>

</document>

<document>

<rank>339</rank>

<title><![CDATA[Reviewer's List]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[xii]]></spage>

<epage><![CDATA[xii]]></epage>

<abstract><![CDATA[Presents a listing of the conference reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7283722]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2472778]]></doi>

<publicationId><![CDATA[7283722]]></publicationId>

<partnum><![CDATA[7283722]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7283722&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7283722]]></pdf>

</document>

<document>

<rank>340</rank>

<title><![CDATA[Importance-driven feature enhancement in volume visualization]]></title>

<authors><![CDATA[Viola, I.;  Kanitsar, A.;  Groller, M.E.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[hidden feature removal]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[visual databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Biomedical optical imaging]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Focusing]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Lesions]]></term>

<term><![CDATA[Liver neoplasms]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[408]]></spage>

<epage><![CDATA[418]]></epage>

<abstract><![CDATA[This paper presents importance-driven feature enhancement as a technique for the automatic generation of cut-away and ghosted views out of volumetric data. The presented focus+context approach removes or suppresses less important parts of a scene to reveal more important underlying information. However, less important parts are fully visible in those regions, where important visual information is not lost, i.e., more relevant features are not occluded. Features within the volumetric data are first classified according to a new dimension, denoted as object importance. This property determines which structures should be readily discernible and which structures are less important. Next, for each feature, various representations (levels of sparseness) from a dense to a sparse depiction are defined. Levels of sparseness define a spectrum of optical properties or rendering styles. The resulting image is generated by ray-casting and combining the intersected features proportional to their importance (importance compositing). The paper includes an extended discussion on several possible schemes for levels of sparseness specification. Furthermore, different approaches to importance compositing are treated.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1432686]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.62]]></doi>

<publicationId><![CDATA[1432686]]></publicationId>

<partnum><![CDATA[1432686]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1432686&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1432686]]></pdf>

</document>

<document>

<rank>341</rank>

<title><![CDATA[Perceptually-Based Depth-Ordering Enhancement for Direct Volume Rendering]]></title>

<authors><![CDATA[Lin Zheng;  Yingcai Wu;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[conjugate gradient methods]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Junctions]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[446]]></spage>

<epage><![CDATA[459]]></epage>

<abstract><![CDATA[Visualizing complex volume data usually renders selected parts of the volume semitransparently to see inner structures of the volume or provide a context. This presents a challenge for volume rendering methods to produce images with unambiguous depth-ordering perception. Existing methods use visual cues such as halos and shadows to enhance depth perception. Along with other limitations, these methods introduce redundant information and require additional overhead. This paper presents a new approach to enhancing depth-ordering perception of volume rendered images without using additional visual cues. We set up an energy function based on quantitative perception models to measure the quality of the images in terms of the effectiveness of depth-ordering and transparency perception as well as the faithfulness of the information revealed. Guided by the function, we use a conjugate gradient method to iteratively and judiciously enhance the results. Our method can complement existing systems for enhancing volume rendering results. The experimental results demonstrate the usefulness and effectiveness of our approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6226392]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.144]]></doi>

<publicationId><![CDATA[6226392]]></publicationId>

<partnum><![CDATA[6226392]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6226392&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226392]]></pdf>

</document>

<document>

<rank>342</rank>

<title><![CDATA[Visual Analysis and Dissemination of Scientific Literature Collections with SurVis]]></title>

<authors><![CDATA[Beck, F.;  Koch, S.;  Weiskopf, D.]]></authors>

<affiliations><![CDATA[VISUS, Univ. of Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[bibliographies]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[inference mechanisms]]></term>

<term><![CDATA[information analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Browsers]]></term>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Tag clouds]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[180]]></spage>

<epage><![CDATA[189]]></epage>

<abstract><![CDATA[Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192633]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467757]]></doi>

<publicationId><![CDATA[7192633]]></publicationId>

<partnum><![CDATA[7192633]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192633&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192633]]></pdf>

</document>

<document>

<rank>343</rank>

<title><![CDATA[Dual-Matrix Sampling for Scalable Translucent Material Rendering]]></title>

<authors><![CDATA[Yu-Ting Wu;  Tzu-Mao Li;  Yu-Hsun Lin;  Yung-Yu Chuang]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sampling methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Materials]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[363]]></spage>

<epage><![CDATA[374]]></epage>

<abstract><![CDATA[This paper introduces a scalable algorithm for rendering translucent materials with complex lighting. We represent the light transport with a diffusion approximation by a dual-matrix representation with the Light-to-Surface and Surface-to-Camera matrices. By exploiting the structures within the matrices, the proposed method can locate surface samples with little contribution by using only subsampled matrices and avoid wasting computation on these samples. The decoupled estimation of irradiance and diffuse BSSRDFs also allows us to have a tight error bound, making the adaptive diffusion approximation more efficient and accurate. Experiments show that our method outperforms previous methods for translucent material rendering, especially in large scenes with massive translucent surfaces shaded by complex illumination.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6994841]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2385059]]></doi>

<publicationId><![CDATA[6994841]]></publicationId>

<partnum><![CDATA[6994841]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6994841&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6994841]]></pdf>

</document>

<document>

<rank>344</rank>

<title><![CDATA[Paper Reviewers]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[x]]></spage>

<epage><![CDATA[x]]></epage>

<abstract><![CDATA[The publication offers a note of thanks and lists its reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6165129]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.54]]></doi>

<publicationId><![CDATA[6165129]]></publicationId>

<partnum><![CDATA[6165129]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165129&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165129]]></pdf>

</document>

<document>

<rank>345</rank>

<title><![CDATA[Conceptual Recurrence Plots: Revealing Patterns in Human Discourse]]></title>

<authors><![CDATA[Angus, D.;  Smith, A.;  Wiles, J.]]></authors>

<affiliations><![CDATA[Sch. of Inf. Technol. & Electr. Eng., Univ. of Queensland, Brisbane, QLD, Australia]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[text analysis]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Pain]]></term>

<term><![CDATA[Semantics]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Time series analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[988]]></spage>

<epage><![CDATA[997]]></epage>

<abstract><![CDATA[Human discourse contains a rich mixture of conceptual information. Visualization of the global and local patterns within this data stream is a complex and challenging problem. Recurrence plots are an information visualization technique that can reveal trends and features in complex time series data. The recurrence plot technique works by measuring the similarity of points in a time series to all other points in the same time series and plotting the results in two dimensions. Previous studies have applied recurrence plotting techniques to textual data; however, these approaches plot recurrence using term-based similarity rather than conceptual similarity of the text. We introduce conceptual recurrence plots, which use a model of language to measure similarity between pairs of text utterances, and the similarity of all utterances is measured and displayed. In this paper, we explore how the descriptive power of the recurrence plotting technique can be used to discover patterns of interaction across a series of conversation transcripts. The results suggest that the conceptual recurrence plotting technique is a useful tool for exploring the structure of human discourse.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5887327]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.100]]></doi>

<publicationId><![CDATA[5887327]]></publicationId>

<partnum><![CDATA[5887327]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5887327&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887327]]></pdf>

</document>

<document>

<rank>346</rank>

<title><![CDATA[On the Interpolation of Data with Normally Distributed Uncertainty for Visualization]]></title>

<authors><![CDATA[Schlegel, S.;  Korn, N.;  Scheuermann, G.]]></authors>

<affiliations><![CDATA[Univ. of Leipzig, Leipzig, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[Gaussian distribution]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed databases]]></term>

<term><![CDATA[Gaussian processes]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Random variables]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2305]]></spage>

<epage><![CDATA[2314]]></epage>

<abstract><![CDATA[In many fields of science or engineering, we are confronted with uncertain data. For that reason, the visualization of uncertainty received a lot of attention, especially in recent years. In the majority of cases, Gaussian distributions are used to describe uncertain behavior, because they are able to model many phenomena encountered in science. Therefore, in most applications uncertain data is (or is assumed to be) Gaussian distributed. If such uncertain data is given on fixed positions, the question of interpolation arises for many visualization approaches. In this paper, we analyze the effects of the usual linear interpolation schemes for visualization of Gaussian distributed data. In addition, we demonstrate that methods known in geostatistics and machine learning have favorable properties for visualization purposes in this case.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327235]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.249]]></doi>

<publicationId><![CDATA[6327235]]></publicationId>

<partnum><![CDATA[6327235]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327235&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327235]]></pdf>

</document>

<document>

<rank>347</rank>

<title><![CDATA[Message from the Paper Chairs and Guest Editors]]></title>

<authors><![CDATA[van Ham, Frank;  Machiraju, Raghu;  Mueller, Klaus;  Scheuermann, Gerik;  Weaver, Chris]]></authors>

<affiliations><![CDATA[IBM Research]]></affiliations>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Information processing]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[x]]></spage>

<epage><![CDATA[x]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6064930]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.222]]></doi>

<publicationId><![CDATA[6064930]]></publicationId>

<partnum><![CDATA[6064930]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064930&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064930]]></pdf>

</document>

<document>

<rank>348</rank>

<title><![CDATA[Corrections to "the prioritized-layered projection algorithm for visible set estimation"]]></title>

<authors><![CDATA[Klosowski, J.T.;  Silva, C.T.]]></authors>

<thesaurusterms>

<term><![CDATA[Computer errors]]></term>

<term><![CDATA[Error correction]]></term>

<term><![CDATA[Production]]></term>

<term><![CDATA[Projection algorithms]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sorting]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[380]]></spage>

<epage><![CDATA[380]]></epage>

<abstract><![CDATA[<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00895881.png" border="0">]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[895881]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2000.895881]]></doi>

<publicationId><![CDATA[895881]]></publicationId>

<partnum><![CDATA[895881]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=895881&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=895881]]></pdf>

</document>

<document>

<rank>349</rank>

<title><![CDATA[Crest lines for surface segmentation and flattening]]></title>

<authors><![CDATA[Stylianou, G.;  Farin, G.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Cyprus Coll., Nicosia, Cyprus]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[differential geometry]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Brain]]></term>

<term><![CDATA[Cerebral cortex]]></term>

<term><![CDATA[Conformal mapping]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Medical simulation]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface fitting]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[536]]></spage>

<epage><![CDATA[544]]></epage>

<abstract><![CDATA[We present a method for extracting feature curves called crest lines from a triangulated surface. Then, we calculate the geodesic Voronoi diagram of crest lines to segment the surface into several regions. Afterward, barycentric surface flattening using theory from graph embeddings is implemented and, using the geodesic Voronoi diagram, we develop a faster surface flattening algorithm.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1310279]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.24]]></doi>

<publicationId><![CDATA[1310279]]></publicationId>

<partnum><![CDATA[1310279]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310279&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310279]]></pdf>

</document>

<document>

<rank>350</rank>

<title><![CDATA[A Data-Driven Approach to Hue-Preserving Color-Blending]]></title>

<authors><![CDATA[Kuhne, L.;  Giesen, J.;  Zhiyuan Zhang;  Sungsoo Ha;  Mueller, K.]]></authors>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[colour graphics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[knowledge based systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[support vector machines]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Standards]]></term>

<term><![CDATA[Support vector machines]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2122]]></spage>

<epage><![CDATA[2129]]></epage>

<abstract><![CDATA[Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327217]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.186]]></doi>

<publicationId><![CDATA[6327217]]></publicationId>

<partnum><![CDATA[6327217]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327217&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327217]]></pdf>

</document>

<document>

<rank>351</rank>

<title><![CDATA[A Spherical Gaussian Framework for Bayesian Monte Carlo Rendering of Glossy Surfaces]]></title>

<authors><![CDATA[Marques, R.;  Bouville, C.;  Ribardiere, M.;  Santos, L.P.;  Bouatouch, K.]]></authors>

<affiliations><![CDATA[Inst. Nat. de Rech. en Inf. et Autom., Rennes, France]]></affiliations>

<controlledterms>

<term><![CDATA[Bayes methods]]></term>

<term><![CDATA[Gaussian processes]]></term>

<term><![CDATA[Monte Carlo methods]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[parameter estimation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sampling methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bayes methods]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Monte Carlo methods]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1619]]></spage>

<epage><![CDATA[1632]]></epage>

<abstract><![CDATA[The Monte Carlo method has proved to be very powerful to cope with global illumination problems but it remains costly in terms of sampling operations. In various applications, previous work has shown that Bayesian Monte Carlo can significantly outperform importance sampling Monte Carlo thanks to a more effective use of the prior knowledge and of the information brought by the samples set. These good results have been confirmed in the context of global illumination but strictly limited to the perfect diffuse case. Our main goal in this paper is to propose a more general Bayesian Monte Carlo solution that allows dealing with nondiffuse BRDFs thanks to a spherical Gaussian-based framework. We also propose a fast hyperparameters determination method that avoids learning the hyperparameters for each BRDF. These contributions represent two major steps toward generalizing Bayesian Monte Carlo for global illumination rendering. We show that we achieve substantial quality improvements over importance sampling at comparable computational cost.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6514875]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.79]]></doi>

<publicationId><![CDATA[6514875]]></publicationId>

<partnum><![CDATA[6514875]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6514875&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6514875]]></pdf>

</document>

<document>

<rank>352</rank>

<title><![CDATA[Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research]]></title>

<authors><![CDATA[Engel, D.;  Greff, K.;  Garth, C.;  Bein, K.;  Wexler, A.;  Hamann, B.;  Hagen, H.]]></authors>

<affiliations><![CDATA[Univ. of Kaiserslautern, Kaiserslautern, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[aerosols]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[formal verification]]></term>

<term><![CDATA[mass spectroscopy]]></term>

<term><![CDATA[matrix decomposition]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aerosols]]></term>

<term><![CDATA[Atmospheric measurements]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Error analysis]]></term>

<term><![CDATA[Mass spectroscopy]]></term>

<term><![CDATA[Optimization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2275]]></spage>

<epage><![CDATA[2284]]></epage>

<abstract><![CDATA[The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327232]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.280]]></doi>

<publicationId><![CDATA[6327232]]></publicationId>

<partnum><![CDATA[6327232]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327232&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327232]]></pdf>

</document>

<document>

<rank>353</rank>

<title><![CDATA[Complex Logarithmic Views for Small Details in Large Contexts]]></title>

<authors><![CDATA[Bottger, J.;  Balzer, M.;  Deussen, O.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Konstanz Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[conformal mapping]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Conformal mapping]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image coding]]></term>

<term><![CDATA[Image recognition]]></term>

<term><![CDATA[Information geometry]]></term>

<term><![CDATA[Information science]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Nonlinear distortion]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[845]]></spage>

<epage><![CDATA[852]]></epage>

<abstract><![CDATA[Commonly known detail in context techniques for the two-dimensional Euclidean space enlarge details and shrink their context using mapping functions that introduce geometrical compression. This makes it difficult or even impossible to recognize shapes for large differences in magnification factors. In this paper we propose to use the complex logarithm and the complex root functions to show very small details even in very large contexts. These mappings are conformal, which means they only locally rotate and scale, thus keeping shapes intact and recognizable. They allow showing details that are orders of magnitude smaller than their surroundings in combination with their context in one seamless visualization. We address the utilization of this universal technique for the interaction with complex two-dimensional data considering the exploration of large graphs and other examples]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015438]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.126]]></doi>

<publicationId><![CDATA[4015438]]></publicationId>

<partnum><![CDATA[4015438]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015438&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015438]]></pdf>

</document>

<document>

<rank>354</rank>

<title><![CDATA[Mixed Reality Humans: Evaluating Behavior, Usability, and Acceptability]]></title>

<authors><![CDATA[Kotranza, A.;  Lok, Benjamin;  Deladisma, A.;  Pugh, C.M.;  Lind, D.S.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical education]]></term>

<term><![CDATA[computer aided instruction]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Breast]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Medical simulation]]></term>

<term><![CDATA[Medical treatment]]></term>

<term><![CDATA[Technological innovation]]></term>

<term><![CDATA[Usability]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[369]]></spage>

<epage><![CDATA[382]]></epage>

<abstract><![CDATA[This paper presents mixed reality humans (MRHs), a new type of embodied agent enabling touch-driven communication. Affording touch between human and agent allows MRHs to simulate interpersonal scenarios in which touch is crucial. Two studies provide initial evaluation of user behavior with a MRH patient and the usability and acceptability of a MRH patient for practice and evaluation of medical students' clinical skills. In Study I (n = 8) it was observed that students treated MRHs as social actors more than students in prior interactions with virtual human patients (n = 27), and used interpersonal touch to comfort and reassure the MRH patient similarly to prior interactions with human patients (n = 76). In the within-subjects Study II (n = 11), medical students performed a clinical breast exam on each of a MRH and human patient. Participants performed equivalent exams with the MRH and human patients, demonstrating the usability of MRHs to evaluate students' exam skills. The acceptability of the MRH patient for practicing exam skills was high as students rated the experience as believable and educationally beneficial. Acceptability was improved from Study I to Study II due to an increase in the MRH's visual realism, demonstrating that visual realism is critical for simulation of specific interpersonal scenarios.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4689554]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.195]]></doi>

<publicationId><![CDATA[4689554]]></publicationId>

<partnum><![CDATA[4689554]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4689554&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4689554]]></pdf>

</document>

<document>

<rank>355</rank>

<title><![CDATA[Modal warping: real-time simulation of large rotational deformation and manipulation]]></title>

<authors><![CDATA[Min Gyu Choi;  Hyeong-Seok Ko]]></authors>

<affiliations><![CDATA[Graphics & Media Lab., Seoul Nat. Univ., South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[modal analysis]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[structural engineering computing]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Capacitive sensors]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Modal analysis]]></term>

<term><![CDATA[Nonlinear systems]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Strain measurement]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[91]]></spage>

<epage><![CDATA[101]]></epage>

<abstract><![CDATA[This work proposes a real-time simulation technique for large deformations. Green's nonlinear strain tensor accurately models large deformations; however, time stepping of the resulting nonlinear system can be computationally expensive. Modal analysis based on a linear strain tensor has been shown to be suitable for real-time simulation, but is accurate only for moderately small deformations. In the present work, we identify the rotational component of an infinitesimal deformation and extend traditional linear modal analysis to track that component. We then develop a procedure to integrate the small rotations occurring at the nodal points. An interesting feature of our formulation is that it can implement both position and orientation constraints in a straightforward manner. These constraints can be used to interactively manipulate the shape of a deformable solid by dragging/twisting a set of nodes. Experiments show that the proposed technique runs in real-time, even for a complex model, and that it can simulate large bending and/or twisting deformations with acceptable realism.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1359737]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.13]]></doi>

<publicationId><![CDATA[1359737]]></publicationId>

<partnum><![CDATA[1359737]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359737&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359737]]></pdf>

</document>

<document>

<rank>356</rank>

<title><![CDATA[Tiled++: An Enhanced Tiled Hi-Res Display Wall]]></title>

<authors><![CDATA[Ebert, A.;  Thelen, S.;  Olech, P.-S.;  Meyer, J.;  Hagen, H.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Univ. of Kaiserslautern, Kaiserslautern, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[high definition television]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[liquid crystal displays]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[120]]></spage>

<epage><![CDATA[132]]></epage>

<abstract><![CDATA[In recent years, high-resolution displays have become increasingly important to decision makers and scientists because large screens combined with a high pixel count facilitate content rich, simultaneous display of computer-generated imagery and high-definition video data from multiple sources. Tiled displays are attractive due to their extended screen real estate, scalability, and low cost. LCD panels are usually preferred over projectors because of their superior resolution. One of the drawbacks of LCD-based tiled displays is the fact that users sometimes get distracted by the screens' bezels, which cause discontinuities in rendered images, animations, or videos. Most conventional solutions either ignore the bezels and display all pixels, causing objects to become distorted, or eliminate the pixels that would normally fall under the bezels, causing pixels to be missing in the display of static images. In animations, the missing pixels will eventually reappear when the object moves, providing an experience that is similar to looking through a French window. In this paper, we present a new scalable approach that leads neither to discontinuities nor to significant loss of information. By projecting onto the bezels, we demonstrate that a combination of LCD-based tiled displays and projection significantly reduces the bezel problem. Our technique eliminates ambiguities that commonly occur on tiled displays in the fields of information visualization, visual data analysis, human-computer interaction, and scientific data display. It improves the usability of multimonitor systems by virtually eliminating the bezels. We describe a setup and provide results from an evaluation experiment conducted on a 3 times 3 and on a 10 times 5 tiled display wall.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4967580]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.57]]></doi>

<publicationId><![CDATA[4967580]]></publicationId>

<partnum><![CDATA[4967580]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4967580&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967580]]></pdf>

</document>

<document>

<rank>357</rank>

<title><![CDATA[Guest Editorial: Special Section on Visual Analytics]]></title>

<authors><![CDATA[Keim, D.A.;  Robertson, G.G.;  Thomas, J.J.;  van Wijk, J.J.]]></authors>

<thesaurusterms>

<term><![CDATA[Communication networks]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Research and development]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Turning]]></term>

<term><![CDATA[Visual analytics]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1361]]></spage>

<epage><![CDATA[1362]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1703358]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.93]]></doi>

<publicationId><![CDATA[1703358]]></publicationId>

<partnum><![CDATA[1703358]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1703358&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703358]]></pdf>

</document>

<document>

<rank>358</rank>

<title><![CDATA[A Generic and Scalable Pipeline for GPU Tetrahedral Grid Rendering]]></title>

<authors><![CDATA[Georgii, J.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization Group, Technische Univ. Munchen]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[pipeline processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Feedforward systems]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Personal communication networks]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Plastics]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1345]]></spage>

<epage><![CDATA[1352]]></epage>

<abstract><![CDATA[Recent advances in algorithms and graphics hardware have opened the possibility to render tetrahedral grids at interactive rates on commodity PCs. This paper extends on this work in that it presents a direct volume rendering method for such grids which supports both current and upcoming graphics hardware architectures, large and deformable grids, as well as different rendering options. At the core of our method is the idea to perform the sampling of tetrahedral elements along the view rays entirely in local barycentric coordinates. Then, sampling requires minimum GPU memory and texture access operations, and it maps efficiently onto a feed-forward pipeline of multiple stages performing computation and geometry construction. We propose to spawn rendered elements from one single vertex. This makes the method amenable to upcoming Direct3D 10 graphics hardware which allows to create geometry on the GPU. By only modifying the algorithm slightly it can be used to render per-pixel iso-surfaces and to perform tetrahedral cell projection. As our method neither requires any pre-processing nor an intermediate grid representation it can efficiently deal with dynamic and large 3D meshes]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015501]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.110]]></doi>

<publicationId><![CDATA[4015501]]></publicationId>

<partnum><![CDATA[4015501]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015501&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015501]]></pdf>

</document>

<document>

<rank>359</rank>

<title><![CDATA[Extended Pie Menus for Immersive Virtual Environments]]></title>

<authors><![CDATA[Gebhardt, S.;  Pick, S.;  Leithold, F.;  Hentschel, B.;  Kuhlen, T.]]></authors>

<controlledterms>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atmospheric measurements]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Error analysis]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Usability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[644]]></spage>

<epage><![CDATA[651]]></epage>

<abstract><![CDATA[Pie menus are a well-known technique for interacting with 2D environments and so far a large body of research documents their usage and optimizations. Yet, comparatively little research has been done on the usability of pie menus in immersive virtual environments (IVEs). In this paper we reduce this gap by presenting an implementation and evaluation of an extended hierarchical pie menu system for IVEs that can be operated with a six-degrees-of-freedom input device. Following an iterative development process, we first developed and evaluated a basic hierarchical pie menu system. To better understand how pie menus should be operated in IVEs, we tested this system in a pilot user study with 24 participants and focus on item selection. Regarding the results of the study, the system was tweaked and elements like check boxes, sliders, and color map editors were added to provide extended functionality. An expert review with five experts was performed with the extended pie menus being integrated into an existing VR application to identify potential design issues. Overall results indicated high performance and efficient design.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6479193]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.31]]></doi>

<publicationId><![CDATA[6479193]]></publicationId>

<partnum><![CDATA[6479193]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479193&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479193]]></pdf>

</document>

<document>

<rank>360</rank>

<title><![CDATA[Orientation-Preserving Rod Elements for Real-Time Thin-Shell Simulation]]></title>

<authors><![CDATA[Zhang, N.;  Huamin Qu;  Sweet, R.]]></authors>

<affiliations><![CDATA[Urologic Surg. Dept., Univ. of Minnesota at Twin Cities, Minneapolis, MN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[bending]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[elastic constants]]></term>

<term><![CDATA[plates (structures)]]></term>

<term><![CDATA[rods (structures)]]></term>

<term><![CDATA[shells (structures)]]></term>

<term><![CDATA[structural engineering computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Springs]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[822]]></spage>

<epage><![CDATA[835]]></epage>

<abstract><![CDATA[We propose a new computation model for simulating elastic thin shells at interactive rates. Existing graphical simulation methods are mostly based on dihedral angle energy functions, which need to compute the first order and second order partial derivatives with respect to current vertex positions as bending forces and stiffness matrices. The symbolic derivatives are complicated in nonisometric element deformations. To simplify computing the derivatives, instead of directly constructing the dihedral angle energy, we use the orientation change energy of mesh edges. A continuum-mechanics-based orientation-preserving rod element model is developed to provide the bending forces. The advantage of our method is simple bending force and stiffness matrix computation, since in the rod model, we apply a novel incremental construction of the deformation gradient tensor to linearize both tensile and orientation deformations. Consequently, our model is efficient, easy to implement, and supports both quadrilateral and triangle meshes. It also treats shells and plates uniformly.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5487516]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.92]]></doi>

<publicationId><![CDATA[5487516]]></publicationId>

<partnum><![CDATA[5487516]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5487516&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487516]]></pdf>

</document>

<document>

<rank>361</rank>

<title><![CDATA[Focus+Context Metro Maps]]></title>

<authors><![CDATA[Yu-Shuen Wang;  Ming-Te Chi]]></authors>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[mobile handsets]]></term>

<term><![CDATA[railways]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Nonlinear distortion]]></term>

<term><![CDATA[Optimization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2528]]></spage>

<epage><![CDATA[2535]]></epage>

<abstract><![CDATA[We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065020]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.205]]></doi>

<publicationId><![CDATA[6065020]]></publicationId>

<partnum><![CDATA[6065020]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065020&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065020]]></pdf>

</document>

<document>

<rank>362</rank>

<title><![CDATA[From the Lab to the Field: Steve Roth&#8212;A Memoriam]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Capacitive sensors]]></term>

<term><![CDATA[Decision making]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Military computing]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Research and development]]></term>

<term><![CDATA[Scheduling]]></term>

<term><![CDATA[Software prototyping]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[609]]></spage>

<epage><![CDATA[610]]></epage>

<abstract><![CDATA[From the Lab to the Field: Steve Roth&#8212;A Memoriam]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512011]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.101]]></doi>

<publicationId><![CDATA[1512011]]></publicationId>

<partnum><![CDATA[1512011]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512011&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512011]]></pdf>

</document>

<document>

<rank>363</rank>

<title><![CDATA[Graph Drawing Aesthetics&#x02014;Created by Users, Not Algorithms]]></title>

<authors><![CDATA[Purchase, H.C.;  Pilcher, C.;  Plimmer, B.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci., Univ. of Glasgow, Glasgow, UK]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Education]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Interviews]]></term>

<term><![CDATA[Layout]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[81]]></spage>

<epage><![CDATA[92]]></epage>

<abstract><![CDATA[Prior empirical work on layout aesthetics for graph drawing algorithms has concentrated on the interpretation of existing graph drawings. We report on experiments which focus on the creation and layout of graph drawings: participants were asked to draw graphs based on adjacency lists, and to lay them out "nicely.&#x201D; Two interaction methods were used for creating the drawings: a sketch interface which allows for easy, natural hand movements, and a formal point-and-click interface similar to a typical graph editing system. We find, in common with many other studies, that removing edge crossings is the most significant aesthetic, but also discover that aligning nodes and edges to an underlying grid is important. We observe that the aesthetics favored by participants during creation of a graph drawing are often not evident in the final product and that the participants did not make a clear distinction between the processes of creation and layout. Our results suggest that graph drawing systems should integrate automatic layout with the user's manual editing process, and provide facilities to support grid-based graph creation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5674033]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.269]]></doi>

<publicationId><![CDATA[5674033]]></publicationId>

<partnum><![CDATA[5674033]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5674033&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674033]]></pdf>

</document>

<document>

<rank>364</rank>

<title><![CDATA[Isosurface Extraction and Spatial Filtering using Persistent Octree (POT)]]></title>

<authors><![CDATA[Shi, Q.;  Jaja, J.]]></authors>

<affiliations><![CDATA[Dept. of Electr. & Comput. Eng., Maryland Univ., College Park, MD]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[database indexing]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[octrees]]></term>

<term><![CDATA[spatial data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Active filters]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Indexing]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Tree data structures]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1283]]></spage>

<epage><![CDATA[1290]]></epage>

<abstract><![CDATA[We propose a novel persistent octree (POT) indexing structure for accelerating isosurface extraction and spatial filtering from volumetric data. This data structure efficiently handles a wide range of visualization problems such as the generation of view-dependent isosurfaces, ray tracing, and isocontour slicing for high dimensional data. POT can be viewed as a hybrid data structure between the interval tree and the branch-on-need octree (BONO) in the sense that it achieves the asymptotic bound of the interval tree for identifying the active cells corresponding to an isosurface and is more efficient than BONO for handling spatial queries. We encode a compact octree for each isovalue. Each such octree contains only the corresponding active cells, in such a way that the combined structure has linear space. The inherent hierarchical structure associated with the active cells enables very fast filtering of the active cells based on spatial constraints. We demonstrate the effectiveness of our approach by performing view-dependent isosurfacing on a wide variety of volumetric data sets and 4D isocontour slicing on the time-varying Richtmyer-Meshkov instability dataset]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015493]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.157]]></doi>

<publicationId><![CDATA[4015493]]></publicationId>

<partnum><![CDATA[4015493]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015493&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015493]]></pdf>

</document>

<document>

<rank>365</rank>

<title><![CDATA[Image metamorphosis with scattered feature constraints]]></title>

<authors><![CDATA[Seungyong Lee;  Wolberg, G.;  Kyung-Yong Chwa;  Sung Yong Shin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Pohang Univ. of Sci. & Technol., South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Digital images]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[TV]]></term>

<term><![CDATA[Visual effects]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[337]]></spage>

<epage><![CDATA[354]]></epage>

<abstract><![CDATA[This paper describes an image metamorphosis technique to handle scattered feature constraints specified with points, polylines, and splines. Solutions to the following three problems are presented: feature specification, warp generation, and transition control. We demonstrate the use of snakes to reduce the burden of feature specification. Next, we propose the use of multilevel free-form deformations (MFFD) to compute C<sup>2</sup>-continuous and one-to-one mapping functions among the specified features. The resulting technique, based on B-spline approximation, is simpler and faster than previous warp generation methods. Furthermore, it produces smooth image transformations without undesirable ripples and foldovers. Finally, we simplify the MFFD algorithm to derive transition functions to control geometry and color blending. Implementation details are furnished and comparisons among various metamorphosis techniques are presented]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[556502]]></arnumber>

<doi><![CDATA[10.1109/2945.556502]]></doi>

<publicationId><![CDATA[556502]]></publicationId>

<partnum><![CDATA[556502]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=556502&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556502]]></pdf>

</document>

<document>

<rank>366</rank>

<title><![CDATA[A hardware-assisted scalable solution for interactive volume rendering of time-varying data]]></title>

<authors><![CDATA[Lum, E.B.;  Kwan-Liu Ma;  Clyne, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., California Univ., Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decoding]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[microcomputer applications]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[turbulence]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bit rate]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Decoding]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Personal communication networks]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Space technology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[286]]></spage>

<epage><![CDATA[301]]></epage>

<abstract><![CDATA[We present a scalable volume rendering technique that exploits lossy compression and low-cost commodity hardware to permit highly interactive exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3D graphics card. Using a single PC equipped with a modest amount of memory, a texture-capable graphics card and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 42 million voxels each time step) at interactive rates. By clustering multiple PCs together, we demonstrate the data-size scalability of our method. The frame rates achieved make possible the interactive exploration of data in the temporal, spatial and transfer function domains. A comprehensive evaluation of our method based on experimental studies using data sets (up to 134 million voxels per time step) from turbulence flow simulations is also presented.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1021580]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2002.1021580]]></doi>

<publicationId><![CDATA[1021580]]></publicationId>

<partnum><![CDATA[1021580]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1021580&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1021580]]></pdf>

</document>

<document>

<rank>367</rank>

<title><![CDATA[Projected tetrahedra revisited: a barycentric formulation applied to digital radiograph reconstruction using higher-order attenuation functions]]></title>

<authors><![CDATA[Sadowsky, O.;  Cohen, J.D.;  Taylor, R.H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Johns Hopkins Univ., Baltimore, MD, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diagnostic radiography]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Attenuation]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Radiography]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[461]]></spage>

<epage><![CDATA[473]]></epage>

<abstract><![CDATA[This paper presents a novel method for volume rendering of unstructured grids. Previously, we introduced an algorithm for perspective-correct interpolation of barycentric coordinates and computing polynomial attenuation integrals for a projected tetrahedron using graphics hardware. In this paper, we enhance the algorithm by providing a simple and efficient method to compute the projected shape (silhouette) and tessellation of a tetrahedron, in perspective and orthographic projection models. Our tessellation algorithm is published for the first time. Compared with works of other groups on rendering unstructured grids, the main contributions of this work are: 1) A new algorithm for finding the silhouette of a projected tetrahedron. 2) A method for interpolating barycentric coordinates and thickness on the faces of the tetrahedron. 3) Visualizing higher-order attenuation functions using GPU without preintegration. 4) Capability of applying shape deformations to a rendered tetrahedral mesh without significant performance loss. Our visualization model is independent of depth-sorting of the cells. We present imaging and timing results of our implementation, and an application in time-critical "2D-3D" deformable registration of anatomical models. We discuss the impact of using higher-order functions on quality and performance.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634312]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.77]]></doi>

<publicationId><![CDATA[1634312]]></publicationId>

<partnum><![CDATA[1634312]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634312&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634312]]></pdf>

</document>

<document>

<rank>368</rank>

<title><![CDATA[Perception of human motion with different geometric models]]></title>

<authors><![CDATA[Hodgins, J.K.;  O'Brien, J.F.;  Tumblin, J.]]></authors>

<affiliations><![CDATA[Graphics, Visualization, & Usability Center, Georgia Inst. of Technol., Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[human factors]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sensitivity]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Lifting equipment]]></term>

<term><![CDATA[Muscles]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[307]]></spage>

<epage><![CDATA[316]]></epage>

<abstract><![CDATA[Human figures have been animated using a variety of geometric models, including stick figures, polygonal models and NURBS-based models with muscles, flexible skin or clothing. This paper reports on experimental results indicating that a viewer's perception of motion characteristics is affected by the geometric model used for rendering. Subjects were shown a series of paired motion sequences and asked if the two motions in each pair were the same or different. The motion sequences in each pair were rendered using the same geometric model. For the three types of motion variation tested, sensitivity scores indicate that subjects were better able to observe changes with the polygonal model than they were with the stick-figure model]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[765325]]></arnumber>

<doi><![CDATA[10.1109/2945.765325]]></doi>

<publicationId><![CDATA[765325]]></publicationId>

<partnum><![CDATA[765325]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=765325&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=765325]]></pdf>

</document>

<document>

<rank>369</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6238451]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.154]]></doi>

<publicationId><![CDATA[6238451]]></publicationId>

<partnum><![CDATA[6238451]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6238451&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6238451]]></pdf>

</document>

<document>

<rank>370</rank>

<title><![CDATA[Visualization of boundaries in volumetric data sets using LH histograms]]></title>

<authors><![CDATA[Sereda, P.;  Bartroli, A.V.;  Serlie, I.W.O.;  Gerritsen, F.A.]]></authors>

<affiliations><![CDATA[Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Optical imaging]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[208]]></spage>

<epage><![CDATA[218]]></epage>

<abstract><![CDATA[A crucial step in volume rendering is the design of transfer functions that highlights those aspects of the volume data that are of interest to the user. For many applications, boundaries carry most of the relevant information. Reliable detection of boundaries is often hampered by limitations of the imaging process, such as blurring and noise. We present a method to identify the materials that form the boundaries. These materials are then used in a new domain that facilitates interactive and semiautomatic design of appropriate transfer functions. We also show how the obtained boundary information can be used in region-growing-based segmentation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1580455]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.39]]></doi>

<publicationId><![CDATA[1580455]]></publicationId>

<partnum><![CDATA[1580455]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580455&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580455]]></pdf>

</document>

<document>

<rank>371</rank>

<title><![CDATA[Temporal Radiance Caching]]></title>

<authors><![CDATA[Gautron, P.;  Bouatouch, K.;  Pattanaik, S.]]></authors>

<controlledterms>

<term><![CDATA[blood vessels]]></term>

<term><![CDATA[endoscopes]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[891]]></spage>

<epage><![CDATA[901]]></epage>

<abstract><![CDATA[Curved planar reformation (CPR) has proven to be a practical and widely used tool for the visualization of curved tubular structures within the human body. It has been useful in medical procedures involving the examination of blood vessels and the spine. However, it is more difficult to use it for large tubular structures such as the trachea and the colon because abnormalities may be smaller relative to the size of the structure and may not have such distinct density and shape characteristics. Our new approach improves on this situation by using volume rendering for hollow regions and standard CPR for the surrounding tissue. This effectively combines gray-scale contextual information with detailed color information from the area of interest. The approach is successfully used with each of the standard CPR types, and the resulting images are promising as an alternative to virtual endoscopy. Because CPR and volume rendering are tightly coupled, the projection method used has a significant effect on the properties of the volume renderer, such as distortion and isometry. We describe and compare the different CPR projection methods and how they affect the volume rendering process. A version of the algorithm is also presented which makes use of importance-driven techniques; this ensures the users' attention is always focused on the area of interest and also improves the speed of the algorithm.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4135667]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1061]]></doi>

<publicationId><![CDATA[4135667]]></publicationId>

<partnum><![CDATA[4135667]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4135667&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4135667]]></pdf>

</document>

<document>

<rank>372</rank>

<title><![CDATA[Perception of Average Value in Multiclass Scatterplots]]></title>

<authors><![CDATA[Gleicher, M.;  Correll, M.;  Nothelfer, C.;  Franconeri, S.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Wisconsin - Madison, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color imaging]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Visual systems]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2316]]></spage>

<epage><![CDATA[2325]]></epage>

<abstract><![CDATA[The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634120]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.183]]></doi>

<publicationId><![CDATA[6634120]]></publicationId>

<partnum><![CDATA[6634120]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634120&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634120]]></pdf>

</document>

<document>

<rank>373</rank>

<title><![CDATA[RankExplorer: Visualization of Ranking Changes in Large Time Series Data]]></title>

<authors><![CDATA[Conglei Shi;  Weiwei Cui;  Shixia Liu;  Panpan Xu;  Wei Chen;  Huamin Qu]]></authors>

<affiliations><![CDATA[Hong Kong Univ. of Sci. & Technol., Hong Kong, China]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[search engines]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Time series analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2669]]></spage>

<epage><![CDATA[2678]]></epage>

<abstract><![CDATA[For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327273]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.253]]></doi>

<publicationId><![CDATA[6327273]]></publicationId>

<partnum><![CDATA[6327273]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327273&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327273]]></pdf>

</document>

<document>

<rank>374</rank>

<title><![CDATA[Physically-based stochastic simplification of mathematical knots]]></title>

<authors><![CDATA[Grzeszczuk, R.P.;  Huang, M.;  Kauffman, L.H.]]></authors>

<affiliations><![CDATA[Silicon Graphics Comput. Syst., Mountain View, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[mathematics]]></term>

<term><![CDATA[mathematics computing]]></term>

<term><![CDATA[simulated annealing]]></term>

<term><![CDATA[stochastic processes]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Electrostatics]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Mirrors]]></term>

<term><![CDATA[Optimization methods]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Simulated annealing]]></term>

<term><![CDATA[Stability]]></term>

<term><![CDATA[Stochastic processes]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[262]]></spage>

<epage><![CDATA[272]]></epage>

<abstract><![CDATA[The article describes a tool for simplification and analysis of tangled configurations of mathematical knots. The proposed method addresses optimization issues common in energy based approaches to knot classification. In this class of methods, an initially tangled elastic rope is &ldquo;charged&rdquo; with an electrostatic like field which causes it to self repel, prompting it to evolve into a mechanically stable configuration. This configuration is believed to be characteristic for its knot type. We propose a physically based model to implicitly guard against isotopy violation during such evolution and suggest that a robust stochastic optimization procedure, simulated annealing, be used for the purpose of identifying the globally optimal solution. Because neither of these techniques depends on the properties of the energy function being optimized, our method is of general applicability, even though we applied it to a specific potential here. The method has successfully analyzed several complex tangles and is applicable to simplifying a large class of knots and links. Our work also shows that energy based techniques will not necessarily terminate in a unique configuration, thus we empirically refute a prior conjecture that one of the commonly used energy functions (J. Simon, 1994) is unimodal. Based on these results we also compare techniques that rely on geometric energy optimization to conventional algebraic methods with regards to their classification power]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[620492]]></arnumber>

<doi><![CDATA[10.1109/2945.620492]]></doi>

<publicationId><![CDATA[620492]]></publicationId>

<partnum><![CDATA[620492]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=620492&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620492]]></pdf>

</document>

<document>

<rank>375</rank>

<title><![CDATA[Real-Time Tracking of Visually Attended Objects in Virtual Environments and Its Application to LOD]]></title>

<authors><![CDATA[Sungkil Lee;  Jounghyun Kim, G.;  Seungmoon Choi]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Haptics & Virtual Reality Lab., Pohang]]></affiliations>

<controlledterms>

<term><![CDATA[object recognition]]></term>

<term><![CDATA[target tracking]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[High performance computing]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Target tracking]]></term>

<term><![CDATA[Video compression]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Visual perception]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[6]]></spage>

<epage><![CDATA[19]]></epage>

<abstract><![CDATA[This paper presents a real-time framework for computationally tracking objects visually attended by the user while navigating in interactive virtual environments. In addition to the conventional bottom-up (stimulus-driven) saliency map, the proposed framework uses top-down (goal-directed) contexts inferred from the user's spatial and temporal behaviors, and identifies the most plausibly attended objects among candidates in the object saliency map. The computational framework was implemented using GPU, exhibiting high computational performance adequate for interactive virtual environments. A user experiment was also conducted to evaluate the prediction accuracy of the tracking framework by comparing objects regarded as visually attended by the framework to actual human gaze collected with an eye tracker. The results indicated that the accuracy was in the level well supported by the theory of human cognition for visually identifying single and multiple attentive targets, especially owing to the addition of top-down contextual information. Finally, we demonstrate how the visual attention tracking framework can be applied to managing the level of details in virtual environments, without any hardware for head or eye tracking.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4531740]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.82]]></doi>

<publicationId><![CDATA[4531740]]></publicationId>

<partnum><![CDATA[4531740]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4531740&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4531740]]></pdf>

</document>

<document>

<rank>376</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1608029]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.46]]></doi>

<publicationId><![CDATA[1608029]]></publicationId>

<partnum><![CDATA[1608029]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1608029&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608029]]></pdf>

</document>

<document>

<rank>377</rank>

<title><![CDATA[NeuroBlocks &#x2013; Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects]]></title>

<authors><![CDATA[Al-Awami, A.K.;  Beyer, J.;  Haehn, D.;  Kasthuri, N.;  Lichtman, J.W.;  Pfister, H.;  Hadwiger, M.]]></authors>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[neurophysiology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Neurons]]></term>

<term><![CDATA[Neuroscience]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[738]]></spage>

<epage><![CDATA[746]]></epage>

<abstract><![CDATA[In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192653]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467441]]></doi>

<publicationId><![CDATA[7192653]]></publicationId>

<partnum><![CDATA[7192653]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192653&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192653]]></pdf>

</document>

<document>

<rank>378</rank>

<title><![CDATA[Perceptually Uniform Motion Space]]></title>

<authors><![CDATA[Birkeland, A.;  Turkay, C.;  Viola, I.]]></authors>

<affiliations><![CDATA[Dept. of Inf., Univ. of Bergen, Bergen, Norway]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[flow visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brain modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Motion detection]]></term>

<term><![CDATA[Particle measurements]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1542]]></spage>

<epage><![CDATA[1554]]></epage>

<abstract><![CDATA[Flow data is often visualized by animated particles inserted into a flow field. The velocity of a particle on the screen is typically linearly scaled by the velocities in the data. However, the perception of velocity magnitude in animated particles is not necessarily linear. We present a study on how different parameters affect relative motion perception. We have investigated the impact of four parameters. The parameters consist of speed multiplier, direction, contrast type and the global velocity scale. In addition, we investigated if multiple motion cues, and point distribution, affect the speed estimation. Several studies were executed to investigate the impact of each parameter. In the initial results, we noticed trends in scale and multiplier. Using the trends for the significant parameters, we designed a compensation model, which adjusts the particle speed to compensate for the effect of the parameters. We then performed a second study to investigate the performance of the compensation model. From the second study we detected a constant estimation error, which we adjusted for in the last study. In addition, we connect our work to established theories in psychophysics by comparing our model to a model based on Stevens' Power Law.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6811168]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2322363]]></doi>

<publicationId><![CDATA[6811168]]></publicationId>

<partnum><![CDATA[6811168]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6811168&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6811168]]></pdf>

</document>

<document>

<rank>379</rank>

<title><![CDATA[Image-space visibility ordering for cell projection volume rendering of unstructured data]]></title>

<authors><![CDATA[Cook, R.;  Max, N.;  Silva, C.T.;  Williams, P.L.]]></authors>

<affiliations><![CDATA[Lawrence Livermore Nat. Lab., CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Information retrieval]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sorting]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[695]]></spage>

<epage><![CDATA[707]]></epage>

<abstract><![CDATA[Projection methods for volume rendering unstructured data work by projecting, in visibility order, the polyhedral cells of the mesh onto the image plane, and incrementally compositing each cell's color and opacity into the final image. Normally, such methods require an algorithm to determine a visibility order of the cells. The meshed polyhedra visibility order (MPVO) algorithm can provide such an order for convex meshes by considering the implications of local ordering relations between cells sharing a common face. However, in nonconvex meshes, one must also consider ordering relations along viewing rays which cross empty space between cells. In order to include these relations, the algorithm described in this paper, the scanning exact meshed polyhedra visibility ordering (SXMPVO) algorithm, scan-converts the exterior faces of the mesh and saves the ray-face intersections in an A-buffer data structure which is then used for retrieving the extra ordering relations. The image which SXMPVO produces is the same as would be produced by ordering the cells exactly, even though SXMPVO does not compute an exact visibility ordering. This is because the image resolution used for computing the visibility ordering relations is the same as that which is used for the actual volume rendering and we choose our A-buffer rays at the same sample points that are used to establish a polygon's pixel coverage during hardware scan conversion. Thus, the algorithm is image-space correct. The SXMPVO algorithm has several desirable features; among them are speed, simplicity of implementation, and no extra (i.e., with respect to MPVO) preprocessing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1333667]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.45]]></doi>

<publicationId><![CDATA[1333667]]></publicationId>

<partnum><![CDATA[1333667]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1333667&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333667]]></pdf>

</document>

<document>

<rank>380</rank>

<title><![CDATA[The Data Context Map: Fusing Data and Attributes into a Unified Display]]></title>

<authors><![CDATA[Shenghui Cheng;  Mueller, K.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[encoding]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[sensor fusion]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Symmetric matrices]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[121]]></spage>

<epage><![CDATA[130]]></epage>

<abstract><![CDATA[Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7194836]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467552]]></doi>

<publicationId><![CDATA[7194836]]></publicationId>

<partnum><![CDATA[7194836]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7194836&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194836]]></pdf>

</document>

<document>

<rank>381</rank>

<title><![CDATA[A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete]]></title>

<authors><![CDATA[Fritz, L.;  Hadwiger, M.;  Geier, G.;  Pittino, G.;  Groller, E.]]></authors>

<affiliations><![CDATA[VRVis Res. Center, Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[cast iron]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[nondestructive testing]]></term>

<term><![CDATA[reinforced concrete]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Concrete]]></term>

<term><![CDATA[Iron]]></term>

<term><![CDATA[Nondestructive testing]]></term>

<term><![CDATA[Optical fiber testing]]></term>

<term><![CDATA[Spraying]]></term>

<term><![CDATA[Steel]]></term>

<term><![CDATA[Stress]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1343]]></spage>

<epage><![CDATA[1350]]></epage>

<abstract><![CDATA[This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290747]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.115]]></doi>

<publicationId><![CDATA[5290747]]></publicationId>

<partnum><![CDATA[5290747]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290747&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290747]]></pdf>

</document>

<document>

<rank>382</rank>

<title><![CDATA[Perceptual Calibration for Immersive Display Environments]]></title>

<authors><![CDATA[Ponto, K.;  Gleicher, M.;  Radwin, R.G.;  Hyun Joon Shin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[distance measurement]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Calibration]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Virtual environments]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[691]]></spage>

<epage><![CDATA[700]]></epage>

<abstract><![CDATA[The perception of objects, depth, and distance has been repeatedly shown to be divergent between virtual and physical environments. We hypothesize that many of these discrepancies stem from incorrect geometric viewing parameters, specifically that physical measurements of eye position are insufficiently precise to provide proper viewing parameters. In this paper, we introduce a perceptual calibration procedure derived from geometric models. While most research has used geometric models to predict perceptual errors, we instead use these models inversely to determine perceptually correct viewing parameters. We study the advantages of these new psychophysically determined viewing parameters compared to the commonly used measured viewing parameters in an experiment with 20 subjects. The perceptually calibrated viewing parameters for the subjects generally produced new virtual eye positions that were wider and deeper than standard practices would estimate. Our study shows that perceptually calibrated viewing parameters can significantly improve depth acuity, distance estimation, and the perception of shape.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479210]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.36]]></doi>

<publicationId><![CDATA[6479210]]></publicationId>

<partnum><![CDATA[6479210]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479210&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479210]]></pdf>

</document>

<document>

<rank>383</rank>

<title><![CDATA[Volume Splitting and Its Applications]]></title>

<authors><![CDATA[Islam, S.;  Silver, D.;  Chen, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Wales Univ., Swansea]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Explosions]]></term>

<term><![CDATA[Focusing]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Silver]]></term>

<term><![CDATA[Surgery]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[193]]></spage>

<epage><![CDATA[203]]></epage>

<abstract><![CDATA[Splitting a volumetric object is a useful operation in volume graphics and its applications, but is not widely supported by existing systems for volume-based modeling and rendering. In this paper, we present an investigation into two main algorithmic approaches, namely, explicit and implicit splitting, for modeling and rendering splitting actions. We consider a generalized notion based on scalar fields, which encompasses discrete specifications (e.g., volume data sets) as well as procedural specifications (e.g., hypertextures) of volumetric objects. We examine the correctness, effectiveness, efficiency, and deficiencies of each approach in specifying and controlling a spatial and temporal specification of splitting. We propose methods for implementing these approaches and for overcoming their deficiencies. We present a modeling tool for creating specifications of splitting functions, and describe the use of volume scene graphs for facilitating direct rendering of volume splitting. We demonstrate the use of these approaches with examples of volume visualization, medical illustration, volume animation, and special effects]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4069230]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.48]]></doi>

<publicationId><![CDATA[4069230]]></publicationId>

<partnum><![CDATA[4069230]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4069230&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069230]]></pdf>

</document>

<document>

<rank>384</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5730195]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.58]]></doi>

<publicationId><![CDATA[5730195]]></publicationId>

<partnum><![CDATA[5730195]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5730195&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5730195]]></pdf>

</document>

<document>

<rank>385</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5331924]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.4]]></doi>

<publicationId><![CDATA[5331924]]></publicationId>

<partnum><![CDATA[5331924]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5331924&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331924]]></pdf>

</document>

<document>

<rank>386</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1608014]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.43]]></doi>

<publicationId><![CDATA[1608014]]></publicationId>

<partnum><![CDATA[1608014]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1608014&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608014]]></pdf>

</document>

<document>

<rank>387</rank>

<title><![CDATA[VisWeek Conference Committee]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[xiv]]></spage>

<epage><![CDATA[xiv]]></epage>

<abstract><![CDATA[Provides a listing of current committee members.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327201]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.293]]></doi>

<publicationId><![CDATA[6327201]]></publicationId>

<partnum><![CDATA[6327201]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327201&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327201]]></pdf>

</document>

<document>

<rank>388</rank>

<title><![CDATA[IEEE Transactions on Visualization and Computer Graphics]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[01]]></spage>

<epage><![CDATA[01]]></epage>

<abstract><![CDATA[Presents the cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1272722]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1272722]]></doi>

<publicationId><![CDATA[1272722]]></publicationId>

<partnum><![CDATA[1272722]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1272722&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272722]]></pdf>

</document>

<document>

<rank>389</rank>

<title><![CDATA[Visualizing nD Point Clouds as Topological Landscape Profiles to Guide Local Data Analysis]]></title>

<authors><![CDATA[Oesterling, P.;  Heine, C.;  Weber, G.H.;  Scheuermann, G.]]></authors>

<affiliations><![CDATA[Inst. fur Inf., Univ. Leipzig, Leipzig, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Density functional theory]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Vegetation]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[514]]></spage>

<epage><![CDATA[526]]></epage>

<abstract><![CDATA[Analyzing high-dimensional point clouds is a classical challenge in visual analytics. Traditional techniques, such as projections or axis-based techniques, suffer from projection artifacts, occlusion, and visual complexity. We propose to split data analysis into two parts to address these shortcomings. First, a structural overview phase abstracts data by its density distribution. This phase performs topological analysis to support accurate and nonoverlapping presentation of the high-dimensional cluster structure as a topological landscape profile. Utilizing a landscape metaphor, it presents clusters and their nesting as hills whose height, width, and shape reflect cluster coherence, size, and stability, respectively. A second local analysis phase utilizes this global structural knowledge to select individual clusters or point sets for further, localized data analysis. Focusing on structural entities significantly reduces visual clutter in established geometric visualizations and permits a clearer, more thorough data analysis. This analysis complements the global topological perspective and enables the user to study subspaces or geometric properties, such as shape.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6197281]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.120]]></doi>

<publicationId><![CDATA[6197281]]></publicationId>

<partnum><![CDATA[6197281]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6197281&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197281]]></pdf>

</document>

<document>

<rank>390</rank>

<title><![CDATA[Directing Crowd Simulations Using Navigation Fields]]></title>

<authors><![CDATA[Patil, S.;  van den Berg, J.;  Curtis, S.;  Lin, M.C.;  Manocha, D.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[collision avoidance]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[navigation]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Artificial intelligence]]></term>

<term><![CDATA[Collision avoidance]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Decision making]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[244]]></spage>

<epage><![CDATA[254]]></epage>

<abstract><![CDATA[We present a novel approach to direct and control virtual crowds using navigation fields. Our method guides one or more agents toward desired goals based on guidance fields. The system allows the user to specify these fields by either sketching paths directly in the scene via an intuitive authoring interface or by importing motion flow fields extracted from crowd video footage. We propose a novel formulation to blend input guidance fields to create singularity-free, goal-directed navigation fields. Our method can be easily combined with the most current local collision avoidance methods and we use two such methods as examples to highlight the potential of our approach. We illustrate its performance on several simulation scenarios.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5416702]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.33]]></doi>

<publicationId><![CDATA[5416702]]></publicationId>

<partnum><![CDATA[5416702]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5416702&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416702]]></pdf>

</document>

<document>

<rank>391</rank>

<title><![CDATA[A Time-Dependent Vector Field Topology Based on Streak Surfaces]]></title>

<authors><![CDATA[Uffinger, M.;  Sadlo, F.;  Ertl, T.]]></authors>

<affiliations><![CDATA[Visualization Res. Center, Univ. of Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Eigenvalues and eigenfunctions]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[379]]></spage>

<epage><![CDATA[392]]></epage>

<abstract><![CDATA[It was shown recently how the 2D vector field topology concept, directly applicable to stationary vector fields only, can be generalized to time-dependent vector fields by replacing the role of stream lines by streak lines [1]. The present paper extends this concept to 3D vector fields. In traditional 3D vector field topology separatrices can be obtained by integrating stream lines from 0D seeds corresponding to critical points. We show that in our new concept, in contrast, 1D seeding constructs are required for computing streak-based separatrices. In analogy to the 2D generalization we show that invariant manifolds can be obtained by seeding streak surfaces along distinguished path surfaces emanating from intersection curves between codimension-1 ridges in the forward and reverse finite-time Lyapunov exponent (FTLE) fields. These path surfaces represent a time-dependent generalization of critical points and convey further structure in time-dependent topology of vector fields. Compared to the traditional approach based on FTLE ridges, the resulting streak manifolds ease the analysis of Lagrangian coherent structures (LCS) with respect to visual quality and computational cost, especially when time series of LCS are computed. We exemplify validity and utility of the new approach using both synthetic examples and computational fluid dynamics results.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6203503]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.131]]></doi>

<publicationId><![CDATA[6203503]]></publicationId>

<partnum><![CDATA[6203503]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6203503&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6203503]]></pdf>

</document>

<document>

<rank>392</rank>

<title><![CDATA[FacetAtlas: Multifaceted Visualization for Rich Text Corpora]]></title>

<authors><![CDATA[Nan Cao;  Jimeng Sun;  Yu-Ru Lin;  Gotz, D.;  Shixia Liu;  Huamin Qu]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[search problems]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Diabetes]]></term>

<term><![CDATA[Diseases]]></term>

<term><![CDATA[Switches]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1172]]></spage>

<epage><![CDATA[1181]]></epage>

<abstract><![CDATA[Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613456]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.154]]></doi>

<publicationId><![CDATA[5613456]]></publicationId>

<partnum><![CDATA[5613456]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613456&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613456]]></pdf>

</document>

<document>

<rank>393</rank>

<title><![CDATA[Interactive Formation Control in Complex Environments]]></title>

<authors><![CDATA[Henry, J.;  Shum, H.P.H.;  Komura, T.]]></authors>

<affiliations><![CDATA[Sch. of Inf., Univ. of Edinburgh, Edinburgh, UK]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[computer games]]></term>

<term><![CDATA[peripheral interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Real-time systems]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[211]]></spage>

<epage><![CDATA[222]]></epage>

<abstract><![CDATA[The degrees of freedom of a crowd is much higher than that provided by a standard user input device. Typically, crowd-control systems require multiple passes to design crowd movements by specifying waypoints, and then defining character trajectories and crowd formation. Such multi-pass control would spoil the responsiveness and excitement of real-time control systems. In this paper, we propose a single-pass algorithm to control a crowd in complex environments. We observe that low-level details in crowd movement are related to interactions between characters and the environment, such as diverging/merging at cross points, or climbing over obstacles. Therefore, we simplify the problem by representing the crowd with a deformable mesh, and allow the user, via multitouch input, to specify high-level movements and formations that are important for context delivery. To help prevent congestion, our system dynamically reassigns characters in the formation by employing a mass transport solver to minimize their overall movement. The solver uses a cost function to evaluate the impact from the environment, including obstacles and areas affecting movement speed. Experimental results show realistic crowd movement created with minimal high-level user inputs. Our algorithm is particularly useful for real-time applications including strategy games and interactive animation creation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6582419]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.116]]></doi>

<publicationId><![CDATA[6582419]]></publicationId>

<partnum><![CDATA[6582419]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6582419&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6582419]]></pdf>

</document>

<document>

<rank>394</rank>

<title><![CDATA[Guest editor's introduction: special issue on IEEE visualization 2001]]></title>

<authors><![CDATA[Joy, K.I.]]></authors>

<affiliations><![CDATA[University of California at Davis]]></affiliations>

<thesaurusterms>

<term><![CDATA[Bars]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Low pass filters]]></term>

<term><![CDATA[Personal communication networks]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[209]]></spage>

<epage><![CDATA[210]]></epage>

<abstract><![CDATA[<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/01021574.png" border="0">]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1021574]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2002.1021574]]></doi>

<publicationId><![CDATA[1021574]]></publicationId>

<partnum><![CDATA[1021574]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1021574&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1021574]]></pdf>

</document>

<document>

<rank>395</rank>

<title><![CDATA[Preserving Fluid Sheets with Adaptively Sampled Anisotropic Particles]]></title>

<authors><![CDATA[Ando, R.;  Thurey, Nils;  Tsuruno, Reiji]]></authors>

<affiliations><![CDATA[Grad. Sch. of Design, Kyushu Univ., Fukuoka, Japan]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptation models]]></term>

<term><![CDATA[Boundary conditions]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Surface reconstruction]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1202]]></spage>

<epage><![CDATA[1214]]></epage>

<abstract><![CDATA[This paper presents a particle-based model for preserving fluid sheets of animated liquids with an adaptively sampled Fluid-Implicit-Particle (FLIP) method. In our method, we preserve fluid sheets by filling the breaking sheets with particle splitting in the thin regions, and by collapsing them in the deep water. To identify the critically thin parts, we compute the anisotropy of the particle neighborhoods, and use this information as a resampling criterion to reconstruct thin liquid surfaces. Unlike previous approaches, our method does not suffer from diffusive surfaces or complex remeshing operations, and robustly handles topology changes with the use of a meshless representation. We extend the underlying FLIP model with an anisotropic position correction to improve the particle spacing, and adaptive sampling to efficiently perform simulations of larger volumes. Due to the Lagrangian nature of our method, it can be easily implemented and efficiently parallelized. The results show that our method can produce visually complex liquid animations with thin structures and vivid motions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6171182]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.87]]></doi>

<publicationId><![CDATA[6171182]]></publicationId>

<partnum><![CDATA[6171182]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6171182&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171182]]></pdf>

</document>

<document>

<rank>396</rank>

<title><![CDATA[[Cover 4]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6129457]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.18]]></doi>

<publicationId><![CDATA[6129457]]></publicationId>

<partnum><![CDATA[6129457]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6129457&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129457]]></pdf>

</document>

<document>

<rank>397</rank>

<title><![CDATA[Visualization and Analysis of Vortex-Turbine Intersections in Wind Farms]]></title>

<authors><![CDATA[Shafii, S.;  Obermaier, H.;  Linn, R.;  Eunmo Koo;  Hlawitschka, M.;  Garth, C.;  Hamann, B.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[blades]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[numerical analysis]]></term>

<term><![CDATA[turbulence]]></term>

<term><![CDATA[vortices]]></term>

<term><![CDATA[wind turbines]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Blades]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Force]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Wind turbines]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1579]]></spage>

<epage><![CDATA[1591]]></epage>

<abstract><![CDATA[Characterizing the interplay between the vortices and forces acting on a wind turbine's blades in a qualitative and quantitative way holds the potential for significantly improving large wind turbine design. This paper introduces an integrated pipeline for highly effective wind and force field analysis and visualization. We extract vortices induced by a turbine's rotation in a wind field, and characterize vortices in conjunction with numerically simulated forces on the blade surfaces as these vortices strike another turbine's blades downstream. The scientifically relevant issue to be studied is the relationship between the extracted, approximate locations on the blades where vortices strike the blades and the forces that exist in those locations. This integrated approach is used to detect and analyze turbulent flow that causes local impact on the wind turbine blade structure. The results that we present are based on analyzing the wind and force field data sets generated by numerical simulations, and allow domain scientists to relate vortex-blade interactions with power output loss in turbines and turbine life expectancy. Our methods have the potential to improve turbine design to save costs related to turbine operation and maintenance.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6461884]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.18]]></doi>

<publicationId><![CDATA[6461884]]></publicationId>

<partnum><![CDATA[6461884]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6461884&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461884]]></pdf>

</document>

<document>

<rank>398</rank>

<title><![CDATA[A model for smooth viewing and navigation of large 2D information spaces]]></title>

<authors><![CDATA[van Wijk, J.J.;  Nuij, W.A.A.]]></authors>

<affiliations><![CDATA[Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Cities and towns]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Uninterruptible power systems]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[447]]></spage>

<epage><![CDATA[458]]></epage>

<abstract><![CDATA[Large 2D information spaces, such as maps, images, or abstract visualizations, require views at various level of detail: close ups to inspect details, overviews to maintain (literally) an overview. Users often change their view during a session. Smooth animations enable the user to maintain an overview during interactive viewing and to understand the context of separate views. We present a generic model to handle smooth image viewing. The core of the model is a metric on the effect of simultaneous zooming and panning, based on an estimate of the perceived velocity. Using this metric, solutions for various problems are derived, such as the optimal animation between two views, automatic zooming, and the parametrization of arbitrary camera paths. Optimal is defined here as smooth and efficient. Solutions are based on the shortest paths of a virtual camera, given the metric. The model has two free parameters: animation speed and zoom/pan trade off. A user experiment to find good values for these is described. Finally, it is shown how the model can be extended to deal also with rotation and nonuniform scaling.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1298802]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1]]></doi>

<publicationId><![CDATA[1298802]]></publicationId>

<partnum><![CDATA[1298802]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1298802&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298802]]></pdf>

</document>

<document>

<rank>399</rank>

<title><![CDATA[2008 TVCG Reviewers List]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[IEEE]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[174]]></spage>

<epage><![CDATA[176]]></epage>

<abstract><![CDATA[Lists, in alphabetical order, the reviewers who contributed to the IEEE Transactions on Visualization and Computer Graphics from 5 October 2007 through 27 September 2008.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4675194]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.1]]></doi>

<publicationId><![CDATA[4675194]]></publicationId>

<partnum><![CDATA[4675194]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4675194&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4675194]]></pdf>

</document>

<document>

<rank>400</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5946036]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.123]]></doi>

<publicationId><![CDATA[5946036]]></publicationId>

<partnum><![CDATA[5946036]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5946036&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946036]]></pdf>

</document>

<document>

<rank>401</rank>

<title><![CDATA[BirdVis: Visualizing and Understanding Bird Populations]]></title>

<authors><![CDATA[Ferreira, N.;  Lins, L.;  Fink, D.;  Kelling, S.;  Wood, C.;  Freire, J.;  Silva, C.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[ecology]]></term>

<term><![CDATA[environmental science computing]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[zoology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Ornithology]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Spatial databases]]></term>

<term><![CDATA[Tag clouds]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2374]]></spage>

<epage><![CDATA[2383]]></epage>

<abstract><![CDATA[Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case s- udies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065004]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.176]]></doi>

<publicationId><![CDATA[6065004]]></publicationId>

<partnum><![CDATA[6065004]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065004&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065004]]></pdf>

</document>

<document>

<rank>402</rank>

<title><![CDATA[Multiscale Symmetry Detection in Scalar Fields by Clustering Contours]]></title>

<authors><![CDATA[Thomas, D.M.;  Natarajan, V.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Multi-scale systems]]></term>

<term><![CDATA[Noise measurement]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Volume measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2427]]></spage>

<epage><![CDATA[2436]]></epage>

<abstract><![CDATA[The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875976]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346332]]></doi>

<publicationId><![CDATA[6875976]]></publicationId>

<partnum><![CDATA[6875976]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875976&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875976]]></pdf>

</document>

<document>

<rank>403</rank>

<title><![CDATA[A Linguistic Approach to Categorical Color Assignment for Data Visualization]]></title>

<authors><![CDATA[Setlur, V.;  Stone, M.C.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[linguistics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Databases]]></term>

<term><![CDATA[Google]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Semantics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[698]]></spage>

<epage><![CDATA[707]]></epage>

<abstract><![CDATA[When data categories have strong color associations, it is useful to use these semantically meaningful concept-color associations in data visualizations. In this paper, we explore how linguistic information about the terms defining the data can be used to generate semantically meaningful colors. To do this effectively, we need first to establish that a term has a strong semantic color association, then discover which color or colors express it. Using co-occurrence measures of color name frequencies from Google n-grams, we define a measure for colorability that describes how strongly associated a given term is to any of a set of basic color terms. We then show how this colorability score can be used with additional semantic analysis to rank and retrieve a representative color from Google Images. Alternatively, we use symbolic relationships defined by WordNet to select identity colors for categories such as countries or brands. To create visually distinct color palettes, we use k-means clustering to create visually distinct sets, iteratively reassigning terms with multiple basic color associations as needed. This can be additionally constrained to use colors only in a predefined palette.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192709]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467471]]></doi>

<publicationId><![CDATA[7192709]]></publicationId>

<partnum><![CDATA[7192709]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192709&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192709]]></pdf>

</document>

<document>

<rank>404</rank>

<title><![CDATA[Parallel Edge Splatting for Scalable Dynamic Graph Visualization]]></title>

<authors><![CDATA[Burch, M.;  Vehlow, C.;  Beck, F.;  Diehl, S.;  Weiskopf, D.]]></authors>

<affiliations><![CDATA[VISUS, Univ. of Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Software engineering]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2344]]></spage>

<epage><![CDATA[2353]]></epage>

<abstract><![CDATA[We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065001]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.226]]></doi>

<publicationId><![CDATA[6065001]]></publicationId>

<partnum><![CDATA[6065001]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065001&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065001]]></pdf>

</document>

<document>

<rank>405</rank>

<title><![CDATA[A particle system for interactive visualization of 3D flows]]></title>

<authors><![CDATA[Kruger, J.;  Kipfer, P.;  Konclratieva, P.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Technische Univ. Munchen, Garching, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Particle accelerators]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sorting]]></term>

<term><![CDATA[Streaming media]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[744]]></spage>

<epage><![CDATA[756]]></epage>

<abstract><![CDATA[We present a particle system for interactive visualization of steady 3D flow fields on uniform grids. For the amount of particles we target, particle integration needs to be accelerated and the transfer of these sets for rendering must be avoided. To fulfill these requirements, we exploit features of recent graphics accelerators to advect particles in the graphics processing unit (GPU), saving particle positions in graphics memory, and then sending these positions through the GPU again to obtain images in the frame buffer. This approach allows for interactive streaming and rendering of millions of particles and it enables virtual exploration of high resolution fields in a way similar to real-world experiments. The ability to display the dynamics of large particle sets using visualization options like shaded points or oriented texture splats provides an effective means for visual flow analysis that is far beyond existing solutions. For each particle, flow quantities like vorticity magnitude and A2 are computed and displayed. Built upon a previously published GPU implementation of a sorting network, visibility sorting of transparent particles is implemented. To provide additional visual cues, the GPU constructs and displays visualization geometry like particle lines and stream ribbons.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512024]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.87]]></doi>

<publicationId><![CDATA[1512024]]></publicationId>

<partnum><![CDATA[1512024]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512024&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512024]]></pdf>

</document>

<document>

<rank>406</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on the IEEE Pacific Visualization Symposium 2012]]></title>

<authors><![CDATA[Hauser, Helwig;  Kobourov, Stephen;  Qu, Huamin]]></authors>

<affiliations><![CDATA[University of Bergen]]></affiliations>

<thesaurusterms>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[898]]></spage>

<epage><![CDATA[899]]></epage>

<abstract><![CDATA[The papers in this special section are extended versions of three selected papers from the IEEE Pacific Visualization Symposium 2012 (PacificVis) which took place in Songdo, Korea from 28 February to 2 March 2012.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6494564]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.70]]></doi>

<publicationId><![CDATA[6494564]]></publicationId>

<partnum><![CDATA[6494564]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6494564&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6494564]]></pdf>

</document>

<document>

<rank>407</rank>

<title><![CDATA[Statistical Invariance for Texture Synthesis]]></title>

<authors><![CDATA[Xiaopei Liu;  Lei Jiang;  Tien-Tsin Wong;  Chi-Wing Fu]]></authors>

<affiliations><![CDATA[Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[image texture]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1836]]></spage>

<epage><![CDATA[1848]]></epage>

<abstract><![CDATA[Estimating illumination and deformation fields on textures is essential for both analysis and application purposes. Traditional methods for such estimation usually require complicated and sometimes labor-intensive processing. In this paper, we propose a new perspective for this problem and suggest a novel statistical approach which is much simpler and more efficient. Our experiments show that many textures in daily life are statistically invariant in terms of colors and gradients. Variations of such statistics can be assumed to be influenced by illumination and deformation. This implies that we can inversely estimate the spatially varying illumination and deformation according to the variation of the texture statistics. This enables us to decompose a texture photo into an illumination field, a deformation field, and an implicit texture which are illumination- and deformation-free, within a short period of time, and with minimal user input. By processing and recombining these components, a variety of synthesis effects, such as exemplar preparation, texture replacement, surface relighting, as well as geometry modification, can be well achieved. Finally, convincing results are shown to demonstrate the effectiveness of the proposed method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6165278]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.75]]></doi>

<publicationId><![CDATA[6165278]]></publicationId>

<partnum><![CDATA[6165278]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165278&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165278]]></pdf>

</document>

<document>

<rank>408</rank>

<title><![CDATA[Front Cover]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[i]]></spage>

<epage><![CDATA[Bii]]></epage>

<abstract><![CDATA[Presents the front cover from this conference.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7283728]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2473395]]></doi>

<publicationId><![CDATA[7283728]]></publicationId>

<partnum><![CDATA[7283728]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7283728&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7283728]]></pdf>

</document>

<document>

<rank>409</rank>

<title><![CDATA[Visual Methods for Analyzing Time-Oriented Data]]></title>

<authors><![CDATA[Aigner, W.;  Miksch, S.;  Muller, W.;  Schumann, H.;  Tominski, C.]]></authors>

<affiliations><![CDATA[Danube Univ. Krems, Krems]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[principal component analysis]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[47]]></spage>

<epage><![CDATA[60]]></epage>

<abstract><![CDATA[Providing appropriate methods to facilitate the analysis of time-oriented data is a key issue in many application domains. In this paper, we focus on the unique role of the parameter time in the context of visually driven data analysis. We will discuss three major aspects - visualization, analysis, and the user. It will be illustrated that it is necessary to consider the characteristics of time when generating visual representations. For that purpose, we take a look at different types of time and present visual examples. Integrating visual and analytical methods has become an increasingly important issue. Therefore, we present our experiences in temporal data abstraction, principal component analysis, and clustering of larger volumes of time-oriented data. The third main aspect we discuss is supporting user-centered visual analysis. We describe event-based visualization as a promising means to adapt the visualization pipeline to needs and tasks of users.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359494]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70415]]></doi>

<publicationId><![CDATA[4359494]]></publicationId>

<partnum><![CDATA[4359494]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359494&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359494]]></pdf>

</document>

<document>

<rank>410</rank>

<title><![CDATA[Function representation for sweeping by a moving solid]]></title>

<authors><![CDATA[Sourin, A.I.;  Pasko, A.A.]]></authors>

<affiliations><![CDATA[School of Applied Sci., Nanyang Technol. Univ., Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[functions]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cities and towns]]></term>

<term><![CDATA[Drilling]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Machining]]></term>

<term><![CDATA[Manipulators]]></term>

<term><![CDATA[Motion planning]]></term>

<term><![CDATA[Robots]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[11]]></spage>

<epage><![CDATA[18]]></epage>

<abstract><![CDATA[Studies a function representation of point sets swept by moving solids. The original solid-generator is defined by an inequality f(x,y,z,t)&ges;0 where x, y, z are Cartesian coordinates and t is treated as the time. This definition allows us to include solids which change their shapes in time. Constructive solids can be used as generators also when described by R-functions. The trajectory of the generator can be defined in parametric form as movement of its local coordinate system. In the paper, we did it with superposition of time-dependent affine transformations. To get the function representation F(x,y,z)&ges;0 of the swept solid, we apply the concept of an envelope, previously used basically for boundary represented objects. We have reduced the problem of swept solid description to a global extremum search by the t variable. The algorithm for procedural swept solid modeling is discussed. The benefit of our model is that it is applied not only for visualization but allows one to use the swept solid as an argument for other operations. For example, the swept solid can be intersected with other ones that are useful for the implementation of such operations as cutting and drilling. Ordinary texture mapping and hypertexturing can also be applied to it. The possibility of using a functionally defined generator with variable shape allows us to achieve a complexity of swept solids which was hardly possible before]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[489382]]></arnumber>

<doi><![CDATA[10.1109/2945.489382]]></doi>

<publicationId><![CDATA[489382]]></publicationId>

<partnum><![CDATA[489382]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=489382&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=489382]]></pdf>

</document>

<document>

<rank>411</rank>

<title><![CDATA[Supporters]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[xxiii]]></spage>

<epage><![CDATA[xxiii]]></epage>

<abstract><![CDATA[This is the the list of supporters at time of printing. Please check out http://visweek.org for an up to date list of VisWeek 2012 supporters.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327303]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.268]]></doi>

<publicationId><![CDATA[6327303]]></publicationId>

<partnum><![CDATA[6327303]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327303&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327303]]></pdf>

</document>

<document>

<rank>412</rank>

<title><![CDATA[ThemeDelta: Dynamic Segmentations over Temporal Topic Models]]></title>

<authors><![CDATA[Gad, S.;  Javed, W.;  Ghani, S.;  Elmqvist, N.;  Ewing, T.;  Hampton, K.N.;  Ramakrishnan, N.]]></authors>

<affiliations><![CDATA[Virginia Tech, Blacksburg, VA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Web sites]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Heuristic algorithms]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Tag clouds]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[672]]></spage>

<epage><![CDATA[685]]></epage>

<abstract><![CDATA[We present ThemeDelta, a visual analytics system for extracting and visualizing temporal trends, clustering, and reorganization in time-indexed textual datasets. ThemeDelta is supported by a dynamic temporal segmentation algorithm that integrates with topic modeling algorithms to identify change points where significant shifts in topics occur. This algorithm detects not only the clustering and associations of keywords in a time period, but also their convergence into topics (groups of keywords) that may later diverge into new groups. The visual representation of ThemeDelta uses sinuous, variable-width lines to show this evolution on a timeline, utilizing color for categories, and line width for keyword strength. We demonstrate how interaction with ThemeDelta helps capture the rise and fall of topics by analyzing archives of historical newspapers, of U.S. presidential campaign speeches, and of social messages collected through iNeighbors, a web-based social website. ThemeDelta is evaluated using a qualitative expert user study involving three researchers from rhetoric and history using the historical newspapers corpus.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7001093]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2388208]]></doi>

<publicationId><![CDATA[7001093]]></publicationId>

<partnum><![CDATA[7001093]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7001093&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001093]]></pdf>

</document>

<document>

<rank>413</rank>

<title><![CDATA[Polynomial surfaces interpolating arbitrary triangulations]]></title>

<authors><![CDATA[Hahmann, S.;  Bonneau, G.-P.]]></authors>

<affiliations><![CDATA[Lab. LMC-IMAG, Univ. of Grenoble, France]]></affiliations>

<controlledterms>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[polynomial approximation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer aided manufacturing]]></term>

<term><![CDATA[Containers]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface topography]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[99]]></spage>

<epage><![CDATA[109]]></epage>

<abstract><![CDATA[Triangular Bezier patches are an important tool for defining smooth surfaces over arbitrary triangular meshes. The previously introduced 4-split method interpolates the vertices of a 2-manifold triangle mesh by a set of tangent plane continuous triangular Bezier patches of degree five. The resulting surface has an explicit closed form representation and is defined locally. In this paper, we introduce a new method for visually smooth interpolation of arbitrary triangle meshes based on a regular 4-split of the domain triangles. Ensuring tangent plane continuity of the surface is not enough for producing an overall fair shape. Interpolation of irregular control-polygons, be that in 1D or in 2D, often yields unwanted undulations. Note that this undulation problem is not particular to parametric interpolation, but also occurs with interpolatory subdivision surfaces. Our new method avoids unwanted undulations by relaxing the constraint of the first derivatives at the input mesh vertices: The tangent directions of the boundary curves at the mesh vertices are now completely free. Irregular triangulations can be handled much better in the sense that unwanted undulations due to flat triangles in the mesh are now avoided.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1175100]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1175100]]></doi>

<publicationId><![CDATA[1175100]]></publicationId>

<partnum><![CDATA[1175100]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1175100&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1175100]]></pdf>

</document>

<document>

<rank>414</rank>

<title><![CDATA[Silhouette Smoothing for Real-Time Rendering of Mesh Surfaces]]></title>

<authors><![CDATA[Lu Wang;  Changhe Tu;  Wenping Wang;  Xiangxu Meng;  Bin Chan;  Dongming Yan]]></authors>

<affiliations><![CDATA[Shandong Univ., Jinan]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[piecewise linear techniques]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[smoothing methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Availability]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Piecewise linear approximation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Surface reconstruction]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[640]]></spage>

<epage><![CDATA[652]]></epage>

<abstract><![CDATA[Coarse piecewise linear approximation of surfaces causes the undesirable polygonal appearance of silhouettes. We present an efficient method for smoothing the silhouettes of coarse triangle meshes using efficient 3D curve reconstruction and simple local remeshing. It does not assume the availability of a fine mesh and generates only a moderate amount of additional data at runtime. Furthermore, polygonal feature edges are also smoothed in a unified framework. Our method is based on a novel interpolation scheme over silhouette triangles, and this ensures that smooth silhouettes are faithfully reconstructed and always change continuously with respect to the continuous movement of the viewpoint or objects. We speed up computation with GPU assistance to achieve real-time rendering of coarse meshes with the smoothed silhouettes. Experiments show that this method outperforms previous methods for silhouette smoothing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4472706]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.8]]></doi>

<publicationId><![CDATA[4472706]]></publicationId>

<partnum><![CDATA[4472706]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4472706&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4472706]]></pdf>

</document>

<document>

<rank>415</rank>

<title><![CDATA[Hybrid, Multiresolution Wires with Massless Frictional Contacts]]></title>

<authors><![CDATA[Servin, M.;  Lacoursie&#x0300; re, C.;  Nordfelth, F.;  Bodin, K.]]></authors>

<affiliations><![CDATA[Umea Univ., Umea, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[friction]]></term>

<term><![CDATA[mechanical contact]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[wires]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptation model]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Numerical models]]></term>

<term><![CDATA[Visualization]]></term>

<term><![CDATA[Wires]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[970]]></spage>

<epage><![CDATA[982]]></epage>

<abstract><![CDATA[We describe a method for the visual interactive simulation of wires contacting with rigid multibodies. The physical model used is a hybrid combining lumped elements and massless quasistatic representations. The latter is based on a kinematic constraint preserving the total length of the wire along a segmented path which can involve multiple bodies simultaneously and dry frictional contact nodes used for roping, lassoing, and fastening. These nodes provide stick and slide friction along the edges of the contacting geometries. The lumped element resolution is adapted dynamically based on local stability criteria, becoming coarser as the tension increases, and up to the purely kinematic representation. Kinematic segments and contact nodes are added, deleted, and propagated based on contact geometries and dry friction configurations. The method gives a dramatic increase in both performance and robustness because it quickly decimates superfluous nodes without loosing stability, yet adapts to complex configurations with many contacts and high curvature, keeping a fixed, large integration time step. Numerical results demonstrating the performance and stability of the adaptive multiresolution scheme are presented along with an array of representative simulation examples illustrating the versatility of the frictional contact model.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5601814]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.122]]></doi>

<publicationId><![CDATA[5601814]]></publicationId>

<partnum><![CDATA[5601814]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5601814&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601814]]></pdf>

</document>

<document>

<rank>416</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on ACM VRST]]></title>

<authors><![CDATA[Komura, Taku;  Peng, Qunsheng;  Gaciu, George;  Lau, Rynson W.H.]]></authors>

<thesaurusterms>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Software engineering]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[354]]></spage>

<epage><![CDATA[355]]></epage>

<abstract><![CDATA[The articles in this special section contain selected papers from the 2010 ACM Virtual Reality Software and Technology Symposium.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6129453]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.20]]></doi>

<publicationId><![CDATA[6129453]]></publicationId>

<partnum><![CDATA[6129453]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6129453&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129453]]></pdf>

</document>

<document>

<rank>417</rank>

<title><![CDATA[Reconstruction of Cellular Biological Structures from Optical Microscopy Data]]></title>

<authors><![CDATA[Mosaliganti, K.;  Cooper, Lee;  Sharp, R.;  Machiraju, R.;  Leone, G.;  Kun Huang;  Saltz, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH]]></affiliations>

<controlledterms>

<term><![CDATA[cellular biophysics]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[optical images]]></term>

<term><![CDATA[optical microscopy]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[863]]></spage>

<epage><![CDATA[876]]></epage>

<abstract><![CDATA[Developments in optical microscopy imaging have generated large high-resolution data sets that have spurred medical researchers to conduct investigations into mechanisms of disease, including cancer at cellular and subcellular levels. The work reported here demonstrates that a suitable methodology can be conceived that isolates modality-dependent effects from the larger segmentation task and that 3D reconstructions can be cognizant of shapes as evident in the available 2D planar images. In the current realization, a method based on active geodesic contours is first deployed to counter the ambiguity that exists in separating overlapping cells on the image plane. Later, another segmentation effort based on a variant of Voronoi tessellations improves the delineation of the cell boundaries using a Bayesian formulation. In the next stage, the cells are interpolated across the third dimension thereby mitigating the poor structural correlation that exists in that dimension. We deploy our methods on three separate data sets obtained from light, confocal, and phase-contrast microscopy and validate the results appropriately.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4445666]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.30]]></doi>

<publicationId><![CDATA[4445666]]></publicationId>

<partnum><![CDATA[4445666]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4445666&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4445666]]></pdf>

</document>

<document>

<rank>418</rank>

<title><![CDATA[[Advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[112]]></spage>

<epage><![CDATA[112]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1359740]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.3]]></doi>

<publicationId><![CDATA[1359740]]></publicationId>

<partnum><![CDATA[1359740]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359740&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359740]]></pdf>

</document>

<document>

<rank>419</rank>

<title><![CDATA[The FLOWLENS: A Focus-and-Context Visualization Approach for Exploration of Blood Flow in Cerebral Aneurysms]]></title>

<authors><![CDATA[Gasteiger, R.;  Neugebauer, M.;  Beuing, O.;  Preim, B.]]></authors>

<affiliations><![CDATA[Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[haemodynamics]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aneurysm]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Flow visualization]]></term>

<term><![CDATA[Hemodynamics]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2183]]></spage>

<epage><![CDATA[2192]]></epage>

<abstract><![CDATA[Blood flow and derived data are essential to investigate the initiation and progression of cerebral aneurysms as well as their risk of rupture. An effective visual exploration of several hemodynamic attributes like the wall shear stress (WSS) and the inflow jet is necessary to understand the hemodynamics. Moreover, the correlation between focus-and-context attributes is of particular interest. An expressive visualization of these attributes and anatomic information requires appropriate visualization techniques to minimize visual clutter and occlusions. We present the FLOWLENS as a focus-and-context approach that addresses these requirements. We group relevant hemodynamic attributes to pairs of focus-and-context attributes and assign them to different anatomic scopes. For each scope, we propose several FLOWLENS visualization templates to provide a flexible visual filtering of the involved hemodynamic pairs. A template consists of the visualization of the focus attribute and the additional depiction of the context attribute inside the lens. Furthermore, the FLOWLENS supports local probing and the exploration of attribute changes over time. The FLOWLENS minimizes visual cluttering, occlusions, and provides a flexible exploration of a region of interest. We have applied our approach to seven representative datasets, including steady and unsteady flow data from CFD simulations and 4D PC-MRI measurements. Informal user interviews with three domain experts confirm the usefulness of our approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064983]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.243]]></doi>

<publicationId><![CDATA[6064983]]></publicationId>

<partnum><![CDATA[6064983]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064983&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064983]]></pdf>

</document>

<document>

<rank>420</rank>

<title><![CDATA[VIS Conference Committee]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[xvi]]></spage>

<epage><![CDATA[xvi]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6935061]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346663]]></doi>

<publicationId><![CDATA[6935061]]></publicationId>

<partnum><![CDATA[6935061]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6935061&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935061]]></pdf>

</document>

<document>

<rank>421</rank>

<title><![CDATA[Query-Driven Visualization of Time-Varying Adaptive Mesh Refinement Data]]></title>

<authors><![CDATA[Gosink, L.J.;  Anderson, J.C.;  Bethel, E.W.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Inst. for Data Anal. & Visualization, Univ. of California, Davis, CA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[query processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive mesh refinement]]></term>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Medical simulation]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1715]]></spage>

<epage><![CDATA[1722]]></epage>

<abstract><![CDATA[The visualization and analysis of AMR-based simulations is integral to the process of obtaining new insight in scientific research. We present a new method for performing query-driven visualization and analysis on AMR data, with specific emphasis on time-varying AMR data. Our work introduces a new method that directly addresses the dynamic spatial and temporal properties of AMR grids that challenge many existing visualization techniques. Further, we present the first implementation of query-driven visualization on the GPU that uses a GPU-based indexing structure to both answer queries and efficiently utilize GPU memory. We apply our method to two different science domains to demonstrate its broad applicability.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658195]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.157]]></doi>

<publicationId><![CDATA[4658195]]></publicationId>

<partnum><![CDATA[4658195]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658195&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658195]]></pdf>

</document>

<document>

<rank>422</rank>

<title><![CDATA[Dynamic interactions in physically realistic collaborative virtual environments]]></title>

<authors><![CDATA[Jorissen, P.;  Wijnants, M.;  Lamotte, W.]]></authors>

<affiliations><![CDATA[Expertise Centre for Digital Media, Hasselt Univ., Diepenbeek, Belgium]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[avatars]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[motion estimation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Avatars]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Kinematics]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[649]]></spage>

<epage><![CDATA[660]]></epage>

<abstract><![CDATA[This work describes our efforts in creating a general object interaction framework for dynamic collaborative virtual environments. Furthermore, we increase the realism of the interactive world by using a rigid body simulator to calculate all actor and object movements. The main idea behind our interactive platform is to construct a virtual world using only objects that contain their own interaction information. As a result, the object interactions are application independent and only a single scheme is required to handle all interactions in the virtual world. In order to have more dynamic interactions, we also created a new and efficient way for human users to dynamically interact within virtual worlds through their avatar. In particular, we show how inverse kinematics can be used to increase the interaction possibilities and realism in collaborative virtual environments. This results in a higher feeling of presence for connected users and allows for easy, on-the-fly creation of new interactions. For the distribution of both the interactive objects and the dynamic avatar interactions, we keep the network load as low as possible. To demonstrate the effectiveness of our techniques, we incorporate them into an existing CVE framework.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512016]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.100]]></doi>

<publicationId><![CDATA[1512016]]></publicationId>

<partnum><![CDATA[1512016]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512016&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512016]]></pdf>

</document>

<document>

<rank>423</rank>

<title><![CDATA[Views on Visualization]]></title>

<authors><![CDATA[van Wijk, J.J.]]></authors>

<affiliations><![CDATA[IEEE]]></affiliations>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Data engineering]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Pattern analysis]]></term>

<term><![CDATA[Stock markets]]></term>

<term><![CDATA[Supercomputers]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[421]]></spage>

<epage><![CDATA[432]]></epage>

<abstract><![CDATA[The field of visualization is maturing. Many problems have been solved and new directions are sought. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. In this paper, visualization is considered from multiple points of view. First, a technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented and benefits and costs are established. Next, consequences and limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjectiveness, and the role of interaction). Example uses of the model for the judgment of existing classes of methods are given to understand why they are or are not used in practice. However, such an economic view is too restrictive. Alternative views on visualization are presented and discussed: visualization as an art, visualization as design and, finally, visualization as a scientific discipline.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634309]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.80]]></doi>

<publicationId><![CDATA[1634309]]></publicationId>

<partnum><![CDATA[1634309]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634309&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634309]]></pdf>

</document>

<document>

<rank>424</rank>

<title><![CDATA[Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans]]></title>

<authors><![CDATA[Ropinski, T.;  Hermann, S.;  Reich, R.;  Schafers, M.;  Hinrichs, K.]]></authors>

<affiliations><![CDATA[Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[cardiovascular system]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data acquisition]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diseases]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[positron emission tomography]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atherosclerosis]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Cardiology]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Lesions]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Molecular imaging]]></term>

<term><![CDATA[Positron emission tomography]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1515]]></spage>

<epage><![CDATA[1522]]></epage>

<abstract><![CDATA[In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290768]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.169]]></doi>

<publicationId><![CDATA[5290768]]></publicationId>

<partnum><![CDATA[5290768]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290768&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290768]]></pdf>

</document>

<document>

<rank>425</rank>

<title><![CDATA[Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes]]></title>

<authors><![CDATA[Ragan, E.D.;  Endert, A.;  Sanyal, J.;  Jian Chen]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Organizations]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[31]]></spage>

<epage><![CDATA[40]]></epage>

<abstract><![CDATA[While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192714]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467551]]></doi>

<publicationId><![CDATA[7192714]]></publicationId>

<partnum><![CDATA[7192714]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192714&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192714]]></pdf>

</document>

<document>

<rank>426</rank>

<title><![CDATA[Skeleton-Based Edge Bundling for Graph Visualization]]></title>

<authors><![CDATA[Ersoy, O.;  Hurter, C.;  Paulovich, F.V.;  Cantareiro, G.;  Telea, A.]]></authors>

<affiliations><![CDATA[Univ. of Groningen, Groningen, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2364]]></spage>

<epage><![CDATA[2373]]></epage>

<abstract><![CDATA[In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065003]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.233]]></doi>

<publicationId><![CDATA[6065003]]></publicationId>

<partnum><![CDATA[6065003]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065003&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065003]]></pdf>

</document>

<document>

<rank>427</rank>

<title><![CDATA[The Effects of Avatars, Stereo Vision and Display Size on Reaching and Motion Reproduction]]></title>

<authors><![CDATA[Camporesi, C.;  Kallmann, M.]]></authors>

<affiliations><![CDATA[C. Camporesi is with the School of Engineering,University of California, Merced, CA, 95343.(email:ccamporesi@ucmerced.edu)]]></affiliations>

<thesaurusterms>

<term><![CDATA[Avatars]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Stereo vision]]></term>

<term><![CDATA[Tracking]]></term>

<term><![CDATA[Training]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Thanks to recent advances on motion capture devices and stereoscopic consumer displays, animated virtual characters can now realistically interact with users in a variety of applications. We investigate in this paper the effect of avatars, stereo vision and display size on task execution in immersive virtual environments. We report results obtained with three experiments in varied configurations that are commonly used in rehabilitation applications. The first experiment analyzes the accuracy of reaching tasks under different system configurations: with and without an avatar, with and without stereo vision, and employing a 2D desktop monitor versus a large multi-tile visualization display. The second experiment analyzes the use of avatars and user-perspective stereo vision on the ability to perceive and subsequently reproduce motions demonstrated by an autonomous virtual character. The third experiment evaluates the overall user experience with a complete immersive user interface for motion modeling by direct demonstration. Our experiments expose and quantify the benefits of using stereo vision and avatars, and show that the use of avatars improve the quality of produced motions and the resemblance of replicated motions; however, direct interaction in user-perspective leads to tasks executed in less time and to targets more accurately reached. These and additional tradeoffs are important for the effective design of avatar-based training systems.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7118232]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2440231]]></doi>

<publicationId><![CDATA[7118232]]></publicationId>

<partnum><![CDATA[7118232]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7118232&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118232]]></pdf>

</document>

<document>

<rank>428</rank>

<title><![CDATA[Real-Time GPU Surface Curvature Estimation on Deforming Meshes and Volumetric Data Sets]]></title>

<authors><![CDATA[Griffin, Wesley;  Wang, Yu;  Berrios, David;  Olano, Marc]]></authors>

<affiliations><![CDATA[University of Maryland, Baltimore County, Baltimore]]></affiliations>

<thesaurusterms>

<term><![CDATA[Face recognition]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Real time systems]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1603]]></spage>

<epage><![CDATA[1613]]></epage>

<abstract><![CDATA[Surface curvature is used in a number of areas in computer graphics, including texture synthesis and shape representation, mesh simplification, surface modeling, and nonphotorealistic line drawing. Most real-time applications must estimate curvature on a triangular mesh. This estimation has been limited to CPU algorithms, forcing object geometry to reside in main memory. However, as more computational work is done directly on the GPU, it is increasingly common for object geometry to exist only in GPU memory. Examples include vertex skinned animations and isosurfaces from GPU-based surface reconstruction algorithms. For static models, curvature can be precomputed and CPU algorithms are a reasonable choice. For deforming models where the geometry only resides on the GPU, transferring the deformed mesh back to the CPU limits performance. We introduce a GPU algorithm for estimating curvature in real time on arbitrary triangular meshes. We demonstrate our algorithm with curvature-based NPR feature lines and a curvature-based approximation for an ambient occlusion. We show curvature computation on volumetric data sets with a GPU isosurface extraction algorithm and vertex-skinned animations. We present a graphics pipeline and CUDA implementation. Our curvature estimation is up to {sim}18{times} faster than a multithreaded CPU benchmark.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6185550]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.113]]></doi>

<publicationId><![CDATA[6185550]]></publicationId>

<partnum><![CDATA[6185550]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6185550&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185550]]></pdf>

</document>

<document>

<rank>429</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4530425]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.75]]></doi>

<publicationId><![CDATA[4530425]]></publicationId>

<partnum><![CDATA[4530425]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4530425&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4530425]]></pdf>

</document>

<document>

<rank>430</rank>

<title><![CDATA[Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis]]></title>

<authors><![CDATA[Kindlmann, G.;  Chiw, C.;  Seltzer, N.;  Samuels, L.;  Reppy, J.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[mathematical programming]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[tensors]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Force]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Parallel processing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[867]]></spage>

<epage><![CDATA[876]]></epage>

<abstract><![CDATA[Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192663]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467449]]></doi>

<publicationId><![CDATA[7192663]]></publicationId>

<partnum><![CDATA[7192663]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192663&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192663]]></pdf>

</document>

<document>

<rank>431</rank>

<title><![CDATA[On View Consistency in Multi-Server Distributed Virtual Environments]]></title>

<authors><![CDATA[Haiyang Hu;  Lau, R.W.H.;  Hua Hu;  Wah, B.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci. & Technol., Hangzhou Dianzi Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[distributed processing]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[resource allocation]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Delays]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Load management]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Servers]]></term>

<term><![CDATA[Synchronization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1428]]></spage>

<epage><![CDATA[1440]]></epage>

<abstract><![CDATA[A distributed virtual environment (DVE) is a shared virtual environment (VE) that allows remote users to interact with each other through networks. DVEs are becoming very popular due to some prominent applications, such as online games and virtual worlds. To support a large number of users, a multi-server DVE architecture may be adopted, with each server managing a subset of users. However, there are two critical problems with this architecture: view inconsistency caused by delays and server overloading caused by uneven distribution of users. While the first problem affects users' perception of the VE and causes user disputes, the second problem affects the system response time. In this paper, we first show that the view inconsistency problem and the load balancing problem are conflicting objectives. We then propose an efficient joint optimization framework to address both problems. Our results show that the proposed method can improve the view inconsistency problem significantly, which is important to the interactivity of DVE applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6636307]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.244]]></doi>

<publicationId><![CDATA[6636307]]></publicationId>

<partnum><![CDATA[6636307]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6636307&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6636307]]></pdf>

</document>

<document>

<rank>432</rank>

<title><![CDATA[Uncertainty-Aware Multidimensional Ensemble Data Visualization and Exploration]]></title>

<authors><![CDATA[Haidong Chen;  Song Zhang;  Wei Chen;  Honghui Mei;  Jiawei Zhang;  Mercer, A.;  Ronghua Liang;  Huamin Qu]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD & CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bandwidth]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Numerical models]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Symmetric matrices]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1072]]></spage>

<epage><![CDATA[1086]]></epage>

<abstract><![CDATA[This paper presents an efficient visualization and exploration approach for modeling and characterizing the relationships and uncertainties in the context of a multidimensional ensemble dataset. Its core is a novel dissimilarity-preserving projection technique that characterizes not only the relationships among the mean values of the ensemble data objects but also the relationships among the distributions of ensemble members. This uncertainty-aware projection scheme leads to an improved understanding of the intrinsic structure in an ensemble dataset. The analysis of the ensemble dataset is further augmented by a suite of visual encoding and exploration tools. Experimental results on both artificial and real-world datasets demonstrate the effectiveness of our approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7055260]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2410278]]></doi>

<publicationId><![CDATA[7055260]]></publicationId>

<partnum><![CDATA[7055260]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7055260&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7055260]]></pdf>

</document>

<document>

<rank>433</rank>

<title><![CDATA[IEEE Transactions on Visualization and Computer Graphics - Table of contents]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[0_1]]></spage>

<epage><![CDATA[0_1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1304817]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1304817]]></doi>

<publicationId><![CDATA[1304817]]></publicationId>

<partnum><![CDATA[1304817]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1304817&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1304817]]></pdf>

</document>

<document>

<rank>434</rank>

<title><![CDATA[Automatic Tuning of Spatially Varying Transfer Functions for Blood Vessel Visualization]]></title>

<authors><![CDATA[Lathen, G.;  Lindholm, S.;  Lenz, R.;  Persson, A.;  Borga, M.]]></authors>

<affiliations><![CDATA[Center for Med. Image Sci. & Visualization (CMIV), Linkoping Univ., Linkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[blood vessels]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Blood vessels]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2345]]></spage>

<epage><![CDATA[2354]]></epage>

<abstract><![CDATA[Computed Tomography Angiography (CTA) is commonly used in clinical routine for diagnosing vascular diseases. The procedure involves the injection of a contrast agent into the blood stream to increase the contrast between the blood vessels and the surrounding tissue in the image data. CTA is often visualized with Direct Volume Rendering (DVR) where the enhanced image contrast is important for the construction of Transfer Functions (TFs). For increased efficiency, clinical routine heavily relies on preset TFs to simplify the creation of such visualizations for a physician. In practice, however, TF presets often do not yield optimal images due to variations in mixture concentration of contrast agent in the blood stream. In this paper we propose an automatic, optimization-based method that shifts TF presets to account for general deviations and local variations of the intensity of contrast enhanced blood vessels. Some of the advantages of this method are the following. It computationally automates large parts of a process that is currently performed manually. It performs the TF shift locally and can thus optimize larger portions of the image than is possible with manual interaction. The method is based on a well known vesselness descriptor in the definition of the optimization criterion. The performance of the method is illustrated by clinically relevant CT angiography datasets displaying both improved structural overviews of vessel trees and improved adaption to local variations of contrast concentration.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327239]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.203]]></doi>

<publicationId><![CDATA[6327239]]></publicationId>

<partnum><![CDATA[6327239]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327239&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327239]]></pdf>

</document>

<document>

<rank>435</rank>

<title><![CDATA[Real-Time Adaptive Radiometric Compensation]]></title>

<authors><![CDATA[Grundhofer, A.;  Bimber, O.]]></authors>

<affiliations><![CDATA[Bauhaus-Univ. Weimar, Weimar]]></affiliations>

<controlledterms>

<term><![CDATA[cameras]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image texture]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[97]]></spage>

<epage><![CDATA[108]]></epage>

<abstract><![CDATA[Recent radiometric compensation techniques make it possible to project images onto colored and textured surfaces. This is realized with projector-camera systems by scanning the projection surface on a per-pixel basis. Using the captured information, a compensation image is calculated that neutralizes geometric distortions and color blending caused by the underlying surface. As a result, the brightness and the contrast of the input image is reduced compared to a conventional projection onto a white canvas. If the input image is not manipulated in its intensities, the compensation image can contain values that are outside the dynamic range of the projector. These will lead to clipping errors and to visible artifacts on the surface. In this article, we present an innovative algorithm that dynamically adjusts the content of the input images before radiometric compensation is carried out. This reduces the perceived visual artifacts while simultaneously preserving a maximum of luminance and contrast. The algorithm is implemented entirely on the GPU and is the first of its kind to run in real time.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359477]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1052]]></doi>

<publicationId><![CDATA[4359477]]></publicationId>

<partnum><![CDATA[4359477]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359477&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359477]]></pdf>

</document>

<document>

<rank>436</rank>

<title><![CDATA[Vortical Inviscid Flows with Two-Way Solid-Fluid Coupling]]></title>

<authors><![CDATA[Vines, M.;  Houston, B.;  Jochen Lang;  Won-Sook Lee]]></authors>

<affiliations><![CDATA[Univ. of Ottawa, Ottawa, ON, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[turbulence]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Vortexes]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[303]]></spage>

<epage><![CDATA[315]]></epage>

<abstract><![CDATA[Vortex methods increasingly receive attention from the computer graphics community for simple and direct modeling of complex flow phenomena such as turbulence. The coupling between free-form solids, represented by arbitrary surface meshes, and fluids simulated with vortex methods, leads to visually rich simulations. In this paper, we introduce a novel approach for simulating the interaction between solids and inviscid fluids for high-quality simulations using Lagrangian vortex particles. The key aspect of our method is simulating the creation of vorticity at a solid's surface. While previous vortex simulators only focus on modeling the solid as a boundary for the fluid, our approach allows the accurate simulation of two processes of visual interest. The first is the introduction of surface vorticity in the main flow as turbulence (vortex shedding). The second is the motion of the solid induced by fluid forces. We also introduce to computer graphics the concept of source panels to model nonturbulent flow around objects. To the best of our knowledge, this is the first work on two-way coupling of 3D solids and fluids using Lagrangian vortex methods in computer graphics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6547144]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.95]]></doi>

<publicationId><![CDATA[6547144]]></publicationId>

<partnum><![CDATA[6547144]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6547144&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547144]]></pdf>

</document>

<document>

<rank>437</rank>

<title><![CDATA[Video Painting Based on a Stabilized Time-Varying Flow Field]]></title>

<authors><![CDATA[Jong-Chul Yoon;  In-Kwon Lee;  Kang, Henry]]></authors>

<affiliations><![CDATA[Dept. of Broadcasting Visual Art Technol. & Entertainment, Kangwon Nat. Univ. at Samcheuk, Samcheuk, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Coherence]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Painting]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[58]]></spage>

<epage><![CDATA[67]]></epage>

<abstract><![CDATA[We present a method for constructing 3D feature flow from video and its application to video stylization. Our method extracts smoothly aligned 3D vectors that describe the smallest variation of colors within a spatiotemporal video cube, and thus effectively preserves both spatial and temporal coherence in a relatively inexpensive manner. As an application of this flow field we present a particle-based video stylization technique to rerender the video in a feature enhancing, painterly style. Our method consists of per-pixel operations and is suitable for GPU implementation, which enables real-time video stylization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5728800]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.47]]></doi>

<publicationId><![CDATA[5728800]]></publicationId>

<partnum><![CDATA[5728800]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5728800&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728800]]></pdf>

</document>

<document>

<rank>438</rank>

<title><![CDATA[Matching Visual Saliency to Confidence in Plots of Uncertain Data]]></title>

<authors><![CDATA[Feng, D.;  Kwock, L.;  Yueh Lee;  Taylor, R.M.]]></authors>

<affiliations><![CDATA[Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[probability]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Gaussian distribution]]></term>

<term><![CDATA[Spectroscopy]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[980]]></spage>

<epage><![CDATA[989]]></epage>

<abstract><![CDATA[Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613435]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.176]]></doi>

<publicationId><![CDATA[5613435]]></publicationId>

<partnum><![CDATA[5613435]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613435&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613435]]></pdf>

</document>

<document>

<rank>439</rank>

<title><![CDATA[Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation]]></title>

<authors><![CDATA[Moran, P.J.;  Ellsworth, D.]]></authors>

<affiliations><![CDATA[Ames Res. Center, NASA, Moffett Field, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[hydrodynamics]]></term>

<term><![CDATA[interpolation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptation models]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1862]]></spage>

<epage><![CDATA[1871]]></epage>

<abstract><![CDATA[We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C<sup>0</sup> continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates "stitching cells" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064949]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.252]]></doi>

<publicationId><![CDATA[6064949]]></publicationId>

<partnum><![CDATA[6064949]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064949&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064949]]></pdf>

</document>

<document>

<rank>440</rank>

<title><![CDATA[Fast collision detection among multiple moving spheres]]></title>

<authors><![CDATA[Dong-Jin Kim;  Guibas, L.J.;  Sung-Yong Shin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Taejon, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Discrete event simulation]]></term>

<term><![CDATA[Event detection]]></term>

<term><![CDATA[Fires]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Kinetic theory]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[230]]></spage>

<epage><![CDATA[242]]></epage>

<abstract><![CDATA[This paper presents an event-driven approach that efficiently detects collisions among multiple ballistic spheres moving in the 3D space. Adopting a hierarchical uniform space subdivision scheme, we are able to trace the trajectories of spheres and their time-varying spatial distribution. We identify three types of events to detect the sequence of all collisions during our simulation: collision, entering, and leaving. The first type of event is due to actual collisions, and the other two types occur when spheres move from subspace to subspace in the space. Tracing all such events in the order of their occurring times, we are able to avoid fixed time step simulation. When the size of the largest sphere is bounded by a constant multiple of that of the smallest, it takes O(n&macr;<sub>c</sub> log n+n&macr;<sub>e</sub> log n) time with O(n) space after O(n log n) time preprocessing to simulate n moving spheres, where n&macr;<sub>c</sub> and n&macr;<sub>e</sub> are the number of actual collisions and that of entering and leaving events during the simulation, respectively. Since n&macr;<sub>e</sub>, depends on the size of subspaces, we modify the collision model from kinetic theory for molecular gas to determine the subspace sizes for the space subdivision scheme, that minimize simulation time. Experimental results show that collision detection can be done in linear time in n over a large range]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[722297]]></arnumber>

<doi><![CDATA[10.1109/2945.722297]]></doi>

<publicationId><![CDATA[722297]]></publicationId>

<partnum><![CDATA[722297]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=722297&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722297]]></pdf>

</document>

<document>

<rank>441</rank>

<title><![CDATA[Representing Flow Patterns by Using Streamlines with Glyphs]]></title>

<authors><![CDATA[Pilar, D.H.F.;  Ware, C.]]></authors>

<affiliations><![CDATA[Center for Coastal & Ocean Mapping, Univ. of New Hampshire, Durham, NH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[weather forecasting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bars]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Shafts]]></term>

<term><![CDATA[Visualization]]></term>

<term><![CDATA[Wind forecasting]]></term>

<term><![CDATA[Wind speed]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1331]]></spage>

<epage><![CDATA[1341]]></epage>

<abstract><![CDATA[Most professional wind visualizations show wind speed and direction using a glyph called a wind barb in a grid pattern. Research into flow visualization has suggested that streamlines better represent flow patterns but these methods lack a key property - unlike the wind barb, they do not accurately convey the wind speed. With the goal of improving the perception of wind patterns, and at least equaling the quantitative quality of wind barbs, we designed two variations on the wind barb and designed a new quantitative glyph. All of our new designs space glyph elements along equally spaced streamlines. To evaluate these designs, we used a North American mesoscale forecast model. We tested the ability of subjects to determine direction and speed using two different densities each of three new designs as well as the classic wind barb. A second experiment evaluated how effectively each of the designs represented wind patterns. The results showed that the new design is superior to the classic, but they also showed that the classic barb can be redesigned and substantially improved. We suggest that flow patterns with integrated glyphs may have widespread application in flow visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6420829]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.10]]></doi>

<publicationId><![CDATA[6420829]]></publicationId>

<partnum><![CDATA[6420829]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6420829&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6420829]]></pdf>

</document>

<document>

<rank>442</rank>

<title><![CDATA[iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization]]></title>

<authors><![CDATA[Ziyi Zheng;  Ahmed, N.;  Mueller, K.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[entropy]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[set theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Entropy]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1959]]></spage>

<epage><![CDATA[1968]]></epage>

<abstract><![CDATA[The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064959]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.218]]></doi>

<publicationId><![CDATA[6064959]]></publicationId>

<partnum><![CDATA[6064959]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064959&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064959]]></pdf>

</document>

<document>

<rank>443</rank>

<title><![CDATA[An Information-Theoretic Framework for Flow Visualization]]></title>

<authors><![CDATA[Lijie Xu;  Teng-Yok Lee;  Han-Wei Shen]]></authors>

<affiliations><![CDATA[Ohio State Univ., Columbus, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[entropy]]></term>

<term><![CDATA[flow visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Entropy]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Information theory]]></term>

<term><![CDATA[Streaming media]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1216]]></spage>

<epage><![CDATA[1224]]></epage>

<abstract><![CDATA[The process of visualization can be seen as a visual communication channel where the input to the channel is the raw data, and the output is the result of a visualization algorithm. From this point of view, we can evaluate the effectiveness of visualization by measuring how much information in the original data is being communicated through the visual communication channel. In this paper, we present an information-theoretic framework for flow visualization with a special focus on streamline generation. In our framework, a vector field is modeled as a distribution of directions from which Shannon's entropy is used to measure the information content in the field. The effectiveness of the streamlines displayed in visualization can be measured by first constructing a new distribution of vectors derived from the existing streamlines, and then comparing this distribution with that of the original data set using the conditional entropy. The conditional entropy between these two distributions indicates how much information in the original data remains hidden after the selected streamlines are displayed. The quality of the visualization can be improved by progressively introducing new streamlines until the conditional entropy converges to a small value. We describe the key components of our framework with detailed analysis, and show that the framework can effectively visualize 2D and 3D flow data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613461]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.131]]></doi>

<publicationId><![CDATA[5613461]]></publicationId>

<partnum><![CDATA[5613461]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613461&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613461]]></pdf>

</document>

<document>

<rank>444</rank>

<title><![CDATA[Quantitative Texton Sequences for Legible Bivariate Maps]]></title>

<authors><![CDATA[Ware, C.]]></authors>

<affiliations><![CDATA[Center for Coastal & Ocean Mapping, Univ. of New Hampshire, Durham, NH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[colour graphics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Geology]]></term>

<term><![CDATA[Ocean temperature]]></term>

<term><![CDATA[Organisms]]></term>

<term><![CDATA[Sea measurements]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Temperature distribution]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1523]]></spage>

<epage><![CDATA[1530]]></epage>

<abstract><![CDATA[Representing bivariate scalar maps is a common but difficult visualization problem. One solution has been to use two dimensional color schemes, but the results are often hard to interpret and inaccurately read. An alternative is to use a color sequence for one variable and a texture sequence for another. This has been used, for example, in geology, but much less studied than the two dimensional color scheme, although theory suggests that it should lead to easier perceptual separation of information relating to the two variables. To make a texture sequence more clearly readable the concept of the quantitative texton sequence (QTonS) is introduced. A QTonS is defined a sequence of small graphical elements, called textons, where each texton represents a different numerical value and sets of textons can be densely displayed to produce visually differentiable textures. An experiment was carried out to compare two bivariate color coding schemes with two schemes using QTonS for one bivariate map component and a color sequence for the other. Two different key designs were investigated (a key being a sequence of colors or textures used in obtaining quantitative values from a map). The first design used two separate keys, one for each dimension, in order to measure how accurately subjects could independently estimate the underlying scalar variables. The second key design was two dimensional and intended to measure the overall integral accuracy that could be obtained. The results show that the accuracy is substantially higher for the QTonS/color sequence schemes. A hypothesis that texture/color sequence combinations are better for independent judgments of mapped quantities was supported. A second experiment probed the limits of spatial resolution for QTonSs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290769]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.175]]></doi>

<publicationId><![CDATA[5290769]]></publicationId>

<partnum><![CDATA[5290769]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290769&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290769]]></pdf>

</document>

<document>

<rank>445</rank>

<title><![CDATA[A Design Space of Visualization Tasks]]></title>

<authors><![CDATA[Schulz, H.-J.;  Nocke, T.;  Heitzler, M.;  Schumann, H.]]></authors>

<affiliations><![CDATA[Univ. of Rostock, Rostock, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Meteorology]]></term>

<term><![CDATA[Taxonomy]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2366]]></spage>

<epage><![CDATA[2375]]></epage>

<abstract><![CDATA[Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634156]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.120]]></doi>

<publicationId><![CDATA[6634156]]></publicationId>

<partnum><![CDATA[6634156]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634156&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634156]]></pdf>

</document>

<document>

<rank>446</rank>

<title><![CDATA[The Persuasive Power of Data Visualization]]></title>

<authors><![CDATA[Pandey, A.V.;  Manivannan, A.;  Nov, O.;  Satterthwaite, M.;  Bertini, E.]]></authors>

<affiliations><![CDATA[New York Univ., New York, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[psychology]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[User interfaces]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2211]]></spage>

<epage><![CDATA[2220]]></epage>

<abstract><![CDATA[Data visualization has been used extensively to inform users. However, little research has been done to examine the effects of data visualization in influencing users or in making a message more persuasive. In this study, we present experimental research to fill this gap and present an evidence-based analysis of persuasive visualization. We built on persuasion research from psychology and user interfaces literature in order to explore the persuasive effects of visualization. In this experimental study we define the circumstances under which data visualization can make a message more persuasive, propose hypotheses, and perform quantitative and qualitative analyses on studies conducted to test these hypotheses. We compare visual treatments with data presented through barcharts and linecharts on the one hand, treatments with data presented through tables on the other, and then evaluate their persuasiveness. The findings represent a first step in exploring the effectiveness of persuasive visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876023]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346419]]></doi>

<publicationId><![CDATA[6876023]]></publicationId>

<partnum><![CDATA[6876023]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876023&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876023]]></pdf>

</document>

<document>

<rank>447</rank>

<title><![CDATA[The Sinogram Polygonizer for Reconstructing 3D Shapes]]></title>

<authors><![CDATA[Yamanaka, D.;  Ohtake, Y.;  Suzuki, H.]]></authors>

<affiliations><![CDATA[Dept. of Precision Eng., Univ. of Tokyo, Tokyo, Japan]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Materials]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[X-ray imaging]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1911]]></spage>

<epage><![CDATA[1922]]></epage>

<abstract><![CDATA[This paper proposes a novel approach, the sinogram polygonizer, for directly reconstructing 3D shapes from sinograms (i.e., the primary output from X-ray computed tomography (CT) scanners consisting of projection image sequences of an object shown from different viewing angles). To obtain a polygon mesh approximating the surface of a scanned object, a grid-based isosurface polygonizer, such as Marching Cubes, has been conventionally applied to the CT volume reconstructed from a sinogram. In contrast, the proposed method treats CT values as a continuous function and directly extracts a triangle mesh based on tetrahedral mesh deformation. This deformation involves quadratic error metric minimization and optimal Delaunay triangulation for the generation of accurate, high-quality meshes. Thanks to the analytical gradient estimation of CT values, sharp features are well approximated, even though the generated mesh is very coarse. Moreover, this approach eliminates aliasing artifacts on triangle meshes.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6520857]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.87]]></doi>

<publicationId><![CDATA[6520857]]></publicationId>

<partnum><![CDATA[6520857]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6520857&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6520857]]></pdf>

</document>

<document>

<rank>448</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6129450]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.15]]></doi>

<publicationId><![CDATA[6129450]]></publicationId>

<partnum><![CDATA[6129450]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6129450&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129450]]></pdf>

</document>

<document>

<rank>449</rank>

<title><![CDATA[Real-Time Molecular Visualization Supporting Diffuse Interreflections and Ambient Occlusion]]></title>

<authors><![CDATA[Skanberg, R.;  Vazquez, P.-P.;  Guallar, V.;  Ropinski, T.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[molecular dynamics method]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[regression analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atomic measurements]]></term>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Real-time systems]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[718]]></spage>

<epage><![CDATA[727]]></epage>

<abstract><![CDATA[Today molecular simulations produce complex data sets capturing the interactions of molecules in detail. Due to the complexity of this time-varying data, advanced visualization techniques are required to support its visual analysis. Current molecular visualization techniques utilize ambient occlusion as a global illumination approximation to improve spatial comprehension. Besides these shadow-like effects, interreflections are also known to improve the spatial comprehension of complex geometric structures. Unfortunately, the inherent computational complexity of interreflections would forbid interactive exploration, which is mandatory in many scenarios dealing with static and time-varying data. In this paper, we introduce a novel analytic approach for capturing interreflections of molecular structures in real-time. By exploiting the knowledge of the underlying space filling representations, we are able to reduce the required parameters and can thus apply symbolic regression to obtain an analytic expression for interreflections. We show how to obtain the data required for the symbolic regression analysis, and how to exploit our analytic solution to enhance interactive molecular visualizations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192702]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467293]]></doi>

<publicationId><![CDATA[7192702]]></publicationId>

<partnum><![CDATA[7192702]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192702&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192702]]></pdf>

</document>

<document>

<rank>450</rank>

<title><![CDATA[Beautification of Design Sketches Using Trainable Stroke Clustering and Curve Fitting]]></title>

<authors><![CDATA[Orbay, G.;  Kara, L.B.]]></authors>

<affiliations><![CDATA[Dept. of Mech. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Artificial neural networks]]></term>

<term><![CDATA[Bifurcation]]></term>

<term><![CDATA[Curve fitting]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Training]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[694]]></spage>

<epage><![CDATA[708]]></epage>

<abstract><![CDATA[We propose a new sketch parsing and beautification method that converts digitally created design sketches into beautified line drawings. Our system uses a trainable, sequential bottom-up and top-down stroke clustering method that learns how to parse input pen strokes into groups of strokes each representing a single curve, followed by point-cloud ordering that facilitates curve fitting and smoothing. This approach enables greater conceptual freedom during visual ideation activities by allowing designers to develop their sketches using multiple, casually drawn strokes without requiring them to indicate the separation between different stroke groups. With the proposed method, raw sketches are seamlessly converted into vectorized geometric models, thus, facilitating downstream assessment and editing activities.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5710858]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.105]]></doi>

<publicationId><![CDATA[5710858]]></publicationId>

<partnum><![CDATA[5710858]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5710858&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710858]]></pdf>

</document>

<document>

<rank>451</rank>

<title><![CDATA[IDSS: A Novel Representation for Woven Fabrics]]></title>

<authors><![CDATA[Jiahua Zhang;  Baciu, G.;  Dejun Zheng;  Cheng Liang;  Guiqing Li;  Jinlian Hu]]></authors>

<affiliations><![CDATA[Dept. Comput., Hong Kong Polytech. Univ., Kowloon, China]]></affiliations>

<controlledterms>

<term><![CDATA[fabrics]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[production engineering computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Fabrics]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Weaving]]></term>

<term><![CDATA[Yarn]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[420]]></spage>

<epage><![CDATA[432]]></epage>

<abstract><![CDATA[The appearance of woven fabrics is intrinsically determined by the geometric details of their meso/micro scale structure. In this paper, we propose a multiscale representation and tessellation approach for woven fabrics. We extend the Displaced Subdivision Surface (DSS) to a representation named Interlaced/Intertwisted Displacement Subdivision Surface (IDSS). IDSS maps the geometric detail, scale by scale, onto a ternary interpolatory subdivision surface that is approximated by Bezier patches. This approach is designed for woven fabric rendering on DX11 GPUs. We introduce the Woven Patch, a structure based on DirectX's new primitive, patch, to describe an area of a woven fabric so that it can be easily implemented in the graphics pipeline using a hull shader, a tessellator and a domain shader. We can render a woven piece of fabric at 25 frames per second on a low-performance NVIDIA 8400 MG mobile GPU. This allows for large-scale representations of woven fabrics that maintain the geometric variances of real yarn and fiber.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6155717]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.66]]></doi>

<publicationId><![CDATA[6155717]]></publicationId>

<partnum><![CDATA[6155717]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6155717&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155717]]></pdf>

</document>

<document>

<rank>452</rank>

<title><![CDATA[Space-Time Transfinite Interpolation of Volumetric Material Properties]]></title>

<authors><![CDATA[Sanchez, M.;  Fryazinov, O.;  Adzhiev, V.;  Comninos, P.;  Pasko, A.]]></authors>

<affiliations><![CDATA[Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mathematical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Material properties]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[278]]></spage>

<epage><![CDATA[288]]></epage>

<abstract><![CDATA[The paper presents a novel technique based on extension of a general mathematical method of transfinite interpolation to solve an actual problem in the context of a heterogeneous volume modelling area. It deals with time-dependent changes to the volumetric material properties (material density, colour, and others) as a transformation of the volumetric material distributions in space-time accompanying geometric shape transformations such as metamorphosis. The main idea is to represent the geometry of both objects by scalar fields with distance properties, to establish in a higher-dimensional space a time gap during which the geometric transformation takes place, and to use these scalar fields to apply the new space-time transfinite interpolation to volumetric material attributes within this time gap. The proposed solution is analytical in its nature, does not require heavy numerical computations and can be used in real-time applications. Applications of this technique also include texturing and displacement mapping of time-variant surfaces, and parametric design of volumetric microstructures.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6894217]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2356196]]></doi>

<publicationId><![CDATA[6894217]]></publicationId>

<partnum><![CDATA[6894217]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6894217&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6894217]]></pdf>

</document>

<document>

<rank>453</rank>

<title><![CDATA[Color nonuniformity in projection-based displays: analysis and solutions]]></title>

<authors><![CDATA[Majumder, A.;  Stevens, R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., California Univ., Irvine, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[colour displays]]></term>

<term><![CDATA[large screen displays]]></term>

<term><![CDATA[optical projectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Attenuation]]></term>

<term><![CDATA[Brightness]]></term>

<term><![CDATA[Calibration]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Liquid crystal displays]]></term>

<term><![CDATA[Photometry]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[177]]></spage>

<epage><![CDATA[188]]></epage>

<abstract><![CDATA[Large-area displays made up of several projectors show significant variation in color. Here, we identify different projector parameters that cause the color variation and study their effects on the luminance and chrominance characteristics of the display. This work leads to the realization that luminance varies significantly within and across projectors, while chrominance variation is relatively small, especially across projectors of same model. To address this situation, we present a method to achieve luminance matching across all pixels of a multiprojector display that results in photometrically uniform displays. We use a camera as a measurement device for this purpose. Our method comprises a one-time calibration step that generates a per channel per projector luminance attenuation map (LAM), which is then used to correct any image projected on the display at interactive rates on commodity graphics hardware. To the best of our knowledge, this is the first effort to match luminance across all the pixels of a multiprojector display.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1260769]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1260769]]></doi>

<publicationId><![CDATA[1260769]]></publicationId>

<partnum><![CDATA[1260769]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260769&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260769]]></pdf>

</document>

<document>

<rank>454</rank>

<title><![CDATA[Message fron the Editor-in-Chief]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[x]]></spage>

<epage><![CDATA[x]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634135]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.176]]></doi>

<publicationId><![CDATA[6634135]]></publicationId>

<partnum><![CDATA[6634135]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634135&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634135]]></pdf>

</document>

<document>

<rank>455</rank>

<title><![CDATA[Segmentation of Three-dimensional Retinal Image Data]]></title>

<authors><![CDATA[Fuller, A.R.;  Zawadzki, R.J.;  Choi, S.;  Wiley, D.F.;  Werner, J.S.;  Hamann, B.]]></authors>

<affiliations><![CDATA[Univ. of California at Davis, Davis]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[optical tomography]]></term>

<term><![CDATA[support vector machines]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Diseases]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Noise level]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Retina]]></term>

<term><![CDATA[Support vector machines]]></term>

<term><![CDATA[Tomography]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1719]]></spage>

<epage><![CDATA[1726]]></epage>

<abstract><![CDATA[We have combined methods from volume visualization and data analysis to support better diagnosis and treatment of human retinal diseases. Many diseases can be identified by abnormalities in the thicknesses of various retinal layers captured using optical coherence tomography (OCT). We used a support vector machine (SVM) to perform semi-automatic segmentation of retinal layers for subsequent analysis including a comparison of layer thicknesses to known healthy parameters. We have extended and generalized an older SVM approach to support better performance in a clinical setting through performance enhancements and graceful handling of inherent noise in OCT data by considering statistical characteristics at multiple levels of resolution. The addition of the multi-resolution hierarchy extends the SVM to have "global awareness". A feature, such as a retinal layer, can therefore be modeled within the SVM as a combination of statistical characteristics across all levels; thus capturing high- and low-frequency information. We have compared our semi-automatically generated segmentations to manually segmented layers for verification purposes. Our main goals were to provide a tool that could (i) be used in a clinical setting; (ii) operate on noisy OCT data; and (iii) isolate individual or multiple retinal layers in both healthy and disease cases that contain structural deformities.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376207]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70590]]></doi>

<publicationId><![CDATA[4376207]]></publicationId>

<partnum><![CDATA[4376207]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376207&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376207]]></pdf>

</document>

<document>

<rank>456</rank>

<title><![CDATA[The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration]]></title>

<authors><![CDATA[Viau, C.;  McGuffin, M.J.;  Chiricota, Y.;  Jurisica, I.]]></authors>

<affiliations><![CDATA[Ecole de Technol. Super., Montreal, QC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[matrix algebra]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Joining processes]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1100]]></spage>

<epage><![CDATA[1108]]></epage>

<abstract><![CDATA[A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613448]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.205]]></doi>

<publicationId><![CDATA[5613448]]></publicationId>

<partnum><![CDATA[5613448]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613448&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613448]]></pdf>

</document>

<document>

<rank>457</rank>

<title><![CDATA[Adaptive real-time level-of-detail based rendering for polygonal models]]></title>

<authors><![CDATA[Xia, J.C.;  El-Sana, J.;  Varshney, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Electrical capacitance tomography]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Iterative algorithms]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[171]]></spage>

<epage><![CDATA[183]]></epage>

<abstract><![CDATA[We present an algorithm for performing adaptive real-time level-of-detail-based rendering for triangulated polygonal models. The simplifications are dependent on viewing direction, lighting, and visibility and are performed by taking advantage of image-space, object-space, and frame-to-frame coherences. In contrast to the traditional approaches of precomputing a fixed number of level-of-detail representations for a given object, our approach involves statically generating a continuous level-of-detail representation for the object. This representation is then used at run time to guide the selection of appropriate triangles for display. The list of displayed triangles is updated incrementally from one frame to the next. Our approach is more effective than the current level-of-detail-based rendering approaches for most scientific visualization applications, where there are a limited number of highly complex objects that stay relatively close to the viewer. Our approach is applicable for scalar (such as distance from the viewer) as well as vector (such as normal direction) attributes]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[597799]]></arnumber>

<doi><![CDATA[10.1109/2945.597799]]></doi>

<publicationId><![CDATA[597799]]></publicationId>

<partnum><![CDATA[597799]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=597799&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=597799]]></pdf>

</document>

<document>

<rank>458</rank>

<title><![CDATA[Wetting of Porous Solids]]></title>

<authors><![CDATA[Patkar, S.;  Chaudhuri, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stanford Univ., Stanford, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[diffusion]]></term>

<term><![CDATA[flow through porous media]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[porous materials]]></term>

<term><![CDATA[wetting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Absorption]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Gravity]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Solids]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1592]]></spage>

<epage><![CDATA[1604]]></epage>

<abstract><![CDATA[This paper presents a simple, three stage method to simulate the mechanics of wetting of porous solid objects, like sponges and cloth, when they interact with a fluid. In the first stage, we model the absorption of fluid by the object when it comes in contact with the fluid. In the second stage, we model the transport of absorbed fluid inside the object, due to diffusion, as a flow in a deforming, unstructured mesh. The fluid diffuses within the object depending on saturation of its various parts and other body forces. Finally, in the third stage, oversaturated parts of the object shed extra fluid by dripping. The simulation model is motivated by the physics of imbibition of fluids into porous solids in the presence of gravity. It is phenomenologically capable of simulating wicking and imbibition, dripping, surface flows over wet media, material weakening, and volume expansion due to wetting. The model is inherently mass conserving and works for both thin 2D objects like cloth and for 3D volumetric objects like sponges. It is also designed to be computationally efficient and can be easily added to existing cloth, soft body, and fluid simulation pipelines.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6409844]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.8]]></doi>

<publicationId><![CDATA[6409844]]></publicationId>

<partnum><![CDATA[6409844]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6409844&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6409844]]></pdf>

</document>

<document>

<rank>459</rank>

<title><![CDATA[A Structure-Based Distance Metric for High-Dimensional Space Exploration with Multidimensional Scaling]]></title>

<authors><![CDATA[Lee, J.H.;  McDonnell, K.T.;  Zelenyuk, A.;  Imre, D.;  Mueller, K.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[embedded systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Euclidean distance]]></term>

<term><![CDATA[Extraterrestrial measurements]]></term>

<term><![CDATA[Indexes]]></term>

<term><![CDATA[Layout]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[351]]></spage>

<epage><![CDATA[364]]></epage>

<abstract><![CDATA[Although the euclidean distance does well in measuring data distances within high-dimensional clusters, it does poorly when it comes to gauging intercluster distances. This significantly impacts the quality of global, low-dimensional space embedding procedures such as the popular multidimensional scaling (MDS) where one can often observe nonintuitive layouts. We were inspired by the perceptual processes evoked in the method of parallel coordinates which enables users to visually aggregate the data by the patterns the polylines exhibit across the dimension axes. We call the path of such a polyline its structure and suggest a metric that captures this structure directly in high-dimensional space. This allows us to better gauge the distances of spatially distant data constellations and so achieve data aggregations in MDS plots that are more cognizant of existing high-dimensional structure similarities. Our biscale framework distinguishes far-distances from near-distances. The coarser scale uses the structural similarity metric to separate data aggregates obtained by prior classification or clustering, while the finer scale employs the appropriate euclidean distance.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6560006]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.101]]></doi>

<publicationId><![CDATA[6560006]]></publicationId>

<partnum><![CDATA[6560006]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6560006&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560006]]></pdf>

</document>

<document>

<rank>460</rank>

<title><![CDATA[2009 Reviewers List]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[IEEE]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[174]]></spage>

<epage><![CDATA[176]]></epage>

<abstract><![CDATA[Lists the reviewers who contributed to the IEEE Transactions on Visualization and Computer Graphics from 28 September 2008 through 15 October 2009.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5331927]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.2]]></doi>

<publicationId><![CDATA[5331927]]></publicationId>

<partnum><![CDATA[5331927]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5331927&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331927]]></pdf>

</document>

<document>

<rank>461</rank>

<title><![CDATA[Underexposed Video Enhancement via Perception-driven Progressive Fusion]]></title>

<authors><![CDATA[Zhang, Q.;  Nie, Y.;  Zhang, L.;  Xiao, C.]]></authors>

<affiliations><![CDATA[Qing Zhang is with the Computer school of Wuhan University, Wuhan, China, 430072 (e-mail: zhangqing.whu.cs@gmail.com).]]></affiliations>

<thesaurusterms>

<term><![CDATA[Dynamic range]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Image sequences]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Video sequences]]></term>

<term><![CDATA[Visual perception]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Underexposed video enhancement aims at revealing hidden details that are barely noticeable in LDR video frames with noise. Previous work typically relies on a single heuristic tone mapping curve to expand the dynamic range, which inevitably leads to uneven exposure and visual artifacts. In this paper, we present a novel approach for underexposed video enhancement using an efficient perception-driven progressive fusion. For an input underexposed video, we first remap each video frame using a series of tentative tone mapping curves to generate an multi-exposure image sequence that contains different exposed versions of the original video frame. Guided by some visual perception quality measures encoding the desirable exposed appearance, we locate all the best exposed regions from multi-exposure image sequences and then integrate them into a well-exposed video in a temporally consistent manner. Finally, we further perform an effective texture-preserving spatio-temporal filtering on this well-exposed video to obtain a highquality noise-free result. Experimental results have shown that the enhanced video exhibits uniform exposure, brings out noticeable details, preserves temporal coherence, and avoids visual artifacts. Besides, we demonstrate applications of our approach to a set of problems including video dehazing, video denoising and HDR video reconstruction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7167723]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2461157]]></doi>

<publicationId><![CDATA[7167723]]></publicationId>

<partnum><![CDATA[7167723]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7167723&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167723]]></pdf>

</document>

<document>

<rank>462</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on the ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA)]]></title>

<authors><![CDATA[Kry, P.G.;  Lee, J.]]></authors>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2]]></spage>

<epage><![CDATA[3]]></epage>

<abstract><![CDATA[This special section presents expanded versions of three of the best papers from the 11th Annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA 2012), which was held in Lausanne, Switzerland, from 29-31 July 2012. SCA has established itself as the premier conference dedicated specifically to innovations in the software and technology of computer animation. SCA 2012 received 80 submissions and each submission was reviewed by at least three members of the international program committee. After a thorough online discussion, the 72-member international program committee decided on the 27 full papers and nine short presentation papers accepted for the final program. Out of 27 full papers, the symposium's Best Papers Award Committee selected one best paper, two runner-ups, and four honorable mentions. The selection was informed by the original reviews and the conference presentations. We are delighted to present three out of the six very best papers of SCA 2012 invited for this special section. Each of the invited papers contains a minimum of 30 percent new material and received at least three reviews, including one reviewer not among the original SCA reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6674943]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.3]]></doi>

<publicationId><![CDATA[6674943]]></publicationId>

<partnum><![CDATA[6674943]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6674943&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6674943]]></pdf>

</document>

<document>

<rank>463</rank>

<title><![CDATA[A Comparison of Gradient Estimation Methods for Volume Rendering on Unstructured Meshes]]></title>

<authors><![CDATA[Correa, C.;  Hero, R.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[net structures (mechanical)]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Reconstruction algorithms]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Spatial resolution]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[305]]></spage>

<epage><![CDATA[319]]></epage>

<abstract><![CDATA[This paper presents a study of gradient estimation methods for rendering unstructured-mesh volume data. Gradient estimation is necessary for rendering shaded isosurfaces and specular highlights, which provide important cues for shape and depth. Gradient estimation has been widely studied and deployed for regular-grid volume data to achieve local illumination effects, but has been, otherwise, for unstructured-mesh data. As a result, most of the unstructured-mesh volume visualizations made so far were unlit. In this paper, we present a comprehensive study of gradient estimation methods for unstructured meshes with respect to their cost and performance. Through a number of benchmarks, we discuss the effects of mesh quality and scalar function complexity in the accuracy of the reconstruction, and their impact in lighting-enabled volume rendering. Based on our study, we also propose two heuristic improvements to the gradient reconstruction process. The first heuristic improves the rendering quality with a hybrid algorithm that combines the results of the multiple reconstruction methods, based on the properties of a given mesh. The second heuristic improves the efficiency of its GPU implementation, by restricting the computation of the gradient on a fixed-size local neighborhood.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5262940]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.105]]></doi>

<publicationId><![CDATA[5262940]]></publicationId>

<partnum><![CDATA[5262940]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5262940&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5262940]]></pdf>

</document>

<document>

<rank>464</rank>

<title><![CDATA[Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces]]></title>

<authors><![CDATA[Matkovic, K.;  Gracanin, D.;  Klarin, B.;  Hauser, H.]]></authors>

<affiliations><![CDATA[VRVis Res. Center, Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[automobile industry]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[electrohydrodynamics]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[lubrication]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aggregates]]></term>

<term><![CDATA[Automotive engineering]]></term>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Context modeling]]></term>

<term><![CDATA[Data engineering]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Lubrication]]></term>

<term><![CDATA[Meteorology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1351]]></spage>

<epage><![CDATA[1358]]></epage>

<abstract><![CDATA[The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290748]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.155]]></doi>

<publicationId><![CDATA[5290748]]></publicationId>

<partnum><![CDATA[5290748]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290748&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290748]]></pdf>

</document>

<document>

<rank>465</rank>

<title><![CDATA[Visual Verification and Analysis of Cluster Detection for Molecular Dynamics]]></title>

<authors><![CDATA[Grottel, S.;  Reina, G.;  Vrabec, J.;  Ertl, T.]]></authors>

<affiliations><![CDATA[Univ. Stuttgart, Stuttgart]]></affiliations>

<controlledterms>

<term><![CDATA[molecular dynamics method]]></term>

<term><![CDATA[nucleation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Detection algorithms]]></term>

<term><![CDATA[Energy efficiency]]></term>

<term><![CDATA[Energy resolution]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Metastasis]]></term>

<term><![CDATA[Thermodynamics]]></term>

<term><![CDATA[Turbines]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1624]]></spage>

<epage><![CDATA[1631]]></epage>

<abstract><![CDATA[A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376195]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70614]]></doi>

<publicationId><![CDATA[4376195]]></publicationId>

<partnum><![CDATA[4376195]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376195&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376195]]></pdf>

</document>

<document>

<rank>466</rank>

<title><![CDATA[Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations]]></title>

<authors><![CDATA[Collins, C.;  Penn, G.;  Carpendale, S.]]></authors>

<affiliations><![CDATA[Univ. of Toronto, Toronto, ON, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[set theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Air conditioning]]></term>

<term><![CDATA[Cognitive science]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1009]]></spage>

<epage><![CDATA[1016]]></epage>

<abstract><![CDATA[While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290706]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.122]]></doi>

<publicationId><![CDATA[5290706]]></publicationId>

<partnum><![CDATA[5290706]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290706&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290706]]></pdf>

</document>

<document>

<rank>467</rank>

<title><![CDATA[Caricaturistic Visualization]]></title>

<authors><![CDATA[Rautek, P.;  Viola, I.;  Groller, E.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[face recognition]]></term>

<term><![CDATA[feature extraction]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Brain modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Evolution (biology)]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Focusing]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Quality control]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1085]]></spage>

<epage><![CDATA[1092]]></epage>

<abstract><![CDATA[Caricatures are pieces of art depicting persons or sociological conditions in a non-veridical way. In both cases caricatures are referring to a reference model. The deviations from the reference model are the characteristic features of the depicted subject. Good caricatures exaggerate the characteristics of a subject in order to accent them. The concept of caricaturistic visualization is based on the caricature metaphor. The aim of caricaturistic visualization is an illustrative depiction of characteristics of a given dataset by exaggerating deviations from the reference model. We present the general concept of caricaturistic visualization as well as a variety of examples. We investigate different visual representations for the depiction of caricatures. Further, we present the caricature matrix, a technique to make differences between datasets easily identifiable]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015468]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.123]]></doi>

<publicationId><![CDATA[4015468]]></publicationId>

<partnum><![CDATA[4015468]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015468&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015468]]></pdf>

</document>

<document>

<rank>468</rank>

<title><![CDATA[Corrections to "On a construction of a hierarchy of beat linear spline approximations using repeated bisection"]]></title>

<authors><![CDATA[Hamann, B.;  Jordan, B.W.;  Wiley, D.F.]]></authors>

<affiliations><![CDATA[University of California]]></affiliations>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computer errors]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Linear approximation]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[190]]></spage>

<epage><![CDATA[190]]></epage>

<abstract><![CDATA[<div style="font-variant: small-caps; font-size: .9em;">First Page of the Article</div><img class="img-abs-container" style="width: 95%; border: 1px solid #808080;" src="/xploreAssets/images/absImages/00773812.png" border="0">]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[773812]]></arnumber>

<doi><![CDATA[10.1109/TVCG.1999.773812]]></doi>

<publicationId><![CDATA[773812]]></publicationId>

<partnum><![CDATA[773812]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=773812&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=773812]]></pdf>

</document>

<document>

<rank>469</rank>

<title><![CDATA[Editor's Note]]></title>

<authors><![CDATA[Ertl, Thomas]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[417]]></spage>

<epage><![CDATA[419]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4297683]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1042]]></doi>

<publicationId><![CDATA[4297683]]></publicationId>

<partnum><![CDATA[4297683]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297683&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297683]]></pdf>

</document>

<document>

<rank>470</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5165578]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.77]]></doi>

<publicationId><![CDATA[5165578]]></publicationId>

<partnum><![CDATA[5165578]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5165578&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5165578]]></pdf>

</document>

<document>

<rank>471</rank>

<title><![CDATA[IEEE Visualization and Graphics Technical Committee]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[ix]]></spage>

<epage><![CDATA[ix]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6777459]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.28]]></doi>

<publicationId><![CDATA[6777459]]></publicationId>

<partnum><![CDATA[6777459]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777459&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777459]]></pdf>

</document>

<document>

<rank>472</rank>

<title><![CDATA[The Lattice-Boltzmann Method on Optimal Sampling Lattices]]></title>

<authors><![CDATA[Alim, U.;  Entezari, A.;  Moller, T.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC]]></affiliations>

<controlledterms>

<term><![CDATA[cavitation]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[convolution]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[lattice Boltzmann methods]]></term>

<term><![CDATA[smoke]]></term>

<term><![CDATA[turbulence]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Frequency domain analysis]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Signal processing algorithms]]></term>

<term><![CDATA[Signal sampling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[630]]></spage>

<epage><![CDATA[641]]></epage>

<abstract><![CDATA[In this paper, we extend the single relaxation time lattice-Boltzmann method (LBM) to the 3D body-centered cubic (BCC) lattice. We show that the D3bQ15 lattice defined by a 15 neighborhood connectivity of the BCC lattice is not only capable of more accurately discretizing the velocity space of the continuous Boltzmann equation as compared to the D3Q15 Cartesian lattice, it also achieves a comparable spatial discretization with 30 percent less samples. We validate the accuracy of our proposed lattice by investigating its performance on the 3D lid-driven cavity flow problem and show that the D3bQ15 lattice offers significant cost savings while maintaining a comparable accuracy. We demonstrate the efficiency of our method and the impact on graphics and visualization techniques via the application of line-integral convolution on 2D slices as well as the extraction of streamlines of the 3D flow. We further study the benefits of our proposed lattice by applying it to the problem of simulating smoke and show that the D3bQ15 lattice yields more detail and turbulence at a reduced computational cost.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4745632]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.201]]></doi>

<publicationId><![CDATA[4745632]]></publicationId>

<partnum><![CDATA[4745632]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4745632&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745632]]></pdf>

</document>

<document>

<rank>473</rank>

<title><![CDATA[Drawing on Air: Input Techniques for Controlled 3D Line Illustration]]></title>

<authors><![CDATA[Keefe, D.F.;  Zeleznik, R.C.;  Laidlaw, D.H.]]></authors>

<affiliations><![CDATA[Brown Univ., Providence]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[haptic interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Control systems]]></term>

<term><![CDATA[Electrical equipment industry]]></term>

<term><![CDATA[Feedback]]></term>

<term><![CDATA[Friction]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Industrial training]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1067]]></spage>

<epage><![CDATA[1081]]></epage>

<abstract><![CDATA[We present drawing on air, a haptic-aided input technique for drawing controlled 3D curves through space. Drawing on air addresses a control problem with current 3D modeling approaches based on sweeping movement of the hands through the air. Although artists praise the immediacy and intuitiveness of these systems, a lack of control makes it nearly impossible to create 3D forms beyond quick design sketches or gesture drawings. Drawing on air introduces two new strategies for more controlled 3D drawing: one-handed drag drawing and two-handed tape drawing. Both approaches have advantages for drawing certain types of curves. We describe a tangent preserving method for transitioning between the two techniques while drawing. Haptic-aided redrawing and line weight adjustment while drawing are also supported in both approaches. In a quantitative user study evaluation by illustrators, the one and two-handed techniques performed at roughly the same level and both significantly outperformed freehand drawing and freehand drawing augmented with a haptic friction effect. We present the design and results of this experiment, as well as user feedback from artists and 3D models created in a style of line illustration for challenging artistic and scientific subjects.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4135646]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1060]]></doi>

<publicationId><![CDATA[4135646]]></publicationId>

<partnum><![CDATA[4135646]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4135646&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4135646]]></pdf>

</document>

<document>

<rank>474</rank>

<title><![CDATA[Virtual Training: Learning Transfer of Assembly Tasks]]></title>

<authors><![CDATA[Carlson, P.;  Peters, A.;  Gilbert, S.B.;  Vance, J.M.;  Luse, A.]]></authors>

<affiliations><![CDATA[Dept. of Human-Comput. Interaction (HCI), Iowa State Univ., Ames, IA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer based training]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Assembly]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Training]]></term>

<term><![CDATA[Virtual environments]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[770]]></spage>

<epage><![CDATA[782]]></epage>

<abstract><![CDATA[In training assembly workers in a factory, there are often barriers such as cost and lost productivity due to shutdown. The use of virtual reality (VR) training has the potential to reduce these costs. This research compares virtual bimanual haptic training versus traditional physical training and the effectiveness for learning transfer. In a mixed experimental design, participants were assigned to either virtual or physical training and trained by assembling a wooden burr puzzle as many times as possible during a twenty minute time period. After training, participants were tested using the physical puzzle and were retested again after two weeks. All participants were trained using brightly colored puzzle pieces. To examine the effect of color, testing involved the assembly of colored physical parts and natural wood colored physical pieces. Spatial ability as measured using a mental rotation test, was shown to correlate with the number of assemblies they were able to complete in the training. While physical training outperformed virtual training, after two weeks the virtually trained participants actually improved their test assembly times. The results suggest that the color of the puzzle pieces helped the virtually trained participants in remembering the assembly process.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7014246]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2393871]]></doi>

<publicationId><![CDATA[7014246]]></publicationId>

<partnum><![CDATA[7014246]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7014246&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014246]]></pdf>

</document>

<document>

<rank>475</rank>

<title><![CDATA[Table of contents]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[i]]></spage>

<epage><![CDATA[x]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5613417]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.201]]></doi>

<publicationId><![CDATA[5613417]]></publicationId>

<partnum><![CDATA[5613417]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613417&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613417]]></pdf>

</document>

<document>

<rank>476</rank>

<title><![CDATA[VASA: Interactive Computational Steering of Large Asynchronous Simulation Pipelines for Societal Infrastructure]]></title>

<authors><![CDATA[Sungahn Ko;  Jieqiong Zhao;  Jing Xia;  Afzal, S.;  Xiaoyu Wang;  Abram, G.;  Elmqvist, N.;  Kne, L.;  Van Riper, D.;  Gaither, K.;  Kennedy, S.;  Tolone, W.;  Ribarsky, W.;  Ebert, D.S.]]></authors>

<affiliations><![CDATA[Purdue Univ. in West Lafayette, West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[public administration]]></term>

<term><![CDATA[security]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Emergency serivces]]></term>

<term><![CDATA[Meteorology]]></term>

<term><![CDATA[Supply chains]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1853]]></spage>

<epage><![CDATA[1862]]></epage>

<abstract><![CDATA[We present VASA, a visual analytics platform consisting of a desktop application, a component model, and a suite of distributed simulation components for modeling the impact of societal threats such as weather, food contamination, and traffic on critical infrastructure such as supply chains, road networks, and power grids. Each component encapsulates a high-fidelity simulation model that together form an asynchronous simulation pipeline: a system of systems of individual simulations with a common data and parameter exchange format. At the heart of VASA is the Workbench, a visual analytics application providing three distinct features: (1) low-fidelity approximations of the distributed simulation components using local simulation proxies to enable analysts to interactively configure a simulation run; (2) computational steering mechanisms to manage the execution of individual simulation components; and (3) spatiotemporal and interactive methods to explore the combined results of a simulation run. We showcase the utility of the platform using examples involving supply chains during a hurricane as well as food contamination in a fast food restaurant chain.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875926]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346911]]></doi>

<publicationId><![CDATA[6875926]]></publicationId>

<partnum><![CDATA[6875926]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875926&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875926]]></pdf>

</document>

<document>

<rank>477</rank>

<title><![CDATA[A wavelet representation of reflectance functions]]></title>

<authors><![CDATA[Lalonde, P.;  Fournier, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[light reflection]]></term>

<term><![CDATA[realistic images]]></term>

<term><![CDATA[reflectivity]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Distribution functions]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Reflectivity]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[329]]></spage>

<epage><![CDATA[336]]></epage>

<abstract><![CDATA[Analytical models of light reflection are in common use in computer graphics. However, models based on measured reflectance data promise increased realism by making it possible to simulate many more types of surfaces to a greater level of accuracy than with analytical models. They also require less expert knowledge about the illumination models and their parameters. There are a number of hurdles to using measured reflectance functions, however. The data sets are very large. A reflectance distribution function sampled at five degrees angular resolution, arguably sparse enough to miss highlights and other high frequency effects, can easily require over a million samples, which in turn amount to over four megabytes of data. These data then also require some form of interpolation and filtering to be used effectively. We examine issues of representation of measured reflectance distribution functions. In particular, we examine a wavelet basis representation of reflectance functions, and the algorithms required for efficient point-wise reconstruction of the BRDF. We show that the nonstandard wavelet decomposition leads to considerably more efficient algorithms than the standard wavelet decomposition. We also show that thresholding allows considerable improvement in running times, without unduly sacrificing image quality]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[646236]]></arnumber>

<doi><![CDATA[10.1109/2945.646236]]></doi>

<publicationId><![CDATA[646236]]></publicationId>

<partnum><![CDATA[646236]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=646236&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=646236]]></pdf>

</document>

<document>

<rank>478</rank>

<title><![CDATA[UnTangle Map: Visual Analysis of Probabilistic Multi-Label Data]]></title>

<authors><![CDATA[Cao, N.;  Lin, Yu-Ru;  Gotz, D.]]></authors>

<affiliations><![CDATA[Nan Cao is with the IBM T.J. Watson Research Center.(Email: nancao@us.ibm.com)]]></affiliations>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed databases]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Motion pictures]]></term>

<term><![CDATA[Probabilistic logic]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Data with multiple probabilistic labels are common in many situations. For example, a movie may be associated with multiple genres with different levels of confidence. Despite their ubiquity, the problem of visualizing probabilistic labels has not been adequately addressed. Existing approaches often either discard the probabilistic information, or map the data to a low-dimensional subspace where their associations with original labels are obscured. In this paper, we propose a novel visual technique, UnTangle Map, for visualizing probabilistic multi-labels. In our proposed visualization, data items are placed inside a web of connected triangles, with labels assigned to the triangle vertices such that nearby labels are more relevant to each other. The positions of the data items are determined based on the probabilistic associations between items and labels. UnTangle Map provides both (a) an automatic label placement algorithm, and (b) adaptive interactions that allow users to control the label positioning for different information needs. Our work makes a unique contribution by providing an effective way to investigate the relationship between data items and their probabilistic labels, as well as the relationships among labels. Our user study suggests that the visualization effectively helps users discover emergent patterns and compare the nuances of probabilistic information in the data labels.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7091015]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2424878]]></doi>

<publicationId><![CDATA[7091015]]></publicationId>

<partnum><![CDATA[7091015]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7091015&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091015]]></pdf>

</document>

<document>

<rank>479</rank>

<title><![CDATA[Point-based probabilistic surfaces to show surface uncertainty]]></title>

<authors><![CDATA[Grigoryan, G.;  Rheingans, P.]]></authors>

<affiliations><![CDATA[Dept. of Biol., Massachusetts Univ., Cambridge, MA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[colour graphics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[probability]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[tumours]]></term>

<term><![CDATA[uncertainty handling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Crystallography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Neoplasms]]></term>

<term><![CDATA[Oil pollution]]></term>

<term><![CDATA[Pollution measurement]]></term>

<term><![CDATA[Surface contamination]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[564]]></spage>

<epage><![CDATA[573]]></epage>

<abstract><![CDATA[Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. In these applications, the correct course of action may depend not only on the location of a boundary, but on the precision with which that location is known. Examples include environmental pollution borderline detection, oil basin edge characterization, or discrimination between cancerous and healthy tissue in medicine. We present a method for producing visualizations of surfaces with uncertainties using points as display primitives. Our approach is to render the surface as a collection of points and to displace each point from its original location along the surface normal by an amount proportional to the uncertainty at that point. This approach can be used in combination with other techniques such as pseudocoloring to produce efficient and revealing visualizations. The basic approach is sufficiently flexible to allow natural extensions; we show incorporation of expressive modulation of opacity, change of the stroke primitive, and addition of an underlying polygonal model. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries. The point-based technique is compared to pseudocoloring for a position estimation task in a preliminary user study.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1310282]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.30]]></doi>

<publicationId><![CDATA[1310282]]></publicationId>

<partnum><![CDATA[1310282]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310282&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310282]]></pdf>

</document>

<document>

<rank>480</rank>

<title><![CDATA[Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization]]></title>

<authors><![CDATA[Bertini, E.;  Tatu, A.;  Keim, D.]]></authors>

<affiliations><![CDATA[Univ. of Konstanz, Konstanz, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Measurements]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2203]]></spage>

<epage><![CDATA[2212]]></epage>

<abstract><![CDATA[In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064985]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.229]]></doi>

<publicationId><![CDATA[6064985]]></publicationId>

<partnum><![CDATA[6064985]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064985&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064985]]></pdf>

</document>

<document>

<rank>481</rank>

<title><![CDATA[Spatioangular Prefiltering for Multiview 3D Displays]]></title>

<authors><![CDATA[Ramachandra, V.;  Hirakawa, K.;  Zwicker, M.;  Truong Nguyen]]></authors>

<affiliations><![CDATA[Qualcomm Inc., San Diego, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[low-pass filters]]></term>

<term><![CDATA[stereo image processing]]></term>

<term><![CDATA[three-dimensional displays]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Frequency domain analysis]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image analysis]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Low pass filters]]></term>

<term><![CDATA[Narrowband]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Signal reconstruction]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visual system]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[642]]></spage>

<epage><![CDATA[654]]></epage>

<abstract><![CDATA[In this paper, we analyze the reproduction of light fields on multiview 3D displays. A three-way interaction between the input light field signal (which is often aliased), the joint spatioangular sampling grids of multiview 3D displays, and the interview light leakage in modern multiview 3D displays is characterized in the joint spatioangular frequency domain. Reconstruction of light fields by all physical 3D displays is prone to light leakage, which means that the reconstruction low-pass filter implemented by the display is too broad in the angular domain. As a result, 3D displays excessively attenuate angular frequencies. Our analysis shows that this reduces sharpness of the images shown in the 3D displays. In this paper, stereoscopic image recovery is recast as a problem of joint spatioangular signal reconstruction. The combination of the 3D display point spread function and human visual system provides the narrow-band low-pass filter which removes spectral replicas in the reconstructed light field on the multiview display. The nonideality of this filter is corrected with the proposed prefiltering. The proposed light field reconstruction method performs light field antialiasing as well as angular sharpening to compensate for the nonideal response of the 3D display. The union of cosets approach which has been used earlier by others is employed here to model the nonrectangular spatioangular sampling grids on a multiview display in a generic fashion. We confirm the effectiveness of our approach in simulation and in physical hardware, and demonstrate improvement over existing techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5482579]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.86]]></doi>

<publicationId><![CDATA[5482579]]></publicationId>

<partnum><![CDATA[5482579]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5482579&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482579]]></pdf>

</document>

<document>

<rank>482</rank>

<title><![CDATA[Value-Cell Bar Charts for Visualizing Large Transaction Data Sets]]></title>

<authors><![CDATA[Keim, D.A.;  Hao, M.C.;  Dayal, U.;  Lyons, M.]]></authors>

<affiliations><![CDATA[Univ. of Konstanz, Konstanz]]></affiliations>

<controlledterms>

<term><![CDATA[bar charts]]></term>

<term><![CDATA[business data processing]]></term>

<term><![CDATA[customer profiles]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[sales management]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Decision trees]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Marketing and sales]]></term>

<term><![CDATA[Multidimensional systems]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[822]]></spage>

<epage><![CDATA[833]]></epage>

<abstract><![CDATA[One of the common problems businesses need to solve is how to use large volumes of sales histories, Web transactions, and other data to understand the behavior of their customers and increase their revenues. Bar charts are widely used for daily analysis, but only show highly aggregated data. Users often need to visualize detailed multidimensional information reflecting the health of their businesses. In this paper, we propose an innovative visualization solution based on the use of value cells within bar charts to represent business metrics. The value of a transaction can be discretized into one or multiple cells: high-value transactions are mapped to multiple value cells, whereas many small-value transactions are combined into one cell. With value-cell bar charts, users can 1) visualize transaction value distributions and correlations, 2) identify high-value transactions and outliers at a glance, and 3) instantly display values at the transaction record level. Value-cell bar charts have been applied with success to different sales and IT service usage applications, demonstrating the benefits of the technique over traditional charting techniques. A comparison with two variants of the well-known Tree map technique and our earlier work on pixel bar charts is also included.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4293024]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1023]]></doi>

<publicationId><![CDATA[4293024]]></publicationId>

<partnum><![CDATA[4293024]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4293024&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293024]]></pdf>

</document>

<document>

<rank>483</rank>

<title><![CDATA[Crease Surfaces: From Theory to Extraction and Application to Diffusion Tensor MRI]]></title>

<authors><![CDATA[Schultz, T.;  Theisel, H.;  Seidel, H.-P.]]></authors>

<affiliations><![CDATA[Dept. 4 -Comput. Graphics, MPI Inf., Saarbrucken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[Hessian matrices]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[magnetic resonance imaging]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[109]]></spage>

<epage><![CDATA[119]]></epage>

<abstract><![CDATA[Crease surfaces are two-dimensional manifolds along which a scalar field assumes a local maximum (ridge) or a local minimum (valley) in a constrained space. Unlike isosurfaces, they are able to capture extremal structures in the data. Creases have a long tradition in image processing and computer vision, and have recently become a popular tool for visualization. When extracting crease surfaces, degeneracies of the Hessian (i.e., lines along which two eigenvalues are equal) have so far been ignored. We show that these loci, however, have two important consequences for the topology of crease surfaces: First, creases are bounded not only by a side constraint on eigenvalue sign, but also by Hessian degeneracies. Second, crease surfaces are not, in general, orientable. We describe an efficient algorithm for the extraction of crease surfaces which takes these insights into account and demonstrate that it produces more accurate results than previous approaches. Finally, we show that diffusion tensor magnetic resonance imaging (DT-MRI) stream surfaces, which were previously used for the analysis of planar regions in diffusion tensor MRI data, are mathematically ill-defined. As an example application of our method, creases in a measure of planarity are presented as a viable substitute.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4840340]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.44]]></doi>

<publicationId><![CDATA[4840340]]></publicationId>

<partnum><![CDATA[4840340]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4840340&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4840340]]></pdf>

</document>

<document>

<rank>484</rank>

<title><![CDATA[Stenomaps: Shorthand for shapes]]></title>

<authors><![CDATA[van Goethem, A.;  Reimer, A.;  Speckmann, B.;  Wood, J.]]></authors>

<affiliations><![CDATA[Tech. Univ. Eindhoven, Eindhoven, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[dynamic programming]]></term>

<term><![CDATA[splines (mathematics)]]></term>

<term><![CDATA[storms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Dynamic programming]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Splines (mathematics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2053]]></spage>

<epage><![CDATA[2062]]></epage>

<abstract><![CDATA[We address some of the challenges in representing spatial data with a novel form of geometric abstraction-the stenomap. The stenomap comprises a series of smoothly curving linear glyphs that each represent both the boundary and the area of a polygon. We present an efficient algorithm to automatically generate these open, C<sup>1</sup>-continuous splines from a set of input polygons. Feature points of the input polygons are detected using the medial axis to maintain important shape properties. We use dynamic programming to compute a planar non-intersecting spline representing each polygon's base shape. The results are stylised glyphs whose appearance may be parameterised and that offer new possibilities in the 'cartographic design space'. We compare our glyphs with existing forms of geometric schematisation and discuss their relative merits and shortcomings. We describe several use cases including the depiction of uncertain model data in the form of hurricane track forecasting; minimal ink thematic mapping; and the depiction of continuous statistical data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876003]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346274]]></doi>

<publicationId><![CDATA[6876003]]></publicationId>

<partnum><![CDATA[6876003]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876003&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876003]]></pdf>

</document>

<document>

<rank>485</rank>

<title><![CDATA[Adaptive Synthesis of Distance Fields]]></title>

<authors><![CDATA[Sung-Ho Lee;  Taejung Park;  Jong-Hyun Kim;  Chang-Hun Kim]]></authors>

<affiliations><![CDATA[Comput. Graphics Lab., Korea Univ., Seoul, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computer games]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[multiprocessing systems]]></term>

<term><![CDATA[resource allocation]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptation models]]></term>

<term><![CDATA[Jitter]]></term>

<term><![CDATA[Memory management]]></term>

<term><![CDATA[Octrees]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1135]]></spage>

<epage><![CDATA[1145]]></epage>

<abstract><![CDATA[We address the computational resource requirements of 3D example-based synthesis with an adaptive synthesis technique that uses a tree-based synthesis map. A signed-distance field (SDF) is determined for the 3D exemplars, and then new models can be synthesized as SDFs by neighborhood matching. Unlike voxel synthesis approach, our input is posed in the real domain to preserve maximum detail. In comparison to straightforward extensions to the existing volume texture synthesis approach, we made several improvements in terms of memory requirements, computation times, and synthesis quality. The inherent parallelism in this method makes it suitable for a multicore CPU. Results show that computation times and memory requirements are very much reduced, and large synthesized scenes exhibit fine details which mimic the exemplars.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5975144]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.134]]></doi>

<publicationId><![CDATA[5975144]]></publicationId>

<partnum><![CDATA[5975144]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5975144&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975144]]></pdf>

</document>

<document>

<rank>486</rank>

<title><![CDATA[Participatory Visualization with Wordle]]></title>

<authors><![CDATA[Viegas, F.B.;  Wattenberg, M.;  Feinberg, J.]]></authors>

<affiliations><![CDATA[IBM Res., Hawthorne, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Web sites]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1137]]></spage>

<epage><![CDATA[1144]]></epage>

<abstract><![CDATA[We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290722]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.171]]></doi>

<publicationId><![CDATA[5290722]]></publicationId>

<partnum><![CDATA[5290722]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290722&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290722]]></pdf>

</document>

<document>

<rank>487</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5746565]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.69]]></doi>

<publicationId><![CDATA[5746565]]></publicationId>

<partnum><![CDATA[5746565]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5746565&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5746565]]></pdf>

</document>

<document>

<rank>488</rank>

<title><![CDATA[Automated Aesthetic Analysis of Photographic Images]]></title>

<authors><![CDATA[Aydin, T.O.;  Smolic, A.;  Gross, M.]]></authors>

<affiliations><![CDATA[Dept. of Adv. Video Technol., Disney Res. Zurich, Zurich, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[image processing]]></term>

<term><![CDATA[photography]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Abstracts]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Image quality]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Photography]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[31]]></spage>

<epage><![CDATA[42]]></epage>

<abstract><![CDATA[We present a perceptually calibrated system for automatic aesthetic evaluation of photographic images. Our work builds upon the concepts of no-reference image quality assessment, with the main difference being our focus on rating image aesthetic attributes rather than detecting image distortions. In contrast to the recent attempts on the highly subjective aesthetic judgment problems such as binary aesthetic classification and the prediction of an image's overall aesthetics rating, our method aims on providing a reliable objective basis of comparison between aesthetic properties of different photographs. To that end our system computes perceptually calibrated ratings for a set of fundamental and meaningful aesthetic attributes, that together form an &#x201C;aesthetic signature&#x201D; of an image. We show that aesthetic signatures can still be used to improve upon the current state-of-the-art in automatic aesthetic judgment, but also enable interesting new photo editing applications such as automated aesthetic analysis, HDR tone mapping evaluation, and providing aesthetic feedback during multi-scale contrast manipulation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6819054]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2325047]]></doi>

<publicationId><![CDATA[6819054]]></publicationId>

<partnum><![CDATA[6819054]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6819054&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6819054]]></pdf>

</document>

<document>

<rank>489</rank>

<title><![CDATA[Adaptive extraction of time-varying isosurfaces]]></title>

<authors><![CDATA[Gregorski, B.;  Senecal, J.;  Duchaineau, M.A.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[surface fitting]]></term>

<term><![CDATA[very large databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Spatial resolution]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[683]]></spage>

<epage><![CDATA[694]]></epage>

<abstract><![CDATA[We present an algorithm for adaptively extracting and rendering isosurfaces from compressed time-varying volume data sets. Tetrahedral meshes defined by longest edge bisection are used to create a multiresolution representation of the volume in the spatial domain that is adapted overtime to approximate the time-varying volume. The reextraction of the isosurface at each time step is accelerated with the vertex programming capabilities of modern graphics hardware. A data layout scheme which follows the access pattern indicated by mesh refinement is used to access the volume in a spatially and temporally coherent manner. This data layout scheme allows our algorithm to be used for out-of-core visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1333666]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.35]]></doi>

<publicationId><![CDATA[1333666]]></publicationId>

<partnum><![CDATA[1333666]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1333666&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333666]]></pdf>

</document>

<document>

<rank>490</rank>

<title><![CDATA[Structured penumbral irradiance computation]]></title>

<authors><![CDATA[Drettakis, G.;  Flume, E.L.]]></authors>

<affiliations><![CDATA[Inst. Nat. de Recherche en Inf. et Autom., Grenoble, France]]></affiliations>

<controlledterms>

<term><![CDATA[brightness]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[299]]></spage>

<epage><![CDATA[312]]></epage>

<abstract><![CDATA[A definitive understanding of irradiance behavior in penumbral regions has been hard to come by, mainly due to the computational expense of determining the visible parts of an area light source. Consequently, sampling strategies have been mostly ad hoc, and evaluation of the resulting approximations has been difficult. In this paper, the structure of penumbral irradiance is investigated empirically and numerically. This study has been made feasible by the use of the discontinuity mesh and the backprojection, an efficient data structure representing visibility in regions of partial occlusion. Regions of penumbrae in which irradiance varies nonmonotonically are characterized empirically, and numerical tests are performed to determine the frequency of their occurrence. This study inspired the development of two algorithms for the construction of interpolating approximations to irradiance: one algorithm reduces the number of edges in the mesh defining the interpolant domain; and the other algorithm chooses among linear, quadratic, and mixed interpolants based on irradiance monotonicity. Results from numerical tests and images are presented that demonstrate good performance of the new algorithms for various realistic test configurations]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[556499]]></arnumber>

<doi><![CDATA[10.1109/2945.556499]]></doi>

<publicationId><![CDATA[556499]]></publicationId>

<partnum><![CDATA[556499]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=556499&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556499]]></pdf>

</document>

<document>

<rank>491</rank>

<title><![CDATA[Real-time markerless tracking for augmented reality: the virtual visual servoing framework]]></title>

<authors><![CDATA[Comport, A.I.;  Marchand, E.;  Pressigout, M.;  Chaumette, F.]]></authors>

<affiliations><![CDATA[IRISA-INRIA Rennes, France]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[least squares approximations]]></term>

<term><![CDATA[object detection]]></term>

<term><![CDATA[tracking]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Augmented reality]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Delay]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Machine vision]]></term>

<term><![CDATA[Real time systems]]></term>

<term><![CDATA[Robust control]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Visual servoing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[615]]></spage>

<epage><![CDATA[628]]></epage>

<abstract><![CDATA[Tracking is a very important research subject in a real-time augmented reality context. The main requirements for trackers are high accuracy and little latency at a reasonable cost. In order to address these issues, a real-time, robust, and efficient 3D model-based tracking algorithm is proposed for a "video see through" monocular vision system. The tracking of objects in the scene amounts to calculating the pose between the camera and the objects. Virtual objects can then be projected into the scene using the pose. In this paper, nonlinear pose estimation is formulated by means of a virtual visual servoing approach. In this context, the derivation of point-to-curves interaction matrices are given for different 3D geometrical primitives including straight lines, circles, cylinders, and spheres. A local moving edges tracker is used in order to provide real-time tracking of points normal to the object contours. Robustness is obtained by integrating an M-estimator into the visual control law via an iteratively reweighted least squares implementation. This approach is then extended to address the 3D model-free augmented reality problem. The method presented in this paper has been validated on several complex image sequences including outdoor environments. Results show the method to be robust to occlusion, changes in illumination, and mistracking.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634325]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.78]]></doi>

<publicationId><![CDATA[1634325]]></publicationId>

<partnum><![CDATA[1634325]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634325&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634325]]></pdf>

</document>

<document>

<rank>492</rank>

<title><![CDATA[Stable Anisotropic Materials]]></title>

<authors><![CDATA[Yijing Li;  Barbic, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[elasticity]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[mechanical stability]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Elasticity]]></term>

<term><![CDATA[Stability analysis]]></term>

<term><![CDATA[Strain]]></term>

<term><![CDATA[Symmetric matrices]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1129]]></spage>

<epage><![CDATA[1137]]></epage>

<abstract><![CDATA[The Finite Element Method (FEM) is commonly used to simulate isotropic deformable objects in computer graphics. Several applications (wood, plants, muscles) require modeling the directional dependence of the material elastic properties in three orthogonal directions. We investigate linear orthotropic materials, a special class of linear anisotropic materials where the shear stresses are decoupled from normal stresses, as well as general linear (non-orthotropic) anisotropic materials. Orthotropic materials generalize transversely isotropic materials, by exhibiting different stiffness in three orthogonal directions. Orthotropic materials are, however, parameterized by nine values that are difficult to tune in practice, as poorly adjusted settings easily lead to simulation instabilities. We present a user-friendly approach to setting these parameters that is guaranteed to be stable. Our approach is intuitive as it extends the familiar intuition known from isotropic materials. Similarly to linear orthotropic materials, we also derive a stability condition for a subset of general linear anisotropic materials, and give intuitive approaches to tuning them. In order to simulate large deformations, we augment linear corotational FEM simulations with our orthotropic and general anisotropic materials.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7130660]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2448105]]></doi>

<publicationId><![CDATA[7130660]]></publicationId>

<partnum><![CDATA[7130660]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7130660&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130660]]></pdf>

</document>

<document>

<rank>493</rank>

<title><![CDATA[Author Index IEEE Transactions on Visualization and Computer Graphics Vol. 20]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[xxvii]]></spage>

<epage><![CDATA[xxviii]]></epage>

<abstract><![CDATA[Presents the author index from this conference.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7307930]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2471375]]></doi>

<publicationId><![CDATA[7307930]]></publicationId>

<partnum><![CDATA[7307930]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7307930&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307930]]></pdf>

</document>

<document>

<rank>494</rank>

<title><![CDATA[Guest Editor' Introduction: Special Issue on the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games 2013]]></title>

<authors><![CDATA[Meenakshisundaram, G.;  Yoon, S.-E.]]></authors>

<affiliations><![CDATA[Department of Computer Science , University of California, Irvine,]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Special issues and sections]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[955]]></spage>

<epage><![CDATA[956]]></epage>

<abstract><![CDATA[The articles in this special were presented at the ACM Interactive 3D Graphics and Games (I3D) 2013 conference that was held March 21-23 in Orlando, FL.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6748102]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2307973]]></doi>

<publicationId><![CDATA[6748102]]></publicationId>

<partnum><![CDATA[6748102]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6748102&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6748102]]></pdf>

</document>

<document>

<rank>495</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4297682]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70417]]></doi>

<publicationId><![CDATA[4297682]]></publicationId>

<partnum><![CDATA[4297682]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297682&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297682]]></pdf>

</document>

<document>

<rank>496</rank>

<title><![CDATA[Real-Time Resolution of Self-Intersection in Dynamic Cylindrical Free-Form Deformation]]></title>

<authors><![CDATA[Woojin Ahn;  Doo Yong Lee]]></authors>

<affiliations><![CDATA[Dept. of Mech. Eng., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Detection algorithms]]></term>

<term><![CDATA[Jacobian matrices]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[Sufficient conditions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[515]]></spage>

<epage><![CDATA[526]]></epage>

<abstract><![CDATA[This paper presents a method of self-intersection detection and resolution for dynamic cylindrical-lattice-based free-form deformation (FFD). The lattice-based approach allows efficient computation of deformation of complex geometries. But excessive deformation can cause visual anomalies such as surface infiltration and distortion. This paper derives a geometrically intuitive sufficient condition to guarantee that the FFD function is a homeomorphism and there is no self-intersection. The FFD function is defined by linear and quadratic B-Spline functions with the control points of the cylindrical lattice cell. The sufficient condition is satisfied if each trilinear function of the nine prism-shaped pentahedrons derived from the cell has a positive Jacobian determinant. The positivity is satisfied if the 12 tetrahedrons derived from the pentahedron have positive volumes. Based on the sufficient condition, the proposed method converts the self-intersection problem into a point-face collision detection and response problem suitable for dynamic simulation. The efficiency and accuracy of the self-intersection detection algorithm is analyzed and compared with a previous method. The results show that the proposed technique allows simulation of excessive deformation of tubular objects in an efficient and realistic manner.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5438989]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.54]]></doi>

<publicationId><![CDATA[5438989]]></publicationId>

<partnum><![CDATA[5438989]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5438989&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5438989]]></pdf>

</document>

<document>

<rank>497</rank>

<title><![CDATA[Context-Preserving Visual Links]]></title>

<authors><![CDATA[Steinberger, M.;  Waldner, M.;  Streit, M.;  Lex, A.;  Schmalstieg, D.]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Image color analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2249]]></spage>

<epage><![CDATA[2258]]></epage>

<abstract><![CDATA[Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064990]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.183]]></doi>

<publicationId><![CDATA[6064990]]></publicationId>

<partnum><![CDATA[6064990]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064990&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064990]]></pdf>

</document>

<document>

<rank>498</rank>

<title><![CDATA[Sequential Document Visualization]]></title>

<authors><![CDATA[Yi Mao;  Dillon, J.V.;  Lebanon, G.]]></authors>

<affiliations><![CDATA[Purdue Univ., West Lafayette]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[document handling]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Amino acids]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Proteins]]></term>

<term><![CDATA[Statistics]]></term>

<term><![CDATA[Time series analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1208]]></spage>

<epage><![CDATA[1215]]></epage>

<abstract><![CDATA[Documents and other categorical valued time series are often characterized by the frequencies of short range sequential patterns such as n-grams. This representation converts sequential data of varying lengths to high dimensional histogram vectors which are easily modeled by standard statistical models. Unfortunately, the histogram representation ignores most of the medium and long range sequential dependencies making it unsuitable for visualizing sequential data. We present a novel framework for sequential visualization of discrete categorical time series based on the idea of local statistical modeling. The framework embeds categorical time series as smooth curves in the multinomial simplex summarizing the progression of sequential trends. We discuss several visualization techniques based on the above framework and demonstrate their usefulness for document visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376142]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70592]]></doi>

<publicationId><![CDATA[4376142]]></publicationId>

<partnum><![CDATA[4376142]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376142&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376142]]></pdf>

</document>

<document>

<rank>499</rank>

<title><![CDATA[VR Reviewers]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[xi]]></spage>

<epage><![CDATA[xi]]></epage>

<abstract><![CDATA[Presents a listing of the 2015 Virtual Realty Conference reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7064848]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2399594]]></doi>

<publicationId><![CDATA[7064848]]></publicationId>

<partnum><![CDATA[7064848]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7064848&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064848]]></pdf>

</document>

<document>

<rank>500</rank>

<title><![CDATA[International Program Committees]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xvii]]></spage>

<epage><![CDATA[xviii]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634148]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.171]]></doi>

<publicationId><![CDATA[6634148]]></publicationId>

<partnum><![CDATA[6634148]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634148&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634148]]></pdf>

</document>

<document>

<rank>501</rank>

<title><![CDATA[Editor&#x0027;s Note]]></title>

<authors><![CDATA[Igarashi, T.;  Klinker, G.;  Thomas, B.H.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1319]]></spage>

<epage><![CDATA[1320]]></epage>

<abstract><![CDATA[Presents the introductory editorial for this issue of the publication.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7299344]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2484498]]></doi>

<publicationId><![CDATA[7299344]]></publicationId>

<partnum><![CDATA[7299344]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7299344&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299344]]></pdf>

</document>

<document>

<rank>502</rank>

<title><![CDATA[Camera-based detection and removal of shadows from interactive multiprojector displays]]></title>

<authors><![CDATA[Jaynes, C.;  Webb, S.;  Steele, R.M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Kentucky Univ., Lexington, KY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[hidden feature removal]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[interactive terminals]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Calibration]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Large screen displays]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[290]]></spage>

<epage><![CDATA[301]]></epage>

<abstract><![CDATA[Front-projection displays are a cost-effective and increasingly popular method for large format visualization and immersive rendering of virtual models. New approaches to projector tiling, automatic calibration, and color balancing have made multiprojector display systems feasible without undue infrastructure changes and maintenance. As a result, front-projection displays are being used to generate seamless, visually immersive worlds for virtual reality and visualization applications with reasonable cost and maintenance overhead. However, these systems suffer from a fundamental problem: Users and other objects in the environment can easily and inadvertently block projectors, creating shadows on the displayed image. Shadows occlude potentially important information and detract from the sense of presence an immersive display may have conveyed. We introduce a technique that detects and corrects shadows in a multiprojector display while it is in use. Cameras observe the display and compare observations with an expected image to detect shadowed regions. These regions are transformed to the appropriate projector frames, where corresponding pixel values are increased and/or attenuated. In display regions where more than one projector contributes to the image, shadow regions are eliminated.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1272728]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1272728]]></doi>

<publicationId><![CDATA[1272728]]></publicationId>

<partnum><![CDATA[1272728]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1272728&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272728]]></pdf>

</document>

<document>

<rank>503</rank>

<title><![CDATA[City Forensics: Using Visual Elements to Predict Non-Visual City Attributes]]></title>

<authors><![CDATA[Arietta, S.M.;  Efros, A.A.;  Ramamoorthi, R.;  Agrawala, M.]]></authors>

<affiliations><![CDATA[EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[image processing]]></term>

<term><![CDATA[regression analysis]]></term>

<term><![CDATA[support vector machines]]></term>

<term><![CDATA[traffic engineering computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cities and towns]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Forensics]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Support vector machines]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2624]]></spage>

<epage><![CDATA[2633]]></epage>

<abstract><![CDATA[We present a method for automatically identifying and validating predictive relationships between the visual appearance of a city and its non-visual attributes (e.g. crime statistics, housing prices, population density etc.). Given a set of street-level images and (location, city-attribute-value) pairs of measurements, we first identify visual elements in the images that are discriminative of the attribute. We then train a predictor by learning a set of weights over these elements using non-linear Support Vector Regression. To perform these operations efficiently, we implement a scalable distributed processing framework that speeds up the main computational bottleneck (extracting visual elements) by an order of magnitude. This speedup allows us to investigate a variety of city attributes across 6 different American cities. We find that indeed there is a predictive relationship between visual elements and a number of city attributes including violent crime rates, theft rates, housing prices, population density, tree presence, graffiti presence, and the perception of danger. We also test human performance for predicting theft based on street-level images and show that our predictor outperforms this baseline with 33% higher accuracy on average. Finally, we present three prototype applications that use our system to (1) define the visual boundary of city neighborhoods, (2) generate walking directions that avoid or seek out exposure to city attributes, and (3) validate user-specified visual elements for prediction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875954]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346446]]></doi>

<publicationId><![CDATA[6875954]]></publicationId>

<partnum><![CDATA[6875954]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875954&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875954]]></pdf>

</document>

<document>

<rank>504</rank>

<title><![CDATA[Visualization of Cellular and Microvascular Relationships]]></title>

<authors><![CDATA[Mayerich, D.M.;  Abbott, L.;  Keyser, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Texas A&M Univ., College Station, TX]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[cellular biophysics]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Arteries]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Blood vessels]]></term>

<term><![CDATA[Cells (biology)]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Microscopy]]></term>

<term><![CDATA[Veins]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1611]]></spage>

<epage><![CDATA[1618]]></epage>

<abstract><![CDATA[Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658182]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.179]]></doi>

<publicationId><![CDATA[4658182]]></publicationId>

<partnum><![CDATA[4658182]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658182&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658182]]></pdf>

</document>

<document>

<rank>505</rank>

<title><![CDATA[A Multi-Threading Architecture to Support Interactive Visual Exploration]]></title>

<authors><![CDATA[Piringer, H.;  Tominski, C.;  Muigg, P.;  Berger, W.]]></authors>

<affiliations><![CDATA[VRVis Res. Center, Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[multi-threading]]></term>

<term><![CDATA[software architecture]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Communication system control]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Delay]]></term>

<term><![CDATA[Feedback]]></term>

<term><![CDATA[Frequency synchronization]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Manipulator dynamics]]></term>

<term><![CDATA[Navigation]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1113]]></spage>

<epage><![CDATA[1120]]></epage>

<abstract><![CDATA[During continuous user interaction, it is hard to provide rich visual feedback at interactive rates for datasets containing millions of entries. The contribution of this paper is a generic architecture that ensures responsiveness of the application even when dealing with large data and that is applicable to most types of information visualizations. Our architecture builds on the separation of the main application thread and the visualization thread, which can be cancelled early due to user interaction. In combination with a layer mechanism, our architecture facilitates generating previews incrementally to provide rich visual feedback quickly. To help avoiding common pitfalls of multi-threading, we discuss synchronization and communication in detail. We explicitly denote design choices to control trade-offs. A quantitative evaluation based on the system VI S P L ORE shows fast visual feedback during continuous interaction even for millions of entries. We describe instantiations of our architecture in additional tools.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290719]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.110]]></doi>

<publicationId><![CDATA[5290719]]></publicationId>

<partnum><![CDATA[5290719]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290719&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290719]]></pdf>

</document>

<document>

<rank>506</rank>

<title><![CDATA[Visualizing Nuclear Scission through a Multifield Extension of Topological Analysis]]></title>

<authors><![CDATA[Duke, D.;  Carr, H.;  Knoll, A.;  Schunck, N.;  Hai Ah Nam;  Staszczak, A.]]></authors>

<affiliations><![CDATA[Sch. of Comput., Univ. of Leeds, Leeds, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[density functional theory]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[fission]]></term>

<term><![CDATA[nuclear engineering computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Discrete Fourier transforms]]></term>

<term><![CDATA[Nuclear physics]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2033]]></spage>

<epage><![CDATA[2040]]></epage>

<abstract><![CDATA[In nuclear science, density functional theory (DFT) is a powerful tool to model the complex interactions within the atomic nucleus, and is the primary theoretical approach used by physicists seeking a better understanding of fission. However DFT simulations result in complex multivariate datasets in which it is difficult to locate the crucial `scission' point at which one nucleus fragments into two, and to identify the precursors to scission. The Joint Contour Net (JCN) has recently been proposed as a new data structure for the topological analysis of multivariate scalar fields, analogous to the contour tree for univariate fields. This paper reports the analysis of DFT simulations using the JCN, the first application of the JCN technique to real data. It makes three contributions to visualization: (i) a set of practical methods for visualizing the JCN, (ii) new insight into the detection of nuclear scission, and (iii) an analysis of aesthetic criteria to drive further work on representing the JCN.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327207]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.287]]></doi>

<publicationId><![CDATA[6327207]]></publicationId>

<partnum><![CDATA[6327207]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327207&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327207]]></pdf>

</document>

<document>

<rank>507</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on the IEEE Symposium on Visual Analytics Science and Technology (VAST)]]></title>

<authors><![CDATA[Ertl, Thomas]]></authors>

<thesaurusterms>

<term><![CDATA[Collaborative tools]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Sections]]></term>

<term><![CDATA[Senior members]]></term>

<term><![CDATA[User interfaces]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[177]]></spage>

<epage><![CDATA[177]]></epage>

<abstract><![CDATA[The three papers in this special section were originally presented at the IEEE Symposium on Visual Analytics Science and Technology (VAST) in Columbus, Ohio, in October 2008.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5380817]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.16]]></doi>

<publicationId><![CDATA[5380817]]></publicationId>

<partnum><![CDATA[5380817]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5380817&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380817]]></pdf>

</document>

<document>

<rank>508</rank>

<title><![CDATA[Open-Box Spectral Clustering: Applications to Medical Image Analysis]]></title>

<authors><![CDATA[Schultz, T.;  Kindlmann, G.L.]]></authors>

<affiliations><![CDATA[Univ. of Bonn, Bonn, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Eigenvalues and eigenfunctions]]></term>

<term><![CDATA[Image analysis]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Laplace equations]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2100]]></spage>

<epage><![CDATA[2108]]></epage>

<abstract><![CDATA[Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634089]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.181]]></doi>

<publicationId><![CDATA[6634089]]></publicationId>

<partnum><![CDATA[6634089]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634089&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634089]]></pdf>

</document>

<document>

<rank>509</rank>

<title><![CDATA[Efficient streamline, streamribbon, and streamtube constructions on unstructured grids]]></title>

<authors><![CDATA[Shyh-Kuang Ueng;  Sikorski, C.;  Ma, K.-L.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Runge-Kutta methods]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[difference equations]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[physics]]></term>

<term><![CDATA[physics computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cities and towns]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Computer applications]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Convergence]]></term>

<term><![CDATA[Differential equations]]></term>

<term><![CDATA[NASA]]></term>

<term><![CDATA[Postal services]]></term>

<term><![CDATA[Vectors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[100]]></spage>

<epage><![CDATA[110]]></epage>

<abstract><![CDATA[Streamline construction is one of the most fundamental techniques for visualizing steady flow fields. Streamribbons and streamtubes are extensions for visualizing the rotation and the expansion of the flow. The paper presents efficient algorithms for constructing streamlines, streamribbons, and streamtubes on unstructured grids. A specialized Runge-Kutta method is developed to speed up the tracing of streamlines. Explicit solutions are derived for calculating the angular rotation rates of streamribbons and the radii of streamtubes. In order to simplify mathematical formulations and reduce computational costs, all calculations are carried out in the canonical coordinate system instead of the physical coordinate system. The resulting speed up in overall performance helps explore large flow fields]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[506222]]></arnumber>

<doi><![CDATA[10.1109/2945.506222]]></doi>

<publicationId><![CDATA[506222]]></publicationId>

<partnum><![CDATA[506222]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=506222&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506222]]></pdf>

</document>

<document>

<rank>510</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5872085]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.89]]></doi>

<publicationId><![CDATA[5872085]]></publicationId>

<partnum><![CDATA[5872085]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5872085&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5872085]]></pdf>

</document>

<document>

<rank>511</rank>

<title><![CDATA[Ambiguity-Free Edge-Bundling for Interactive Graph Visualization]]></title>

<authors><![CDATA[Sheng-Jie Luo;  Chun-Liang Liu;  Bing-Yu Chen;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Nat. Taiwan Univ., Taipei, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clutter]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Routing]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[810]]></spage>

<epage><![CDATA[821]]></epage>

<abstract><![CDATA[Graph visualization has been widely used to understand and present both global structural and local adjacency information in relational data sets (e.g., transportation networks, citation networks, or social networks). Graphs with dense edges, however, are difficult to visualize because fast layout and good clarity are not always easily achieved. When the number of edges is large, edge bundling can be used to improve the clarity, but in many cases, the edges could be still too cluttered to permit correct interpretation of the relations between nodes. In this paper, we present an ambiguity-free edge-bundling method especially for improving local detailed view of a complex graph. Our method makes more efficient use of display space and supports detail-on-demand viewing through an interactive interface. We demonstrate the effectiveness of our method with public coauthorship network data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5887331]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.104]]></doi>

<publicationId><![CDATA[5887331]]></publicationId>

<partnum><![CDATA[5887331]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5887331&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887331]]></pdf>

</document>

<document>

<rank>512</rank>

<title><![CDATA[Novel interaction techniques for neurosurgical planning and stereotactic navigation]]></title>

<authors><![CDATA[Joshi, A.;  Scheinost, D.;  Vives, K.P.;  Spencer, D.D.;  Staib, L.H.;  Papademetris, X.]]></authors>

<affiliations><![CDATA[Dept. of Diagnostic Radiol., Yale Sch. of Med., New Haven, CT]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[surgery]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Electrodes]]></term>

<term><![CDATA[Epilepsy]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Neurosurgery]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Single photon emission computed tomography]]></term>

<term><![CDATA[Surgery]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1587]]></spage>

<epage><![CDATA[1594]]></epage>

<abstract><![CDATA[Neurosurgical planning and image guided neurosurgery require the visualization of multimodal data obtained from various functional and structural image modalities, such as magnetic resonance imaging (MRI), computed tomography (CT), functional MRI, Single photon emission computed tomography (SPECT) and so on. In the case of epilepsy neurosurgery for example, these images are used to identify brain regions to guide intracranial electrode implantation and resection. Generally, such data is visualized using 2D slices and in some cases using a 3D volume rendering along with the functional imaging results. Visualizing the activation region effectively by still preserving sufficient surrounding brain regions for context is exceedingly important to neurologists and surgeons. We present novel interaction techniques for visualization of multimodal data to facilitate improved exploration and planning for neurosurgery. We extended the line widget from VTK to allow surgeons to control the shape of the region of the brain that they can visually crop away during exploration and surgery. We allow simple spherical, cubical, ellipsoidal and cylindrical (probe aligned cuts) for exploration purposes. In addition we integrate the cropping tool with the image-guided navigation system used for epilepsy neurosurgery. We are currently investigating the use of these new tools in surgical planning and based on further feedback from our neurosurgeons we will integrate them into the setup used for image-guided neurosurgery.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658179]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.150]]></doi>

<publicationId><![CDATA[4658179]]></publicationId>

<partnum><![CDATA[4658179]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658179&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658179]]></pdf>

</document>

<document>

<rank>513</rank>

<title><![CDATA[Planetary-Scale Terrain Composition]]></title>

<authors><![CDATA[Kooima, R.;  Leigh, J.;  Johnson, A.;  Roberts, D.;  SubbaRao, M.;  DeFanti, T.A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. (MC 152), Univ. of Illinois at Chicago, Chicago, IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[terrain mapping]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[719]]></spage>

<epage><![CDATA[733]]></epage>

<abstract><![CDATA[Many interrelated planetary height map and surface image map data sets exist, and more data are collected each day. Broad communities of scientists require tools to compose these data interactively and explore them via real-time visualization. While related, these data sets are often unregistered with one another, having different projection, resolution, format, and type. We present a GPU-centric approach to the real-time composition and display of unregistered-but-related planetary-scale data. This approach employs a GPGPU process to tessellate spherical height fields. It uses a render-to-vertex-buffer technique to operate upon polygonal surface meshes in image space, allowing geometry processes to be expressed in terms of image processing. With height and surface map data processing unified in this fashion, a number of powerful composition operations may be uniformly applied to both. Examples include adaptation to nonuniform sampling due to projection, seamless blending of data of disparate resolution or transformation regardless of boundary, and the smooth interpolation of levels of detail in both geometry and imagery. Issues of scalability and precision are addressed, giving out-of-core access to giga-pixel data sources, and correct rendering at scales approaching one meter.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4840339]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.43]]></doi>

<publicationId><![CDATA[4840339]]></publicationId>

<partnum><![CDATA[4840339]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4840339&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4840339]]></pdf>

</document>

<document>

<rank>514</rank>

<title><![CDATA[Per-Pixel Opacity Modulation for Feature Enhancement in Volume Rendering]]></title>

<authors><![CDATA[Marchesin, S.;  Dischler, J.-M.;  Mongenet, C.]]></authors>

<affiliations><![CDATA[Lab. des Sci. de I''Image, de I''lnformatique et de la Teledetection, Univ. de Strasbourg, Strasbourg, France]]></affiliations>

<controlledterms>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image enhancement]]></term>

<term><![CDATA[opacity]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[560]]></spage>

<epage><![CDATA[570]]></epage>

<abstract><![CDATA[Classical direct volume rendering techniques accumulate color and opacity contributions using the standard volume rendering equation approximated by alpha blending. However, such standard rendering techniques, often also aiming at visual realism, are not always adequate for efficient data exploration, especially when large opaque areas are present in a data set, since such areas can occlude important features and make them invisible. On the other hand, the use of highly transparent transfer functions allows viewing all the features at once, but often makes these features barely visible. In order to enhance feature visibility, we present in this paper a straightforward rendering technique that consists of modifying the traditional volume rendering equation. Our approach does not require an opacity transfer function, and instead is based on a function quantifying the relative importance of each voxel in the final rendering called relevance function. This function is subsequently used to dynamically adjust the opacity of the contributions per pixel. We conduct experiments with a number of possible relevance functions in order to show the influence of this parameter. As will be shown by our comparative study, our rendering method is much more suitable than standard volume rendering for interactive data exploration at a low extra cost. Thereby, our method avoids feature visibility restrictions without relying on a transfer function and yet maintains a visual similarity with standard volume rendering.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5406522]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.30]]></doi>

<publicationId><![CDATA[5406522]]></publicationId>

<partnum><![CDATA[5406522]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5406522&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406522]]></pdf>

</document>

<document>

<rank>515</rank>

<title><![CDATA[Human Motion Capture Data Tailored Transform Coding]]></title>

<authors><![CDATA[Junhui Hou;  Lap-Pui Chau;  Magnenat-Thalmann, N.;  Ying He]]></authors>

<affiliations><![CDATA[Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[data compression]]></term>

<term><![CDATA[discrete cosine transforms]]></term>

<term><![CDATA[image coding]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[video coding]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Discrete cosine transforms]]></term>

<term><![CDATA[Silicon]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Transform coding]]></term>

<term><![CDATA[Videos]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[848]]></spage>

<epage><![CDATA[859]]></epage>

<abstract><![CDATA[Human motion capture (mocap) is a widely used technique for digitalizing human movements. With growing usage, compressing mocap data has received increasing attention, since compact data size enables efficient storage and transmission. Our analysis shows that mocap data have some unique characteristics that distinguish themselves from images and videos. Therefore, directly borrowing image or video compression techniques, such as discrete cosine transform, does not work well. In this paper, we propose a novel mocap-tailored transform coding algorithm that takes advantage of these features. Our algorithm segments the input mocap sequences into clips, which are represented in 2D matrices. Then it computes a set of data-dependent orthogonal bases to transform the matrices to frequency domain, in which the transform coefficients have significantly less dependency. Finally, the compression is obtained by entropy coding of the quantized coefficients and the bases. Our method has low computational cost and can be easily extended to compress mocap databases. It also requires neither training nor complicated parameter setting. Experimental results demonstrate that the proposed scheme significantly outperforms state-of-the-art algorithms in terms of compression performance and speed.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7042272]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2403328]]></doi>

<publicationId><![CDATA[7042272]]></publicationId>

<partnum><![CDATA[7042272]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7042272&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042272]]></pdf>

</document>

<document>

<rank>516</rank>

<title><![CDATA[TimeLineCurator: Interactive Authoring of Visual Timelines from Unstructured Text]]></title>

<authors><![CDATA[Fulda, J.;  Brehmer, M.;  Munzner, T.]]></authors>

<controlledterms>

<term><![CDATA[authoring systems]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[natural language processing]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Manuals]]></term>

<term><![CDATA[Natural language processing]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[300]]></spage>

<epage><![CDATA[309]]></epage>

<abstract><![CDATA[We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192669]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467531]]></doi>

<publicationId><![CDATA[7192669]]></publicationId>

<partnum><![CDATA[7192669]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192669&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192669]]></pdf>

</document>

<document>

<rank>517</rank>

<title><![CDATA[Interpolation over arbitrary topology meshes using a two-phase subdivision scheme]]></title>

<authors><![CDATA[Jianmin Zheng;  Yiyu Cai]]></authors>

<affiliations><![CDATA[Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[splines (mathematics)]]></term>

<term><![CDATA[surface fitting]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Electrical equipment industry]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface topography]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[301]]></spage>

<epage><![CDATA[310]]></epage>

<abstract><![CDATA[The construction of a smooth surface interpolating a mesh of arbitrary topological type is an important problem in many graphics applications. This paper presents a two-phase process, based on a topological modification of the control mesh and a subsequent Catmull-Clark subdivision, to construct a smooth surface that interpolates some or all of the vertices of a mesh with arbitrary topology. It is also possible to constrain the surface to have specified tangent planes at an arbitrary subset of the vertices to be interpolated. The method has the following features: 1) it is guaranteed to always work and the computation is numerically stable, 2) there is no need to solve a system of linear equations and the whole computation complexity is O(K) where K is the number of the vertices, and 3) each vertex can be associated with a scalar shape handle for local shape control. These features make interpolation using Catmull-Clark surfaces simple and, thus, make the new method itself suitable for interactive free-form shape design.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1608017]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.49]]></doi>

<publicationId><![CDATA[1608017]]></publicationId>

<partnum><![CDATA[1608017]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1608017&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608017]]></pdf>

</document>

<document>

<rank>518</rank>

<title><![CDATA[Physics-Based Subsurface Visualization of Human Tissue]]></title>

<authors><![CDATA[Sharp, R.;  Adams, J.;  Machiraju, R.;  Lee, R.;  Crane, R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH]]></affiliations>

<controlledterms>

<term><![CDATA[bio-optics]]></term>

<term><![CDATA[biodiffusion]]></term>

<term><![CDATA[biomedical optical imaging]]></term>

<term><![CDATA[blood]]></term>

<term><![CDATA[cancer]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[infrared imaging]]></term>

<term><![CDATA[light scattering]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[permeability]]></term>

<term><![CDATA[phantoms]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[tumours]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Blood]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Light scattering]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Neoplasms]]></term>

<term><![CDATA[Numerical models]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[620]]></spage>

<epage><![CDATA[629]]></epage>

<abstract><![CDATA[In this paper, we present a framework for simulating light transport in three-dimensional tissue with inhomogeneous scattering properties. Our approach employs a computational model to simulate light scattering in tissue through the finite element solution of the diffusion equation. Although our model handles both visible and nonvisible wavelengths, we especially focus on the interaction of near infrared (NIR) light with tissue. Since most human tissue is permeable to NIR light, tools to noninvasively image tumors, blood vasculature, and monitor blood oxygenation levels are being constructed. We apply this model to a numerical phantom to visually reproduce the images generated by these real-world tools. Therefore, in addition to enabling inverse design of detector instruments, our computational tools produce physically-accurate visualizations of subsurface structures]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4297691]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1003]]></doi>

<publicationId><![CDATA[4297691]]></publicationId>

<partnum><![CDATA[4297691]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297691&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297691]]></pdf>

</document>

<document>

<rank>519</rank>

<title><![CDATA[Rethinking Map Legends with Visualization]]></title>

<authors><![CDATA[Dykes, J.;  Wood, J.;  Slingsby, A.]]></authors>

<affiliations><![CDATA[Dept. of Inf. Sci., City Univ. London, London, UK]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geospatial analysis]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[890]]></spage>

<epage><![CDATA[899]]></epage>

<abstract><![CDATA[This design paper presents new guidance for creating map legends in a dynamic environment. Our contribution is a set ofguidelines for legend design in a visualization context and a series of illustrative themes through which they may be expressed. Theseare demonstrated in an applications context through interactive software prototypes. The guidelines are derived from cartographicliterature and in liaison with EDINA who provide digital mapping services for UK tertiary education. They enhance approaches tolegend design that have evolved for static media with visualization by considering: selection, layout, symbols, position, dynamismand design and process. Broad visualization legend themes include: The Ground Truth Legend, The Legend as Statistical Graphicand The Map is the Legend. Together, these concepts enable us to augment legends with dynamic properties that address specificneeds, rethink their nature and role and contribute to a wider re-evaluation of maps as artifacts of usage rather than statements offact. EDINA has acquired funding to enhance their clients with visualization legends that use these concepts as a consequence ofthis work. The guidance applies to the design of a wide range of legends and keys used in cartography and information visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613425]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.191]]></doi>

<publicationId><![CDATA[5613425]]></publicationId>

<partnum><![CDATA[5613425]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613425&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613425]]></pdf>

</document>

<document>

<rank>520</rank>

<title><![CDATA[A Framework for 3D Model-Based Visual Tracking Using a GPU-Accelerated Particle Filter]]></title>

<authors><![CDATA[Brown, J.A.;  Capson, D.W.]]></authors>

<affiliations><![CDATA[Dept. of Electr. & Comput. Eng., McMaster Univ., Hamilton, ON, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[object tracking]]></term>

<term><![CDATA[particle filtering (numerical methods)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Target tracking]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[68]]></spage>

<epage><![CDATA[80]]></epage>

<abstract><![CDATA[A novel framework for acceleration of particle filtering approaches to 3D model-based, markerless visual tracking in monocular video is described. Specifically, we present a methodology for partitioning and mapping the computationally expensive weight-update stage of a particle filter to a graphics processing unit (GPU) to achieve particle- and pixel-level parallelism. Nvidia CUDA and Direct3D are employed to harness the massively parallel computational power of modern GPUs for simulation (3D model rendering) and evaluation (segmentation, feature extraction, and weight calculation) of hundreds of particles at high speeds. The proposed framework addresses the computational intensity that is intrinsic to all particle filter approaches, including those that have been modified to minimize the number of particles required for a particular task. Performance and tracking quality results for rigid object and articulated hand tracking experiments demonstrate markerless, model-based visual tracking on consumer-grade graphics hardware with pixel-level accuracy up to 95 percent at 60+ frames per second. The framework accelerates particle evaluation up to 49 times over a comparable CPU-only implementation, providing an increased particle count while maintaining real-time frame rates.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5710904]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.34]]></doi>

<publicationId><![CDATA[5710904]]></publicationId>

<partnum><![CDATA[5710904]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5710904&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710904]]></pdf>

</document>

<document>

<rank>521</rank>

<title><![CDATA[Vision-an architecture for global illumination calculations]]></title>

<authors><![CDATA[Slusallek, P.;  Seidel, H.-P.]]></authors>

<affiliations><![CDATA[Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[brightness]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[object-oriented methods]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Differential equations]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Integral equations]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Object oriented modeling]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[77]]></spage>

<epage><![CDATA[96]]></epage>

<abstract><![CDATA[So far, the problem of global illumination calculation has almost exclusively been approached from an algorithmic point of view. We propose an architectural approach to global illumination. The proposed rendering architecture Vision is derived from a model of the physical rendering process, which is subsequently mapped onto an object-oriented hierarchy of classes. This design is powerful and flexible enough to support and exploit a large body of existing illumination algorithms for the simulation of various aspects of the underlying physical model. Additionally, the Vision architecture offers a platform for developing new algorithms and for combining them to create new rendering solutions. We discuss both abstract design as well as implementation issues. In particular, we give a detailed description of the global lighting subsystem and show how algorithms for path tracing, bidirectional estimators, irradiance caching, hierarchical radiosity, wavelet radiosity, and wavelet radiance have been implemented within Vision]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[468387]]></arnumber>

<doi><![CDATA[10.1109/2945.468387]]></doi>

<publicationId><![CDATA[468387]]></publicationId>

<partnum><![CDATA[468387]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=468387&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468387]]></pdf>

</document>

<document>

<rank>522</rank>

<title><![CDATA[Motion Imitation with a Handheld Camera]]></title>

<authors><![CDATA[Guofeng Zhang;  Hanqing Jiang;  Jin Huang;  Jiaya Jia;  Tien-Tsin Wong;  Kun Zhou;  Hujun Bao]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[cameras]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Target tracking]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1475]]></spage>

<epage><![CDATA[1486]]></epage>

<abstract><![CDATA[In this paper, we present a novel method to extract motion of a dynamic object from a video that is captured by a handheld camera, and apply it to a 3D character. Unlike the motion capture techniques, neither special sensors/trackers nor a controllable environment is required. Our system significantly automates motion imitation which is traditionally conducted by professional animators via manual keyframing. Given the input video sequence, we track the dynamic reference object to obtain trajectories of both 2D and 3D tracking points. With them as constraints, we then transfer the motion to the target 3D character by solving an optimization problem to maintain the motion gradients. We also provide a user-friendly editing environment for users to fine tune the motion details. As casual videos can be used, our system, therefore, greatly increases the supply source of motion data. Examples of imitating various types of animal motion are shown.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5887298]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.254]]></doi>

<publicationId><![CDATA[5887298]]></publicationId>

<partnum><![CDATA[5887298]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5887298&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887298]]></pdf>

</document>

<document>

<rank>523</rank>

<title><![CDATA[Subjective Quantification of Perceptual Interactions among some 2D Scientific Visualization Methods]]></title>

<authors><![CDATA[Acevedo, D.;  Laidlaw, D.H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Brown Univ., Providence, RI]]></affiliations>

<controlledterms>

<term><![CDATA[Poisson distribution]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brightness]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Design optimization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Interference]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1133]]></spage>

<epage><![CDATA[1140]]></epage>

<abstract><![CDATA[We present an evaluation of a parameterized set of 2D icon-based visualization methods where we quantified how perceptual interactions among visual elements affect effective data exploration. During the experiment, subjects quantified three different design factors for each method: the spatial resolution it could represent, the number of data values it could display at each point, and the degree to which it is visually linear. The class of visualization methods includes Poisson-disk distributed icons where icon size, icon spacing, and icon brightness can be set to a constant or coupled to data values from a 2D scalar field. By only coupling one of those visual components to data, we measured filtering interference for all three design factors. Filtering interference characterizes how different levels of the constant visual elements affect the evaluation of the data-coupled element. Our novel experimental methodology allowed us to generalize this perceptual information, gathered using ad-hoc artificial datasets, onto quantitative rules for visualizing real scientific datasets. This work also provides a framework for evaluating visualizations of multi-valued data that incorporate additional visual cues, such as icon orientation or color]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015474]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.180]]></doi>

<publicationId><![CDATA[4015474]]></publicationId>

<partnum><![CDATA[4015474]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015474&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015474]]></pdf>

</document>

<document>

<rank>524</rank>

<title><![CDATA[Visualizing Nonmanifold and Singular Implicit Surfaces with Point Clouds]]></title>

<authors><![CDATA[Balsys, R.J.;  Harbinson, D.J.;  Suffern, K.G.]]></authors>

<affiliations><![CDATA[Centre for Intell. & Networked Syst., Central Queensland Univ., Rockhampton, QLD, Australia]]></affiliations>

<controlledterms>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[octrees]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Octrees]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[188]]></spage>

<epage><![CDATA[201]]></epage>

<abstract><![CDATA[We use octree spatial subdivision to generate point clouds on complex nonmanifold implicit surfaces in order to visualize them. The new spatial subdivision scheme only uses point sampling and an interval exclusion test. The algorithm includes a test for pruning the resulting plotting nodes so that only points in the closest nodes to the surface are used in rendering. This algorithm results in improved image quality compared to the naive use of intervals or affine arithmetic when rendering implicit surfaces, particularly in regions of high curvature. We discuss and compare CPU and GPU versions of the algorithm. We can now render nonmanifold features such as rays, ray-like tubes, cusps, ridges, thin sections that are at arbitrary angles to the octree node edges, and singular points located within plot nodes, all without artifacts. Our previous algorithm could not render these without severe aliasing. The algorithm can render the self-intersection curves of implicit surfaces by exploiting the fact that surfaces are singular where they self-intersect. It can also render the intersection curves of two implicit surfaces. We present new image space and object space algorithms for rendering these intersection curves as contours on one of the surfaces. These algorithms are better at rendering high curvature contours than our previous algorithms. To demonstrate the robustness of the node pruning algorithm we render a number of complex implicit surfaces such as high order polynomial surfaces and Gaussian curvature surfaces. We also compare the algorithm with ray casting in terms of speed and image quality. For the surfaces presented here, the point clouds can be computed in seconds to minutes on a typical Intel based PC. Once this is done, the surfaces can be rendered at much higher frame rates to allow some degree of interactive visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5753895]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.79]]></doi>

<publicationId><![CDATA[5753895]]></publicationId>

<partnum><![CDATA[5753895]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5753895&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753895]]></pdf>

</document>

<document>

<rank>525</rank>

<title><![CDATA[A Survey on Hair Modeling: Styling, Simulation, and Rendering]]></title>

<authors><![CDATA[Ward, K.;  Bertails, Florence;  Kim, T.-Y.;  Marschner, S.R.;  Cani, M.-P.;  Lin, M.C.]]></authors>

<affiliations><![CDATA[Walt Disney Feature Animation, Burbank, CA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Hair]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Light scattering]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[213]]></spage>

<epage><![CDATA[234]]></epage>

<abstract><![CDATA[Realistic hair modeling is a fundamental part of creating virtual humans in computer graphics. This paper surveys the state of the art in the major topics of hair modeling: hairstyling, hair simulation, and hair rendering. Because of the difficult, often unsolved problems that arise in alt these areas, a broad diversity of approaches is used, each with strengths that make it appropriate for particular applications. We discuss each of these major topics in turn, presenting the unique challenges facing each area and describing solutions that have been presented over the years to handle these complex issues. Finally, we outline some of the remaining computational challenges in hair modeling]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4069232]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.30]]></doi>

<publicationId><![CDATA[4069232]]></publicationId>

<partnum><![CDATA[4069232]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4069232&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069232]]></pdf>

</document>

<document>

<rank>526</rank>

<title><![CDATA[An Effective Illustrative Visualization Framework Based on Photic Extremum Lines (PELs)]]></title>

<authors><![CDATA[Xuexiang Xie;  Ying He;  Feng Tian;  Hock-Soon Seah;  Xianfeng Gu;  Hong Qin]]></authors>

<affiliations><![CDATA[Nanyang Technol. Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[edge detection]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1328]]></spage>

<epage><![CDATA[1335]]></epage>

<abstract><![CDATA[Conveying shape using feature lines is an important visualization tool in visual computing. The existing feature lines (e.g., ridges, valleys, silhouettes, suggestive contours, etc.) are solely determined by local geometry properties (e.g., normals and curvatures) as well as the view position. This paper is strongly inspired by the observation in human vision and perception that a sudden change in the luminance plays a critical role to faithfully represent and recover the 3D information. In particular, we adopt the edge detection techniques in image processing for 3D shape visualization and present photic extremum lines (PELs) which emphasize significant variations of illumination over 3D surfaces. Comparing with the existing feature lines, PELs are more flexible and offer users more freedom to achieve desirable visualization effects. In addition, the user can easily control the shape visualization by changing the light position, the number of light sources, and choosing various light models. We compare PELs with the existing approaches and demonstrate that PEL is a flexible and effective tool to illustrate 3D surface and volume for visual computing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376158]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70538]]></doi>

<publicationId><![CDATA[4376158]]></publicationId>

<partnum><![CDATA[4376158]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376158&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376158]]></pdf>

</document>

<document>

<rank>527</rank>

<title><![CDATA[Real-time 3D human capture system for mixed-reality art and entertainment]]></title>

<authors><![CDATA[Nguyen, T.H.D.;  Qui, T.C.T.;  Xu, K.;  Cheok, A.D.;  Teo, S.L.;  Zhou, Z.Y.;  Mallawaarachchi, A.;  Lee, S.P.;  Liu, W.;  Teo, H.S.;  Thang, L.N.;  Li, Y.;  Kato, H.]]></authors>

<affiliations><![CDATA[Res. Techno Plaza, Nanyang Technol. Univ., Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[entertainment]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[helmet mounted displays]]></term>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[teleconferencing]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Art]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Microcomputers]]></term>

<term><![CDATA[Real time systems]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[706]]></spage>

<epage><![CDATA[721]]></epage>

<abstract><![CDATA[A real-time system for capturing humans in 3D and placing them into a mixed reality environment is presented in this paper. Nine cameras surrounding her capture the subject. Looking through a head-mounted-display with a camera in front pointing at a marker, the user can see the 3D image of this subject overlaid onto a mixed reality scene. The 3D images of the subject viewed from this viewpoint are constructed using a robust and fast shape-from-silhouette algorithm. The paper also presents several techniques to produce good quality and speed up the whole system. The frame rate of our system is around 25 fps using only standard Intel processor-based personal computers. Besides a remote live 3D conferencing and collaborating system, we also describe an application of the system in art and entertainment, named Magic Land, which is a mixed reality environment where captured avatars of human and 3D computer generated virtual animations can form an interactive story and play with each other. This system demonstrates many technologies in human computer interaction: mixed reality, tangible interaction, and 3D communication. The result of the user study not only emphasizes the benefits, but also addresses some issues of these technologies.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512021]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.105]]></doi>

<publicationId><![CDATA[1512021]]></publicationId>

<partnum><![CDATA[1512021]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512021&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512021]]></pdf>

</document>

<document>

<rank>528</rank>

<title><![CDATA[Activity Detection in Scientific Visualization]]></title>

<authors><![CDATA[Ozer, S.;  Silver, D.;  Bemis, K.;  Martin, P.]]></authors>

<affiliations><![CDATA[Dept. of Electr. & Comput. Eng., Rutgers Univ., Piscataway, NJ, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer vision]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[object detection]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Petri nets]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[377]]></spage>

<epage><![CDATA[390]]></epage>

<abstract><![CDATA[For large-scale simulations, the data sets are so massive that it is sometimes not feasible to view the data with basic visualization methods, let alone explore all time steps in detail. Automated tools are necessary for knowledge discovery, i.e., to help sift through the data and isolate specific time steps that can then be further explored. Scientists study patterns and interactions and want to know when and where interesting things happen. Activity detection, the detection of specific interactions of objects which span a limited duration of time, has been an active research area in the computer vision community. In this paper, we introduce activity detection to scientific simulations and show how it can be utilized in scientific visualization. We show how activity detection allows a scientist to model an activity and can then validate their hypothesis on the underlying processes. Three case studies are presented.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6583163]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.117]]></doi>

<publicationId><![CDATA[6583163]]></publicationId>

<partnum><![CDATA[6583163]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6583163&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6583163]]></pdf>

</document>

<document>

<rank>529</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4015413]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.129]]></doi>

<publicationId><![CDATA[4015413]]></publicationId>

<partnum><![CDATA[4015413]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015413&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015413]]></pdf>

</document>

<document>

<rank>530</rank>

<title><![CDATA[Improving contact realism through event-based haptic feedback]]></title>

<authors><![CDATA[Kuchenbecker, K.J.;  Fiene, J.;  Niemeyer, G.]]></authors>

<affiliations><![CDATA[Dept. of Mech. Eng., Stanford Univ., CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[force feedback]]></term>

<term><![CDATA[haptic interfaces]]></term>

<term><![CDATA[realistic images]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Force feedback]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Material properties]]></term>

<term><![CDATA[Muscles]]></term>

<term><![CDATA[Pressing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[219]]></spage>

<epage><![CDATA[230]]></epage>

<abstract><![CDATA[Tapping on surfaces in a typical virtual environment feels like contact with soft foam rather than a hard object. The realism of such interactions can be dramatically improved by superimposing event-based, high-frequency transient forces over traditional position-based feedback. When scaled by impact velocity, hand-tuned pulses and decaying sinusoids produce haptic cues that resemble those experienced during real impacts. Our new method for generating appropriate transients inverts a dynamic model of the haptic device to determine the motor forces required to create prerecorded acceleration profiles at the user's fingertips. After development, the event-based haptic paradigm and the method of acceleration matching were evaluated in a carefully controlled user study. Sixteen individuals blindly tapped on nine virtual and three real samples, rating the degree to which each felt like real wood. Event-based feedback achieved significantly higher realism ratings than the traditional rendering method. The display of transient signals made virtual objects feel similar to a real sample of wood on a foam substrate, while position feedback alone received ratings similar to those of foam. This work provides an important new avenue for increasing the realism of contact in haptic interactions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1580456]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.32]]></doi>

<publicationId><![CDATA[1580456]]></publicationId>

<partnum><![CDATA[1580456]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580456&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580456]]></pdf>

</document>

<document>

<rank>531</rank>

<title><![CDATA[On Mesh-Free Valley Surface Extraction with Application to Low Frequency Sound Simulation]]></title>

<authors><![CDATA[Obermaier, H.;  Mohring, J.;  Deines, E.;  Hering-Bertram, M.;  Hagen, H.]]></authors>

<affiliations><![CDATA[Univ. of California Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[acoustic noise]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acoustics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Linear approximation]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[270]]></spage>

<epage><![CDATA[282]]></epage>

<abstract><![CDATA[Crease surfaces describe extremal structures of 3D scalar fields. We present a new region-growing-based approach to the meshless extraction of adaptive nonmanifold valley and ridge surfaces that overcomes limitations of previous approaches by decoupling point seeding and triangulation of the surface. Our method is capable of extracting valley surface skeletons as connected minimum structures. As our algorithm is inherently mesh-free and curvature adaptive, it is suitable for surface construction in fields with an arbitrary neighborhood structure. As an application for insightful visualization with valley surfaces, we choose a low frequency acoustics simulation. We use our valley surface construction approach to visualize the resulting complex-valued scalar pressure field for arbitrary frequencies to identify regions of sound cancellation. This provides an expressive visualization of the topology of wave node and antinode structures in simulated acoustics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5887325]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.98]]></doi>

<publicationId><![CDATA[5887325]]></publicationId>

<partnum><![CDATA[5887325]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5887325&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887325]]></pdf>

</document>

<document>

<rank>532</rank>

<title><![CDATA[Corrections to &#x0201C;A Physiologically-Based Model for Simulation of Color Vision Deficiency&#x0201C; [Nov-Dec 09 1291-1298]]]></title>

<authors><![CDATA[Machado, Gustavo M.;  Oliveira, M.M.;  Fernandes, Leandro A.F.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[352]]></spage>

<epage><![CDATA[352]]></epage>

<abstract><![CDATA[In the above titled paper (ibid., vol. 15, no. 6, pp. 1291-1298, Nov./Dec. 09), there were typos in equations (17) and (18). The correct versions are presented here.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5380819]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.10]]></doi>

<publicationId><![CDATA[5380819]]></publicationId>

<partnum><![CDATA[5380819]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5380819&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380819]]></pdf>

</document>

<document>

<rank>533</rank>

<title><![CDATA[Tissue classification based on 3D local intensity structures for volume rendering]]></title>

<authors><![CDATA[Sato, Y.;  Westin, C.-F.;  Bhalerao, A.;  Nakajima, S.;  Shiraga, N.;  Tamura, S.;  Kikinis, R.]]></authors>

<affiliations><![CDATA[Biomed Res. Centre, Osaka Univ., Japan]]></affiliations>

<controlledterms>

<term><![CDATA[biological tissues]]></term>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image classification]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[stereo image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Information filtering]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[160]]></spage>

<epage><![CDATA[180]]></epage>

<abstract><![CDATA[This paper describes a novel approach to tissue classification using three-dimensional (3D) derivative features in the volume rendering pipeline. In conventional tissue classification for a scalar volume, tissues of interest are characterized by an opacity transfer function defined as a one-dimensional (1D) function of the original volume intensity. To overcome the limitations inherent in conventional 1D opacity functions, we propose a tissue classification method that employs a multidimensional opacity function, which is a function of the 3D derivative features calculated from a scalar volume as well as the volume intensity. Tissues of interest are characterized by explicitly defined classification rules based on 3D filter responses highlighting local structures, such as edge, sheet, line, and blob, which typically correspond to tissue boundaries, cortices, vessels, and nodules, respectively, in medical volume data. The 3D local structure filters are formulated using the gradient vector and Hessian matrix of the volume intensity function combined with isotropic Gaussian blurring. These filter responses and the original intensity define a multidimensional feature space in which multichannel tissue classification strategies are designed. The usefulness of the proposed method is demonstrated by comparisons with conventional single-channel classification using both synthesized data and clinical data acquired with CT (computed tomography) and MRI (magnetic resonance imaging) scanners. The improvement in image quality obtained using multichannel classification is confirmed by evaluating the contrast and contrast-to-noise ratio in the resultant volume-rendered images with variable opacity values]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[856997]]></arnumber>

<doi><![CDATA[10.1109/2945.856997]]></doi>

<publicationId><![CDATA[856997]]></publicationId>

<partnum><![CDATA[856997]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=856997&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=856997]]></pdf>

</document>

<document>

<rank>534</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1541993]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.4]]></doi>

<publicationId><![CDATA[1541993]]></publicationId>

<partnum><![CDATA[1541993]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1541993&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1541993]]></pdf>

</document>

<document>

<rank>535</rank>

<title><![CDATA[Lighting Design for Globally Illuminated Volume Rendering]]></title>

<authors><![CDATA[Yubo Zhang;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Univ. of California, Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Volume rendering]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2946]]></spage>

<epage><![CDATA[2955]]></epage>

<abstract><![CDATA[With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634193]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.172]]></doi>

<publicationId><![CDATA[6634193]]></publicationId>

<partnum><![CDATA[6634193]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634193&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634193]]></pdf>

</document>

<document>

<rank>536</rank>

<title><![CDATA[Scalable WIM: Effective Exploration in Large-scale Astrophysical Environments]]></title>

<authors><![CDATA[Li, Y.;  Chi-Wing Fu;  Hanson, A.J.]]></authors>

<affiliations><![CDATA[Indiana Univ., IN]]></affiliations>

<controlledterms>

<term><![CDATA[astronomy computing]]></term>

<term><![CDATA[cosmology]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Astronomy]]></term>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Context modeling]]></term>

<term><![CDATA[Impedance]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Space exploration]]></term>

<term><![CDATA[User interfaces]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1005]]></spage>

<epage><![CDATA[1012]]></epage>

<abstract><![CDATA[Navigating through large-scale virtual environments such as simulations of the astrophysical Universe is difficult. The huge spatial range of astronomical models and the dominance of empty space make it hard for users to travel across cosmological scales effectively, and the problem of wayfinding further impedes the user's ability to acquire reliable spatial knowledge of astronomical contexts. We introduce a new technique called the scalable world-in-miniature (WIM) map as a unifying interface to facilitate travel and wayfinding in a virtual environment spanning gigantic spatial scales: power-law spatial seating enables rapid and accurate transitions among widely separated regions; logarithmically mapped miniature spaces offer a global overview mode when the full context is too large; 3D landmarks represented in the WIM are enhanced by scale, positional, and directional cues to augment spatial context awareness; a series of navigation models are incorporated into the scalable WIM to improve the performance of travel tasks posed by the unique characteristics of virtual cosmic exploration. The scalable WIM user interface supports an improved physical navigation experience and assists pragmatic cognitive understanding of a visualization context that incorporates the features of large-scale astronomy]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015458]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.176]]></doi>

<publicationId><![CDATA[4015458]]></publicationId>

<partnum><![CDATA[4015458]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015458&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015458]]></pdf>

</document>

<document>

<rank>537</rank>

<title><![CDATA[MegaMol&#x2014;A Prototyping Framework for Particle-Based Visualization]]></title>

<authors><![CDATA[Grottel, S.;  Krone, M.;  Muller, C.;  Reina, G.;  Ertl, T.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Graphics & Visualization, Tech. Univ. Dresden, Dresden, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data handling]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[public domain software]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics processing units]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[201]]></spage>

<epage><![CDATA[214]]></epage>

<abstract><![CDATA[Visualization applications nowadays not only face increasingly larger datasets, but have to solve increasingly complex research questions. They often require more than a single algorithm and consequently a software solution will exceed the possibilities of simple research prototypes. Well-established systems intended for such complex visual analysis purposes have usually been designed for classical, mesh-based graphics approaches. For particle-based data, however, existing visualization frameworks are too generic - e.g. lacking possibilities for consistent low-level GPU optimization for high-performance graphics - and at the same time are too limited - e.g. by enforcing the use of structures suboptimal for some computations. Thus, we developed the system softwareMegaMol for visualization research on particle-based data. On the one hand, flexible data structures and functional module design allow for easy adaption to changing research questions, e.g. studying vapors in thermodynamics, solid material in physics, or complex functional macromolecules like proteins in biochemistry. Therefore, MegaMol is designed as a development framework. On the other hand, common functionality for data handling and advanced rendering implementations are available and beneficial for all applications. We present several case studies of work implemented using our system as well as a comparison to other freely available or open source systems.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6881728]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2350479]]></doi>

<publicationId><![CDATA[6881728]]></publicationId>

<partnum><![CDATA[6881728]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6881728&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6881728]]></pdf>

</document>

<document>

<rank>538</rank>

<title><![CDATA[Real-Time Illustration of Vascular Structures]]></title>

<authors><![CDATA[Ritter, F.;  Hansen, C.;  Dicken, V.;  Konrad, O.;  Preim, B.;  Peitgen, H.-O.]]></authors>

<affiliations><![CDATA[MeVis GmbH]]></affiliations>

<controlledterms>

<term><![CDATA[blood vessels]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Absorption]]></term>

<term><![CDATA[Liver]]></term>

<term><![CDATA[Medical treatment]]></term>

<term><![CDATA[Reflection]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface morphology]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Veins]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[877]]></spage>

<epage><![CDATA[884]]></epage>

<abstract><![CDATA[We present real-time vascular visualization methods, which extend on illustrative rendering techniques to particularly accentuate spatial depth and to improve the perceptive separation of important vascular properties such as branching level and supply area. The resulting visualization can and has already been used for direct projection on a patient's organ in the operation theater where the varying absorption and reflection characteristics of the surface limit the use of color. The important contributions of our work are a GPU-based hatching algorithm for complex tubular structures that emphasizes shape and depth as well as GPU-accelerated shadow-like depth indicators, which enable reliable comparisons of depth distances in a static monoscopic 3D visualization. In addition, we verify the expressiveness of our illustration methods in a large, quantitative study with 160 subjects]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015442]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.172]]></doi>

<publicationId><![CDATA[4015442]]></publicationId>

<partnum><![CDATA[4015442]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015442&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015442]]></pdf>

</document>

<document>

<rank>539</rank>

<title><![CDATA[Clifford Fourier transform on vector fields]]></title>

<authors><![CDATA[Ebling, J.;  Scheuermann, G.]]></authors>

<affiliations><![CDATA[Leipzig Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[Fourier transforms]]></term>

<term><![CDATA[algebra]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer vision]]></term>

<term><![CDATA[convolution]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[pattern matching]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algebra]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Fourier transforms]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Robustness]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[469]]></spage>

<epage><![CDATA[479]]></epage>

<abstract><![CDATA[Image processing and computer vision have robust methods for feature extraction and the computation of derivatives of scalar fields. Furthermore, interpolation and the effects of applying a filter can be analyzed in detail and can be advantages when applying these methods to vector fields to obtain a solid theoretical basis for feature extraction. We recently introduced the Clifford convolution, which is an extension of the classical convolution on scalar fields and provides a unified notation for the convolution of scalar and vector fields. It has attractive geometric properties that allow pattern matching on vector fields. In image processing, the convolution and the Fourier transform operators are closely related by the convolution theorem and, in this paper, we extend the Fourier transform to include general elements of Clifford Algebra, called multivectors, including scalars and vectors. The resulting convolution and derivative theorems are extensions of those for convolution and the Fourier transform on scalar fields. The Clifford Fourier transform allows a frequency analysis of vector fields and the behavior of vector-valued filters. In frequency space, vectors are transformed into general multivectors of the Clifford Algebra. Many basic vector-valued patterns, such as source, sink, saddle points, and potential vortices, can be described by a few multivectors in frequency space.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1432692]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.54]]></doi>

<publicationId><![CDATA[1432692]]></publicationId>

<partnum><![CDATA[1432692]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1432692&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1432692]]></pdf>

</document>

<document>

<rank>540</rank>

<title><![CDATA[Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials]]></title>

<authors><![CDATA[Gyulassy, A.;  Knoll, A.;  Chun Lau;  Bei Wang]]></authors>

<controlledterms>

<term><![CDATA[adsorption]]></term>

<term><![CDATA[anodes]]></term>

<term><![CDATA[carbon]]></term>

<term><![CDATA[crystal defects]]></term>

<term><![CDATA[diffusion]]></term>

<term><![CDATA[interface phenomena]]></term>

<term><![CDATA[interstitials]]></term>

<term><![CDATA[lithium]]></term>

<term><![CDATA[materials science computing]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[molecular dynamics method]]></term>

<term><![CDATA[nanoparticles]]></term>

<term><![CDATA[secondary cells]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Batteries]]></term>

<term><![CDATA[Carbon]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Discrete Fourier transforms]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Lithium]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[916]]></spage>

<epage><![CDATA[925]]></epage>

<abstract><![CDATA[Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192674]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467432]]></doi>

<publicationId><![CDATA[7192674]]></publicationId>

<partnum><![CDATA[7192674]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192674&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192674]]></pdf>

</document>

<document>

<rank>541</rank>

<title><![CDATA[Box Spline Reconstruction On The Face-Centered Cubic Lattice]]></title>

<authors><![CDATA[Minho Kim;  Entezari, A.;  Peters, J.]]></authors>

<affiliations><![CDATA[CISE Dept., Univ. of Florida, Gainesville, FL]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[FCC]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Reconstruction algorithms]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Signal resolution]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1523]]></spage>

<epage><![CDATA[1530]]></epage>

<abstract><![CDATA[We introduce and analyze an efficient reconstruction algorithm for FCC-sampled data. The reconstruction is based on the 6-direction box spline that is naturally associated with the FCC lattice and shares the continuity and approximation order of the triquadratic B-spline. We observe less aliasing for generic level sets and derive special techniques to attain the higher evaluation efficiency promised by the lower degree and smaller stencil-size of the C1 6-direction box spline over the triquadratic B-spline.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658171]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.115]]></doi>

<publicationId><![CDATA[4658171]]></publicationId>

<partnum><![CDATA[4658171]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658171&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658171]]></pdf>

</document>

<document>

<rank>542</rank>

<title><![CDATA[High-quality texture reconstruction from multiple scans]]></title>

<authors><![CDATA[Bernardini, F.;  Martin, I.M.;  Rushmeier, H.]]></authors>

<affiliations><![CDATA[IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[image processing]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Reflectivity]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[318]]></spage>

<epage><![CDATA[332]]></epage>

<abstract><![CDATA[The creation of three-dimensional digital content by scanning real objects has become common practice in graphics applications for which visual quality is paramount, such as animation, e-commerce, and virtual museums. While a lot of attention has been devoted recently to the problem of accurately capturing the geometry of scanned objects, the acquisition of high-quality textures is equally important, but not as widely studied. In this paper, we focus on methods to construct accurate digital models of scanned objects by integrating high-quality texture and normal maps with geometric data. These methods are designed for use with inexpensive, electronic camera-based systems in which low-resolution range images and high-resolution intensity images are acquired. The resulting models are well-suited for interactive rendering on the latest-generation graphics hardware with support for bump mapping. Our contributions include new techniques for processing range, reflectance, and surface normal data, for image-based registration of scans, and for reconstructing high-quality textures for the output digital object]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[965346]]></arnumber>

<doi><![CDATA[10.1109/2945.965346]]></doi>

<publicationId><![CDATA[965346]]></publicationId>

<partnum><![CDATA[965346]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=965346&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965346]]></pdf>

</document>

<document>

<rank>543</rank>

<title><![CDATA[Principles and Tools for Collaborative Entity-Based Intelligence Analysis]]></title>

<authors><![CDATA[Bier, E.A.;  Card, S.K.;  Bodnar, J.W.]]></authors>

<affiliations><![CDATA[Palo Alto Res. Center, Inc., Palo Alto, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[groupware]]></term>

<term><![CDATA[software tools]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[178]]></spage>

<epage><![CDATA[191]]></epage>

<abstract><![CDATA[Software tools that make it easier for analysts to collaborate as a natural part of their work will lead to better analysis that is informed by more perspectives. We are interested to know if software tools can be designed that support collaboration even as they allow analysts to find documents and organize information (including evidence, schemas, and hypotheses). We have modified the Entity Workspace system, described previously, to test such designs. We have evaluated the resulting design in both a laboratory study and a study where it is situated with an analysis team. In both cases, effects on collaboration appear to be positive. Key aspects of the design include an evidence notebook optimized for organizing entities (rather than text characters), information structures that can be collapsed and expanded, visualization of evidence that emphasizes events and documents (rather than emphasizing the entity graph), and a notification system that finds entities of mutual interest to multiple analysts. Long-term tests suggest that this approach can support both top-down and bottom-up styles of analysis.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5226632]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.104]]></doi>

<publicationId><![CDATA[5226632]]></publicationId>

<partnum><![CDATA[5226632]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5226632&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5226632]]></pdf>

</document>

<document>

<rank>544</rank>

<title><![CDATA[Faster shading by equal angle interpolation of vectors]]></title>

<authors><![CDATA[Barrera, T.;  Hast, A.;  Bengtsson, E.]]></authors>

<affiliations><![CDATA[Barrera Kristiansen AB, Uppsala, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[Chebyshev approximation]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Chebyshev approximation]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Finite difference methods]]></term>

<term><![CDATA[Handheld computers]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[217]]></spage>

<epage><![CDATA[223]]></epage>

<abstract><![CDATA[We show how spherical linear interpolation can be used to produce shading with a quality at least similar to Phong shading at a computational effort in the inner loop that is close to that of the Gouraud method. We show how to use the Chebyshev's recurrence relation in order to compute the shading very efficiently. Furthermore, it can also be used to interpolate vectors in such a way that normalization is not necessary, which will make the interpolation very fast. The somewhat larger setup effort required by this approach can be handled through table look up techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1260773]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1260773]]></doi>

<publicationId><![CDATA[1260773]]></publicationId>

<partnum><![CDATA[1260773]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260773&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260773]]></pdf>

</document>

<document>

<rank>545</rank>

<title><![CDATA[Discontinuities in Continuous Scatter Plots]]></title>

<authors><![CDATA[Lehmann, D.J.;  Theisel, H.]]></authors>

<affiliations><![CDATA[Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Density functional theory]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Joining processes]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1291]]></spage>

<epage><![CDATA[1300]]></epage>

<abstract><![CDATA[The concept of continuous scatterplot (CSP) is a modern visualization technique. The idea is to define a scalar density value based on the map between an n-dimensional spatial domain and an m-dimensional data domain, which describe the CSP space. Usually the data domain is two-dimensional to visually convey the underlying, density coded, data. In this paper we investigate kinds of map-based discontinuities, especially for the practical cases n = m = 2 and n = 3 | m = 2, and we depict relations between them and attributes of the resulting CSP itself. Additionally, we show that discontinuities build critical line structures, and we introduce algorithms to detect them. Further, we introduce a discontinuity-based visualization approach - called contribution map (CM) -which establishes a relationship between the CSP's data domain and the number of connected components in the spatial domain. We show that CMs enhance the CSP-based linking &amp; brushing interaction. Finally, we apply our approaches to a number of synthetic as well as real data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613469]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.146]]></doi>

<publicationId><![CDATA[5613469]]></publicationId>

<partnum><![CDATA[5613469]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613469&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613469]]></pdf>

</document>

<document>

<rank>546</rank>

<title><![CDATA[2006 Reviewers List]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[IEEE]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[190]]></spage>

<epage><![CDATA[192]]></epage>

<abstract><![CDATA[Lists the reviewers who contributed to IEEE Transactions on Visualization and Computer Graphics in 2006.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4015409]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1]]></doi>

<publicationId><![CDATA[4015409]]></publicationId>

<partnum><![CDATA[4015409]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015409&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015409]]></pdf>

</document>

<document>

<rank>547</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on the IEEE Virtual Reality Conference (VR)]]></title>

<authors><![CDATA[Lin, M.C.;  Steed, A.;  Cruz-Neira, Carolina]]></authors>

<thesaurusterms>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Medical simulation]]></term>

<term><![CDATA[Physics computing]]></term>

<term><![CDATA[Sections]]></term>

<term><![CDATA[Usability]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Wearable computers]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[353]]></spage>

<epage><![CDATA[354]]></epage>

<abstract><![CDATA[The three papers in this special section are expanded versions of the three best papers from the IEEE VR 2008 proceedings.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4800286]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.37]]></doi>

<publicationId><![CDATA[4800286]]></publicationId>

<partnum><![CDATA[4800286]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4800286&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4800286]]></pdf>

</document>

<document>

<rank>548</rank>

<title><![CDATA[Analysis of Time-Dependent Flow-Sensitive PC-MRI Data]]></title>

<authors><![CDATA[Krishnan, H.;  Garth, C.;  Guhring, J.;  Gulsun, M.A.;  Greiser, A.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Inst. of Data Anal. & Visualization, Univ. of California, Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[blood vessels]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[haemodynamics]]></term>

<term><![CDATA[integration]]></term>

<term><![CDATA[medical computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Blood]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[966]]></spage>

<epage><![CDATA[977]]></epage>

<abstract><![CDATA[Many flow visualization techniques, especially integration-based methods, are problematic when the measured data exhibit noise and discretization issues. Particularly, this is the case for flow-sensitive phase-contrast magnetic resonance imaging (PC-MRI) data sets which not only record anatomic information, but also time-varying flow information. We propose a novel approach for the visualization of such data sets using integration-based methods. Our ideas are based upon finite-time Lyapunov exponents (FTLE) and enable identification of vessel boundaries in the data as high regions of separation. This allows us to correctly restrict integration-based visualization to blood vessels. We validate our technique by comparing our approach to existing anatomy-based methods as well as addressing the benefits and limitations of using FTLE to restrict flow. We also discuss the importance of parameters, i.e., advection length and data resolution, in establishing a well-defined vessel boundary. We extract appropriate flow lines and surfaces that enable the visualization of blood flow within the vessels. We further enhance the visualization by analyzing flow behavior in the seeded region and generating simplified depictions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5753896]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.80]]></doi>

<publicationId><![CDATA[5753896]]></publicationId>

<partnum><![CDATA[5753896]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5753896&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753896]]></pdf>

</document>

<document>

<rank>549</rank>

<title><![CDATA[Online Tracking of Outdoor Lighting Variations for Augmented Reality with Moving Cameras]]></title>

<authors><![CDATA[Yanli Liu;  Granier, X.]]></authors>

<affiliations><![CDATA[Coll. of Comput. Sci., Sichuan Univ., Chengdu, China]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[cameras]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[object tracking]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[573]]></spage>

<epage><![CDATA[580]]></epage>

<abstract><![CDATA[In augmented reality, one of key tasks to achieve a convincing visual appearance consistency between virtual objects and video scenes is to have a coherent illumination along the whole sequence. As outdoor illumination is largely dependent on the weather, the lighting condition may change from frame to frame. In this paper, we propose a full image-based approach for online tracking of outdoor illumination variations from videos captured with moving cameras. Our key idea is to estimate the relative intensities of sunlight and skylight via a sparse set of planar feature-points extracted from each frame. To address the inevitable feature misalignments, a set of constraints are introduced to select the most reliable ones. Exploiting the spatial and temporal coherence of illumination, the relative intensities of sunlight and skylight are finally estimated by using an optimization process. We validate our technique on a set of real-life videos and show that the results with our estimations are visually coherent along the video sequences.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6165138]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.53]]></doi>

<publicationId><![CDATA[6165138]]></publicationId>

<partnum><![CDATA[6165138]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165138&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165138]]></pdf>

</document>

<document>

<rank>550</rank>

<title><![CDATA[Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[012]]></spage>

<epage><![CDATA[012]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1272736]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1272736]]></doi>

<publicationId><![CDATA[1272736]]></publicationId>

<partnum><![CDATA[1272736]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1272736&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272736]]></pdf>

</document>

<document>

<rank>551</rank>

<title><![CDATA[Table of Contents]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[iii]]></spage>

<epage><![CDATA[iv]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the publication.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7064827]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2399596]]></doi>

<publicationId><![CDATA[7064827]]></publicationId>

<partnum><![CDATA[7064827]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7064827&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064827]]></pdf>

</document>

<document>

<rank>552</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5331930]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.6]]></doi>

<publicationId><![CDATA[5331930]]></publicationId>

<partnum><![CDATA[5331930]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5331930&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331930]]></pdf>

</document>

<document>

<rank>553</rank>

<title><![CDATA[A statistical wisp model and pseudophysical approaches for interactive hairstyle generation]]></title>

<authors><![CDATA[Byoungwon Choe;  Hyeong-Seok Ko]]></authors>

<affiliations><![CDATA[Sch. of Electr. Eng. & Comput. Sci., Seoul Nat. Univ., South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[Markov processes]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[realistic images]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Elasticity]]></term>

<term><![CDATA[Facial animation]]></term>

<term><![CDATA[Gravity]]></term>

<term><![CDATA[Hair]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Shafts]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[160]]></spage>

<epage><![CDATA[170]]></epage>

<abstract><![CDATA[This work presents an interactive technique that produces static hairstyles by generating individual hair strands of the desired shape and color, subject to the presence of gravity and collisions. A variety of hairstyles can be generated by adjusting the wisp parameters, while the deformation is solved efficiently, accounting for the effects of gravity and collisions. Wisps are generated employing statistical approaches. As for hair deformation, we propose a method which is based on physical simulation concepts, but is simplified to efficiently solve the static shape of hair. On top of the statistical wisp model and the deformation solver, a constraint-based styler is proposed to model artificial features that oppose the natural flow of hair under gravity and hair elasticity, such as a hairpin. Our technique spans a wider range of human hairstyles than previously proposed methods and the styles generated by this technique are fairly realistic.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1388227]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.20]]></doi>

<publicationId><![CDATA[1388227]]></publicationId>

<partnum><![CDATA[1388227]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1388227&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1388227]]></pdf>

</document>

<document>

<rank>554</rank>

<title><![CDATA[Automatic Extraction of Manhattan-World Building Masses from 3D Laser Range Scans]]></title>

<authors><![CDATA[Vanegas, Carlos A.;  Aliaga, Daniel G.;  Benes, Bedrich]]></authors>

<affiliations><![CDATA[Purdue University, West Lafayette]]></affiliations>

<thesaurusterms>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1627]]></spage>

<epage><![CDATA[1637]]></epage>

<abstract><![CDATA[We propose a novel approach for the reconstruction of urban structures from 3D point clouds with an assumption of Manhattan World (MW) building geometry; i.e., the predominance of three mutually orthogonal directions in the scene. Our approach works in two steps. First, the input points are classified according to the MW assumption into four local shape types: walls, edges, corners, and edge corners. The classified points are organized into a connected set of clusters from which a volume description is extracted. The MW assumption allows us to robustly identify the fundamental shape types, describe the volumes within the bounding box, and reconstruct visible and occluded parts of the sampled structure. We show results of our reconstruction that has been applied to several synthetic and real-world 3D point data sets of various densities and from multiple viewpoints. Our method automatically reconstructs 3D building models from up to 10 million points in 10 to 60 seconds.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6143940]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.30]]></doi>

<publicationId><![CDATA[6143940]]></publicationId>

<partnum><![CDATA[6143940]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6143940&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6143940]]></pdf>

</document>

<document>

<rank>555</rank>

<title><![CDATA[Interactive Visualization and Analysis of Transitional Flow]]></title>

<authors><![CDATA[Johnson, G.P.;  Calo, V.M.;  Gaither, K.P.]]></authors>

<affiliations><![CDATA[Texas Adv. Comput. Center, Univ. of Texas, Austin, TX]]></affiliations>

<controlledterms>

<term><![CDATA[boundary layers]]></term>

<term><![CDATA[cache storage]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[laminar flow]]></term>

<term><![CDATA[turbulence]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Fluctuations]]></term>

<term><![CDATA[Fluid flow]]></term>

<term><![CDATA[Fluid flow control]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Stochastic processes]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1420]]></spage>

<epage><![CDATA[1427]]></epage>

<abstract><![CDATA[A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658158]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.146]]></doi>

<publicationId><![CDATA[4658158]]></publicationId>

<partnum><![CDATA[4658158]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658158&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658158]]></pdf>

</document>

<document>

<rank>556</rank>

<title><![CDATA[FacetMap: A Scalable Search and Browse Visualization]]></title>

<authors><![CDATA[Smith, G.;  Czerwinski, M.;  Meyers, B.Robbins.;  Robertson, G.;  Tan, D.S.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[meta data]]></term>

<term><![CDATA[personal information systems]]></term>

<term><![CDATA[query processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Driver circuits]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Information retrieval]]></term>

<term><![CDATA[Investments]]></term>

<term><![CDATA[Microcomputers]]></term>

<term><![CDATA[Operating systems]]></term>

<term><![CDATA[Web pages]]></term>

<term><![CDATA[Web search]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[797]]></spage>

<epage><![CDATA[804]]></epage>

<abstract><![CDATA[The dominant paradigm for searching and browsing large data stores is text-based: presenting a scrollable list of search results in response to textual search term input. While this works well for the Web, there is opportunity for improvement in the domain of personal information stores, which tend to have more heterogeneous data and richer metadata. In this paper, we introduce FacetMap, an interactive, query-driven visualization, generalizable to a wide range of metadata-rich data stores. FacetMap uses a visual metaphor for both input (selection of metadata facets as filters) and output. Results of a user study provide insight into tradeoffs between FacetMap's graphical approach and the traditional text-oriented approach]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015432]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.142]]></doi>

<publicationId><![CDATA[4015432]]></publicationId>

<partnum><![CDATA[4015432]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015432&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015432]]></pdf>

</document>

<document>

<rank>557</rank>

<title><![CDATA[Ray casting architectures for volume visualization]]></title>

<authors><![CDATA[Ray, H.;  Pfister, H.;  Silver, D.;  Cook, T.A.]]></authors>

<affiliations><![CDATA[Dept. of Electr. & Comput. Eng., Rutgers Univ., New Brunswick, NJ, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[parallel architectures]]></term>

<term><![CDATA[performance evaluation]]></term>

<term><![CDATA[pipeline processing]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[special purpose computers]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geophysics computing]]></term>

<term><![CDATA[High performance computing]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Silver]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[210]]></spage>

<epage><![CDATA[223]]></epage>

<abstract><![CDATA[Real-time visualization of large volume data sets demands high-performance computation, pushing the storage, processing and data communication requirements to the limits of current technology. General-purpose parallel processors have been used to visualize moderate-size data sets at interactive frame rates; however, the cost and size of these supercomputers inhibits the widespread use for real-time visualization. This paper surveys several special-purpose architectures that seek to render volumes at interactive rates. These specialized visualization accelerators have cost, performance and size advantages over parallel processors. All architectures implement ray casting using parallel and pipelined hardware. We introduce a new metric that normalizes performance to compare these architectures. The architectures included in this survey are VOGUE, VIRIM, Array-Based Ray Casting, EM-Cube and VIZARD II. We also discuss future applications of special-purpose accelerators]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[795213]]></arnumber>

<doi><![CDATA[10.1109/2945.795213]]></doi>

<publicationId><![CDATA[795213]]></publicationId>

<partnum><![CDATA[795213]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=795213&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=795213]]></pdf>

</document>

<document>

<rank>558</rank>

<title><![CDATA[Editor's Note]]></title>

<authors><![CDATA[Lin, Ming C.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[2]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6078466]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.9]]></doi>

<publicationId><![CDATA[6078466]]></publicationId>

<partnum><![CDATA[6078466]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6078466&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6078466]]></pdf>

</document>

<document>

<rank>559</rank>

<title><![CDATA[Visualization of Heterogeneous Data]]></title>

<authors><![CDATA[Cammarano, M.;  Xin Dong;  Bryan Chan;  Klingner, J.;  Talbot, J.;  Halevy, A.;  Hanrahan, P.]]></authors>

<affiliations><![CDATA[Stanford Univ., Stanford]]></affiliations>

<controlledterms>

<term><![CDATA[data integrity]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Government]]></term>

<term><![CDATA[Mashups]]></term>

<term><![CDATA[Resource description framework]]></term>

<term><![CDATA[Semantic Web]]></term>

<term><![CDATA[Space technology]]></term>

<term><![CDATA[Visual databases]]></term>

<term><![CDATA[Web services]]></term>

<term><![CDATA[Wikipedia]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1200]]></spage>

<epage><![CDATA[1207]]></epage>

<abstract><![CDATA[Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376141]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70617]]></doi>

<publicationId><![CDATA[4376141]]></publicationId>

<partnum><![CDATA[4376141]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376141&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376141]]></pdf>

</document>

<document>

<rank>560</rank>

<title><![CDATA[Keynote Speaker: Virtual Reality: Current Uses in Medical Simulation and Future]]></title>

<authors><![CDATA[Satava, R.]]></authors>

<affiliations><![CDATA[Med. Center, Univ. of Washington, Seattle, WA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical education]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xii]]></spage>

<epage><![CDATA[xii]]></epage>

<abstract><![CDATA[Virtual reality has gone from research to educational tool to indispensible clinical application in patient care. A brief review of the current status of the use of VR in medicine will provide the springboard for the current gaps that provide future opportunities in simulation as well as an introduction to new advanced technologies that are revolutionizing medicine and which will require VR for educational and training support and clinical applications. Some topics for discussion are virtual patients, cadavers and autopsies, surgical rehearsal, robotic surgery, suspended animation, regeneration and tissue engineering. The challenge: how creatively can VR support these incredible new technologies? The grand challenge &#x00F1; how will 3-D stereolithography revolutionize the practice of medicine? Have you bought your Makerbot yet?]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479171]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.51]]></doi>

<publicationId><![CDATA[6479171]]></publicationId>

<partnum><![CDATA[6479171]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479171&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479171]]></pdf>

</document>

<document>

<rank>561</rank>

<title><![CDATA[Texture Mapping via Optimal Mass Transport]]></title>

<authors><![CDATA[Dominitz, A.;  Tannenbaum, A.]]></authors>

<affiliations><![CDATA[Dept. of Electr. Eng., Technion - Israel Inst. of Technol., Haifa, Israel]]></affiliations>

<controlledterms>

<term><![CDATA[convergence]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[image texture]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[419]]></spage>

<epage><![CDATA[433]]></epage>

<abstract><![CDATA[In this paper, we present a novel method for texture mapping of closed surfaces. Our method is based on the technique of optimal mass transport (also known as the ??earth-mover's metric??). This is a classical problem that concerns determining the optimal way, in the sense of minimal transportation cost, of moving a pile of soil from one site to another. In our context, the resulting mapping is area preserving and minimizes angle distortion in the optimal mass sense. Indeed, we first begin with an angle-preserving mapping (which may greatly distort area) and then correct it using the mass transport procedure derived via a certain gradient flow. In order to obtain fast convergence to the optimal mapping, we incorporate a multiresolution scheme into our flow. We also use ideas from discrete exterior calculus in our computations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5072214]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.64]]></doi>

<publicationId><![CDATA[5072214]]></publicationId>

<partnum><![CDATA[5072214]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5072214&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5072214]]></pdf>

</document>

<document>

<rank>562</rank>

<title><![CDATA[Locally toleranced surface simplification]]></title>

<authors><![CDATA[Gueziec, A.]]></authors>

<affiliations><![CDATA[IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation error]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Computer errors]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Error correction]]></term>

<term><![CDATA[Senior members]]></term>

<term><![CDATA[Software prototyping]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[168]]></spage>

<epage><![CDATA[189]]></epage>

<abstract><![CDATA[We present a technique for simplifying a triangulated surface. Simplifying consists of approximating the surface with another surface of lower triangle count. Our algorithm can preserve the volume of a solid to within machine accuracy; it favors the creation of near-equilateral triangles. We develop novel methods for reporting and representing a bound to the approximation error between a simplified surface and the original, and respecting a variable tolerance across the surface. A different positive error value is reported at each vertex. By linearly blending the error values in between vertices, we define a volume of space, called the error volume, as the union of balls of linearly varying radii. The error volume is built dynamically as the simplification progresses, on top of preexisting error volumes that it contains. We also build a tolerance volume to forbid simplification errors exceeding a local tolerance. The information necessary to compute error values is local to the star of a vertex; accordingly, the complexity of the algorithm is either linear or in O(n log n) in the original number of surface edges, depending on the variant. We extend the mechanisms of error and tolerance volumes to preserve during simplification scalar and vector attributes associated with surface vertices. Assuming a linear variation across triangles, error and tolerance volumes are defined in the same fashion as for positional error. For normals, a corrective term is applied to the error measured at the vertices to compensate for nonlinearities]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[773810]]></arnumber>

<doi><![CDATA[10.1109/2945.773810]]></doi>

<publicationId><![CDATA[773810]]></publicationId>

<partnum><![CDATA[773810]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=773810&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=773810]]></pdf>

</document>

<document>

<rank>563</rank>

<title><![CDATA[Summarizing Dynamic Bipolar Conflict Structures]]></title>

<authors><![CDATA[Brandes, U.;  Fleischer, D.;  Lerner, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Konstanz Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[International relations]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Statistical analysis]]></term>

<term><![CDATA[Text mining]]></term>

<term><![CDATA[Vents]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1486]]></spage>

<epage><![CDATA[1499]]></epage>

<abstract><![CDATA[We present a method for visual summary of bilateral conflict structures embodied in event data. Such data consists of actors linked by time-stamped events and may be extracted from various sources such as news reports and dossiers. When analyzing political events, it is of particular importance to be able to recognize conflicts and actors involved in them. By projecting actors into a conflict space, we are able to highlight the main opponents in a series of tens of thousands of events and provide a graphic overview of the conflict structure. Moreover, our method allows for smooth animation of the dynamics of a conflict]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1703369]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.105]]></doi>

<publicationId><![CDATA[1703369]]></publicationId>

<partnum><![CDATA[1703369]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1703369&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703369]]></pdf>

</document>

<document>

<rank>564</rank>

<title><![CDATA[A Coherent Grid Traversal Approach to Visualizing Particle-Based Simulation Data]]></title>

<authors><![CDATA[Gribble, C.P.;  Ize, T.;  Kensler, A.;  Wald, I.;  Parker, S.G.]]></authors>

<affiliations><![CDATA[Grove City Coll., Grove]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[758]]></spage>

<epage><![CDATA[768]]></epage>

<abstract><![CDATA[We present an approach to visualizing particle-based simulation data using interactive ray tracing and describe an algorithmic enhancement that exploits the properties of these data sets to provide highly interactive performance and reduced storage requirements. This algorithm for fast packet-based ray tracing of multilevel grids enables the interactive visualization of large time-varying data sets with millions of particles and incorporates advanced features like soft shadows. We compare the performance of our approach with two recent particle visualization systems: one based on an optimized single ray grid traversal algorithm and the other on programmable graphics hardware. This comparison demonstrates that the new algorithm offers an attractive alternative for interactive particle visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4293019]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1059]]></doi>

<publicationId><![CDATA[4293019]]></publicationId>

<partnum><![CDATA[4293019]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4293019&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293019]]></pdf>

</document>

<document>

<rank>565</rank>

<title><![CDATA[A Survey of Radial Methods for Information Visualization]]></title>

<authors><![CDATA[Draper, G.;  Livnat, Y.;  Riesenfeld, R.F.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Brigham Young Univ. Hawaii, Laie, HI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[759]]></spage>

<epage><![CDATA[776]]></epage>

<abstract><![CDATA[Radial visualization, or the practice of displaying data in a circular or elliptical pattern, is an increasingly common technique in information visualization research. In spite of its prevalence, little work has been done to study this visualization paradigm as a methodology in its own right. We provide a historical review of radial visualization, tracing it to its roots in centuries-old statistical graphics. We then identify the types of problem domains to which modern radial visualization techniques have been applied. A taxonomy for radial visualization is proposed in the form of seven design patterns encompassing nearly all recent works in this area. From an analysis of these patterns, we distill a series of design considerations that system builders can use to create new visualizations that address aspects of the design space that have not yet been explored. It is hoped that our taxonomy will provide a framework for facilitating discourse among researchers and stimulate the development of additional theories and systems involving radial visualization as a distinct design metaphor.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4770098]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.23]]></doi>

<publicationId><![CDATA[4770098]]></publicationId>

<partnum><![CDATA[4770098]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4770098&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4770098]]></pdf>

</document>

<document>

<rank>566</rank>

<title><![CDATA[International Program Committee]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[xi]]></spage>

<epage><![CDATA[xi]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6777447]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.29]]></doi>

<publicationId><![CDATA[6777447]]></publicationId>

<partnum><![CDATA[6777447]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777447&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777447]]></pdf>

</document>

<document>

<rank>567</rank>

<title><![CDATA[Balloon Focus: a Seamless Multi-Focus+Context Method for Treemaps]]></title>

<authors><![CDATA[Ying Tu;  Han-Wei Shen]]></authors>

<affiliations><![CDATA[Comput. Sci. & Eng. Dept., Ohio State Univ., Columbus, OH]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[directed graphs]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer interfaces]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[File systems]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Manuals]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Telecommunication traffic]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1157]]></spage>

<epage><![CDATA[1164]]></epage>

<abstract><![CDATA[The treemap is one of the most popular methods for visualizing hierarchical data. When a treemap contains a large number of items, inspecting or comparing a few selected items in a greater level of detail becomes very challenging. In this paper, we present a seamless multi-focus and context technique, called Balloon Focus, that allows the user to smoothly enlarge multiple treemap items served as the foci, while maintaining a stable treemap layout as the context. Our method has several desirable features. First, this method is quite general and can be used with different treemap layout algorithms. Second, as the foci are enlarged, the relative positions among all items are preserved. Third, the foci are placed in a way that the remaining space is evenly distributed back to the non-focus treemap items. When Balloon Focus enlarges the focus items to a maximum degree, the above features ensure that the treemap will maintain a consistent appearance and avoid any abrupt layout changes. In our algorithm, a DAG (Directed Acyclic Graph) is used to maintain the positional constraints, and an elastic model is employed to govern the placement of the treemap items. We demonstrate a treemap visualization system that integrates data query, manual focus selection, and our novel multi-focus+context technique, Balloon Focus, together. A user study was conducted. Results show that with Balloon Focus, users can better perform the tasks of comparing the values and the distribution of the foci.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658125]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.114]]></doi>

<publicationId><![CDATA[4658125]]></publicationId>

<partnum><![CDATA[4658125]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658125&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658125]]></pdf>

</document>

<document>

<rank>568</rank>

<title><![CDATA[The Effect on Lower Spine Muscle Activation of Walking on a Narrow Beam in Virtual Reality]]></title>

<authors><![CDATA[Antley, A.;  Slater, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. Coll. London, London, UK]]></affiliations>

<controlledterms>

<term><![CDATA[electromyography]]></term>

<term><![CDATA[medical signal processing]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Electromyography]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Information systems]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Multimedia systems]]></term>

<term><![CDATA[Muscles]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[255]]></spage>

<epage><![CDATA[259]]></epage>

<abstract><![CDATA[To what extent do people behave in immersive virtual environments as they would in similar situations in a physical environment? There are many ways to address this question, ranging from questionnaires, behavioral studies, and the use of physiological measures. Here, we compare the onsets of muscle activity using surface electromyography (EMG) while participants were walking under three different conditions: on a normal floor surface, on a narrow ribbon along the floor, and on a narrow platform raised off the floor. The same situation was rendered in an immersive virtual environment (IVE) Cave-like system, and 12 participants did the three types of walking in a counter-balanced within-groups design. The mean number of EMG activity onsets per unit time followed the same pattern in the virtual environment as in the physical environment-significantly higher for walking on the platform compared to walking on the floor. Even though participants knew that they were in fact really walking at floor level in the virtual environment condition, the visual illusion of walking on a raised platform was sufficient to influence their behavior in a measurable way. This opens up the door for this technique to be used in gait and posture related scenarios including rehabilitation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5406518]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.26]]></doi>

<publicationId><![CDATA[5406518]]></publicationId>

<partnum><![CDATA[5406518]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5406518&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406518]]></pdf>

</document>

<document>

<rank>569</rank>

<title><![CDATA[Simplification of three-dimensional density maps]]></title>

<authors><![CDATA[Natarajan, V.;  Edelsbrunner, H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Duke Univ., Durham, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[function approximation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[scientific information systems]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Computer errors]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Cost function]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Density functional theory]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[587]]></spage>

<epage><![CDATA[597]]></epage>

<abstract><![CDATA[We consider scientific data sets that describe density functions over three-dimensional geometric domains. Such data sets are often large and coarsened representations are needed for visualization and analysis. Assuming a tetrahedral mesh representation, we construct such representations with a simplification algorithm that combines three goals: the approximation of the function, the preservation of the mesh topology, and the improvement of the mesh quality. The third goal is achieved with a novel extension of the well-known quadric error metric. We perform a number of computational experiments to understand the effect of mesh quality improvement on the density map approximation. In addition, we study the effect of geometric simplification on the topological features of the function by monitoring its critical points.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1310284]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.32]]></doi>

<publicationId><![CDATA[1310284]]></publicationId>

<partnum><![CDATA[1310284]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310284&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310284]]></pdf>

</document>

<document>

<rank>570</rank>

<title><![CDATA[A Comparative Study of Desktop, Fishtank, and Cave Systems for the Exploration of Volume Rendered Confocal Data Sets]]></title>

<authors><![CDATA[Prabhat;  Forsberg, A.;  Katzourin, M.;  Wharton, K.;  Slater, M.]]></authors>

<affiliations><![CDATA[Brown Univ., Providence]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[551]]></spage>

<epage><![CDATA[563]]></epage>

<abstract><![CDATA[We present a participant study that compares biological data exploration tasks using volume renderings of laser confocal microscopy data across three environments that vary in level of immersion: a desktop, fishtank, and cave system. For the tasks, data, and visualization approach used in our study, we found that subjects qualitatively preferred and quantitatively performed better in the cave compared with the fishtank and desktop. Subjects performed real-world biological data analysis tasks that emphasized understanding spatial relationships including characterizing the general features in a volume, identifying colocated features, and reporting geometric relationships such as whether clusters of cells were coplanar. After analyzing data in each environment, subjects were asked to choose which environment they wanted to analyze additional data sets in - subjects uniformly selected the cave environment.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359501]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70433]]></doi>

<publicationId><![CDATA[4359501]]></publicationId>

<partnum><![CDATA[4359501]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359501&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359501]]></pdf>

</document>

<document>

<rank>571</rank>

<title><![CDATA[Visual Methods for Analyzing Probabilistic Classification Data]]></title>

<authors><![CDATA[Alsallakh, B.;  Hanbury, A.;  Hauser, H.;  Miksch, S.;  Rauber, A.]]></authors>

<affiliations><![CDATA[Vienna Univ. of Technol., Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data handling]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[probability]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Electric breakdown]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Probabilistic logic]]></term>

<term><![CDATA[Probability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1703]]></spage>

<epage><![CDATA[1712]]></epage>

<abstract><![CDATA[Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875957]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346660]]></doi>

<publicationId><![CDATA[6875957]]></publicationId>

<partnum><![CDATA[6875957]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875957&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875957]]></pdf>

</document>

<document>

<rank>572</rank>

<title><![CDATA[GeneShelf: A Web-based Visual Interface for Large Gene Expression Time-Series Data Repositories]]></title>

<authors><![CDATA[Bohyoung Kim;  Bongshin Lee;  Knoblach, S.;  Hoffman, E.;  Jinwook Seo]]></authors>

<affiliations><![CDATA[Seoul Nat. Univ., Seoul, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[genetics]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Databases]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Gene expression]]></term>

<term><![CDATA[Genetics]]></term>

<term><![CDATA[Injuries]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Rats]]></term>

<term><![CDATA[Spinal cord]]></term>

<term><![CDATA[Time series analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[905]]></spage>

<epage><![CDATA[912]]></epage>

<abstract><![CDATA[A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290693]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.146]]></doi>

<publicationId><![CDATA[5290693]]></publicationId>

<partnum><![CDATA[5290693]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290693&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290693]]></pdf>

</document>

<document>

<rank>573</rank>

<title><![CDATA[PhenoBlocks: Phenotype Comparison Visualizations]]></title>

<authors><![CDATA[Glueck, M.;  Hamilton, P.;  Chevalier, F.;  Breslav, S.;  Khan, A.;  Wigdor, D.;  Brudno, M.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical diagnostic computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Diseases]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Ontologies]]></term>

<term><![CDATA[Semantics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[101]]></spage>

<epage><![CDATA[110]]></epage>

<abstract><![CDATA[The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192670]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467733]]></doi>

<publicationId><![CDATA[7192670]]></publicationId>

<partnum><![CDATA[7192670]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192670&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192670]]></pdf>

</document>

<document>

<rank>574</rank>

<title><![CDATA[INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data]]></title>

<authors><![CDATA[Krause, J.;  Perer, A.;  Bertini, E.]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Prediction algorithms]]></term>

<term><![CDATA[Predictive models]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1614]]></spage>

<epage><![CDATA[1623]]></epage>

<abstract><![CDATA[Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876047]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346482]]></doi>

<publicationId><![CDATA[6876047]]></publicationId>

<partnum><![CDATA[6876047]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876047&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876047]]></pdf>

</document>

<document>

<rank>575</rank>

<title><![CDATA[Message from the Editor-in-Chief]]></title>

<authors><![CDATA[Lin, Ming C.]]></authors>

<affiliations><![CDATA[University of North Carolina at Chapel Hill, USA]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[v]]></spage>

<epage><![CDATA[v]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479166]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.53]]></doi>

<publicationId><![CDATA[6479166]]></publicationId>

<partnum><![CDATA[6479166]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479166&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479166]]></pdf>

</document>

<document>

<rank>576</rank>

<title><![CDATA[Bridging Theory with Practice: An Exploratory Study of Visualization Use and Design for Climate Model Comparison]]></title>

<authors><![CDATA[Dasgupta, A.;  Poco, J.;  Yaxing Wei;  Cook, R.;  Bertini, E.;  Silva, C.T.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., New York Univ., New York, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[climatology]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Meteorology]]></term>

<term><![CDATA[Taxonomy]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[996]]></spage>

<epage><![CDATA[1014]]></epage>

<abstract><![CDATA[Evaluation methodologies in visualization have mostly focused on how well the tools and techniques cater to the analytical needs of the user. While this is important in determining the effectiveness of the tools and advancing the state-of-the-art in visualization research, a key area that has mostly been overlooked is how well established visualization theories and principles are instantiated in practice. This is especially relevant when domain experts, and not visualization researchers, design visualizations for analysis of their data or for broader dissemination of scientific knowledge. There is very little research on exploring the synergistic capabilities of cross-domain collaboration between domain experts and visualization researchers. To fill this gap, in this paper we describe the results of an exploratory study of climate data visualizations conducted in tight collaboration with a pool of climate scientists. The study analyzes a large set of static climate data visualizations for identifying their shortcomings in terms of visualization design. The outcome of the study is a classification scheme that categorizes the design problems in the form of a descriptive taxonomy. The taxonomy is a first attempt for systematically categorizing the types, causes, and consequences of design problems in visualizations created by domain experts. We demonstrate the use of the taxonomy for a number of purposes, such as, improving the existing climate data visualizations, reflecting on the impact of the problems for enabling domain experts in designing better visualizations, and also learning about the gaps and opportunities for future visualization research. We demonstrate the applicability of our taxonomy through a number of examples and discuss the lessons learnt and implications of our findings.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7061479]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2413774]]></doi>

<publicationId><![CDATA[7061479]]></publicationId>

<partnum><![CDATA[7061479]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7061479&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061479]]></pdf>

</document>

<document>

<rank>577</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1310272]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.20]]></doi>

<publicationId><![CDATA[1310272]]></publicationId>

<partnum><![CDATA[1310272]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310272&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310272]]></pdf>

</document>

<document>

<rank>578</rank>

<title><![CDATA[Robust Feature-Preserving Mesh Denoising Based on Consistent Subneighborhoods]]></title>

<authors><![CDATA[Hanqi Fan;  Yizhou Yu;  Qunsheng Peng]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[estimation theory]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[image denoising]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[smoothing methods]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[312]]></spage>

<epage><![CDATA[324]]></epage>

<abstract><![CDATA[In this paper, we introduce a feature-preserving denoising algorithm. It is built on the premise that the underlying surface of a noisy mesh is piecewise smooth, and a sharp feature lies on the intersection of multiple smooth surface regions. A vertex close to a sharp feature is likely to have a neighborhood that includes distinct smooth segments. By defining the consistent subneighborhood as the segment whose geometry and normal orientation most consistent with those of the vertex, we can completely remove the influence from neighbors lying on other segments during denoising. Our method identifies piecewise smooth subneighborhoods using a robust density-based clustering algorithm based on shared nearest neighbors. In our method, we obtain an initial estimate of vertex normals and curvature tensors by robustly fitting a local quadric model. An anisotropic filter based on optimal estimation theory is further applied to smooth the normal field and the curvature tensor field. This is followed by second-order bilateral filtering, which better preserves curvature details and alleviates volume shrinkage during denoising. The support of these filters is defined by the consistent subneighborhood of a vertex. We have applied this algorithm to both generic and CAD models, and sharp features, such as edges and corners, are very well preserved.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5128905]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.70]]></doi>

<publicationId><![CDATA[5128905]]></publicationId>

<partnum><![CDATA[5128905]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5128905&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5128905]]></pdf>

</document>

<document>

<rank>579</rank>

<title><![CDATA[Real-Time Detection and Tracking for Augmented Reality on Mobile Phones]]></title>

<authors><![CDATA[Wagner, Daniel;  Reitmayr, Gerhard;  Mulloni, Alessandro;  Drummond, Tom;  Schmalstieg, D.]]></authors>

<affiliations><![CDATA[Inst. for Comput. Graphics & Vision, Graz Univ. of Technol., Graz, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[mobile computing]]></term>

<term><![CDATA[mobile handsets]]></term>

<term><![CDATA[multimedia systems]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[vocabulary]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[355]]></spage>

<epage><![CDATA[368]]></epage>

<abstract><![CDATA[In this paper, we present three techniques for 6DOF natural feature tracking in real time on mobile phones. We achieve interactive frame rates of up to 30 Hz for natural feature tracking from textured planar targets on current generation phones. We use an approach based on heavily modified state-of-the-art feature descriptors, namely SIFT and Ferns plus a template-matching-based tracker. While SIFT is known to be a strong, but computationally expensive feature descriptor, Ferns classification is fast, but requires large amounts of memory. This renders both original designs unsuitable for mobile phones. We give detailed descriptions on how we modified both approaches to make them suitable for mobile phones. The template-based tracker further increases the performance and robustness of the SIFT- and Ferns-based approaches. We present evaluations on robustness and performance and discuss their appropriateness for Augmented Reality applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5226627]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.99]]></doi>

<publicationId><![CDATA[5226627]]></publicationId>

<partnum><![CDATA[5226627]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5226627&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5226627]]></pdf>

</document>

<document>

<rank>580</rank>

<title><![CDATA[Applying Mixed Reality to Simulate Vulnerable Populations for Practicing Clinical Communication Skills]]></title>

<authors><![CDATA[Joon Hao Chuah;  Lok, B.;  Black, E.]]></authors>

<affiliations><![CDATA[Univ. of Florida, Gainesville, FL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical education]]></term>

<term><![CDATA[computer based training]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[mouse controllers (computers)]]></term>

<term><![CDATA[user interfaces]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Pediatrics]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Sociology]]></term>

<term><![CDATA[Statistics]]></term>

<term><![CDATA[Training]]></term>

<term><![CDATA[Tutorials]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[539]]></spage>

<epage><![CDATA[546]]></epage>

<abstract><![CDATA[Health sciences students often practice and are evaluated on interview and exam skills by working with standardized patients (people that role play having a disease or condition). However, standardized patients do not exist for certain vulnerable populations such as children and the intellectually disabled. As a result, students receive little to no exposure to vulnerable populations before becoming working professionals. To address this problem and thereby increase exposure to vulnerable populations, we propose using virtual humans to simulate members of vulnerable populations. We created a mixed reality pediatric patient that allowed students to practice pediatric developmental exams. Practicing several exams is necessary for students to understand how to properly interact with and correctly assess a variety of children. Practice also increases a student's confidence in performing the exam. Effective practice requires students to treat the virtual child realistically. Treating the child realistically might be affected by how the student and virtual child physically interact, so we created two object interaction interfaces - a natural interface and a mouse-based interface. We tested the complete mixed reality exam and also compared the two object interaction interfaces in a within-subjects user study with 22 participants. Our results showed that the participants accepted the virtual child as a child and treated it realistically. Participants also preferred the natural interface, but the interface did not affect how realistically participants treated the virtual child.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6479180]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.25]]></doi>

<publicationId><![CDATA[6479180]]></publicationId>

<partnum><![CDATA[6479180]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479180&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479180]]></pdf>

</document>

<document>

<rank>581</rank>

<title><![CDATA[The Occlusion Spectrum for Volume Classification and Visualization]]></title>

<authors><![CDATA[Correa, C.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Univ. of California at Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bones]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Intensity modulation]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Skin neoplasms]]></term>

<term><![CDATA[Skull]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1465]]></spage>

<epage><![CDATA[1472]]></epage>

<abstract><![CDATA[Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge.In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290762]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.189]]></doi>

<publicationId><![CDATA[5290762]]></publicationId>

<partnum><![CDATA[5290762]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290762&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290762]]></pdf>

</document>

<document>

<rank>582</rank>

<title><![CDATA[Effective Visualization of Short Routes]]></title>

<authors><![CDATA[Degener, P.;  Schnabel, R.;  Schwartz, C.;  Klein, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics Group, Univ. of Bonn, Bonn]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[realistic images]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1452]]></spage>

<epage><![CDATA[1458]]></epage>

<abstract><![CDATA[In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658162]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.124]]></doi>

<publicationId><![CDATA[4658162]]></publicationId>

<partnum><![CDATA[4658162]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658162&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658162]]></pdf>

</document>

<document>

<rank>583</rank>

<title><![CDATA[Stacking-Based Visualization of Trajectory Attribute Data]]></title>

<authors><![CDATA[Tominski, C.;  Schumann, H.;  Andrienko, G.;  Andrienko, N.]]></authors>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2565]]></spage>

<epage><![CDATA[2574]]></epage>

<abstract><![CDATA[Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327262]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.265]]></doi>

<publicationId><![CDATA[6327262]]></publicationId>

<partnum><![CDATA[6327262]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327262&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327262]]></pdf>

</document>

<document>

<rank>584</rank>

<title><![CDATA[Semiregular Solid Texturing from 2D Image Exemplars]]></title>

<authors><![CDATA[Song-Pei Du;  Shi-Min Hu;  Martin, R.R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[embedded systems]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solids]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[460]]></spage>

<epage><![CDATA[469]]></epage>

<abstract><![CDATA[Solid textures, comprising 3D particles embedded in a matrix in a regular or semiregular pattern, are common in natural and man-made materials, such as brickwork, stone walls, plant cells in a leaf, etc. We present a novel technique for synthesizing such textures, starting from 2D image exemplars which provide cross-sections of the desired volume texture. The shapes and colors of typical particles embedded in the structure are estimated from their 2D cross-sections. Particle positions in the texture images are also used to guide spatial placement of the 3D particles during synthesis of the 3D texture. Our experiments demonstrate that our algorithm can produce higher quality structures than previous approaches; they are both compatible with the input images, and have a plausible 3D nature.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6200268]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.129]]></doi>

<publicationId><![CDATA[6200268]]></publicationId>

<partnum><![CDATA[6200268]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6200268&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200268]]></pdf>

</document>

<document>

<rank>585</rank>

<title><![CDATA[Editor's Note]]></title>

<authors><![CDATA[Ertl, Thomas]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[849]]></spage>

<epage><![CDATA[850]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4276071]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70424]]></doi>

<publicationId><![CDATA[4276071]]></publicationId>

<partnum><![CDATA[4276071]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4276071&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4276071]]></pdf>

</document>

<document>

<rank>586</rank>

<title><![CDATA[Stereoscopic view-dependent visualization of terrain height fields]]></title>

<authors><![CDATA[Gudukbay, U.;  Yilmaz, T.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Eng., Bilkent Univ., Ankara, Turkey]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[image morphing]]></term>

<term><![CDATA[quadtrees]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[software performance evaluation]]></term>

<term><![CDATA[stereo image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Microcomputers]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Workstations]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[330]]></spage>

<epage><![CDATA[345]]></epage>

<abstract><![CDATA[Visualization of large geometric environments has always been an important problem of computer graphics. We present a framework for the stereoscopic view-dependent visualization of large scale terrain models. We use a quadtree based multiresolution representation for the terrain data. This structure is queried to obtain the view-dependent approximations of the terrain model at different levels of detail. In order not to lose depth information, which is crucial for the stereoscopic visualization, we make use of a different simplification criterion, namely, distance-based angular error threshold. We also present an algorithm for the construction of stereo pairs in order to speed up the view-dependent stereoscopic visualization. The approach we use is the simultaneous generation of the triangles for two stereo images using a single draw-list so that the view frustum culling and vertex activation is done only once for each frame. The cracking problem is solved using the dependency information stored for each vertex. We eliminate the popping artifacts that can occur while switching between different resolutions of the data using morphing. We implemented the proposed algorithms on personal computers and graphics workstations. Performance experiments show that the second eye image can be produced approximately 45 percent faster than drawing the two images separately and a smooth stereoscopic visualization can be achieved at interactive frame rates using continuous multiresolution representation of height fields]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1044519]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2002.1044519]]></doi>

<publicationId><![CDATA[1044519]]></publicationId>

<partnum><![CDATA[1044519]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1044519&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044519]]></pdf>

</document>

<document>

<rank>587</rank>

<title><![CDATA[Visual Thinking In Action: Visualizations As Used On Whiteboards]]></title>

<authors><![CDATA[Walny, J.;  Carpendale, S.;  Riche, N.H.;  Venolia, G.;  Fawcett, P.]]></authors>

<affiliations><![CDATA[Univ. of Calgary, Calgary, AB, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[psychology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Image color analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2508]]></spage>

<epage><![CDATA[2517]]></epage>

<abstract><![CDATA[While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065018]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.251]]></doi>

<publicationId><![CDATA[6065018]]></publicationId>

<partnum><![CDATA[6065018]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065018&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065018]]></pdf>

</document>

<document>

<rank>588</rank>

<title><![CDATA[Transitive mesh space of a progressive mesh]]></title>

<authors><![CDATA[Junho Kim;  Seungyong Lee]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Pohang Univ. of Sci. & Technol., South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive control]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Programmable control]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Space technology]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[463]]></spage>

<epage><![CDATA[480]]></epage>

<abstract><![CDATA[The paper investigates the set of all selectively refined meshes that can be obtained from a progressive mesh. We call the set the transitive mesh space of a progressive mesh and present a theoretical analysis of the space. We define selective edge collapse and vertex split transformations, which we use to traverse all selectively refined meshes in the transitive mesh space. We propose a complete selective refinement scheme for a progressive mesh based on the transformations and compare the scheme with previous selective refinement schemes in both theoretical and experimental ways. In our comparison, we show that the complete scheme always generates selectively refined meshes with smaller numbers of vertices and faces than previous schemes for a given refinement criterion. The concept of dual pieces of the vertices in the vertex hierarchy plays a central role in the analysis of the transitive mesh space and the design of selective edge collapse and vertex split transformations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1260742]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1260742]]></doi>

<publicationId><![CDATA[1260742]]></publicationId>

<partnum><![CDATA[1260742]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260742&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260742]]></pdf>

</document>

<document>

<rank>589</rank>

<title><![CDATA[Bristle Maps: A Multivariate Abstraction Technique for Geovisualization]]></title>

<authors><![CDATA[SungYe Kim;  Maciejewski, R.;  Malik, A.;  Yun Jang;  Ebert, D.S.;  Isenberg, T.]]></authors>

<affiliations><![CDATA[Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geography]]></term>

<term><![CDATA[probability]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Spatiotemporal phenomena]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1438]]></spage>

<epage><![CDATA[1454]]></epage>

<abstract><![CDATA[We present Bristle Maps, a novel method for the aggregation, abstraction, and stylization of spatiotemporal data that enables multiattribute visualization, exploration, and analysis. This visualization technique supports the display of multidimensional data by providing users with a multiparameter encoding scheme within a single visual encoding paradigm. Given a set of geographically located spatiotemporal events, we approximate the data as a continuous function using kernel density estimation. The density estimation encodes the probability that an event will occur within the space over a given temporal aggregation. These probability values, for one or more set of events, are then encoded into a bristle map. A bristle map consists of a series of straight lines that extend from, and are connected to, linear map elements such as roads, train, subway lines, and so on. These lines vary in length, density, color, orientation, and transparencya&#x0302;creating the multivariate attribute encoding scheme where event magnitude, change, and uncertainty can be mapped as various bristle parameters. This approach increases the amount of information displayed in a single plot and allows for unique designs for various information schemes. We show the application of our bristle map encoding scheme using categorical spatiotemporal police reports. Our examples demonstrate the use of our technique for visualizing data magnitude, variable comparisons, and a variety of multivariate attribute combinations. To evaluate the effectiveness of our bristle map, we have conducted quantitative and qualitative evaluations in which we compare our bristle map to conventional geovisualization techniques. Our results show that bristle maps are competitive in completion time and accuracy of tasks with various levels of complexity.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6484065]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.66]]></doi>

<publicationId><![CDATA[6484065]]></publicationId>

<partnum><![CDATA[6484065]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6484065&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6484065]]></pdf>

</document>

<document>

<rank>590</rank>

<title><![CDATA[Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[113]]></spage>

<epage><![CDATA[113]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1304819]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1304819]]></doi>

<publicationId><![CDATA[1304819]]></publicationId>

<partnum><![CDATA[1304819]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1304819&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1304819]]></pdf>

</document>

<document>

<rank>591</rank>

<title><![CDATA[Comparing Dot and Landscape Spatializations for Visual Memory Differences]]></title>

<authors><![CDATA[Tory, M.;  Swindells, C.;  Dreezer, R.]]></authors>

<affiliations><![CDATA[Univ. of Victoria, Victoria, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[document handling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Automobiles]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Software systems]]></term>

<term><![CDATA[Surface fitting]]></term>

<term><![CDATA[Surface topography]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Two dimensional displays]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1033]]></spage>

<epage><![CDATA[1040]]></epage>

<abstract><![CDATA[Spatialization displays use a geographic metaphor to arrange non-spatial data. For example, spatializations are commonly applied to document collections so that document themes appear as geographic features such as hills. Many common spatialization interfaces use a 3-D landscape metaphor to present data. However, it is not clear whether 3-D spatializations afford improved speed and accuracy for user tasks compared to similar 2-D spatializations. We describe a user study comparing users' ability to remember dot displays, 2-D landscapes, and 3-D landscapes for two different data densities (500 vs. 1000 points). Participants' visual memory was statistically more accurate when viewing dot displays and 3-D landscapes compared to 2-D landscapes. Furthermore, accuracy remembering a spatialization was significantly better overall for denser spatializations. Theseresults are of benefit to visualization designers who are contemplating the best ways to present data using spatialization techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290709]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.127]]></doi>

<publicationId><![CDATA[5290709]]></publicationId>

<partnum><![CDATA[5290709]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290709&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290709]]></pdf>

</document>

<document>

<rank>592</rank>

<title><![CDATA[Thin structure segmentation and visualization in three-dimensional biomedical images: a shape-based approach]]></title>

<authors><![CDATA[Huang, A.;  Nielson, G.M.;  Razdan, A.;  Farin, G.E.;  Baluch, D.P.;  Capco, D.G.]]></authors>

<affiliations><![CDATA[Diagnostic Radiol. Dept., Nat. Inst. of Health, Bethesda, MD, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Gaussian processes]]></term>

<term><![CDATA[Hessian matrices]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[eigenvalues and eigenfunctions]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[medical image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Biomembranes]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Eigenvalues and eigenfunctions]]></term>

<term><![CDATA[Fiber lasers]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Plasmas]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[93]]></spage>

<epage><![CDATA[102]]></epage>

<abstract><![CDATA[This paper presents a shape-based approach in extracting thin structures, such as lines and sheets, from three-dimensional (3D) biomedical images. Of particular interest is the capability to recover cellular structures, such as microtubule spindle fibers and plasma membranes, from laser scanning confocal microscopic (LSCM) data. Hessian-based shape methods are reviewed. A synthesized linear structure is used to evaluate the sensitivity of the multiscale filtering approach in extracting closely positioned fibers. We find that the multiscale approach tends to fuse lines together, which makes it unsuitable for visualizing mouse egg spindle fibers. Single-scale Gaussian filters, balanced between sensitivity and noise resistance, are adopted instead. In addition, through an ellipsoidal Gaussian model, the eigenvalues of the Hessian matrix are quantitatively associated with the standard deviations of the Gaussian model. Existing shape filters are simplified and applied to LSCM data. A significant improvement in extracting closely positioned thin lines is demonstrated by the resultant images. Further, the direct association of shape models and eigenvalues makes the processed images more understandable qualitatively and quantitatively.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1542003]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.15]]></doi>

<publicationId><![CDATA[1542003]]></publicationId>

<partnum><![CDATA[1542003]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1542003&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542003]]></pdf>

</document>

<document>

<rank>593</rank>

<title><![CDATA[Visualizing Dynamic Hierarchies in Graph Sequences]]></title>

<authors><![CDATA[Vehlow, C.;  Beck, F.;  Weiskopf, D.]]></authors>

<affiliations><![CDATA[Corinna Vehlow is with VISUS, University of Stuttgart, Germany.(email:corinna.vehlow@visus.uni-stuttgart.de)]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Graphs are used to model relations between objects, where these objects can be grouped hierarchically based on their connectivity. In many applications, the relations change over time and so does the hierarchical group structure. We developed a visualization technique that supports the analysis of the topology and the hierarchical group structure of a dynamic graph and the tracking of changes over time. Each graph of a sequence is visualized by an adjacency matrix, where the hierarchical group structure is encoded within the matrix using indentation and nested contours, complemented by icicle plots attached to the matrices. The density within and between subgroups of the hierarchy is represented within the matrices using a gray scale. To visualize changes, transitions and dissimilarities between the hierarchically structured graphs are shown using a flow metaphor and color coding. The design of our visualization technique allows us to show more than one hierarchical group structure of the same graph by stacking the sequences, where hierarchy comparison is supported not only within but also between sequences. To improve the readability, we minimize the number of crossing curves within and between sequences based on a sorting algorithm that sweeps through the sequences of hierarchies.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7352369]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2507595]]></doi>

<publicationId><![CDATA[7352369]]></publicationId>

<partnum><![CDATA[7352369]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7352369&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7352369]]></pdf>

</document>

<document>

<rank>594</rank>

<title><![CDATA[Painting with Polygons: A Procedural Watercolor Engine]]></title>

<authors><![CDATA[DiVerdi, S.;  Krishnaswamy, A.;  Mech, R.;  Ito, D.]]></authors>

<affiliations><![CDATA[Adobe Syst., Inc., Oakland, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[painting]]></term>

<term><![CDATA[pigments]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[screens (display)]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brushes]]></term>

<term><![CDATA[Heuristic algorithms]]></term>

<term><![CDATA[Painting]]></term>

<term><![CDATA[Paints]]></term>

<term><![CDATA[Pigments]]></term>

<term><![CDATA[Tablet computers]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[723]]></spage>

<epage><![CDATA[735]]></epage>

<abstract><![CDATA[Existing natural media painting simulations have produced high-quality results, but have required powerful compute hardware and have been limited to screen resolutions. Digital artists would like to be able to use watercolor-like painting tools, but at print resolutions and on lower end hardware such as laptops or even slates. We present a procedural algorithm for generating watercolor-like dynamic paint behaviors in a lightweight manner. Our goal is not to exactly duplicate watercolor painting, but to create a range of dynamic behaviors that allow users to achieve a similar style of process and result, while at the same time having a unique character of its own. Our stroke representation is vector based, allowing for rendering at arbitrary resolutions, and our procedural pigment advection algorithm is fast enough to support painting on slate devices. We demonstrate our technique in a commercially available slate application used by professional artists. Finally, we present a detailed analysis of the different vector-rendering technologies available.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6314479]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.295]]></doi>

<publicationId><![CDATA[6314479]]></publicationId>

<partnum><![CDATA[6314479]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6314479&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6314479]]></pdf>

</document>

<document>

<rank>595</rank>

<title><![CDATA[Automatic Generation of 3D Caricatures Based on Artistic Deformation Styles]]></title>

<authors><![CDATA[Clarke, L.;  Chen, M.;  Mora, B.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Swansea Univ., Swansea, UK]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Head]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Internet]]></term>

<term><![CDATA[Material properties]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Software systems]]></term>

<term><![CDATA[Usability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[808]]></spage>

<epage><![CDATA[821]]></epage>

<abstract><![CDATA[Caricatures are a form of humorous visual art, usually created by skilled artists for the intention of amusement and entertainment. In this paper, we present a novel approach for automatic generation of digital caricatures from facial photographs, which capture artistic deformation styles from hand-drawn caricatures. We introduced a pseudo stress-strain model to encode the parameters of an artistic deformation style using &#x201C;virtual&#x201D; physical and material properties. We have also developed a software system for performing the caricaturistic deformation in 3D which eliminates the undesirable artifacts in 2D caricaturization. We employed a Multilevel Free-Form Deformation (MFFD) technique to optimize a 3D head model reconstructed from an input facial photograph, and for controlling the caricaturistic deformation. Our results demonstrated the effectiveness and usability of the proposed approach, which allows ordinary users to apply the captured and stored deformation styles to a variety of facial photographs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5473224]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.76]]></doi>

<publicationId><![CDATA[5473224]]></publicationId>

<partnum><![CDATA[5473224]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5473224&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473224]]></pdf>

</document>

<document>

<rank>596</rank>

<title><![CDATA[The Shaping of Information by Visual Metaphors]]></title>

<authors><![CDATA[Ziemkiewicz, C.;  Kosara, R.]]></authors>

<affiliations><![CDATA[UNC, Charlotte, NC]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Delay]]></term>

<term><![CDATA[Knowledge representation]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Usability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1269]]></spage>

<epage><![CDATA[1276]]></epage>

<abstract><![CDATA[The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658138]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.171]]></doi>

<publicationId><![CDATA[4658138]]></publicationId>

<partnum><![CDATA[4658138]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658138&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658138]]></pdf>

</document>

<document>

<rank>597</rank>

<title><![CDATA[VisWeek 2009 Call for Participation]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[351]]></spage>

<epage><![CDATA[351]]></epage>

<abstract><![CDATA[Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4756210]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.20]]></doi>

<publicationId><![CDATA[4756210]]></publicationId>

<partnum><![CDATA[4756210]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4756210&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4756210]]></pdf>

</document>

<document>

<rank>598</rank>

<title><![CDATA[A Multigrid Fluid Pressure Solver Handling Separating Solid Boundary Conditions]]></title>

<authors><![CDATA[Chentanez, N.;  Mueller-Fischer, M.]]></authors>

<affiliations><![CDATA[NVIDIA PhysX Res., Bangkok, Thailand]]></affiliations>

<controlledterms>

<term><![CDATA[Poisson equation]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[differential equations]]></term>

<term><![CDATA[quadratic programming]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Boundary conditions]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Linear systems]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Multigrid methods]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Solids]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1191]]></spage>

<epage><![CDATA[1201]]></epage>

<abstract><![CDATA[We present a multigrid method for solving the linear complementarity problem (LCP) resulting from discretizing the Poisson equation subject to separating solid boundary conditions in an Eulerian liquid simulation's pressure projection step. The method requires only a few small changes to a multigrid solver for linear systems. Our generalized solver is fast enough to handle 3D liquid simulations with separating boundary conditions in practical domain sizes. Previous methods could only handle relatively small 2D domains in reasonable time, because they used expensive quadratic programming (QP) solvers. We demonstrate our technique in several practical scenarios, including nonaxis-aligned containers and moving solids in which the omission of separating boundary conditions results in disturbing artifacts of liquid sticking to solids. Our measurements show, that the convergence rate of our LCP solver is close to that of a standard multigrid solver.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6171181]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.86]]></doi>

<publicationId><![CDATA[6171181]]></publicationId>

<partnum><![CDATA[6171181]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6171181&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171181]]></pdf>

</document>

<document>

<rank>599</rank>

<title><![CDATA[Real-Time Physics-Based 3D Biped Character Animation Using an Inverted Pendulum Model]]></title>

<authors><![CDATA[Yao-Yang Tsai;  Wen-Chieh Lin;  Cheng, K.B.;  Jehee Lee;  Tong-Yee Lee]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng-Kung Univ., Tainan, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[control engineering computing]]></term>

<term><![CDATA[motion control]]></term>

<term><![CDATA[nonlinear systems]]></term>

<term><![CDATA[pendulums]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Angular velocity control]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Character generation]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Motion control]]></term>

<term><![CDATA[PD control]]></term>

<term><![CDATA[Physics computing]]></term>

<term><![CDATA[Torque control]]></term>

<term><![CDATA[Tracking]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[325]]></spage>

<epage><![CDATA[337]]></epage>

<abstract><![CDATA[We present a physics-based approach to generate 3D biped character animation that can react to dynamical environments in real time. Our approach utilizes an inverted pendulum model to online adjust the desired motion trajectory from the input motion capture data. This online adjustment produces a physically plausible motion trajectory adapted to dynamic environments, which is then used as the desired motion for the motion controllers to track in dynamics simulation. Rather than using Proportional-Derivative controllers whose parameters usually cannot be easily set, our motion tracking adopts a velocity-driven method which computes joint torques based on the desired joint angular velocities. Physically correct full-body motion of the 3D character is computed in dynamics simulation using the computed torques and dynamical model of the character. Our experiments demonstrate that tracking motion capture data with real-time response animation can be achieved easily. In addition, physically plausible motion style editing, automatic motion transition, and motion adaptation to different limb sizes can also be generated without difficulty.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5161260]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.76]]></doi>

<publicationId><![CDATA[5161260]]></publicationId>

<partnum><![CDATA[5161260]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5161260&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5161260]]></pdf>

</document>

<document>

<rank>600</rank>

<title><![CDATA[Filtering Non-Linear TransferFunctions on Surfaces]]></title>

<authors><![CDATA[Heitz, E.;  Nowrouzezahrai, D.;  Poulin, P.;  Neyret, F.]]></authors>

<affiliations><![CDATA[INRIA-LJK, Univ. de Grenoble, St. Ismier, France]]></affiliations>

<controlledterms>

<term><![CDATA[Gaussian processes]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image enhancement]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[nonlinear filters]]></term>

<term><![CDATA[nonlinear functions]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[table lookup]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Colored noise]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[996]]></spage>

<epage><![CDATA[1008]]></epage>

<abstract><![CDATA[Applying non-linear transfer functions and look-up tables to procedural functions (such as noise), surface attributes, or even surface geometry are common strategies used to enhance visual detail. Their simplicity and ability to mimic a wide range of realistic appearances have led to their adoption in many rendering problems. As with any textured or geometric detail, proper filtering is needed to reduce aliasing when viewed across a range of distances, but accurate and efficient transfer function filtering remains an open problem for several reasons: transfer functions are complex and non-linear, especially when mapped through procedural noise and/or geometry-dependent functions, and the effects of perspective and masking further complicate the filtering over a pixel's footprint. We accurately solve this problem by computing and sampling from specialized filtering distributions on the fly, yielding very fast performance. We investigate the case where the transfer function to filter is a color map applied to (macroscale) surface textures (like noise), as well as color maps applied according to (microscale) geometric details. We introduce a novel representation of a (potentially modulated) color map's distribution over pixel footprints using Gaussian statistics and, in the more complex case of high-resolution color mapped microsurface details, our filtering is view- and light-dependent, and capable of correctly handling masking and occlusion effects. Our approach can be generalized to filter other physical-based rendering quantities. We propose an application to shading with irradiance environment maps over large terrains. Our framework is also compatible with the case of transfer functions used to warp surface geometry, as long as the transformations can be represented with Gaussian statistics, leading to proper view- and light-dependent filtering results. Our results match ground truth and our solution is well suited to real-time applications, requires only a few- lines of shader code (provided in supplemental material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TVCG.2013.102), is high performance, and has a negligible memory footprint.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6564283]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.102]]></doi>

<publicationId><![CDATA[6564283]]></publicationId>

<partnum><![CDATA[6564283]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6564283&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6564283]]></pdf>

</document>

<document>

<rank>601</rank>

<title><![CDATA[Cover4]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6168458]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.84]]></doi>

<publicationId><![CDATA[6168458]]></publicationId>

<partnum><![CDATA[6168458]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6168458&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168458]]></pdf>

</document>

<document>

<rank>602</rank>

<title><![CDATA[Mixed Reality Virtual Pets to Reduce Childhood Obesity]]></title>

<authors><![CDATA[Johnsen, K.;  Sun Joo Ahn;  Moore, J.;  Brown, S.;  Robertson, T.P.;  Marable, A.;  Basu, A.]]></authors>

<controlledterms>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Avatars]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Obesity]]></term>

<term><![CDATA[Pediatrics]]></term>

<term><![CDATA[Positron emission tomography]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[523]]></spage>

<epage><![CDATA[530]]></epage>

<abstract><![CDATA[Novel approaches are needed to reduce the high rates of childhood obesity in the developed world. While multifactorial in cause, a major factor is an increasingly sedentary lifestyle of children. Our research shows that a mixed reality system that is of interest to children can be a powerful motivator of healthy activity. We designed and constructed a mixed reality system that allowed children to exercise, play with, and train a virtual pet using their own physical activity as input. The health, happiness, and intelligence of each virtual pet grew as its associated child owner exercised more, reached goals, and interacted with their pet. We report results of a research study involving 61 children from a local summer camp that shows a large increase in recorded and observed activity, alongside observational evidence that the virtual pet was responsible for that change. These results, and the ease at which the system integrated into the camp environment, demonstrate the practical potential to impact the exercise behaviors of children with mixed reality.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6777460]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.33]]></doi>

<publicationId><![CDATA[6777460]]></publicationId>

<partnum><![CDATA[6777460]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777460&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777460]]></pdf>

</document>

<document>

<rank>603</rank>

<title><![CDATA[Call For Participation]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[608]]></spage>

<epage><![CDATA[608]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1471697]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.73]]></doi>

<publicationId><![CDATA[1471697]]></publicationId>

<partnum><![CDATA[1471697]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1471697&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471697]]></pdf>

</document>

<document>

<rank>604</rank>

<title><![CDATA[Brushing Dimensions - A Dual Visual Analysis Model for High-Dimensional Data]]></title>

<authors><![CDATA[Turkay, C.;  Filzmoser, P.;  Hauser, H.]]></authors>

<affiliations><![CDATA[Dept. of Inf., Univ. of Bergen, Bergen, Norway]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[lab-on-a-chip]]></term>

<term><![CDATA[set theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Principal component analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2591]]></spage>

<epage><![CDATA[2599]]></epage>

<abstract><![CDATA[In many application fields, data analysts have to deal with datasets that contain many expressions per item. The effective analysis of such multivariate datasets is dependent on the user's ability to understand both the intrinsic dimensionality of the dataset as well as the distribution of the dependent values with respect to the dimensions. In this paper, we propose a visualization model that enables the joint interactive visual analysis of multivariate datasets with respect to their dimensions as well as with respect to the actual data values. We describe a dual setting of visualization and interaction in items space and in dimensions space. The visualization of items is linked to the visualization of dimensions with brushing and focus+context visualization. With this approach, the user is able to jointly study the structure of the dimensions space as well as the distribution of data items with respect to the dimensions. Even though the proposed visualization model is general, we demonstrate its application in the context of a DNA microarray data analysis.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6065027]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.178]]></doi>

<publicationId><![CDATA[6065027]]></publicationId>

<partnum><![CDATA[6065027]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065027&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065027]]></pdf>

</document>

<document>

<rank>605</rank>

<title><![CDATA[A sampling framework for accurate curvature estimation in discrete surfaces]]></title>

<authors><![CDATA[Agam, G.;  Xiaojing Tang]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Illinois Inst. of Technol., Chicago, IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[image recognition]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Object segmentation]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[573]]></spage>

<epage><![CDATA[583]]></epage>

<abstract><![CDATA[Accurate curvature estimation in discrete surfaces is an important problem with numerous applications. Curvature is an indicator of ridges and can be used in applications such as shape analysis and recognition, object segmentation, adaptive smoothing, anisotropic fairing of irregular meshes, and anisotropic texture mapping. In this paper, a new framework is proposed for accurate curvature estimation in discrete surfaces. The proposed framework is based on a local directional curve sampling of the surface where the sampling frequency can be controlled. This local model has a large number of degrees of freedoms compared with known techniques and, so, can better represent the local geometry. The proposed framework is quantitatively evaluated and compared with common techniques for surface curvature estimation. In order to perform an unbiased evaluation in which smoothing effects are factored out, we use a set of randomly generated Bezier surface patches for which the curvature values can be analytically computed. It is demonstrated that, through the establishment of sampling conditions, the error in estimations obtained by the proposed framework is smaller and that the proposed framework is less sensitive to low sampling density, sampling irregularities, and sampling noise.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1471694]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.69]]></doi>

<publicationId><![CDATA[1471694]]></publicationId>

<partnum><![CDATA[1471694]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1471694&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471694]]></pdf>

</document>

<document>

<rank>606</rank>

<title><![CDATA[Enhanced Spatial Stability with Hilbert and Moore Treemaps]]></title>

<authors><![CDATA[Tak, S.;  Cockburn, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Software Eng., Univ. of Canterbury, Christchurch, New Zealand]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Gravity]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Stability criteria]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[141]]></spage>

<epage><![CDATA[148]]></epage>

<abstract><![CDATA[Treemaps are a well known and powerful space-filling visualisation method for displaying hierarchical data. Many alternative treemap algorithms have been proposed, often with the aim being to optimise performance across several criteria, including spatial stability to assist users in locating and monitoring items of interest. In this paper, we demonstrate that spatial stability is not fully captured by the commonly used "distance change&#x201D; (DC) metric, and we introduce a new "location drift&#x201D; (LD) metric to more fully capture spatial stability. An empirical study examines the validity and usefulness of the location drift metric, showing that it explains some effects on user performance that distance change does not. Next, we introduce "Hilbert&#x201D; and "Moore&#x201D; treemap algorithms, which are designed to achieve high spatial stability. We assess their performance in comparison to other treemaps, showing that Hilbert and Moore treemaps perform well across all stability metrics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6185545]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.108]]></doi>

<publicationId><![CDATA[6185545]]></publicationId>

<partnum><![CDATA[6185545]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6185545&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185545]]></pdf>

</document>

<document>

<rank>607</rank>

<title><![CDATA[Fast multiresolution image operations in the wavelet domain]]></title>

<authors><![CDATA[Drori, I.;  Lischinski, D.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci., Tel Aviv Univ., Israel]]></affiliations>

<controlledterms>

<term><![CDATA[convolution]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[frequency-domain analysis]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Frequency domain analysis]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Matrix decomposition]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sparse matrices]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Wavelet domain]]></term>

<term><![CDATA[Wavelet transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[395]]></spage>

<epage><![CDATA[411]]></epage>

<abstract><![CDATA[A wide class of operations on images can be performed directly in the wavelet domain by operating on coefficients of the wavelet transforms of the images and other matrices defined by these operations. Operating in the wavelet domain enables one to perform these operations progressively in a coarse-to-fine fashion, operate on different resolutions, manipulate features at different scales, trade off accuracy for speed, and localize the operation in both the spatial and the frequency domains. Performing such operations in the wavelet domain and then reconstructing the result is also often more efficient than performing the same operation in the standard direct fashion. In this paper, we demonstrate the applicability and advantages of this framework to three common types of image operations: image blending, 3D warping of images and sequences, and convolution of images and image sequences.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1207446]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1207446]]></doi>

<publicationId><![CDATA[1207446]]></publicationId>

<partnum><![CDATA[1207446]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1207446&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1207446]]></pdf>

</document>

<document>

<rank>608</rank>

<title><![CDATA[Visual Analysis of Topic Competition on Social Media]]></title>

<authors><![CDATA[Panpan Xu;  Yingcai Wu;  Enxun Wei;  Tai-Quan Peng;  Shixia Liu;  Zhu, J.J.H.;  Huamin Qu]]></authors>

<affiliations><![CDATA[Hong Kong Univ. of Sci. & Technol., Hong Kong, China]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[social networking (online)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Recruitment]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2012]]></spage>

<epage><![CDATA[2021]]></epage>

<abstract><![CDATA[How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634134]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.221]]></doi>

<publicationId><![CDATA[6634134]]></publicationId>

<partnum><![CDATA[6634134]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634134&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634134]]></pdf>

</document>

<document>

<rank>609</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on the Joint Conference on Geometric Design and Solid and Physical Modeling (GDSPM)]]></title>

<authors><![CDATA[Bronsvoort, W.F.;  Gravesen, Jens;  Keyser, J.]]></authors>

<thesaurusterms>

<term><![CDATA[Meetings]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Special issues and sections]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[713]]></spage>

<epage><![CDATA[714]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5746561]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.71]]></doi>

<publicationId><![CDATA[5746561]]></publicationId>

<partnum><![CDATA[5746561]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5746561&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5746561]]></pdf>

</document>

<document>

<rank>610</rank>

<title><![CDATA[IEEE Computer Society Digital Library [advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[484]]></spage>

<epage><![CDATA[484]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4435115]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.18]]></doi>

<publicationId><![CDATA[4435115]]></publicationId>

<partnum><![CDATA[4435115]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4435115&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4435115]]></pdf>

</document>

<document>

<rank>611</rank>

<title><![CDATA[Computing Length-Preserved Free Boundary for Quasi-Developable Mesh Segmentation]]></title>

<authors><![CDATA[Wang, Charlie C.L.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[25]]></spage>

<epage><![CDATA[36]]></epage>

<abstract><![CDATA[Stretch-free surface flattening has been requested by a variety of applications. At present, the most difficult problem is how to segment a given model into nearly developable atlases so that a nearly stretch-free flattening can be computed. The criterion for segmentation is needed to evaluate the possibility of flattening a given surface patch, which should be fast computed. In this paper, we present a method to compute the length-preserved free boundary (LPFB) of a mesh patch which speeds up the mesh parameterization. The distortion on parameterization can then be employed as the criterion in a trial-and-error algorithm for segmenting a given model into nearly developable atlases. The computation of LPFB is formulated as a numerical optimization problem in the angle space, where we are trying to optimize the angle excesses on the boundary while preserving the constraints derived from the closed-path theorem and the length preservation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359482]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1067]]></doi>

<publicationId><![CDATA[4359482]]></publicationId>

<partnum><![CDATA[4359482]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359482&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359482]]></pdf>

</document>

<document>

<rank>612</rank>

<title><![CDATA[A Task Taxonomy for Network Evolution Analysis]]></title>

<authors><![CDATA[Jae-wook Ahn;  Plaisant, C.;  Shneiderman, B.]]></authors>

<affiliations><![CDATA[Human Comput. Interaction Lab. (HCIL), Univ. of Maryland, College Park, MD, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[evolutionary computation]]></term>

<term><![CDATA[social networking (online)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Communities]]></term>

<term><![CDATA[Compounds]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Evolution (biology)]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Taxonomy]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[365]]></spage>

<epage><![CDATA[376]]></epage>

<abstract><![CDATA[Visualization has proven to be a useful tool for understanding network structures. Yet the dynamic nature of social media networks requires powerful visualization techniques that go beyond static network diagrams. To provide strong temporal network visualization tools, designers need to understand what tasks the users have to accomplish. This paper describes a taxonomy of temporal network visualization tasks. We identify the 1) entities, 2) properties, and 3) temporal features, which were extracted by surveying 53 existing temporal network visualization systems. By building and examining the task taxonomy, we report which tasks are well covered by existing systems and make suggestions for designing future visualization tools. The feedback from 12 network analysts helped refine the taxonomy.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6620874]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.238]]></doi>

<publicationId><![CDATA[6620874]]></publicationId>

<partnum><![CDATA[6620874]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6620874&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6620874]]></pdf>

</document>

<document>

<rank>613</rank>

<title><![CDATA[Identifying White-Matter Fiber Bundles in DTI Data Using an Automated Proximity-Based Fiber-Clustering Method]]></title>

<authors><![CDATA[Song Zhang;  Correia, S.;  Laidlaw, D.H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Mississippi State Univ., Starkville, MS]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[brain]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1044]]></spage>

<epage><![CDATA[1053]]></epage>

<abstract><![CDATA[We present a method for clustering diffusion tensor imaging (DTI) integral curves into anatomically plausible bundles. An expert rater evaluated the anatomical accuracy of the bundles. We also evaluated the method by applying an experimental cross-subject labeling method to the clustering results. We first employ a sampling and culling strategy for generating DTI integral curves and then constrain the curves so that they terminate in gray matter. We then employ a clustering method based on a proximity measure calculated between every pair of curves. We interactively selected a proximity threshold to achieve visually optimal clustering in models from four DTI datasets. An expert rater then assigned a confidence rating about bundle presence and accuracy for each of 12 target fiber bundles of varying calibers and type in each dataset. We then created a fiber bundle template to cluster and label the fiber bundles automatically in new datasets. According to expert evaluation, the automated proximity-based clustering and labeling algorithm consistently yields anatomically plausible fiber bundles on large and coherent clusters. This work has the potential to provide an automatic and robust way to find and study neural fiber bundles within DTI.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4479455]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.52]]></doi>

<publicationId><![CDATA[4479455]]></publicationId>

<partnum><![CDATA[4479455]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4479455&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479455]]></pdf>

</document>

<document>

<rank>614</rank>

<title><![CDATA[Interactive Streak Surface Visualization on the GPU]]></title>

<authors><![CDATA[Burger, K.;  Ferstl, F.;  Theisel, H.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization group, Tech. Univ. Munchen, Munich, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[physics computing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bandwidth]]></term>

<term><![CDATA[Computational complexity]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Hydrogen]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Streaming media]]></term>

<term><![CDATA[Video sequences]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1259]]></spage>

<epage><![CDATA[1266]]></epage>

<abstract><![CDATA[In this paper we present techniques for the visualization of unsteady flows using streak surfaces, which allow for the first time an adaptive integration and rendering of such surfaces in real-time. The techniques consist of two main components, which are both realized on the GPU to exploit computational and bandwidth capacities for numerical particle integration and to minimize bandwidth requirements in the rendering of the surface. In the construction stage, an adaptive surface representation is generated. Surface refinement and coarsening strategies are based on local surface properties like distortion and curvature. We compare two different methods to generate a streak surface: a) by computing a patch-based surface representation that avoids any interdependence between patches, and b) by computing a particle-based surface representation including particle connectivity, and by updating this connectivity during particle refinement and coarsening. In the rendering stage, the surface is either rendered as a set of quadrilateral surface patches using high-quality point-based approaches, or a surface triangulation is built in turn from the given particle connectivity and the resulting triangle mesh is rendered. We perform a comparative study of the proposed techniques with respect to surface quality, visual quality and performance by visualizing streak surfaces in real flows using different rendering options.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290737]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.154]]></doi>

<publicationId><![CDATA[5290737]]></publicationId>

<partnum><![CDATA[5290737]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290737&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290737]]></pdf>

</document>

<document>

<rank>615</rank>

<title><![CDATA[Visually Exploring Transportation Schedules]]></title>

<authors><![CDATA[Palomo, C.;  Zhan Guo;  Silva, C.T.;  Freire, J.]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[delays]]></term>

<term><![CDATA[light rail systems]]></term>

<term><![CDATA[pattern recognition]]></term>

<term><![CDATA[public transport]]></term>

<term><![CDATA[rail traffic]]></term>

<term><![CDATA[scheduling]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bandwidth]]></term>

<term><![CDATA[Delays]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Public transportation]]></term>

<term><![CDATA[Schedules]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[170]]></spage>

<epage><![CDATA[179]]></epage>

<abstract><![CDATA[Public transportation schedules are designed by agencies to optimize service quality under multiple constraints. However, real service usually deviates from the plan. Therefore, transportation analysts need to identify, compare and explain both eventual and systemic performance issues that must be addressed so that better timetables can be created. The purely statistical tools commonly used by analysts pose many difficulties due to the large number of attributes at tripand station-level for planned and real service. Also challenging is the need for models at multiple scales to search for patterns at different times and stations, since analysts do not know exactly where or when relevant patterns might emerge and need to compute statistical summaries for multiple attributes at different granularities. To aid in this analysis, we worked in close collaboration with a transportation expert to design TR-EX, a visual exploration tool developed to identify, inspect and compare spatio-temporal patterns for planned and real transportation service. TR-EX combines two new visual encodings inspired by Marey's Train Schedule: Trips Explorer for trip-level analysis of frequency, deviation and speed; and Stops Explorer for station-level study of delay, wait time, reliability and performance deficiencies such as bunching. To tackle overplotting and to provide a robust representation for a large numbers of trips and stops at multiple scales, the system supports variable kernel bandwidths to achieve the level of detail required by users for different tasks. We justify our design decisions based on specific analysis needs of transportation analysts. We provide anecdotal evidence of the efficacy of TR-EX through a series of case studies that explore NYC subway service, which illustrate how TR-EX can be used to confirm hypotheses and derive new insights through visual exploration.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192706]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467592]]></doi>

<publicationId><![CDATA[7192706]]></publicationId>

<partnum><![CDATA[7192706]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192706&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192706]]></pdf>

</document>

<document>

<rank>616</rank>

<title><![CDATA[Single-Pass Composable 3D Lens Rendering and Spatiotemporal 3D Lenses]]></title>

<authors><![CDATA[Borst, C.W.;  Tiesel, J.-P.;  Habib, E.;  Das, K.]]></authors>

<affiliations><![CDATA[Center for Adv. Comput. Studies, Univ. of Louisiana at Lafayette, Lafayette, LA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[lenses]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[time warp simulation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1259]]></spage>

<epage><![CDATA[1272]]></epage>

<abstract><![CDATA[We present a new 3D lens rendering technique and a new spatiotemporal lens. Interactive 3D lenses, often called volumetric lenses, provide users with alternative views of data sets within 3D lens boundaries while maintaining the surrounding overview (context). In contrast to previous multipass rendering work, we discuss the strengths, limitations, and performance costs of a single-pass technique especially suited to fragment-level lens effects, such as color mapping, lighting, and clipping. Some object-level effects, such as a data set selection lens, are also incorporated, with each object's geometry being processed once by the graphics pipeline. For a substantial range of effects, our approach supports several composable lenses at interactive frame rates without performance loss during increasing lens intersections or manipulation by a user. Other cases, for which this performance cannot be achieved, are also discussed. We illustrate possible applications of our lens system, including Time Warp lenses for exploring time-varying data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5710908]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.38]]></doi>

<publicationId><![CDATA[5710908]]></publicationId>

<partnum><![CDATA[5710908]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5710908&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710908]]></pdf>

</document>

<document>

<rank>617</rank>

<title><![CDATA[Evaluation of memoryless simplification]]></title>

<authors><![CDATA[Lindstrom, P.;  Turk, G.]]></authors>

<affiliations><![CDATA[Graphics, Visualization, & Usability Center, Georgia Inst. of Technol., Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Computer errors]]></term>

<term><![CDATA[Design automation]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Optimization methods]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Terrain mapping]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[98]]></spage>

<epage><![CDATA[115]]></epage>

<abstract><![CDATA[We investigate the effectiveness of the memoryless simplification approach described by Lindstrom and Turk (1998). Like many polygon simplification methods, this approach reduces the number of triangles in a model by performing a sequence of edge collapses. It differs from most recent methods, however, in that it does not retain a history of the geometry of the original model during simplification. We present numerical comparisons showing that the memoryless method results in smaller mean distance measures than many published techniques that retain geometric history. We compare a number of different vertex placement schemes for an edge collapse in order to identify the aspects of the memoryless simplification that are responsible for its high level of fidelity. We also evaluate simplification of models with boundaries, and we show how the memoryless method may be tuned to trade between manifold and boundary fidelity. We found that the memoryless approach yields consistently low mean errors when measured by the Metro mesh comparison tool. In addition to using complex models for the evaluations, we also perform comparisons using a sphere and portions of a sphere. These simple surfaces turn out to match the simplification behaviors for the more complex models that we used]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[773803]]></arnumber>

<doi><![CDATA[10.1109/2945.773803]]></doi>

<publicationId><![CDATA[773803]]></publicationId>

<partnum><![CDATA[773803]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=773803&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=773803]]></pdf>

</document>

<document>

<rank>618</rank>

<title><![CDATA[Semantic Enrichment of Movement Behavior with Foursquare&#x2013;A Visual Analytics Approach]]></title>

<authors><![CDATA[Krueger, R.;  Thom, D.;  Ertl, T.]]></authors>

<affiliations><![CDATA[Inst. of Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision making]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[mobile computing]]></term>

<term><![CDATA[social networking (online)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Semantics]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[903]]></spage>

<epage><![CDATA[915]]></epage>

<abstract><![CDATA[In recent years, many approaches have been developed that efficiently and effectively visualize movement data, e.g., by providing suitable aggregation strategies to reduce visual clutter. Analysts can use them to identify distinct movement patterns, such as trajectories with similar direction, form, length, and speed. However, less effort has been spent on finding the semantics behind movements, i.e. why somebody or something is moving. This can be of great value for different applications, such as product usage and consumer analysis, to better understand urban dynamics, and to improve situational awareness. Unfortunately, semantic information often gets lost when data is recorded. Thus, we suggest to enrich trajectory data with POI information using social media services and show how semantic insights can be gained. Furthermore, we show how to handle semantic uncertainties in time and space, which result from noisy, unprecise, and missing data, by introducing a POI decision model in combination with highly interactive visualizations. Finally, we evaluate our approach with two case studies on a large electric scooter data set and test our model on data with known ground truth.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6960909]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2371856]]></doi>

<publicationId><![CDATA[6960909]]></publicationId>

<partnum><![CDATA[6960909]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6960909&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6960909]]></pdf>

</document>

<document>

<rank>619</rank>

<title><![CDATA[Uncertainty Quantification in Linear Interpolation for Isosurface Extraction]]></title>

<authors><![CDATA[Athawale, T.;  Entezari, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[statistical distributions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Probability density function]]></term>

<term><![CDATA[Random variables]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2723]]></spage>

<epage><![CDATA[2732]]></epage>

<abstract><![CDATA[We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634171]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.208]]></doi>

<publicationId><![CDATA[6634171]]></publicationId>

<partnum><![CDATA[6634171]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634171&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634171]]></pdf>

</document>

<document>

<rank>620</rank>

<title><![CDATA[PrePages]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Conference proceedings]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[i]]></spage>

<epage><![CDATA[xxv]]></epage>

<abstract><![CDATA[Prepages from Vis/InfoVis 2008]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4658122]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.156]]></doi>

<publicationId><![CDATA[4658122]]></publicationId>

<partnum><![CDATA[4658122]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658122&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658122]]></pdf>

</document>

<document>

<rank>621</rank>

<title><![CDATA[Volume illustration: nonphotorealistic rendering of volume models]]></title>

<authors><![CDATA[Rheingans, P.;  Ebert, D.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Electr. Eng., Maryland Univ., Baltimore, MD, USA]]></affiliations>

<controlledterms>

<term><![CDATA[image enhancement]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[optical transfer function]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Manuals]]></term>

<term><![CDATA[Optical attenuators]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[X-rays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[253]]></spage>

<epage><![CDATA[264]]></epage>

<abstract><![CDATA[Accurately and automatically conveying the structure of a volume model is a problem which has not been fully solved by existing volume rendering approaches. Physics-based volume rendering approaches create images which may match the appearance of translucent materials in nature but may not embody important structural details. Transfer function approaches allow flexible design of the volume appearance but generally require substantial hand-tuning for each new data set in order to be effective. We introduce the volume illustration approach, combining the familiarity of a physics-based illumination model with the ability to enhance important features using non-photorealistic rendering techniques. Since the features to be enhanced are defined on the basis of local volume characteristics rather than volume sample values, the application of volume illustration techniques requires less manual tuning than the design of a good transfer function. Volume illustration provides a flexible unified framework for enhancing the structural perception of volume models through the amplification of features and the addition of illumination effects]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[942693]]></arnumber>

<doi><![CDATA[10.1109/2945.942693]]></doi>

<publicationId><![CDATA[942693]]></publicationId>

<partnum><![CDATA[942693]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=942693&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=942693]]></pdf>

</document>

<document>

<rank>622</rank>

<title><![CDATA[Skeleton Cuts&#x02014;An Efficient Segmentation Method for Volume Rendering]]></title>

<authors><![CDATA[Dehui Xiang;  Tian, Jie;  Fei Yang;  Qi Yang;  Xing Zhang;  Qingde Li;  Xin Liu]]></authors>

<affiliations><![CDATA[Inst. of Autom., Chinese Acad. of Sci. & Grad. Univ. of Chinese Acad. of Sci., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[bone]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image classification]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Euclidean distance]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Skeleton]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1295]]></spage>

<epage><![CDATA[1306]]></epage>

<abstract><![CDATA[Volume rendering has long been used as a key technique for volume data visualization, which works by using a transfer function to map color and opacity to each voxel. Many volume rendering approaches proposed so far for voxels classification have been limited in a single global transfer function, which is in general unable to properly visualize interested structures. In this paper, we propose a localized volume data visualization approach which regards volume visualization as a combination of two mutually related processes: the segmentation of interested structures and the visualization using a locally designed transfer function for each individual structure of interest. As shown in our work, a new interactive segmentation algorithm is advanced via skeletons to properly categorize interested structures. In addition, a localized transfer function is subsequently presented to assign optical parameters via interested information such as intensity, thickness and distance. As can be seen from the experimental results, the proposed techniques allow to appropriately visualize interested structures in highly complex volume medical data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5620899]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.239]]></doi>

<publicationId><![CDATA[5620899]]></publicationId>

<partnum><![CDATA[5620899]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5620899&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620899]]></pdf>

</document>

<document>

<rank>623</rank>

<title><![CDATA[On the Fractal Dimension of Isosurfaces]]></title>

<authors><![CDATA[Khoury, M.;  Wenger, R.]]></authors>

<affiliations><![CDATA[Comput. & Inf. Sci. Dept., Ohio State Univ., Columbus, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[fractals]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Area measurement]]></term>

<term><![CDATA[Benchmark testing]]></term>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Fractals]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Noise measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1198]]></spage>

<epage><![CDATA[1205]]></epage>

<abstract><![CDATA[A (3D) scalar grid is a regular n<sub>1</sub> &#x00D7; n<sub>2</sub> &#x00D7; n<sub>3</sub> grid of vertices where each vertex v is associated with some scalar value s<sub>v</sub>. Applying trilinear interpolation, the scalar grid determines a scalar function g where g(v) = s<sub>v</sub> for each grid vertex v. An isosurface with isovalue &#x03C3; is a triangular mesh which approximates the level set g<sup>-1</sup> (&#x03C3;). The fractal dimension of an isosurface represents the growth in the isosurface as the number of grid cubes increases. We define and discuss the fractal isosurface dimension. Plotting the fractal dimension as a function of the isovalues in a data set provides information about the isosurfaces determined by the data set. We present statistics on the average fractal dimension of 60 publicly available benchmark data sets. We also show the fractal dimension is highly correlated with topological noise in the benchmark data sets, measuring the topological noise by the number of connected components in the isosurface. Lastly, we present a formula predicting the fractal dimension as a function of noise and validate the formula with experimental results.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613459]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.182]]></doi>

<publicationId><![CDATA[5613459]]></publicationId>

<partnum><![CDATA[5613459]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613459&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613459]]></pdf>

</document>

<document>

<rank>624</rank>

<title><![CDATA[Visualizing the Evolution and Interaction of Vortices and Shear Layers in Time-Dependent 3D Flow]]></title>

<authors><![CDATA[Schafhitzel, T.;  Baysal, K.;  Vaaraniemi, M.;  Rist, U.;  Weiskopf, D.]]></authors>

<affiliations><![CDATA[Inst. of Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[internal stresses]]></term>

<term><![CDATA[structural engineering computing]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aerodynamics]]></term>

<term><![CDATA[Atmosphere]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Energy dissipation]]></term>

<term><![CDATA[Fluid dynamics]]></term>

<term><![CDATA[Friction]]></term>

<term><![CDATA[Physics computing]]></term>

<term><![CDATA[Power engineering and energy]]></term>

<term><![CDATA[Stress]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[412]]></spage>

<epage><![CDATA[425]]></epage>

<abstract><![CDATA[In this paper, we present a visualization and tracking system for coherent structures. For this purpose, we propose to consider shear stress-the stretching and shear of particles inside a flow-in vortex dynamics. Based on a discussion and comparison of recent methods for computing shear stress, we introduce visualization techniques in order to provide a representation of shear layers according to their physical interpretation. This paper contributes a combination of theory in fluid mechanics and the corresponding visualization: 1) shear layer criteria are assessed according to how well they can be combined with common vortex identification criteria; 2) sheets of maximal shear are introduced as an appropriate visual representation of shear layers; 3) a visualization method is described for simultaneous tracking of vortices and shear layers as well as their interaction; and 4) the relevance of shear layers in vortex dynamics is demonstrated by means of several examples. We have implemented these new techniques in an interactive visualization system for time-dependent 3D flow. The system is used by fluid mechanics experts in their research of shear-vortex interaction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5467066]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.65]]></doi>

<publicationId><![CDATA[5467066]]></publicationId>

<partnum><![CDATA[5467066]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5467066&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467066]]></pdf>

</document>

<document>

<rank>625</rank>

<title><![CDATA[Assessing the Ability of a VR-Based Assembly Task Simulation to Evaluate PhysicalRisk Factors]]></title>

<authors><![CDATA[Pontonnier, C.;  Samani, A.;  Badawi, M.;  Madeleine, P.;  Dumont, G.]]></authors>

<affiliations><![CDATA[IRISA/INRIA, Ecoles Mil. de St.-Cyr Coetquidan, Rennes, France]]></affiliations>

<controlledterms>

<term><![CDATA[bone]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[electromyography]]></term>

<term><![CDATA[ergonomics]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[medical disorders]]></term>

<term><![CDATA[muscle]]></term>

<term><![CDATA[occupational health]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Assembly]]></term>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Electromyography]]></term>

<term><![CDATA[Ergonomics]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Muscles]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[664]]></spage>

<epage><![CDATA[674]]></epage>

<abstract><![CDATA[Nowadays the process of workstation design tends to include assessment steps in a virtual environment (VE) to evaluate the ergonomic features. These approaches are cost-effective and convenient since working directly on the digital mock-up in a VE is preferable to constructing a real physical mock-up in a real environment (RE). This study aimed at understanding the ability of a VR-based assembly tasks simulator to evaluate physical risk factors in ergonomics. Sixteen subjects performed simplified assembly tasks in RE and VE. Motion of the upper body and five muscle electromyographic activities were recorded to compute normalized and averaged objective indicators of discomfort, that is, rapid upper limb assessment score, averaged muscle activations, and total task time. Rated perceived exertion (RPE) and a questionnaire were used as subjective indicators of discomfort. The timing regime and complexity of the assembly tasks were investigated as within-subject factors. The results revealed significant differences between measured indicators in RE and VE. While objective measures indicated lower activity and exposure in VE, the subjects experienced more discomfort than in RE. Fairly good correlation levels were found between RE and VE for six of the objective indicators. This study clearly demonstrates that ergonomic studies of assembly tasks using VR are still challenging. Indeed, objective and subjective measurements of discomfort that are usually used in ergonomics to minimize the risks of work-related musculoskeletal disorders development exhibit opposite trends in RE and VE. Nevertheless, the high level of correlation found during this study indicates that the VR-based simulator can be used for such assessments.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6654129]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.252]]></doi>

<publicationId><![CDATA[6654129]]></publicationId>

<partnum><![CDATA[6654129]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6654129&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654129]]></pdf>

</document>

<document>

<rank>626</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1333659]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.41]]></doi>

<publicationId><![CDATA[1333659]]></publicationId>

<partnum><![CDATA[1333659]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1333659&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333659]]></pdf>

</document>

<document>

<rank>627</rank>

<title><![CDATA[Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps]]></title>

<authors><![CDATA[Bak, P.;  Mansmann, F.;  Janetzko, H.;  Keim, D.A.]]></authors>

<affiliations><![CDATA[Univ. of Konstanz, Konstanz, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[biosensors]]></term>

<term><![CDATA[colour graphics]]></term>

<term><![CDATA[data loggers]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animal behavior]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Spatiotemporal phenomena]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[913]]></spage>

<epage><![CDATA[920]]></epage>

<abstract><![CDATA[Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290694]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.182]]></doi>

<publicationId><![CDATA[5290694]]></publicationId>

<partnum><![CDATA[5290694]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290694&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290694]]></pdf>

</document>

<document>

<rank>628</rank>

<title><![CDATA[Drawing Road Networks with Focus Regions]]></title>

<authors><![CDATA[Haunert, J.-H.;  Sering, L.]]></authors>

<affiliations><![CDATA[Univ. of Wu&#x0308;rzburg, Wu&#x0308;rzburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[convex programming]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[mobile computing]]></term>

<term><![CDATA[polynomials]]></term>

<term><![CDATA[quadratic programming]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[traffic information systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cartography]]></term>

<term><![CDATA[Distortion measurement]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Image analysis]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Quadratic programming]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2555]]></spage>

<epage><![CDATA[2562]]></epage>

<abstract><![CDATA[Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065023]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.191]]></doi>

<publicationId><![CDATA[6065023]]></publicationId>

<partnum><![CDATA[6065023]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065023&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065023]]></pdf>

</document>

<document>

<rank>629</rank>

<title><![CDATA[PIWI: Visually Exploring Graphs Based on Their Community Structure]]></title>

<authors><![CDATA[Jing Yang;  Yujie Liu;  Xin Zhang;  Xiaoru Yuan;  Ye Zhao;  Barlowe, S.;  Shixia Liu]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, Charlotte, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Communities]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Tag clouds]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1034]]></spage>

<epage><![CDATA[1047]]></epage>

<abstract><![CDATA[Community structure is an important characteristic of many real networks, which shows high concentrations of edges within special groups of vertices and low concentrations between these groups. Community related graph analysis, such as discovering relationships among communities, identifying attribute-structure relationships, and selecting a large number of vertices with desired structural features and attributes, are common tasks in knowledge discovery in such networks. The clutter and the lack of interactivity often hinder efforts to apply traditional graph visualization techniques in these tasks. In this paper, we propose PIWI, a novel graph visual analytics approach to these tasks. Instead of using Node-Link Diagrams (NLDs), PIWI provides coordinated, uncluttered visualizations, and novel interactions based on graph community structure. The novel features, applicability, and limitations of this new technique have been discussed in detail. A set of case studies and preliminary user studies have been conducted with real graphs containing thousands of vertices, which provide supportive evidence about the usefulness of PIWI in community related tasks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6269876]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.172]]></doi>

<publicationId><![CDATA[6269876]]></publicationId>

<partnum><![CDATA[6269876]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6269876&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269876]]></pdf>

</document>

<document>

<rank>630</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1471682]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.74]]></doi>

<publicationId><![CDATA[1471682]]></publicationId>

<partnum><![CDATA[1471682]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1471682&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1471682]]></pdf>

</document>

<document>

<rank>631</rank>

<title><![CDATA[Combining Single and Packet-Ray Tracing for Arbitrary Ray Distributions on the Intel MIC Architecture]]></title>

<authors><![CDATA[Benthin, C.;  Wald, I.;  Woop, S.;  Ernst, M.;  Mark, W.R.]]></authors>

<affiliations><![CDATA[Intel Visual Comput. Inst., Saarbruecken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[multiprocessing systems]]></term>

<term><![CDATA[parallel architectures]]></term>

<term><![CDATA[ray tracing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Memory management]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Registers]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1438]]></spage>

<epage><![CDATA[1448]]></epage>

<abstract><![CDATA[Wide-SIMD hardware is power and area efficient, but it is challenging to efficiently map ray tracing algorithms to such hardware especially when the rays are incoherent. The two most commonly used schemes are either packet tracing, or relying on a separate traversal stack for each SIMD lane. Both work great for coherent rays, but suffer when rays are incoherent: The former experiences a dramatic loss of SIMD utilization once rays diverge; the latter requires a large local storage, and generates multiple incoherent streams of memory accesses that present challenges for the memory system. In this paper, we introduce a single-ray tracing scheme for incoherent rays that uses just one traversal stack on 16-wide SIMD hardware. It uses a bounding-volume hierarchy with a branching factor of four as the acceleration structure, exploits four-wide SIMD in each box and primitive intersection test, and uses 16-wide SIMD by always performing four such node or primitive tests in parallel. We then extend this scheme to a hybrid tracing scheme that automatically adapts to varying ray coherence by starting out with a 16-wide packet scheme and switching to the new single-ray scheme as soon as rays diverge. We show that on the Intel Many Integrated Core architecture this hybrid scheme consistently, and over a wide range of scenes and ray distributions, outperforms both packet and single-ray tracing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6081859]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.277]]></doi>

<publicationId><![CDATA[6081859]]></publicationId>

<partnum><![CDATA[6081859]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6081859&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081859]]></pdf>

</document>

<document>

<rank>632</rank>

<title><![CDATA[Texturing of Layered Surfaces for Optimal Viewing]]></title>

<authors><![CDATA[Bair, A.S.;  House, D.H.;  Ware, C.]]></authors>

<affiliations><![CDATA[Texas A&M Univ., College Station, TX]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision trees]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[genetic algorithms]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[search problems]]></term>

<term><![CDATA[surface texture]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analysis of variance]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Gaussian noise]]></term>

<term><![CDATA[Genetic algorithms]]></term>

<term><![CDATA[Guidelines]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Linear discriminant analysis]]></term>

<term><![CDATA[Space exploration]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1125]]></spage>

<epage><![CDATA[1132]]></epage>

<abstract><![CDATA[This paper is a contribution to the literature on perceptually optimal visualizations of layered three-dimensional surfaces. Specifically, we develop guidelines for generating texture patterns, which, when tiled on two overlapped surfaces, minimize confusion in depth-discrimination and maximize the ability to localize distinct features. We design a parameterized texture space and explore this texture space using a "human in the loop" experimental approach. Subjects are asked to rate their ability to identify Gaussian bumps on both upper and lower surfaces of noisy terrain fields. Their ratings direct a genetic algorithm, which selectively searches the texture parameter space to find fruitful areas. Data collected from these experiments are analyzed to determine what combinations of parameters work well and to develop texture generation guidelines. Data analysis methods include ANOVA, linear discriminant analysis, decision trees, and parallel coordinates. To confirm the guidelines, we conduct a post-analysis experiment, where subjects rate textures following our guidelines against textures violating the guidelines. Across all subjects, textures following the guidelines consistently produce high rated textures on an absolute scale, and are rated higher than those that did not follow the guidelines]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015473]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.183]]></doi>

<publicationId><![CDATA[4015473]]></publicationId>

<partnum><![CDATA[4015473]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015473&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015473]]></pdf>

</document>

<document>

<rank>633</rank>

<title><![CDATA[GeneaQuilts: A System for Exploring Large Genealogies]]></title>

<authors><![CDATA[Bezerianos, A.;  Dragicevic, P.;  Fekete, J.;  Juhee Bae;  Watson, B.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Chaos]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1073]]></spage>

<epage><![CDATA[1081]]></epage>

<abstract><![CDATA[GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring &amp; Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613445]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.159]]></doi>

<publicationId><![CDATA[5613445]]></publicationId>

<partnum><![CDATA[5613445]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613445&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613445]]></pdf>

</document>

<document>

<rank>634</rank>

<title><![CDATA[[Advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[496]]></spage>

<epage><![CDATA[496]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1298806]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.4]]></doi>

<publicationId><![CDATA[1298806]]></publicationId>

<partnum><![CDATA[1298806]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1298806&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1298806]]></pdf>

</document>

<document>

<rank>635</rank>

<title><![CDATA[Streak Lines as Tangent Curves of a Derived Vector Field]]></title>

<authors><![CDATA[Weinkauf, T.;  Theisel, H.]]></authors>

<affiliations><![CDATA[Courant Inst. of Math. Sci., New York Univ., New York, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[mathematical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Vectors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1225]]></spage>

<epage><![CDATA[1234]]></epage>

<abstract><![CDATA[Characteristic curves of vector fields include stream, path, and streak lines. Stream and path lines can be obtained by a simple vector field integration of an autonomous ODE system, i.e., they can be described as tangent curves of a vector field. This facilitates their mathematical analysis including the extraction of core lines around which stream or path lines exhibit swirling motion, or the computation of their curvature for every point in the domain without actually integrating them. Such a description of streak lines is not yet available, which excludes them from most of the feature extraction and analysis tools that have been developed in our community. In this paper, we develop the first description of streak lines as tangent curves of a derived vector field - the streak line vector field - and show how it can be computed from the spatial and temporal gradients of the flow map, i.e., a dense path line integration is required. We demonstrate the high accuracy of our approach by comparing it to solutions where the ground truth is analytically known and to solutions where the ground truth has been obtained using the classic streak line computation. Furthermore, we apply a number of feature extraction and analysis tools to the new streak line vector field including the extraction of cores of swirling streak lines and the computation of streak line curvature fields. These first applications foreshadow the large variety of possible future research directions based on our new mathematical description of streak lines.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613462]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.198]]></doi>

<publicationId><![CDATA[5613462]]></publicationId>

<partnum><![CDATA[5613462]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613462&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613462]]></pdf>

</document>

<document>

<rank>636</rank>

<title><![CDATA[A System for High-Resolution Topology Optimization]]></title>

<authors><![CDATA[Wu, J.;  Dick, C.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Jun Wu is with the Computer Graphics and Visualization Group, Technische Universitat Munchen, Munich, Germany.(Email: jun.wu@tum.de)]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Force]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Stress]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[A key requirement in 3D fabrication is to generate objects with individual exterior shapes and their interior being optimized to application-specific force constraints and low material consumption. Accomplishing this task is challenging on desktop computers, due to the extreme model resolutions that are required to accurately predict the physical shape properties, requiring memory and computational capacities going beyond what is currently available. Moreover, fabrication-specific constraints need to be considered to enable printability. To address these challenges, we present a scalable system for generating 3D objects using topology optimization, which allows to efficiently evolve the topology of high-resolution solids towards printable and light-weight-high-resistance structures. To achieve this, the system is equipped with a high-performance GPU solver which can efficiently handle models comprising several millions of elements. A minimum thickness constraint is built into the optimization process to automatically enforce printability of the resulting shapes. We further shed light on the question how to incorporate geometric shape constraints, such as symmetry and pattern repetition, in the optimization process. We analyze the performance of the system and demonstrate its potential by a variety of different shapes such as interior structures within closed surfaces, exposed support structures, and surface models.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7332965]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2502588]]></doi>

<publicationId><![CDATA[7332965]]></publicationId>

<partnum><![CDATA[7332965]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7332965&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332965]]></pdf>

</document>

<document>

<rank>637</rank>

<title><![CDATA[&ldquo;Meshsweeper&rdquo;: dynamic point-to-polygonal mesh distance and applications]]></title>

<authors><![CDATA[]]></authors>

<affiliations><![CDATA[Multigen-Pradigm Inc., Comput. Associates Co., San Jose, CA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[octrees]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Euclidean distance]]></term>

<term><![CDATA[Heuristic algorithms]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Spatial resolution]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[47]]></spage>

<epage><![CDATA[61]]></epage>

<abstract><![CDATA[We introduce a new algorithm for computing the distance from a point to an arbitrary polygonal mesh. Our algorithm uses a multiresolution hierarchy of bounding volumes generated by geometric simplification. Our algorithm is dynamic, exploiting coherence between subsequent queries using a priority process and achieving constant time queries in some cases. It can be applied to meshes that transform rigidly or deform nonrigidly. We illustrate our algorithm with a simulation of particle dynamics and collisions with a deformable mesh, the computation of distance maps and offset surfaces, the computation of an approximation to the expensive Hausdorff distance between two shapes, and the detection of self-intersections. We also report comparison results between our algorithm and an alternative algorithm using an octree, upon which our method permits an order-of-magnitude speed-up]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[910820]]></arnumber>

<doi><![CDATA[10.1109/2945.910820]]></doi>

<publicationId><![CDATA[910820]]></publicationId>

<partnum><![CDATA[910820]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=910820&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=910820]]></pdf>

</document>

<document>

<rank>638</rank>

<title><![CDATA[DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios]]></title>

<authors><![CDATA[Madhavan, K.;  Elmqvist, N.;  Vorvoreanu, M.;  Xin Chen;  Yuetling Wong;  Hanjun Xian;  Zhihua Dong;  Johri, A.]]></authors>

<affiliations><![CDATA[Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[financial data processing]]></term>

<term><![CDATA[research and development]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Government]]></term>

<term><![CDATA[Research and development]]></term>

<term><![CDATA[Science - general]]></term>

<term><![CDATA[Visual analytics]]></term>

<term><![CDATA[Websites]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1823]]></spage>

<epage><![CDATA[1832]]></epage>

<abstract><![CDATA[We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876046]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346747]]></doi>

<publicationId><![CDATA[6876046]]></publicationId>

<partnum><![CDATA[6876046]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876046&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876046]]></pdf>

</document>

<document>

<rank>639</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4917473]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.49]]></doi>

<publicationId><![CDATA[4917473]]></publicationId>

<partnum><![CDATA[4917473]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4917473&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4917473]]></pdf>

</document>

<document>

<rank>640</rank>

<title><![CDATA[Adaptive Extraction and Quantification of Geophysical Vortices]]></title>

<authors><![CDATA[Williams, S.;  Petersen, M.;  Bremer, P.-T.;  Hecht, M.;  Pascucci, V.;  Ahrens, J.;  Hlawitschka, M.;  Hamann, B.]]></authors>

<affiliations><![CDATA[Inst. for Data Anal. & Visualization, Univ. of California, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[oceanography]]></term>

<term><![CDATA[turbulence]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atmospheric modeling]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Information analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2088]]></spage>

<epage><![CDATA[2095]]></epage>

<abstract><![CDATA[We consider the problem of extracting discrete two-dimensional vortices from a turbulent flow. In our approach we use a reference model describing the expected physics and geometry of an idealized vortex. The model allows us to derive a novel correlation between the size of the vortex and its strength, measured as the square of its strain minus the square of its vorticity. For vortex detection in real models we use the strength parameter to locate potential vortex cores, then measure the similarity of our ideal analytical vortex and the real vortex core for different strength thresholds. This approach provides a metric for how well a vortex core is modeled by an ideal vortex. Moreover, this provides insight into the problem of choosing the thresholds that identify a vortex. By selecting a target coefficient of determination (i.e., statistical confidence), we determine on a per-vortex basis what threshold of the strength parameter would be required to extract that vortex at the chosen confidence. We validate our approach on real data from a global ocean simulation and derive from it a map of expected vortex strengths over the global ocean.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064973]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.162]]></doi>

<publicationId><![CDATA[6064973]]></publicationId>

<partnum><![CDATA[6064973]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064973&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064973]]></pdf>

</document>

<document>

<rank>641</rank>

<title><![CDATA[Uncertainty-Aware Guided Volume Segmentation]]></title>

<authors><![CDATA[Prassni, J.-S.;  Ropinski, T.;  Hinrichs, K.]]></authors>

<affiliations><![CDATA[Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Probabilistic logic]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1358]]></spage>

<epage><![CDATA[1365]]></epage>

<abstract><![CDATA[Although direct volume rendering is established as a powerful tool for the visualization of volumetric data, efficient and reliable feature detection is still an open topic. Usually, a tradeoff between fast but imprecise classification schemes and accurate but time-consuming segmentation techniques has to be made. Furthermore, the issue of uncertainty introduced with the feature detection process is completely neglected by the majority of existing approaches.In this paper we propose a guided probabilistic volume segmentation approach that focuses on the minimization of uncertainty. In an iterative process, our system continuously assesses uncertainty of a random walker-based segmentation in order to detect regions with high ambiguity, to which the user's attention is directed to support the correction of potential misclassifications. This reduces the risk of critical segmentation errors and ensures that information about the segmentation's reliability is conveyed to the user in a dependable way. In order to improve the efficiency of the segmentation process, our technique does not only take into account the volume data to be segmented, but also enables the user to incorporate classification information. An interactive workflow has been achieved by implementing the presented system on the GPU using the OpenCL API. Our results obtained for several medical data sets of different modalities, including brain MRI and abdominal CT, demonstrate the reliability and efficiency of our approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613476]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.208]]></doi>

<publicationId><![CDATA[5613476]]></publicationId>

<partnum><![CDATA[5613476]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613476&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613476]]></pdf>

</document>

<document>

<rank>642</rank>

<title><![CDATA[Estimating the Gaze of a Virtuality Human]]></title>

<authors><![CDATA[Roberts, D.J.;  Rae, J.;  Duckworth, T.W.;  Moore, C.M.;  Aspin, R.]]></authors>

<affiliations><![CDATA[Univ. of Salford, Salford, UK]]></affiliations>

<controlledterms>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[iris recognition]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[681]]></spage>

<epage><![CDATA[690]]></epage>

<abstract><![CDATA[The aim of our experiment is to determine if eye-gaze can be estimated from a virtuality human: to within the accuracies that underpin social interaction; and reliably across gaze poses and camera arrangements likely in every day settings. The scene is set by explaining why Immersive Virtuality Telepresence has the potential to meet the grand challenge of faithfully communicating both the appearance and the focus of attention of a remote human participant within a shared 3D computer-supported context. Within the experiment n=22 participants rotated static 3D virtuality humans, reconstructed from surround images, until they felt most looked at. The dependent variable was absolute angular error, which was compared to that underpinning social gaze behaviour in the natural world. Independent variables were 1) relative orientations of eye, head and body of captured subject; and 2) subset of cameras used to texture the form. Analysis looked for statistical and practical significance and qualitative corroborating evidence. The analysed results tell us much about the importance and detail of the relationship between gaze pose, method of video based reconstruction, and camera arrangement. They tell us that virtuality can reproduce gaze to an accuracy useful in social interaction, but with the adopted method of Video Based Reconstruction, this is highly dependent on combination of gaze pose and camera arrangement. This suggests changes in the VBR approach in order to allow more flexible camera arrangements. The work is of interest to those wanting to support expressive meetings that are both socially and spatially situated, and particular those using or building Immersive Virtuality Telepresence to accomplish this. It is also of relevance to the use of virtuality humans in applications ranging from the study of human interactions to gaming and the crossing of the stage line in films and TV.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6479209]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.30]]></doi>

<publicationId><![CDATA[6479209]]></publicationId>

<partnum><![CDATA[6479209]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479209&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479209]]></pdf>

</document>

<document>

<rank>643</rank>

<title><![CDATA[Volume Illustration of Muscle from Diffusion Tensor Images]]></title>

<authors><![CDATA[Wei Chen;  Zhicheng Yan;  Song Zhang;  Crow, J.A.;  Ebert, D.S.;  McLaughlin, R.M.;  Mullins, K.B.;  Cooper, R.;  Zi'ang Ding;  Jun Liao]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD & CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[image texture]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[tensors]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Diffusion tensor imaging]]></term>

<term><![CDATA[Heart]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Muscles]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1425]]></spage>

<epage><![CDATA[1432]]></epage>

<abstract><![CDATA[Medical illustration has demonstrated its effectiveness to depict salient anatomical features while hiding the irrelevant details. Current solutions are ineffective for visualizing fibrous structures such as muscle, because typical datasets (CT or MRI) do not contain directional details. In this paper, we introduce a new muscle illustration approach that leverages diffusion tensor imaging (DTI) data and example-based texture synthesis techniques. Beginning with a volumetric diffusion tensor image, we reformulate it into a scalar field and an auxiliary guidance vector field to represent the structure and orientation of a muscle bundle. A muscle mask derived from the input diffusion tensor image is used to classify the muscle structure. The guidance vector field is further refined to remove noise and clarify structure. To simulate the internal appearance of the muscle, we propose a new two-dimensional example based solid texture synthesis algorithm that builds a solid texture constrained by the guidance vector field. Illustrating the constructed scalar field and solid texture efficiently highlights the global appearance of the muscle as well as the local shape and structure of the muscle fibers in an illustrative fashion. We have applied the proposed approach to five example datasets (four pig hearts and a pig leg), demonstrating plausible illustration and expressiveness.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5290757]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.203]]></doi>

<publicationId><![CDATA[5290757]]></publicationId>

<partnum><![CDATA[5290757]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290757&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290757]]></pdf>

</document>

<document>

<rank>644</rank>

<title><![CDATA[Size-based Transfer Functions: A New Volume Exploration Technique]]></title>

<authors><![CDATA[Correa, C.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Univ. of California, Davis, CA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image classification]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[opacity]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aneurysm]]></term>

<term><![CDATA[Angiography]]></term>

<term><![CDATA[Arteries]]></term>

<term><![CDATA[Cancer detection]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Neoplasms]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Veins]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1380]]></spage>

<epage><![CDATA[1387]]></epage>

<abstract><![CDATA[The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658153]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.162]]></doi>

<publicationId><![CDATA[4658153]]></publicationId>

<partnum><![CDATA[4658153]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658153&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658153]]></pdf>

</document>

<document>

<rank>645</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5762832]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.85]]></doi>

<publicationId><![CDATA[5762832]]></publicationId>

<partnum><![CDATA[5762832]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5762832&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5762832]]></pdf>

</document>

<document>

<rank>646</rank>

<title><![CDATA[Stroscope: Multi-Scale Visualization of Irregularly Measured Time-Series Data]]></title>

<authors><![CDATA[Myoungsu Cho;  Bohyoung Kim;  Hee-Joon Bae;  Jinwook Seo]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Seoul Nat. Univ., Seoul, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[blood pressure measurement]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[medical administrative data processing]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bars]]></term>

<term><![CDATA[Blood pressure]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Frequency measurement]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Time measurement]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[808]]></spage>

<epage><![CDATA[821]]></epage>

<abstract><![CDATA[For irregularly measured time-series data, the measurement frequency or interval is as crucial information as measurements are. A well-known time-series visualization such as the line graph is good at showing an overall temporal pattern of change; however, it is not so effective in revealing the measurement frequency/interval while likely giving illusory confidence in values between measurements. In contrast, the bar graph is more effective in showing the frequency/interval, but less effective in showing an overall pattern than the line graph. We integrate the line graph and bar graph in a unified visualization model, called a ripple graph, to take the benefits of both of them with enhanced graphical integrity. Based on the ripple graph, we implemented an interactive time-series data visualization tool, called Stroscope, which facilitates multi-scale visualizations by providing users with a graphical widget to interactively control the integrated visualization model. We evaluated the visualization model (i.e., the ripple graph) through a controlled user study and Stroscope through long-term case studies with neurologists exploring large blood pressure measurement data of stroke patients. Results from our evaluations demonstrate that the ripple graph outperforms existing time-series visualizations, and that Stroscope has the efficacy and potential as an effective visual analysis tool for (irregularly) measured time-series data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6702502]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.2297933]]></doi>

<publicationId><![CDATA[6702502]]></publicationId>

<partnum><![CDATA[6702502]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6702502&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702502]]></pdf>

</document>

<document>

<rank>647</rank>

<title><![CDATA[A multiresolution representation for massive meshes]]></title>

<authors><![CDATA[Shaffer, E.;  Garland, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Indexing]]></term>

<term><![CDATA[Laser theory]]></term>

<term><![CDATA[Power lasers]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Technological innovation]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[139]]></spage>

<epage><![CDATA[148]]></epage>

<abstract><![CDATA[We present a new external memory multiresolution surface representation for massive polygonal meshes. Previous methods for building such data structures have relied on resampled surface data or employed memory intensive construction algorithms that do not scale well. Our proposed representation combines efficient access to sampled surface data with access to the original surface. The construction algorithm for the surface representation exhibits memory requirements that are insensitive to the size of the input mesh, allowing it to process meshes containing hundreds of millions of polygons. The multiresolution nature of the surface representation has allowed us to develop efficient algorithms for view-dependent rendering, approximate collision detection, and adaptive simplification of massive meshes. The empirical performance of these algorithms demonstrates that the underlying data structure is a powerful and flexible tool for operating on massive geometric data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1388225]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.18]]></doi>

<publicationId><![CDATA[1388225]]></publicationId>

<partnum><![CDATA[1388225]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1388225&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1388225]]></pdf>

</document>

<document>

<rank>648</rank>

<title><![CDATA[Interactive Histology of Large-Scale Biomedical Image Stacks]]></title>

<authors><![CDATA[Won-Ki Jeong;  Schneider, J.;  Turney, S.G.;  Faulkner-Jones, B.E.;  Meyer, D.;  Westermann, R.;  Reid, R.C.;  Lichtman, J.;  Pfister, H.]]></authors>

<controlledterms>

<term><![CDATA[biological tissues]]></term>

<term><![CDATA[data compression]]></term>

<term><![CDATA[image coding]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[microscopy]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Image coding]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Microscopy]]></term>

<term><![CDATA[Pathology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1386]]></spage>

<epage><![CDATA[1395]]></epage>

<abstract><![CDATA[Histology is the study of the structure of biological tissue using microscopy techniques. As digital imaging technology advances, high resolution microscopy of large tissue volumes is becoming feasible; however, new interactive tools are needed to explore and analyze the enormous datasets. In this paper we present a visualization framework that specifically targets interactive examination of arbitrarily large image stacks. Our framework is built upon two core techniques: display-aware processing and GPU-accelerated texture compression. With display-aware processing, only the currently visible image tiles are fetched and aligned on-the-fly, reducing memory bandwidth and minimizing the need for time-consuming global pre-processing. Our novel texture compression scheme for GPUs is tailored for quick browsing of image stacks. We evaluate the usability of our viewer for two histology applications: digital pathology and visualization of neural structure at nanoscale-resolution in serial electron micrographs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613479]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.168]]></doi>

<publicationId><![CDATA[5613479]]></publicationId>

<partnum><![CDATA[5613479]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613479&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613479]]></pdf>

</document>

<document>

<rank>649</rank>

<title><![CDATA[Dynamic free-form deformations for animation synthesis]]></title>

<authors><![CDATA[Faloutsos, P.;  van de Panne, Michiel;  Terzopoulos, D.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Toronto Univ., Ont., Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[elastic deformation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Automatic control]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Electrical capacitance tomography]]></term>

<term><![CDATA[Lagrangian functions]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[201]]></spage>

<epage><![CDATA[214]]></epage>

<abstract><![CDATA[Free form deformations (FFDs) are a popular tool for modeling and keyframe animation. The paper extends the use of FFDs to a dynamic setting. Our goal is to enable normally inanimate graphics objects, such as teapots and tables, to become animated, and learn to move about in a charming, cartoon like manner. To achieve this goal, we implement a system that can transform a wide class of objects into dynamic characters. Our formulation is based on parameterized hierarchical FFDs augmented with Lagrangian dynamics, and provides an efficient way to animate and control the simulated characters. Objects are assigned mass distributions and elastic deformation properties, which allow them to translate, rotate, and deform according to internal and external forces. In addition, we implement an automated optimization process that searches for suitable control strategies. The primary contributions of the work are threefold. First, we formulate a dynamic generalization of conventional, geometric FFDs. The formulation employs deformation modes which are tailored by the user and are expressed in terms of FFDs. Second, the formulation accommodates a hierarchy of dynamic FFDs that can be used to model local as well as global deformations. Third, the deformation modes can be active, thereby producing locomotion]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[620488]]></arnumber>

<doi><![CDATA[10.1109/2945.620488]]></doi>

<publicationId><![CDATA[620488]]></publicationId>

<partnum><![CDATA[620488]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=620488&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620488]]></pdf>

</document>

<document>

<rank>650</rank>

<title><![CDATA[code_swarm: A Design Study in Organic Software Visualization]]></title>

<authors><![CDATA[Ogawa, M.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[VIDI Lab., Univ. of California, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[public domain software]]></term>

<term><![CDATA[software maintenance]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Open source software]]></term>

<term><![CDATA[Programming]]></term>

<term><![CDATA[Software quality]]></term>

<term><![CDATA[Videos]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1097]]></spage>

<epage><![CDATA[1104]]></epage>

<abstract><![CDATA[In May of 2008, we published online a series of software visualization videos using a method called code_swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code_swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code_swarm has positive implications for the future of organic information design and open source information visualization practice.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290717]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.123]]></doi>

<publicationId><![CDATA[5290717]]></publicationId>

<partnum><![CDATA[5290717]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290717&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290717]]></pdf>

</document>

<document>

<rank>651</rank>

<title><![CDATA[Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities]]></title>

<authors><![CDATA[Froese, M.-E.;  Tory, M.;  Evans, G.-W.;  Shrikhande, K.]]></authors>

<controlledterms>

<term><![CDATA[computer based training]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Atmospheric measurements]]></term>

<term><![CDATA[Design automation]]></term>

<term><![CDATA[Optimized production technology]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Spatial resolution]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2810]]></spage>

<epage><![CDATA[2817]]></epage>

<abstract><![CDATA[Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants' abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634097]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.156]]></doi>

<publicationId><![CDATA[6634097]]></publicationId>

<partnum><![CDATA[6634097]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634097&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634097]]></pdf>

</document>

<document>

<rank>652</rank>

<title><![CDATA[ViSizer: A Visualization Resizing Framework]]></title>

<authors><![CDATA[Yingcai Wu;  Xiaotong Liu;  Shixia Liu;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of California, Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[display devices]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[least squares approximations]]></term>

<term><![CDATA[optimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clutter]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Ellipsoids]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[278]]></spage>

<epage><![CDATA[290]]></epage>

<abstract><![CDATA[Visualization resizing is useful for many applications where users may use different display devices. General resizing techniques (e.g., uniform scaling) and image-resizing techniques suffer from several drawbacks, as they do not consider the content of the visualizations. This work introduces ViSizer, a perception-based framework for automatically resizing a visualization to fit any display. We formulate an energy function based on a perception model (feature congestion), which aims to determine the optimal deformation for every local region. We subsequently transform the problem into an optimization problem by the energy function. An efficient algorithm is introduced to iteratively solve the problem, allowing for automatic visualization resizing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6189339]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.114]]></doi>

<publicationId><![CDATA[6189339]]></publicationId>

<partnum><![CDATA[6189339]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6189339&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189339]]></pdf>

</document>

<document>

<rank>653</rank>

<title><![CDATA[Large-Scale Liquid Simulation on Adaptive Hexahedral Grids]]></title>

<authors><![CDATA[Ferstl, F.;  Westermann, R.;  Dick, C.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[octrees]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptation models]]></term>

<term><![CDATA[Boundary conditions]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Liquids]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Octrees]]></term>

<term><![CDATA[Solids]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1405]]></spage>

<epage><![CDATA[1417]]></epage>

<abstract><![CDATA[Regular grids are attractive for numerical fluid simulations because they give rise to efficient computational kernels. However, for simulating high resolution effects in complicated domains they are only of limited suitability due to memory constraints. In this paper we present a method for liquid simulation on an adaptive octree grid using a hexahedral finite element discretization, which reduces memory requirements by coarsening the elements in the interior of the liquid body. To impose free surface boundary conditions with second order accuracy, we incorporate a particular class of Nitsche methods enforcing the Dirichlet boundary conditions for the pressure in a variational sense. We then show how to construct a multigrid hierarchy from the adaptive octree grid, so that a time efficient geometric multigrid solver can be used. To improve solver convergence, we propose a special treatment of liquid boundaries via composite finite elements at coarser scales. We demonstrate the effectiveness of our method for liquid simulations that would require hundreds of millions of simulation elements in a non-adaptive regime.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6747389]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2307873]]></doi>

<publicationId><![CDATA[6747389]]></publicationId>

<partnum><![CDATA[6747389]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6747389&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6747389]]></pdf>

</document>

<document>

<rank>654</rank>

<title><![CDATA[An Exploration Framework to Identify and Track Movement of Cloud Systems]]></title>

<authors><![CDATA[Doraiswamy, H.;  Natarajan, V.;  Nanjundiah, R.S.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Polytech. Inst. of New York Univ., New York, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[clouds]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geophysics computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brightness temperature]]></term>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Meteorology]]></term>

<term><![CDATA[Optical imaging]]></term>

<term><![CDATA[Tracking]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2896]]></spage>

<epage><![CDATA[2905]]></epage>

<abstract><![CDATA[We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634109]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.131]]></doi>

<publicationId><![CDATA[6634109]]></publicationId>

<partnum><![CDATA[6634109]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634109&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634109]]></pdf>

</document>

<document>

<rank>655</rank>

<title><![CDATA[Topological Landscapes: A Terrain Metaphor for Scientific Data]]></title>

<authors><![CDATA[Weber, G.H.;  Bremer, P.-T.;  Pascucci, V.]]></authors>

<affiliations><![CDATA[Lawrence Berkeley Nat. Lab., Berkeley]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[software tools]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Surfaces]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Two dimensional displays]]></term>

<term><![CDATA[User interfaces]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1416]]></spage>

<epage><![CDATA[1423]]></epage>

<abstract><![CDATA[Scientific visualization and illustration tools are designed to help people understand the structure and complexity of scientific data with images that are as informative and intuitive as possible. In this context the use of metaphors plays an important role since they make complex information easily accessible by using commonly known concepts. In this paper we propose a new metaphor, called "topological landscapes," which facilitates understanding the topological structure of scalar functions. The basic idea is to construct a terrain with the same topology as a given dataset and to display the terrain as an easily understood representation of the actual input data. In this projection from an n-dimensional scalar function to a two-dimensional (2D) model we preserve function values of critical points, the persistence (function span) of topological features, and one possible additional metric property (in our examples volume). By displaying this topologically equivalent landscape together with the original data we harness the natural human proficiency in understanding terrain topography and make complex topological information easily accessible.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376169]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70601]]></doi>

<publicationId><![CDATA[4376169]]></publicationId>

<partnum><![CDATA[4376169]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376169&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376169]]></pdf>

</document>

<document>

<rank>656</rank>

<title><![CDATA[Fast Wavefront Propagation (FWP) for Computing Exact Geodesic Distances on Meshes]]></title>

<authors><![CDATA[Chunxu Xu;  Wang, T.Y.;  Yong-Jin Liu;  Ligang Liu;  Ying He]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[differential geometry]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Time complexity]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[822]]></spage>

<epage><![CDATA[834]]></epage>

<abstract><![CDATA[Computing geodesic distances on triangle meshes is a fundamental problem in computational geometry and computer graphics. To date, two notable classes of algorithms, the Mitchell-Mount-Papadimitriou (MMP) algorithm and the Chen-Han (CH) algorithm, have been proposed. Although these algorithms can compute exact geodesic distances if numerical computation is exact, they are computationally expensive, which diminishes their usefulness for large-scale models and/or time-critical applications. In this paper, we propose the fast wavefront propagation (FWP) framework for improving the performance of both the MMP and CH algorithms. Unlike the original algorithms that propagate only a single window (a data structure locally encodes geodesic information) at each iteration, our method organizes windows with a bucket data structure so that it can process a large number of windows simultaneously without compromising wavefront quality. Thanks to its macro nature, the FWP method is less sensitive to mesh triangulation than the MMP and CH algorithms. We evaluate our FWP-based MMP and CH algorithms on a wide range of large-scale real-world models. Computational results show that our method can improve the speed by a factor of 3-10.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7050361]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2407404]]></doi>

<publicationId><![CDATA[7050361]]></publicationId>

<partnum><![CDATA[7050361]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7050361&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050361]]></pdf>

</document>

<document>

<rank>657</rank>

<title><![CDATA[2010 Annual Index]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[Not in Print]]></spage>

<epage><![CDATA[Not in Print]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the coauthors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5629316]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.1]]></doi>

<publicationId><![CDATA[5629316]]></publicationId>

<partnum><![CDATA[5629316]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5629316&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5629316]]></pdf>

</document>

<document>

<rank>658</rank>

<title><![CDATA[Detection and Reconstruction of an Implicit Boundary Surface by Adaptively Expanding A Small Surface Patch in a 3D Image]]></title>

<authors><![CDATA[Lisheng Wang;  Pai Wang;  Liuhang Cheng;  Yu Ma;  Shenzhi Wu;  Yu-Ping Wang;  Zongben Xu]]></authors>

<affiliations><![CDATA[Dept. of Autom., Shanghai Jiao Tong Univ., Shanghai, China]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[image reconstruction]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Face recognition]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1490]]></spage>

<epage><![CDATA[1506]]></epage>

<abstract><![CDATA[In this paper we propose a novel and easy to use 3D reconstruction method. With the method, users only need to specify a small boundary surface patch in a 2D section image, and then an entire continuous implicit boundary surface (CIBS) can be automatically reconstructed from a 3D image. In the method, a hierarchical tracing strategy is used to grow the known boundary surface patch gradually in the 3D image. An adaptive detection technique is applied to detect boundary surface patches from different local regions. The technique is based on both context dependence and adaptive contrast detection as in the human vision system. A recognition technique is used to distinguish true boundary surface patches from the false ones in different cubes. By integrating these different approaches, a high-resolution CIBS model can be automatically reconstructed by adaptively expanding the small boundary surface patch in the 3D image. The effectiveness of our method is demonstrated by its applications to a variety of real 3D images, where the CIBS with complex shapes/branches and with varying gray values/gradient magnitudes can be well reconstructed. Our method is easy to use, which provides a valuable tool for 3D image visualization and analysis as needed in many applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6767138]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2312015]]></doi>

<publicationId><![CDATA[6767138]]></publicationId>

<partnum><![CDATA[6767138]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6767138&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6767138]]></pdf>

</document>

<document>

<rank>659</rank>

<title><![CDATA[How to Display Group Information on Node-Link Diagrams: An Evaluation]]></title>

<authors><![CDATA[Jianu, R.;  Rusu, A.;  Yifan Hu;  Taggart, D.]]></authors>

<affiliations><![CDATA[Sch. of Comput. & Inf. Sci., Florida Int. Univ., Miami, FL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Cluster approximation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Image color analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1530]]></spage>

<epage><![CDATA[1541]]></epage>

<abstract><![CDATA[We present the results of evaluating four techniques for displaying group or cluster information overlaid on node-link diagrams: node coloring, GMap, BubbleSets, and LineSets. The contributions of the paper are three fold. First, we present quantitative results and statistical analyses of data from an online study in which approximately 800 subjects performed 10 types of group and network tasks in the four evaluated visualizations. Specifically, we show that BubbleSets is the best alternative for tasks involving group membership assessment; that visually encoding group information over basic node-link diagrams incurs an accuracy penalty of about 25 percent in solving network tasks; and that GMap's use of prominent group labels improves memorability. We also show that GMap's visual metaphor can be slightly altered to outperform BubbleSets in group membership assessment. Second, we discuss visual characteristics that can explain the observed quantitative differences in the four visualizations and suggest design recommendations. This discussion is supported by a small scale eye-tracking study and previous results from the visualization literature. Third, we present an easily extensible user study methodology.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6787045]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2315995]]></doi>

<publicationId><![CDATA[6787045]]></publicationId>

<partnum><![CDATA[6787045]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6787045&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787045]]></pdf>

</document>

<document>

<rank>660</rank>

<title><![CDATA[Ambient Occlusion Effects for Combined Volumes and Tubular Geometry]]></title>

<authors><![CDATA[Schott, M.;  Martin, T.;  Grosset, A.V.P.;  Smith, S.T.;  Hansen, C.D.]]></authors>

<affiliations><![CDATA[NVIDIA Corp., Santa Clara, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[hidden feature removal]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aerospace electronics]]></term>

<term><![CDATA[Diffusion tensor imaging]]></term>

<term><![CDATA[Electron tubes]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[913]]></spage>

<epage><![CDATA[926]]></epage>

<abstract><![CDATA[This paper details a method for interactive direct volume rendering that computes ambient occlusion effects for visualizations that combine both volumetric and geometric primitives, specifically tube-shaped geometric objects representing streamlines, magnetic field lines or DTI fiber tracts. The algorithm extends the recently presented the directional occlusion shading model to allow the rendering of those geometric shapes in combination with a context providing 3D volume, considering mutual occlusion between structures represented by a volume or geometry. Stream tube geometries are computed using an effective spline-based interpolation and approximation scheme that avoids self-intersection and maintains coherent orientation of the stream tube segments to avoid surface deforming twists. Furthermore, strategies to reduce the geometric and specular aliasing of the stream tubes are discussed.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6361390]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.306]]></doi>

<publicationId><![CDATA[6361390]]></publicationId>

<partnum><![CDATA[6361390]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6361390&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6361390]]></pdf>

</document>

<document>

<rank>661</rank>

<title><![CDATA[In Memoriam: Illuminating Our Paths - James (Jim) Joseph Thomas]]></title>

<authors><![CDATA[Ebert, David S;  Dill, John;  Kasik, David J.]]></authors>

<thesaurusterms>

<term><![CDATA["Thomas, James Joseph "]]></term>

<term><![CDATA[Obituaries]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[xxi]]></spage>

<epage><![CDATA[xxi]]></epage>

<abstract><![CDATA[Recounts the career and contributions of James (Jim) Joseph Thomas.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5613420]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.167]]></doi>

<publicationId><![CDATA[5613420]]></publicationId>

<partnum><![CDATA[5613420]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613420&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613420]]></pdf>

</document>

<document>

<rank>662</rank>

<title><![CDATA[A Scalable Distributed Paradigm for Multi-User Interaction with Tiled Rear Projection Display Walls]]></title>

<authors><![CDATA[Roman, P.;  Lazarov, M.;  Majumder, A.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Univ. of Calif ornia, Irvine, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[gesture recognition]]></term>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[large screen displays]]></term>

<term><![CDATA[optical projectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Arrays]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Servers]]></term>

<term><![CDATA[Tracking]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1623]]></spage>

<epage><![CDATA[1632]]></epage>

<abstract><![CDATA[We present the first distributed paradigm for multiple users to interact simultaneously with large tiled rear projection display walls. Unlike earlier works, our paradigm allows easy scalability across different applications, interaction modalities, displays and users. The novelty of the design lies in its distributed nature allowing well-compartmented, application independent, and application specific modules. This enables adapting to different 2D applications and interaction modalities easily by changing a few application specific modules. We demonstrate four challenging 2D applications on a nine projector display to demonstrate the application scalability of our method: map visualization, virtual graffiti, virtual bulletin board and an emergency management system. We demonstrate the scalability of our method to multiple interaction modalities by showing both gesture-based and laser-based user interfaces. Finally, we improve earlier distributed methods to register multiple projectors. Previous works need multiple patterns to identify the neighbors, the configuration of the display and the registration across multiple projectors in logarithmic time with respect to the number of projectors in the display. We propose a new approach that achieves this using a single pattern based on specially augmented QR codes in constant time. Further, previous distributed registration algorithms are prone to large misregistrations. We propose a novel radially cascading geometric registration technique that yields significantly better accuracy. Thus, our improvements allow a significantly more efficient and accurate technique for distributed self-registration of multi-projector display walls.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613505]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.128]]></doi>

<publicationId><![CDATA[5613505]]></publicationId>

<partnum><![CDATA[5613505]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613505&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613505]]></pdf>

</document>

<document>

<rank>663</rank>

<title><![CDATA[Manifold Dual Contouring]]></title>

<authors><![CDATA[Schaefer, S.;  Ju, T.;  Warren, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Texas A&M Univ., College Station, TX]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[edge detection]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[octrees]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[DC generators]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Surface cracks]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[610]]></spage>

<epage><![CDATA[619]]></epage>

<abstract><![CDATA[Dual contouring (DC) is a feature-preserving isosurfacing method that extracts crack-free surfaces from both uniform and adaptive octree grids. We present an extension of DC that further guarantees that the mesh generated is a manifold even under adaptive simplification. Our main contribution is an octree-based topology-preserving vertex-clustering algorithm for adaptive contouring. The contoured surface generated by our method contains only manifold vertices and edges, preserves sharp features, and possesses much better adaptivity than those generated by other isosurfacing methods under topologically safe simplification]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4297690]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1012]]></doi>

<publicationId><![CDATA[4297690]]></publicationId>

<partnum><![CDATA[4297690]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297690&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297690]]></pdf>

</document>

<document>

<rank>664</rank>

<title><![CDATA[Visually Comparing Weather Features in Forecasts]]></title>

<authors><![CDATA[Quinan, P.S.;  Meyer, M.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision support systems]]></term>

<term><![CDATA[encoding]]></term>

<term><![CDATA[geophysics computing]]></term>

<term><![CDATA[weather forecasting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Weather forecasting]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[389]]></spage>

<epage><![CDATA[398]]></epage>

<abstract><![CDATA[Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192710]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467754]]></doi>

<publicationId><![CDATA[7192710]]></publicationId>

<partnum><![CDATA[7192710]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192710&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192710]]></pdf>

</document>

<document>

<rank>665</rank>

<title><![CDATA[Felix: A Topology based Framework for Visual Exploration of Cosmic Filaments]]></title>

<authors><![CDATA[Shivashankar, N.;  Pranav, P.;  Natarajan, V.;  van de Weygaert, R.;  Bos, P.;  Rieder, S.]]></authors>

<affiliations><![CDATA[Nithin Shivashankar is with the Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India, 560038.(Email: nithin19484@gmail.com)]]></affiliations>

<thesaurusterms>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Indexes]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[The large-scale structure of the universe is comprised of virialized blob-like clusters, linear filaments, sheet-like walls and huge near empty three-dimensional voids. Characterizing the large scale universe is essential to our understanding of the formation and evolution of galaxies. The density range of clusters, walls and voids are relatively well separated, when compared to filaments, which span a relatively larger range. The large scale filamentary network thus forms an intricate part of the cosmic web. In this paper, we describe Felix, a topology based framework for visual exploration of filaments in the cosmic web. The filamentary structure is represented by the ascending manifold geometry of the 2-saddles in the Morse-Smale complex of the density field. We generate a hierarchy of Morse-Smale complexes and query for filaments based on the density ranges at the end points of the filaments. The query is processed efficiently over the entire hierarchical Morse-Smale complex, allowing for interactive visualization. We apply Felix to computer simulations based on the heuristic Voronoi kinematic model and the standard LCDM cosmology, and demonstrate its usefulness through two case studies. First, we extract cosmic filaments within and across cluster like regions in Voronoi kinematic simulation datasets. We demonstrate that we produce similar results to existing structure finders. Second, we extract different classes of filaments based on their density characteristics from the LCDM simulation datasets. Filaments that form the spine of the cosmic web, which exist in high density regions in the current epoch, are isolated using Felix. Also, filaments present in void-like regions are isolated and visualized. These filamentary structures are often over shadowed by higher density range filaments and are not easily characterizable and extractable using other filament extraction methodologies.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7150427]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2452919]]></doi>

<publicationId><![CDATA[7150427]]></publicationId>

<partnum><![CDATA[7150427]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7150427&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7150427]]></pdf>

</document>

<document>

<rank>666</rank>

<title><![CDATA[Colon Flattening Using Heat Diffusion Riemannian Metric]]></title>

<authors><![CDATA[Gurijala, K.C.;  Rui Shi;  Wei Zeng;  Xianfeng Gu;  Kaufman, A.]]></authors>

<affiliations><![CDATA[Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Laplace equations]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical measurement]]></term>

<term><![CDATA[Colonoscopy]]></term>

<term><![CDATA[Harmonic analysis]]></term>

<term><![CDATA[Heating]]></term>

<term><![CDATA[Volume rendering]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2848]]></spage>

<epage><![CDATA[2857]]></epage>

<abstract><![CDATA[We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634145]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.139]]></doi>

<publicationId><![CDATA[6634145]]></publicationId>

<partnum><![CDATA[6634145]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634145&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634145]]></pdf>

</document>

<document>

<rank>667</rank>

<title><![CDATA[Real time responsive animation with personality]]></title>

<authors><![CDATA[Perlin, K.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., New York Univ., NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[stochastic processes]]></term>

<term><![CDATA[time-varying systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Drives]]></term>

<term><![CDATA[Foot]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Mood]]></term>

<term><![CDATA[Noise generators]]></term>

<term><![CDATA[Rhythm]]></term>

<term><![CDATA[Stochastic resonance]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[5]]></spage>

<epage><![CDATA[15]]></epage>

<abstract><![CDATA[Building on principles from prior work on procedural texture synthesis (K. Perlin, 1985), we are able to create remarkably lifelike, responsively animated characters in real time. Rhythmic and stochastic noise functions are used to define time varying parameters that drive computer generated puppets. Because we are conveying just the &ldquo;texture&rdquo; of motion, we are able to avoid computation of dynamics and constraint solvers. The subjective impression of dynamics and other subtle influences on motion can be conveyed with great visual realism by properly tuned expressions containing pseudo random noise functions. For example, we can make a character appear to be dynamically balancing herself, to appear nervous, or to be gesturing in a particular way. Each move has an internal rhythm, and transitions between moves are temporally constrained so that &ldquo;impossible&rdquo; transitions are precluded. For example, if while the character is walking we specify a dance turn, the character will always step into the turn onto the correct weight bearing foot. An operator can make a character perform a properly connected sequence of actions, while conveying particular moods and attitudes, merely by pushing buttons at a high level. Potential uses of such high level &ldquo;textural&rdquo; approaches to computer graphic simulation include role playing games, simulated conferences, &ldquo;clip animation&rdquo;, graphical front ends for MUDs, and synthetic performances]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[468392]]></arnumber>

<doi><![CDATA[10.1109/2945.468392]]></doi>

<publicationId><![CDATA[468392]]></publicationId>

<partnum><![CDATA[468392]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=468392&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468392]]></pdf>

</document>

<document>

<rank>668</rank>

<title><![CDATA[Lattice Cleaving: A Multimaterial Tetrahedral Meshing Algorithm with Guarantees]]></title>

<authors><![CDATA[Bronson, J.;  Levine, J.A.;  Whitaker, R.]]></authors>

<affiliations><![CDATA[Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Finite element analysis]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Joining processes]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Materials]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[223]]></spage>

<epage><![CDATA[237]]></epage>

<abstract><![CDATA[We introduce a new algorithm for generating tetrahedral meshes that conform to physical boundaries in volumetric domains consisting of multiple materials. The proposed method allows for an arbitrary number of materials, produces high-quality tetrahedral meshes with upper and lower bounds on dihedral angles, and guarantees geometric fidelity. Moreover, the method is combinatoric so its implementation enables rapid mesh construction. These meshes are structured in a way that also allows grading, to reduce element counts in regions of homogeneity. Additionally, we provide proofs showing that both element quality and geometric fidelity are bounded using this approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6579593]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.115]]></doi>

<publicationId><![CDATA[6579593]]></publicationId>

<partnum><![CDATA[6579593]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6579593&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6579593]]></pdf>

</document>

<document>

<rank>669</rank>

<title><![CDATA[Join the IEEE Visualization Community [advertisement]]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Calendars]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[482]]></spage>

<epage><![CDATA[482]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4435113]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.20]]></doi>

<publicationId><![CDATA[4435113]]></publicationId>

<partnum><![CDATA[4435113]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4435113&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4435113]]></pdf>

</document>

<document>

<rank>670</rank>

<title><![CDATA[Natural Interaction Metaphors for Functional Validations of Virtual Car Models]]></title>

<authors><![CDATA[Moehring, M.;  Froehlich, B.]]></authors>

<affiliations><![CDATA[Group Res. Virtual Technol., Wolfsburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[automotive components]]></term>

<term><![CDATA[automotive engineering]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[product development]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[User interfaces]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1195]]></spage>

<epage><![CDATA[1208]]></epage>

<abstract><![CDATA[Natural Interaction in virtual environments is a key requirement for the virtual validation of functional aspects in automotive product development processes. Natural Interaction is the metaphor people encounter in reality: the direct manipulation of objects by their hands. To enable this kind of Natural Interaction, we propose a pseudophysical metaphor that is both plausible enough to provide realistic interaction and robust enough to meet the needs of industrial applications. Our analysis of the most common types of objects in typical automotive scenarios guided the development of a set of refined grasping heuristics to support robust finger-based interaction of multiple hands and users. The objects' behavior in reaction to the users' finger motions is based on pseudophysical simulations, which also take various types of constrained objects into account. In dealing with real-world scenarios, we had to introduce the concept of Normal Proxies, which extend objects with appropriate normals for improved grasp detection and grasp stability. An expert review revealed that our interaction metaphors allow for an intuitive and reliable assessment of several functionalities of objects found in a car interior. Follow-up user studies showed that overall task performance and usability are similar for CAVE and HMD environments. For larger objects and more gross manipulation, using the CAVE without employing a virtual hand representation is preferred, but for more fine-grained manipulation and smaller objects, the HMD turns out to be beneficial.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5710906]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.36]]></doi>

<publicationId><![CDATA[5710906]]></publicationId>

<partnum><![CDATA[5710906]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5710906&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710906]]></pdf>

</document>

<document>

<rank>671</rank>

<title><![CDATA[Interpenetration Free Simulation of Thin Shell Rigid Bodies]]></title>

<authors><![CDATA[English, R.E.;  Lentine, M.;  Fedkiw, R.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[object detection]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Dynamics]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[991]]></spage>

<epage><![CDATA[1004]]></epage>

<abstract><![CDATA[We propose a new algorithm for rigid body simulation that guarantees each body is in an interpenetration free state, both increasing the accuracy and robustness of the simulation as well as alleviating the need for ad hoc methods to separate bodies for subsequent simulation and rendering. We cleanly separate collision and contact resolution such that objects move and collide in the first step, with resting contact handled in the second step. The first step of our algorithm guarantees that each time step produces geometry that does not intersect or overlap by using an approximation to the continuous collision detection (and response) problem and, thus, is amenable to thin shells and degenerately flat objects moving at high speeds. In addition, we introduce a novel fail-safe that allows us to resolve all interpenetration without iterating to convergence. Since the first step guarantees a noninterfering state for the geometry, in the second step we propose a contact model for handling thin shells in proximity considering only the instantaneous locations at the ends of the time step.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6295614]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.179]]></doi>

<publicationId><![CDATA[6295614]]></publicationId>

<partnum><![CDATA[6295614]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6295614&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6295614]]></pdf>

</document>

<document>

<rank>672</rank>

<title><![CDATA[On simulated annealing and the construction of linear spline approximations for scattered data]]></title>

<authors><![CDATA[Kreylos, O.;  Hamann, B.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., California Univ., Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[function approximation]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[simulated annealing]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Iterative algorithms]]></term>

<term><![CDATA[Linear approximation]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Optimal control]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Simulated annealing]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[17]]></spage>

<epage><![CDATA[31]]></epage>

<abstract><![CDATA[We describe a method to create optimal linear spline approximations to arbitrary functions of one or two variables, given as scattered data without known connectivity. We start with an initial approximation consisting of a fixed number of vertices and improve this approximation by choosing different vertices, governed by a simulated annealing algorithm. In the case of one variable, the approximation is defined by line segments; in the case of two variables, the vertices are connected to define a Delaunay triangulation of the selected subset of sites in the plane. In a second version of this algorithm, specifically designed for the bivariate case, we choose vertex sets and also change the triangulation to achieve both optimal vertex placement and optimal triangulation. We then create a hierarchy of linear spline approximations, each one being a superset of all lower-resolution ones]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[910818]]></arnumber>

<doi><![CDATA[10.1109/2945.910818]]></doi>

<publicationId><![CDATA[910818]]></publicationId>

<partnum><![CDATA[910818]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=910818&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=910818]]></pdf>

</document>

<document>

<rank>673</rank>

<title><![CDATA[NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity]]></title>

<authors><![CDATA[Al-Awami, A.K.;  Beyer, J.;  Strobelt, H.;  Kasthuri, N.;  Lichtman, J.W.;  Pfister, H.;  Hadwiger, M.]]></authors>

<affiliations><![CDATA[King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[brain models]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[neural nets]]></term>

<term><![CDATA[neurophysiology]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[reverse engineering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Nanoscale devices]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Nerve fibers]]></term>

<term><![CDATA[Neurophysiology]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2369]]></spage>

<epage><![CDATA[2378]]></epage>

<abstract><![CDATA[We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875935]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346312]]></doi>

<publicationId><![CDATA[6875935]]></publicationId>

<partnum><![CDATA[6875935]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875935&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875935]]></pdf>

</document>

<document>

<rank>674</rank>

<title><![CDATA[Who Votes For What? A Visual Query Language for Opinion Data]]></title>

<authors><![CDATA[Draper, G.;  Riesenfeld, R.F.]]></authors>

<affiliations><![CDATA[Sch. of Comput., Univ. of Utah, Salt Lake City, UT]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[query languages]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Database languages]]></term>

<term><![CDATA[Demography]]></term>

<term><![CDATA[Nominations and elections]]></term>

<term><![CDATA[Voting]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1197]]></spage>

<epage><![CDATA[1204]]></epage>

<abstract><![CDATA[Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4658130]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.187]]></doi>

<publicationId><![CDATA[4658130]]></publicationId>

<partnum><![CDATA[4658130]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658130&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658130]]></pdf>

</document>

<document>

<rank>675</rank>

<title><![CDATA[Robust Dense Registration of Partial Nonrigid Shapes]]></title>

<authors><![CDATA[Tingbo Hou;  Hong Qin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[object detection]]></term>

<term><![CDATA[random processes]]></term>

<term><![CDATA[search problems]]></term>

<term><![CDATA[shape recognition]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Eigenvalues and eigenfunctions]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Heating]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1268]]></spage>

<epage><![CDATA[1280]]></epage>

<abstract><![CDATA[This paper presents a complete and robust solution for dense registration of partial nonrigid shapes. Its novel contributions are founded upon the newly proposed heat kernel coordinates (HKCs) that can accurately position points on the shape, and the priority-vicinity search that ensures geometric compatibility during the registration. HKCs index points by computing heat kernels from multiple sources, and their magnitudes serve as priorities of queuing points in registration. We start with shape features as the sources of heat kernels via feature detection and matching. Following the priority order of HKCs, the dense registration is progressively propagated from feature sources to all points. Our method has a superior indexing ability that can produce dense correspondences with fewer flips. The diffusion nature of HKCs, which can be interpreted as a random walk on a manifold, makes our method robust to noise and small holes avoiding surface surgery and repair. Our method searches correspondence only in a small vicinity of registered points, which significantly improves the time performance. Through comprehensive experiments, our new method has demonstrated its technical soundness and robustness by generating highly compatible dense correspondences.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6060815]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.267]]></doi>

<publicationId><![CDATA[6060815]]></publicationId>

<partnum><![CDATA[6060815]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6060815&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6060815]]></pdf>

</document>

<document>

<rank>676</rank>

<title><![CDATA[Flexible Linked Axes for Multivariate Data Visualization]]></title>

<authors><![CDATA[Claessen, J.H.T.;  van Wijk, J.J.]]></authors>

<affiliations><![CDATA[Eindhoven Univ. of Technol., Eindhoven, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Scattering parameters]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2310]]></spage>

<epage><![CDATA[2316]]></epage>

<abstract><![CDATA[Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064997]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.201]]></doi>

<publicationId><![CDATA[6064997]]></publicationId>

<partnum><![CDATA[6064997]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064997&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064997]]></pdf>

</document>

<document>

<rank>677</rank>

<title><![CDATA[Efficient polygon clipping for an SIMD graphics pipeline]]></title>

<authors><![CDATA[Schneider, B.-O.;  van Welzen, J.]]></authors>

<affiliations><![CDATA[IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[multimedia computing]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[reduced instruction set computing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bandwidth]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Engines]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Streaming media]]></term>

<term><![CDATA[VLIW]]></term>

<term><![CDATA[Video compression]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[272]]></spage>

<epage><![CDATA[285]]></epage>

<abstract><![CDATA[SIMD processors have become popular architectures for multimedia. Though most of the 3D graphics pipeline can be implemented on such SIMD platforms in a straightforward manner, polygon clipping tends to cause clumsy and expensive interruptions to the SIMD pipeline. This paper describes a way to increase the efficiency of SIMD clipping without sacrificing the efficient flow of a SIMD graphics pipeline. In order to fully utilize the parallel execution units, we have developed two methods to avoid serialization of the execution stream: deferred clipping postpones polygon clipping and uses hardware assistance to buffer polygons that need to be clipped. SIMD clipping partitions the actual polygon clipping procedure between the SIMD engine and a conventional RISC processor. To increase the efficiency of SIMD clipping, we introduce the concepts of clip-plane pairs and edge batching. Clip-plane pairs allow clipping a polygon against two clip planes without introducing corner vertices. Edge batching reduces the communication and control overhead for starting of clipping on the SIMD engine]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[722301]]></arnumber>

<doi><![CDATA[10.1109/2945.722301]]></doi>

<publicationId><![CDATA[722301]]></publicationId>

<partnum><![CDATA[722301]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=722301&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722301]]></pdf>

</document>

<document>

<rank>678</rank>

<title><![CDATA[Geodesic Binding for Degenerate Character Geometry Using Sparse Voxelization]]></title>

<authors><![CDATA[Dionne, O.;  de Lasa, M.]]></authors>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[iterative methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bones]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Octrees]]></term>

<term><![CDATA[Skin]]></term>

<term><![CDATA[Windings]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1367]]></spage>

<epage><![CDATA[1378]]></epage>

<abstract><![CDATA[We propose a fully automatic method for specifying influence weights for closed-form skinning methods, such as linear blend or dual quaternion skinning. Our method is designed to work with production meshes that may contain non-manifold geometry, be non-watertight, have intersecting triangles, or be comprised of multiple connected components. Starting from a character rest pose mesh and skeleton hierarchy, we first voxelize the input geometry. The resulting sparse voxelization is then used to calculate binding weights, based on the geodesic distance between each voxel lying on a skeleton &#x201C;bone&#x201D; and all non-exterior voxels. This yields smooth weights at interactive rates, without time-constants, iteration parameters, or costly optimization at bind or pose time. By decoupling weight assignment from distance computation we make it possible to modify weights interactively, at pose time, without additional pre-processing or computation. This allows artists to assess impact of weight selection in the context in which they are used.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6809992]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2321563]]></doi>

<publicationId><![CDATA[6809992]]></publicationId>

<partnum><![CDATA[6809992]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6809992&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6809992]]></pdf>

</document>

<document>

<rank>679</rank>

<title><![CDATA[Timeline Editing of Objects in Video]]></title>

<authors><![CDATA[Shao-Ping Lu;  Song-Hai Zhang;  Jin Wei;  Shi-Min Hu;  Martin, R.R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bismuth]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Electron tubes]]></term>

<term><![CDATA[IEEE Potentials]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1218]]></spage>

<epage><![CDATA[1227]]></epage>

<abstract><![CDATA[We present a video editing technique based on changing the timelines of individual objects in video, which leaves them in their original places but puts them at different times. This allows the production of object-level slow motion effects, fast motion effects, or even time reversal. This is more flexible than simply applying such effects to whole frames, as new relationships between objects can be created. As we restrict object interactions to the same spatial locations as in the original video, our approach can produce high-quality results using only coarse matting of video objects. Coarse matting can be done efficiently using automatic video object segmentation, avoiding tedious manual matting. To design the output, the user interactively indicates the desired new life spans of objects, and may also change the overall running time of the video. Our method rearranges the timelines of objects in the video whilst applying appropriate object interaction constraints. We demonstrate that, while this editing technique is somewhat restrictive, it still allows many interesting results.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6226393]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.145]]></doi>

<publicationId><![CDATA[6226393]]></publicationId>

<partnum><![CDATA[6226393]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6226393&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226393]]></pdf>

</document>

<document>

<rank>680</rank>

<title><![CDATA[Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop]]></title>

<authors><![CDATA[Legg, P.A.;  Chung, D.H.S.;  Parry, M.L.;  Bown, R.;  Jones, M.W.;  Griffiths, I.W.;  Min Chen]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Swansea Univ., Swansea, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[video retrieval]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Machine learning]]></term>

<term><![CDATA[Multimedia communication]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2109]]></spage>

<epage><![CDATA[2118]]></epage>

<abstract><![CDATA[Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634165]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.207]]></doi>

<publicationId><![CDATA[6634165]]></publicationId>

<partnum><![CDATA[6634165]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634165&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634165]]></pdf>

</document>

<document>

<rank>681</rank>

<title><![CDATA[Supporting Iterative Cohort Construction with Visual Temporal Queries]]></title>

<authors><![CDATA[Krause, J.;  Perer, A.;  Stavropoulos, H.]]></authors>

<controlledterms>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[query processing]]></term>

<term><![CDATA[temporal databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Databases]]></term>

<term><![CDATA[Diseases]]></term>

<term><![CDATA[Junctions]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Sociology]]></term>

<term><![CDATA[Statistics]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[91]]></spage>

<epage><![CDATA[100]]></epage>

<abstract><![CDATA[Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192665]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467622]]></doi>

<publicationId><![CDATA[7192665]]></publicationId>

<partnum><![CDATA[7192665]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192665&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192665]]></pdf>

</document>

<document>

<rank>682</rank>

<title><![CDATA[ManyEyes: a Site for Visualization at Internet Scale]]></title>

<authors><![CDATA[Viegas, F.B.;  Wattenberg, M.;  van Ham, F.;  Kriss, J.;  McKeon, M.]]></authors>

<affiliations><![CDATA[IBM Res., Yorktown Heights]]></affiliations>

<controlledterms>

<term><![CDATA[Web sites]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Collaborative tools]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Eyes]]></term>

<term><![CDATA[Internet]]></term>

<term><![CDATA[Publishing]]></term>

<term><![CDATA[Space technology]]></term>

<term><![CDATA[Web page design]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1121]]></spage>

<epage><![CDATA[1128]]></epage>

<abstract><![CDATA[We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376131]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70577]]></doi>

<publicationId><![CDATA[4376131]]></publicationId>

<partnum><![CDATA[4376131]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376131&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376131]]></pdf>

</document>

<document>

<rank>683</rank>

<title><![CDATA[GPU-Based Volume Visualization from High-Order Finite Element Fields]]></title>

<authors><![CDATA[Nelson, B.;  Kirby, R.M.;  Haimes, R.]]></authors>

<affiliations><![CDATA[Space Dynamics Lab., Utah State Univ. Res. Found., Logan, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[convergence]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Finite element analysis]]></term>

<term><![CDATA[Graphics processing units]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Spectral analysis]]></term>

<term><![CDATA[Volume measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[70]]></spage>

<epage><![CDATA[83]]></epage>

<abstract><![CDATA[This paper describes a new volume rendering system for spectral/hp finite-element methods that has as its goal to be both accurate and interactive. Even though high-order finite element methods are commonly used by scientists and engineers, there are few visualization methods designed to display this data directly. Consequently, visualizations of high-order data are generally created by first sampling the high-order field onto a regular grid and then generating the visualization via traditional methods based on linear interpolation. This approach, however, introduces error into the visualization pipeline and requires the user to balance image quality, interactivity, and resource consumption. We first show that evaluation of the volume rendering integral, when applied to the composition of piecewise-smooth transfer functions with the high-order scalar field, typically exhibits second-order convergence for a wide range of high-order quadrature schemes, and has worst case first-order convergence. This result provides bounds on the ability to achieve high-order convergence to the volume rendering integral. We then develop an algorithm for optimized evaluation of the volume rendering integral, based on the categorization of each ray according to the local behavior of the field and transfer function. We demonstrate the effectiveness of our system by running performance benchmarks on several high-order fluid-flow simulations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6552195]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.96]]></doi>

<publicationId><![CDATA[6552195]]></publicationId>

<partnum><![CDATA[6552195]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6552195&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6552195]]></pdf>

</document>

<document>

<rank>684</rank>

<title><![CDATA[Editor's Note [2013 Best Associate Editor Award &amp; 2013 Best Reviewer Award]]]></title>

<authors><![CDATA[Lin, M.C.]]></authors>

<thesaurusterms>

<term><![CDATA[Awards]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[822]]></spage>

<epage><![CDATA[822]]></epage>

<abstract><![CDATA[The success of a journal relies heavily on the quality of submissions and of their reviews. The latter is primarily the work and efforts of the associate editors and the anonymous reviewers. The dedication of associate editors and of external reviewers is essential to the continuing growth of the journal. To continue recognizing these "unsung heroes" who drive the scientific peer review process for IEEE Transactions on Visualization and Computer Graphics (TVCG), it is my pleasure to announce the 2013 Best Associate Editor Award and the 2013 Best Reviewer Award. Three associate editors (AEs) for are recognized their dedication and hard work in 2013: Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi. They handled a large number of submissions efficiently with the quickest turnaround (averaging less than 50 days) and provided consistently high-quality, thoughtful AE summary to the authors. In recognizing their distinguished service to the IEEE TVCG, the 2013 TVCG Best Associate Editor Award goes to Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6805680]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2310791]]></doi>

<publicationId><![CDATA[6805680]]></publicationId>

<partnum><![CDATA[6805680]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6805680&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6805680]]></pdf>

</document>

<document>

<rank>685</rank>

<title><![CDATA[Texture mixing and texture movie synthesis using statistical learning]]></title>

<authors><![CDATA[Bar-Joseph, Z.;  El-Yaniv, R.;  Lischinski, D.;  Werman, M.]]></authors>

<affiliations><![CDATA[Lab. for Comput. Sci., MIT, Cambridge, MA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[image texture]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[trees (mathematics)]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Fires]]></term>

<term><![CDATA[Motion pictures]]></term>

<term><![CDATA[Signal generators]]></term>

<term><![CDATA[Signal processing]]></term>

<term><![CDATA[Signal sampling]]></term>

<term><![CDATA[Signal synthesis]]></term>

<term><![CDATA[Statistical learning]]></term>

<term><![CDATA[Stochastic processes]]></term>

<term><![CDATA[Wavelet transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[120]]></spage>

<epage><![CDATA[135]]></epage>

<abstract><![CDATA[We present an algorithm based on statistical learning for synthesizing static and time-varying textures matching the appearance of an input texture. Our algorithm is general and automatic and it works well on various types of textures, including 1D sound textures, 2D texture images, and 3D texture movies. The same method is also used to generate 2D texture mixtures that simultaneously capture the appearance of a number of different input textures. In our approach, input textures are treated as sample signals generated by a stochastic process. We first construct a tree representing a hierarchical multiscale transform of the signal using wavelets. From this tree, new random trees are generated by learning and sampling the conditional probabilities of the paths in the original tree. Transformation of these random trees back into signals results in new random textures. In the case of 2D texture synthesis, our algorithm produces results that are generally as good as or better than those produced by previously described methods in this field. For texture mixtures, our results are better and more general than those produced by earlier methods. For texture movies, we present the first algorithm that is able to automatically generate movie clips of dynamic phenomena such as waterfalls, fire flames, a school of jellyfish, a crowd of people, etc. Our results indicate that the proposed technique is effective and robust]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[928165]]></arnumber>

<doi><![CDATA[10.1109/2945.928165]]></doi>

<publicationId><![CDATA[928165]]></publicationId>

<partnum><![CDATA[928165]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=928165&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=928165]]></pdf>

</document>

<document>

<rank>686</rank>

<title><![CDATA[Automated Construction of Low-Resolution, Texture-Mapped, Class-Optimal Meshes]]></title>

<authors><![CDATA[Patel, A.;  Smith, W.A.P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of York, York, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data acquisition]]></term>

<term><![CDATA[differential geometry]]></term>

<term><![CDATA[group theory]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[surface texture]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Strain]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[434]]></spage>

<epage><![CDATA[446]]></epage>

<abstract><![CDATA[In this paper, we present a framework for the groupwise processing of a set of meshes in dense correspondence. Such sets arise when modeling 3D shape variation or tracking surface motion over time. We extend a number of mesh processing tools to operate in a groupwise manner. Specifically, we present a geodesic-based surface flattening and spectral clustering algorithm which estimates a single class-optimal flattening. We also show how to modify an iterative edge collapse algorithm to perform groupwise simplification while retaining the correspondence of the data. Finally, we show how to compute class-optimal texture coordinates for the simplified meshes. We present alternative algorithms for topologically symmetric data which yield a symmetric flattening and low-resolution mesh topology. We present flattening, simplification, and texture mapping results on three different data sets and show that our approach allows the construction of low-resolution 3D morphable models.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5887328]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.101]]></doi>

<publicationId><![CDATA[5887328]]></publicationId>

<partnum><![CDATA[5887328]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5887328&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887328]]></pdf>

</document>

<document>

<rank>687</rank>

<title><![CDATA[Impulse-Based Control of Joints and Muscles]]></title>

<authors><![CDATA[Weinstein, R.;  Guendelman, E.;  Fedkiw, R.]]></authors>

<affiliations><![CDATA[Stanford Univ. & Ind. Light & Magic, San Francisco]]></affiliations>

<controlledterms>

<term><![CDATA[PD control]]></term>

<term><![CDATA[bone]]></term>

<term><![CDATA[closed loop systems]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[feedback]]></term>

<term><![CDATA[gait analysis]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[medical control systems]]></term>

<term><![CDATA[muscle]]></term>

<term><![CDATA[orthopaedics]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[37]]></spage>

<epage><![CDATA[46]]></epage>

<abstract><![CDATA[We propose a novel approach to proportional derivative (PD) control exploiting the fact that these equations can be solved analytically for a single degree of freedom. The analytic solution indicates what the PD controller would accomplish in isolation without interference from neighboring joints, gravity and external forces, outboard limbs, etc. Our approach to time integration includes an inverse dynamics formulation that automatically incorporates global feedback so that the per joint predictions are achieved. This effectively decouples stiffness from control so that we obtain the desired target regardless of the stiffness of the joint, which merely determines when we get there. We start with simple examples to illustrate our method and then move on to more complex examples including PD control of line segment muscle actuators.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359505]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70437]]></doi>

<publicationId><![CDATA[4359505]]></publicationId>

<partnum><![CDATA[4359505]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359505&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359505]]></pdf>

</document>

<document>

<rank>688</rank>

<title><![CDATA[Multi-Scale Surface Descriptors]]></title>

<authors><![CDATA[Cipriano, G.;  Phillips, G.N.;  Gleicher, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[shape recognition]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Proteins]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface fitting]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1201]]></spage>

<epage><![CDATA[1208]]></epage>

<abstract><![CDATA[Local shape descriptors compactly characterize regions of a surface, and have been applied to tasks in visualization, shape matching, and analysis. Classically, curvature has be used as a shape descriptor; however, this differential property characterizes only an infinitesimal neighborhood. In this paper, we provide shape descriptors for surface meshes designed to be multi-scale, that is, capable of characterizing regions of varying size. These descriptors capture statistically the shape of a neighborhood around a central point by fitting a quadratic surface. They therefore mimic differential curvature, are efficient to compute, and encode anisotropy. We show how simple variants of mesh operations can be used to compute the descriptors without resorting to expensive parameterizations, and additionally provide a statistical approximation for reduced computational cost. We show how these descriptors apply to a number of uses in visualization, analysis, and matching of surfaces, particularly to tasks in protein surface analysis.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290730]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.168]]></doi>

<publicationId><![CDATA[5290730]]></publicationId>

<partnum><![CDATA[5290730]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290730&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290730]]></pdf>

</document>

<document>

<rank>689</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4293027]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.070404]]></doi>

<publicationId><![CDATA[4293027]]></publicationId>

<partnum><![CDATA[4293027]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4293027&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293027]]></pdf>

</document>

<document>

<rank>690</rank>

<title><![CDATA[An Adaptive Prediction-Based Approach to Lossless Compression of Floating-Point Volume Data]]></title>

<authors><![CDATA[Fout, N.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[UC Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data compression]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[polynomials]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Entropy coding]]></term>

<term><![CDATA[Floating-point arithmetic]]></term>

<term><![CDATA[Image coding]]></term>

<term><![CDATA[Polynomials]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2295]]></spage>

<epage><![CDATA[2304]]></epage>

<abstract><![CDATA[In this work, we address the problem of lossless compression of scientific and medical floating-point volume data. We propose two prediction-based compression methods that share a common framework, which consists of a switched prediction scheme wherein the best predictor out of a preset group of linear predictors is selected. Such a scheme is able to adapt to different datasets as well as to varying statistics within the data. The first method, called APE (Adaptive Polynomial Encoder), uses a family of structured interpolating polynomials for prediction, while the second method, which we refer to as ACE (Adaptive Combined Encoder), combines predictors from previous work with the polynomial predictors to yield a more flexible, powerful encoder that is able to effectively decorrelate a wide range of data. In addition, in order to facilitate efficient visualization of compressed data, our scheme provides an option to partition floating-point values in such a way as to provide a progressive representation. We compare our two compressors to existing state-of-the-art lossless floating-point compressors for scientific data, with our data suite including both computer simulations and observational measurements. The results demonstrate that our polynomial predictor, APE, is comparable to previous approaches in terms of speed but achieves better compression rates on average. ACE, our combined predictor, while somewhat slower, is able to achieve the best compression rate on all datasets, with significantly better rates on most of the datasets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327234]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.194]]></doi>

<publicationId><![CDATA[6327234]]></publicationId>

<partnum><![CDATA[6327234]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327234&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327234]]></pdf>

</document>

<document>

<rank>691</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5685305]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.19]]></doi>

<publicationId><![CDATA[5685305]]></publicationId>

<partnum><![CDATA[5685305]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5685305&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685305]]></pdf>

</document>

<document>

<rank>692</rank>

<title><![CDATA[An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization]]></title>

<authors><![CDATA[Roth, R.E.]]></authors>

<affiliations><![CDATA[Univ. of Wisconsin-Madison, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cartography]]></term>

<term><![CDATA[Geophysical measurements]]></term>

<term><![CDATA[Object recognition]]></term>

<term><![CDATA[Search problems]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2356]]></spage>

<epage><![CDATA[2365]]></epage>

<abstract><![CDATA[Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, &amp; delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, &amp; prescribe) and interaction operands (space-alone, attributes-in-space, &amp; space-in-time; elementary &amp; general). The operator sort suggested five enabling operators (import, export, save, edit, &amp; annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, &amp; calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634181]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.130]]></doi>

<publicationId><![CDATA[6634181]]></publicationId>

<partnum><![CDATA[6634181]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634181&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634181]]></pdf>

</document>

<document>

<rank>693</rank>

<title><![CDATA[State of the &#x0022;Art&amp;#x201D;: A Taxonomy of Artistic Stylization Techniques for Images and Video]]></title>

<authors><![CDATA[Kyprianidis, J.E.;  Collomosse, J.;  Tinghuai Wang;  Isenberg, T.]]></authors>

<affiliations><![CDATA[Comput. Graphics Syst. Group, Univ. of Potsdam, Potsdam, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[computer vision]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Painting]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Taxonomy]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[866]]></spage>

<epage><![CDATA[885]]></epage>

<abstract><![CDATA[This paper surveys the field of nonphotorealistic rendering (NPR), focusing on techniques for transforming 2D input (images and video) into artistically stylized renderings. We first present a taxonomy of the 2D NPR algorithms developed over the past two decades, structured according to the design characteristics and behavior of each technique. We then describe a chronology of development from the semiautomatic paint systems of the early nineties, through to the automated painterly rendering systems of the late nineties driven by image gradient analysis. Two complementary trends in the NPR literature are then addressed, with reference to our taxonomy. First, the fusion of higher level computer vision and NPR, illustrating the trends toward scene analysis to drive artistic abstraction and diversity of style. Second, the evolution of local processing approaches toward edge-aware filtering for real-time stylization of images and video. The survey then concludes with a discussion of open challenges for 2D NPR identified in recent NPR symposia, including topics such as user and aesthetic evaluation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6243138]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.160]]></doi>

<publicationId><![CDATA[6243138]]></publicationId>

<partnum><![CDATA[6243138]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6243138&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6243138]]></pdf>

</document>

<document>

<rank>694</rank>

<title><![CDATA[Keynote Speaker: Taking the "Virtual" Out of Virtual Reality]]></title>

<authors><![CDATA[Sequin, C.H.]]></authors>

<affiliations><![CDATA[Univ. of California, Berkeley, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[CAD]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[production engineering computing]]></term>

<term><![CDATA[rapid prototyping (industrial)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[xi]]></spage>

<epage><![CDATA[xi]]></epage>

<abstract><![CDATA[Summary form only given. Today's graphics programs cannot only produce stunning photo-realistic images or convincingly real scene displays for interactive exploration, they can also produce physi cal output - thanks to the emergence of several different layered manufacturing technologies. For many design activities creating tangible models through some rapid prototyping prcess is a new and crucial feedback loop for debugging the functionality or customer-appeal of a new product. Dr. Sequin has two decades of experience with creating mathematical visualization models and designs ranging from university buildings to abstract geometrical sculptures. Turning these virtual creations into physical realities, however, raises a whole new set of issues that are often overlooked in the initial virtual design phase.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6165130]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.49]]></doi>

<publicationId><![CDATA[6165130]]></publicationId>

<partnum><![CDATA[6165130]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165130&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165130]]></pdf>

</document>

<document>

<rank>695</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5730202]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.60]]></doi>

<publicationId><![CDATA[5730202]]></publicationId>

<partnum><![CDATA[5730202]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5730202&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5730202]]></pdf>

</document>

<document>

<rank>696</rank>

<title><![CDATA[Benefitting InfoVis with Visual Difficulties]]></title>

<authors><![CDATA[Hullman, J.;  Adar, E.;  Shah, P.]]></authors>

<controlledterms>

<term><![CDATA[cognition]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[psychology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Time factors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2213]]></spage>

<epage><![CDATA[2222]]></epage>

<abstract><![CDATA[Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative "chartjunk" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064986]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.175]]></doi>

<publicationId><![CDATA[6064986]]></publicationId>

<partnum><![CDATA[6064986]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064986&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064986]]></pdf>

</document>

<document>

<rank>697</rank>

<title><![CDATA[Generalized Anisotropic Stratified Surface Sampling]]></title>

<authors><![CDATA[Quinn, J.A.;  Langbein, F.C.;  Yu-Kun Lai;  Martin, R.R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. Inf., Cardiff Univ., Cardiff, UK]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Manifolds]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1143]]></spage>

<epage><![CDATA[1157]]></epage>

<abstract><![CDATA[We introduce a novel stratified sampling technique for mesh surfaces that gives the user control over sampling density and anisotropy via a tensor field. Our approach is based on sampling space-filling curves mapped onto mesh segments via parametrizations aligned with the tensor field. After a short preprocessing step, samples can be generated in real time. Along with visual examples, we provide rigorous spectral analysis and differential domain analysis of our sampling. The sample distributions are of high quality: they fulfil the blue noise criterion, so have minimal artifacts due to regularity of sampling patterns, and they accurately represent isotropic and anisotropic densities on the plane and on mesh surfaces. They also have low discrepancy, ensuring that the surface is evenly covered.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6378367]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.305]]></doi>

<publicationId><![CDATA[6378367]]></publicationId>

<partnum><![CDATA[6378367]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6378367&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6378367]]></pdf>

</document>

<document>

<rank>698</rank>

<title><![CDATA[Dense and Dynamic 3D Selection for Game-Based Virtual Environments]]></title>

<authors><![CDATA[Cashion, J.;  Wingrave, C.;  LaViola, J.J.]]></authors>

<controlledterms>

<term><![CDATA[computer games]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[user interfaces]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Games]]></term>

<term><![CDATA[Guidelines]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Usability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[634]]></spage>

<epage><![CDATA[642]]></epage>

<abstract><![CDATA[3D object selection is more demanding when, 1) objects densly surround the target object, 2) the target object is significantly occluded, and 3) when the target object is dynamically changing location. Most 3D selection techniques and guidelines were developed and tested on static or mostly sparse environments. In contrast, games tend to incorporate densly packed and dynamic objects as part of their typical interaction. With the increasing popularity of 3D selection in games using hand gestures or motion controllers, our current understanding of 3D selection needs revision. We present a study that compared four different selection techniques under five different scenarios based on varying object density and motion dynamics. We utilized two existing techniques, Raycasting and SQUAD, and developed two variations of them, Zoom and Expand, using iterative design. Our results indicate that while Raycasting and SQUAD both have weaknesses in terms of speed and accuracy in dense and dynamic environments, by making small modifications to them (i.e., flavoring), we can achieve significant performance increases.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6165145]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.40]]></doi>

<publicationId><![CDATA[6165145]]></publicationId>

<partnum><![CDATA[6165145]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165145&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165145]]></pdf>

</document>

<document>

<rank>699</rank>

<title><![CDATA[Committees, Reviewers, and Supporting Organizations]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[xii]]></spage>

<epage><![CDATA[xii]]></epage>

<abstract><![CDATA[The publication offers a note of thanks and lists its reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6064931]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.180]]></doi>

<publicationId><![CDATA[6064931]]></publicationId>

<partnum><![CDATA[6064931]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064931&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064931]]></pdf>

</document>

<document>

<rank>700</rank>

<title><![CDATA[Data streaming in telepresence environments]]></title>

<authors><![CDATA[Lamboray, E.;  Wurmlin, S.;  Gross, Markus]]></authors>

<affiliations><![CDATA[Cyfex AG, Zurich, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[face recognition]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[synchronisation]]></term>

<term><![CDATA[teleconferencing]]></term>

<term><![CDATA[video coding]]></term>

<term><![CDATA[video streaming]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data communication]]></term>

<term><![CDATA[Delay]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Real time systems]]></term>

<term><![CDATA[Streaming media]]></term>

<term><![CDATA[Telecommunication traffic]]></term>

<term><![CDATA[Virtual environment]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[637]]></spage>

<epage><![CDATA[648]]></epage>

<abstract><![CDATA[In this paper, we discuss data transmission in telepresence environments for collaborative virtual reality applications. We analyze data streams in the context of networked virtual environments and classify them according to their traffic characteristics. Special emphasis is put on geometry-enhanced (3D) video. We review architectures for real-time 3D video pipelines and derive theoretical bounds on the minimal system latency as a function of the transmission and processing delays. Furthermore, we discuss bandwidth issues of differential update coding for 3D video. In our telepresence system - the blue-c - we use a point-based 3D video technology which allows for differentially encoded 3D representations of human users. While we discuss the considerations which lead to the design of our three-stage 3D video pipeline, we also elucidate some critical implementation details regarding decoupling of acquisition, processing and rendering frame rates, and audio/video synchronization. Finally, we demonstrate the communication and networking features of the blue-c system in its full deployment. We show how the system can possibly be controlled to face processing or networking bottlenecks by adapting the multiple system components like audio, application data, and 3D video.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512015]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.98]]></doi>

<publicationId><![CDATA[1512015]]></publicationId>

<partnum><![CDATA[1512015]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512015&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512015]]></pdf>

</document>

<document>

<rank>701</rank>

<title><![CDATA[Editor's Note]]></title>

<authors><![CDATA[Ebert, D.S.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[545]]></spage>

<epage><![CDATA[547]]></epage>

<abstract><![CDATA[reg]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1310280]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.25]]></doi>

<publicationId><![CDATA[1310280]]></publicationId>

<partnum><![CDATA[1310280]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1310280&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310280]]></pdf>

</document>

<document>

<rank>702</rank>

<title><![CDATA[Evaluation of Multivariate Visualization on a Multivariate Task]]></title>

<authors><![CDATA[Livingston, M.A.;  Decker, J.W.;  Zhuming Ai]]></authors>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analysis of variance]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Gray-scale]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Quantitative evaluation]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Time factors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2114]]></spage>

<epage><![CDATA[2121]]></epage>

<abstract><![CDATA[Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327216]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.223]]></doi>

<publicationId><![CDATA[6327216]]></publicationId>

<partnum><![CDATA[6327216]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327216&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327216]]></pdf>

</document>

<document>

<rank>703</rank>

<title><![CDATA[A Perceptual-Statistics Shading Model]]></title>

<authors><![CDATA[Solteszova, V.;  Turkay, C.;  Price, M.C.;  Viola, I.]]></authors>

<affiliations><![CDATA[Dept. of Inf., Univ. of Bergen, Bergen, Norway]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistics]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Observers]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Surface reconstruction]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2265]]></spage>

<epage><![CDATA[2274]]></epage>

<abstract><![CDATA[The process of surface perception is complex and based on several influencing factors, e.g., shading, silhouettes, occluding contours, and top down cognition. The accuracy of surface perception can be measured and the influencing factors can be modified in order to decrease the error in perception. This paper presents a novel concept of how a perceptual evaluation of a visualization technique can contribute to its redesign with the aim of improving the match between the distal and the proximal stimulus. During analysis of data from previous perceptual studies, we observed that the slant of 3D surfaces visualized on 2D screens is systematically underestimated. The visible trends in the error allowed us to create a statistical model of the perceived surface slant. Based on this statistical model we obtained from user experiments, we derived a new shading model that uses adjusted surface normals and aims to reduce the error in slant perception. The result is a shape-enhancement of visualization which is driven by an experimentally-founded statistical model. To assess the efficiency of the statistical shading model, we repeated the evaluation experiment and confirmed that the error in perception was decreased. Results of both user experiments are publicly-available datasets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327231]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.188]]></doi>

<publicationId><![CDATA[6327231]]></publicationId>

<partnum><![CDATA[6327231]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327231&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327231]]></pdf>

</document>

<document>

<rank>704</rank>

<title><![CDATA[1995 Index IEEE Transactions on Visualization and Computer Graphics Vol. 1]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[361]]></spage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[485623]]></arnumber>

<doi><![CDATA[10.1109/TVCG.1995.485623]]></doi>

<publicationId><![CDATA[485623]]></publicationId>

<partnum><![CDATA[485623]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=485623&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485623]]></pdf>

</document>

<document>

<rank>705</rank>

<title><![CDATA[Quasi-Developable Mesh Surface Interpolation via Mesh Deformation]]></title>

<authors><![CDATA[Kai Tang;  Ming Chen]]></authors>

<affiliations><![CDATA[Mech. Eng. Dept., Hong Kong Univ. of Sci. & Technol., Hong Kong]]></affiliations>

<controlledterms>

<term><![CDATA[Gaussian processes]]></term>

<term><![CDATA[Laplace equations]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[least squares approximations]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clothing]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Iterative algorithms]]></term>

<term><![CDATA[Laplace equations]]></term>

<term><![CDATA[Minimization methods]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[518]]></spage>

<epage><![CDATA[528]]></epage>

<abstract><![CDATA[We present a new algorithm for finding a most "developable" smooth mesh surface to interpolate a given set of arbitrary points or space curves. Inspired by the recent progress in mesh editing that employs the concepts of preserving the Laplacian coordinates and handle-based shape editing, we formulate the interpolation problem as a mesh deformation process that transforms an initial developable mesh surface, such as a planar figure, to a final mesh surface that interpolates the given points and/or curves. During the deformation, the developability of the intermediate mesh is maintained by means of preserving the zero-valued Gaussian curvature on the mesh. To treat the high nonlinearity of the geometric constrains owing to the preservation of Gaussian curvature, we linearize those nonlinear constraints using Taylor expansion and eventually construct a sparse and over-determined linear system which is subsequently solved by a robust least-squares solution. By iteratively performing this procedure, the initial mesh is gradually and smoothly "dragged" to the given points and/or curves. The initial experimental data has shown some promising aspects of the proposed algorithm as a general quasi-developable surface interpolation tool.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4668342]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.192]]></doi>

<publicationId><![CDATA[4668342]]></publicationId>

<partnum><![CDATA[4668342]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4668342&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4668342]]></pdf>

</document>

<document>

<rank>706</rank>

<title><![CDATA[Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT]]></title>

<authors><![CDATA[Heinzl, C.;  Kastner, J.;  Groller, E.]]></authors>

<affiliations><![CDATA[Upper Austrian Univ. of Appl. Sci., Wels]]></affiliations>

<controlledterms>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image fusion]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[measurement]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Computer industry]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Density measurement]]></term>

<term><![CDATA[Energy resolution]]></term>

<term><![CDATA[Image fusion]]></term>

<term><![CDATA[Metrology]]></term>

<term><![CDATA[Noise reduction]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[X-ray imaging]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1520]]></spage>

<epage><![CDATA[1527]]></epage>

<abstract><![CDATA[This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376182]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70598]]></doi>

<publicationId><![CDATA[4376182]]></publicationId>

<partnum><![CDATA[4376182]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376182&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376182]]></pdf>

</document>

<document>

<rank>707</rank>

<title><![CDATA[Comparing 2D vector field visualization methods: a user study]]></title>

<authors><![CDATA[Laidlaw, D.H.;  Kirby, R.M.;  Jackson, C.D.;  Davidson, J.S.;  Miller, T.S.;  da Silva, M.;  Warren, W.H.;  Tarr, M.J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Brown Univ., USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analysis of variance]]></term>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Fluid flow]]></term>

<term><![CDATA[Pattern analysis]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Performance evaluation]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[59]]></spage>

<epage><![CDATA[70]]></epage>

<abstract><![CDATA[We present results from a user study that compared six visualization methods for two-dimensional vector data. Users performed three simple but representative tasks using visualizations from each method: 1) locating all critical points in an image, 2) identifying critical point types, and 3) advecting a particle. Visualization methods included two that used different spatial distributions of short arrow icons, two that used different distributions of integral curves, one that used wedges located to suggest flow lines, and line-integral convolution (LIC). Results show different strengths and weaknesses for each method. We found that users performed these tasks better with methods that: 1) showed the sign of vectors within the vector field, 2) visually represented integral curves, and 3) visually represented the locations of critical points. Expert user performance was not statistically different from nonexpert user performance. We used several methods to analyze the data including omnibus analysis of variance, pairwise t-tests, and graphical analysis using inferential confidence intervals. We concluded that using the inferential confidence intervals for displaying the overall pattern of results for each task measure and for performing subsequent pairwise comparisons of the condition means was the best method for analyzing the data in this study. These results provide quantitative support for some of the anecdotal evidence concerning visualization methods. The tasks and testing framework also provide a basis for comparing other visualization methods, for creating more effective methods and for defining additional tasks to further understand the tradeoffs among the methods. In the future, we also envision extending this work to more ambitious comparisons, such as evaluating two-dimensional vectors on two-dimensional surfaces embedded in three-dimensional space and defining analogous tasks for three-dimensional visualization methods.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1359732]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.4]]></doi>

<publicationId><![CDATA[1359732]]></publicationId>

<partnum><![CDATA[1359732]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359732&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359732]]></pdf>

</document>

<document>

<rank>708</rank>

<title><![CDATA[Parallel View-Dependent Level-of-Detail Control]]></title>

<authors><![CDATA[Liang Hu;  Sander, P.V.;  Hoppe, H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[718]]></spage>

<epage><![CDATA[728]]></epage>

<abstract><![CDATA[We present a scheme for view-dependent level-of-detail control that is implemented entirely on programmable graphics hardware. Our scheme selectively refines and coarsens an arbitrary triangle mesh at the granularity of individual vertices to create meshes that are highly adapted to dynamic view parameters. Such fine-grain control has previously been demonstrated using sequential CPU algorithms. However, these algorithms involve pointer-based structures with intricate dependencies that cannot be handled efficiently within the restricted framework of GPU parallelism. We show that by introducing new data structures and dependency rules, one can realize fine-grain progressive mesh updates as a sequence of parallel streaming passes over the mesh elements. A major design challenge is that the GPU processes stream elements in isolation. The mesh update algorithm has time complexity proportional to the selectively refined mesh, and moreover, can be amortized across several frames. The result is a single standard index buffer that can be used directly for rendering. The static data structure is remarkably compact, requiring only 57 percent more memory than an indexed triangle list. We demonstrate real-time exploration of complex models with normals and textures, as well as shadowing and semitransparent surface rendering applications that make direct use of the resulting dynamic index buffer.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5226629]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.101]]></doi>

<publicationId><![CDATA[5226629]]></publicationId>

<partnum><![CDATA[5226629]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5226629&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5226629]]></pdf>

</document>

<document>

<rank>709</rank>

<title><![CDATA[Integrality and Separability of Multitouch Interaction Techniques in 3D Manipulation Tasks]]></title>

<authors><![CDATA[Martinet, A.;  Casiez, G.;  Grisoni, L.]]></authors>

<affiliations><![CDATA[Batiment IRCICA, Villeneuve-d''Ascq, France]]></affiliations>

<controlledterms>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[three-dimensional displays]]></term>

<term><![CDATA[touch sensitive screens]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Jacobian matrices]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Taxonomy]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[369]]></spage>

<epage><![CDATA[380]]></epage>

<abstract><![CDATA[Multitouch displays represent a promising technology for the display and manipulation of data. While the manipulation of 2D data has been widely explored, 3D manipulation with multitouch displays remains largely unexplored. Based on an analysis of the integration and separation of degrees of freedom, we propose a taxonomy for 3D manipulation techniques with multitouch displays. Using that taxonomy, we introduce Depth-Separated Screen-Space (DS3), a new 3D manipulation technique based on the separation of translation and rotation. In a controlled experiment, we compared DS3 with Sticky Tools and Screen-Space. Results show that separating the control of translation and rotation significantly affects performance for 3D manipulation, with DS3 performing faster than the two other techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5963662]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.129]]></doi>

<publicationId><![CDATA[5963662]]></publicationId>

<partnum><![CDATA[5963662]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5963662&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963662]]></pdf>

</document>

<document>

<rank>710</rank>

<title><![CDATA[Metric-Driven RoSy Field Design and Remeshing]]></title>

<authors><![CDATA[Yu-Kun Lai;  Miao Jin;  Xuexiang Xie;  Ying He;  Palacios, J.;  Zhang, E.;  Shi-Min Hu;  Xianfeng Gu]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[software metrics]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[95]]></spage>

<epage><![CDATA[108]]></epage>

<abstract><![CDATA[Designing rotational symmetry fields on surfaces is an important task for a wide range of graphics applications. This work introduces a rigorous and practical approach for automatic N-RoSy field design on arbitrary surfaces with user-defined field topologies. The user has full control of the number, positions, and indexes of the singularities (as long as they are compatible with necessary global constraints), the turning numbers of the loops, and is able to edit the field interactively. We formulate N-RoSy field construction as designing a Riemannian metric such that the holonomy along any loop is compatible with the local symmetry of N-RoSy fields. We prove the compatibility condition using discrete parallel transport. The complexity of N-RoSy field design is caused by curvatures. In our work, we propose to simplify the Riemannian metric to make it flat almost everywhere. This approach greatly simplifies the process and improves the flexibility such that it can design N-RoSy fields with single singularity and mixed-RoSy fields. This approach can also be generalized to construct regular remeshing on surfaces. To demonstrate the effectiveness of our approach, we apply our design system to pen-and-ink sketching and geometry remeshing. Furthermore, based on our remeshing results with high global symmetry, we generate Celtic knots on surfaces directly.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4967582]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.59]]></doi>

<publicationId><![CDATA[4967582]]></publicationId>

<partnum><![CDATA[4967582]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4967582&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967582]]></pdf>

</document>

<document>

<rank>711</rank>

<title><![CDATA[About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering]]></title>

<authors><![CDATA[Lindemann, F.;  Ropinski, T.]]></authors>

<affiliations><![CDATA[Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Harmonic analysis]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1922]]></spage>

<epage><![CDATA[1931]]></epage>

<abstract><![CDATA[In this paper, we present a user study in which we have investigated the influence of seven state-of-the-art volumetric illumination models on the spatial perception of volume rendered images. Within the study, we have compared gradient-based shading with half angle slicing, directional occlusion shading, multidirectional occlusion shading, shadow volume propagation, spherical harmonic lighting as well as dynamic ambient occlusion. To evaluate these models, users had to solve three tasks relying on correct depth as well as size perception. Our motivation for these three tasks was to find relations between the used illumination model, user accuracy and the elapsed time. In an additional task, users had to subjectively judge the output of the tested models. After first reviewing the models and their features, we will introduce the individual tasks and discuss their results. We discovered statistically significant differences in the testing performance of the techniques. Based on these findings, we have analyzed the models and extracted those features which are possibly relevant for the improved spatial comprehension in a relational task. We believe that a combination of these distinctive features could pave the way for a novel illumination model, which would be optimized based on our findings.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064955]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.161]]></doi>

<publicationId><![CDATA[6064955]]></publicationId>

<partnum><![CDATA[6064955]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064955&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064955]]></pdf>

</document>

<document>

<rank>712</rank>

<title><![CDATA[Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees]]></title>

<authors><![CDATA[Tierny, J.;  Gyulassy, A.;  Simon, E.;  Pascucci, V.]]></authors>

<affiliations><![CDATA[Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Stress]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1177]]></spage>

<epage><![CDATA[1184]]></epage>

<abstract><![CDATA[This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf<sup>3</sup>. We introduce a procedure called "loop surgery" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290727]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.163]]></doi>

<publicationId><![CDATA[5290727]]></publicationId>

<partnum><![CDATA[5290727]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290727&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290727]]></pdf>

</document>

<document>

<rank>713</rank>

<title><![CDATA[A Spectral Analysis of Function Composition and its Implications for Sampling in Direct Volume Visualization]]></title>

<authors><![CDATA[Bergner, S.;  Moller, T.;  Weiskopf, D.;  Muraki, D.J.]]></authors>

<affiliations><![CDATA[GrUVi-Lab, Simon Fraser Univ., Burnaby, BC]]></affiliations>

<controlledterms>

<term><![CDATA[Fourier analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[signal sampling]]></term>

<term><![CDATA[spectral analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive signal processing]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Optical signal processing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Signal sampling]]></term>

<term><![CDATA[Spectral analysis]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1353]]></spage>

<epage><![CDATA[1360]]></epage>

<abstract><![CDATA[In this paper we investigate the effects of function composition in the form g(f(x)) = h(x) by means of a spectral analysis of h. We decompose the spectral description of h(x) into a scalar product of the spectral description of g(x) and a term that solely depends on f(x) and that is independent of g(x). We then use the method of stationary phase to derive the essential maximum frequency of g(f(x)) bounding the main portion of the energy of its spectrum. This limit is the product of the maximum frequency of g(x) and the maximum derivative of f(x). This leads to a proper sampling of the composition h of the two functions g and f. We apply our theoretical results to a fundamental open problem in volume rendering - the proper sampling of the rendering integral after the application of a transfer function. In particular, we demonstrate how the sampling criterion can be incorporated in adaptive ray integration, visualization with multi-dimensional transfer functions, and pre-integrated volume rendering]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015502]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.113]]></doi>

<publicationId><![CDATA[4015502]]></publicationId>

<partnum><![CDATA[4015502]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015502&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015502]]></pdf>

</document>

<document>

<rank>714</rank>

<title><![CDATA[Design and Evaluation of MagnetViz&amp;#x2014;A Graph Visualization Tool]]></title>

<authors><![CDATA[Spritzer, A.S.;  Dal Sasso Freitas, C.M.]]></authors>

<affiliations><![CDATA[Univ. Fed. do Rio Grande do Sul (UFRGS), Porto Alegre, Brazil]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[directed graphs]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Color]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Magnetic separation]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[822]]></spage>

<epage><![CDATA[835]]></epage>

<abstract><![CDATA[MagnetViz was designed for the interactive manipulation of force-directed graph layouts, allowing the user to obtain visualizations based on the graph topology and/or the attributes of its nodes and edges. The user can introduce virtual magnets anywhere in the graph and these can be set to attract nodes and edges that fulfill user-defined criteria. When a magnet is placed, the force-directed nature of the layout forces it to reorganize itself in order to reflect the changes in the balance of forces, consequently changing the visualization into one that is more semantically relevant to the user. This paper describes MagnetViz's concepts, illustrating them with examples and a case study based on a usage scenario. We also describe how the MagnetViz has evolved since its original version and present the evaluation of its latest version. This evaluation consists of two user studies aiming at assessing generated layout quality and how well the concepts can be apprehended and employed, and a task taxonomy assessment focusing on establishing which graph visualization tasks the technique is able to handle.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5928333]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.106]]></doi>

<publicationId><![CDATA[5928333]]></publicationId>

<partnum><![CDATA[5928333]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5928333&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928333]]></pdf>

</document>

<document>

<rank>715</rank>

<title><![CDATA[ParaGlide: Interactive Parameter Space Partitioning for Computer Simulations]]></title>

<authors><![CDATA[Bergner, S.;  Sedlmair, M.;  Moller, T.;  Abdolyousefi, S.N.;  Saad, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[sampling methods]]></term>

<term><![CDATA[sensitivity]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Animals]]></term>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Mathematical model]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1499]]></spage>

<epage><![CDATA[1512]]></epage>

<abstract><![CDATA[In this paper, we introduce ParaGlide, a visualization system designed for interactive exploration of parameter spaces of multidimensional simulation models. To get the right parameter configuration, model developers frequently have to go back and forth between setting input parameters and qualitatively judging the outcomes of their model. Current state-of-the-art tools and practices, however, fail to provide a systematic way of exploring these parameter spaces, making informed decisions about parameter configurations a tedious and workload-intensive task. ParaGlide endeavors to overcome this shortcoming by guiding data generation using a region-based user interface for parameter sampling and then dividing the model's input parameter space into partitions that represent distinct output behavior. In particular, we found that parameter space partitioning can help model developers to better understand qualitative differences among possibly high-dimensional model outputs. Further, it provides information on parameter sensitivity and facilitates comparison of models. We developed ParaGlide in close collaboration with experts from three different domains, who all were involved in developing new models for their domain. We first analyzed current practices of six domain experts and derived a set of tasks and design requirements, then engaged in a user-centered design process, and finally conducted three longitudinal in-depth case studies underlining the usefulness of our approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6472235]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.61]]></doi>

<publicationId><![CDATA[6472235]]></publicationId>

<partnum><![CDATA[6472235]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6472235&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6472235]]></pdf>

</document>

<document>

<rank>716</rank>

<title><![CDATA[Stable Feature Flow Fields]]></title>

<authors><![CDATA[Weinkauf, T.;  Theisel, H.;  Van Gelder, A.;  Pang, A.]]></authors>

<affiliations><![CDATA[Vision, Learning & Graphics Group, New York Univ., New York, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bifurcation]]></term>

<term><![CDATA[Computer errors]]></term>

<term><![CDATA[Concrete]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Error correction]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Field-flow fractionation]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[770]]></spage>

<epage><![CDATA[780]]></epage>

<abstract><![CDATA[Feature Flow Fields are a well-accepted approach for extracting and tracking features. In particular, they are often used to track critical points in time-dependent vector fields and to extract and track vortex core lines. The general idea is to extract the feature or its temporal evolution using a stream line integration in a derived vector field-the so-called Feature Flow Field (FFF). Hence, the desired feature line is a stream line of the FFF. As we will carefully analyze in this paper, the stream lines around this feature line may diverge from it. This creates an unstable situation: if the integration moves slightly off the feature line due to numerical errors, then it will be captured by the diverging neighborhood and carried away from the real feature line. The goal of this paper is to define a new FFF with the guarantee that the neighborhood of a feature line has always converging behavior. This way, we have an automatic correction of numerical errors: if the integration moves slightly off the feature line, it automatically moves back to it during the ongoing integration. This yields results which are an order of magnitude more accurate than the results from previous schemes. We present new stable FFF formulations for the main applications of tracking critical points and solving the Parallel Vectors operator. We apply our method to a number of data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5487517]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.93]]></doi>

<publicationId><![CDATA[5487517]]></publicationId>

<partnum><![CDATA[5487517]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5487517&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487517]]></pdf>

</document>

<document>

<rank>717</rank>

<title><![CDATA[Interactive Tensor Field Design and Visualization on Surfaces]]></title>

<authors><![CDATA[Zhang, E.;  Hays, J.;  Turk, G.]]></authors>

<affiliations><![CDATA[Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR]]></affiliations>

<controlledterms>

<term><![CDATA[CAD]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[surface fitting]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Image converters]]></term>

<term><![CDATA[Region 1]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Visual effects]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[94]]></spage>

<epage><![CDATA[107]]></epage>

<abstract><![CDATA[Designing tensor fields in the plane and on surfaces is a necessary task in many graphics applications, such as painterly rendering, pen-and-ink sketching of smooth surfaces, and anisotropic remeshing. In this article, we present an interactive design system that allows a user to create a wide variety of symmetric tensor fields over 3D surfaces either from scratch or by modifying a meaningful input tensor field such as the curvature tensor. Our system converts each user specification into a basis tensor field and combines them with the input field to make an initial tensor field. However, such a field often contains unwanted degenerate points which cannot always be eliminated due to topological constraints of the underlying surface. To reduce the artifacts caused by these degenerate points, our system allows the user to move a degenerate point or to cancel a pair of degenerate points that have opposite tensor indices. These operations provide control over the number and location of the degenerate points in the field. We observe that a tensor field can be locally converted into a vector field so that there is a one-to-one correspondence between the set of degenerate points in the tensor field and the set of singularities in the vector field. This conversion allows us to effectively perform degenerate point pair cancellation and movement by using similar operations for vector fields. In addition, we adapt the image-based flow visualization technique to tensor fields, therefore allowing interactive display of tensor fields on surfaces. We demonstrate the capabilities of our tensor field design system with painterly rendering, pen-and-ink sketching of surfaces, and anisotropic remeshing]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015401]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.16]]></doi>

<publicationId><![CDATA[4015401]]></publicationId>

<partnum><![CDATA[4015401]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015401&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015401]]></pdf>

</document>

<document>

<rank>718</rank>

<title><![CDATA[Moving Least-Squares Reconstruction of Large Models with GPUs]]></title>

<authors><![CDATA[Merry, B.;  Gain, J.;  Marais, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Cape Town, Cape Town, South Africa]]></affiliations>

<controlledterms>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[least mean squares methods]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Arrays]]></term>

<term><![CDATA[Graphics processing units]]></term>

<term><![CDATA[Indexes]]></term>

<term><![CDATA[Octrees]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[249]]></spage>

<epage><![CDATA[261]]></epage>

<abstract><![CDATA[Modern laser range scanning campaigns produce extremely large point clouds, and reconstructing a triangulated surface thus requires both out-of-core techniques and significant computational power. We present a GPU-accelerated implementation of the moving least-squares (MLS) surface reconstruction technique. We believe this to be the first GPU-accelerated, out-of-core implementation of surface reconstruction that is suitable for laser range-scanned data. While several previous out-of-core approaches use a sweep-plane approach, we subdivide the space into cubic regions that are processed independently. This independence allows the algorithm to be parallelized using multiple GPUs, either in a single machine or a cluster. It also allows data sets with billions of point samples to be processed on a standard desktop PC. We show that our implementation is an order of magnitude faster than a CPU-based implementation when using a single GPU, and scales well to 8 GPUs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6589586]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.118]]></doi>

<publicationId><![CDATA[6589586]]></publicationId>

<partnum><![CDATA[6589586]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6589586&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6589586]]></pdf>

</document>

<document>

<rank>719</rank>

<title><![CDATA[Pose-Oblivious Shape Signature]]></title>

<authors><![CDATA[Gal, R.;  Shamir, A.;  Cohen-Or, D.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci., Tel-Aviv Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[content-based retrieval]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Databases]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Indexing]]></term>

<term><![CDATA[Level measurement]]></term>

<term><![CDATA[Radio access networks]]></term>

<term><![CDATA[Search engines]]></term>

<term><![CDATA[Shape measurement]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[261]]></spage>

<epage><![CDATA[271]]></epage>

<abstract><![CDATA[A 3D shape signature is a compact representation for some essence of a shape. Shape signatures are commonly utilized as a fast indexing mechanism for shape retrieval. Effective shape signatures capture some global geometric properties which are scale, translation, and rotation invariant. In this paper, we introduce an effective shape signature which is also pose-oblivious. This means that the signature is also insensitive to transformations which change the pose of a 3D shape such as skeletal articulations. Although some topology-based matching methods can be considered pose-oblivious as well, our new signature retains the simplicity and speed of signature indexing. Moreover, contrary to topology-based methods, the new signature is also insensitive to the topology change of the shape, allowing us to match similar shapes with different genus. Our shape signature is a 2D histogram which is a combination of the distribution of two scalar functions defined on the boundary surface of the 3D shape. The first is a definition of a novel function called the local-diameter function. This function measures the diameter of the 3D shape in the neighborhood of each vertex. The histogram of this function is an informative measure of the shape which is insensitive to pose changes. The second is the centricity function that measures the average geodesic distance from one vertex to all other vertices on the mesh. We evaluate and compare a number of methods for measuring the similarity between two signatures, and demonstrate the effectiveness of our pose-oblivious shape signature within a 3D search engine application for different databases containing hundreds of models]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4069235]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.45]]></doi>

<publicationId><![CDATA[4069235]]></publicationId>

<partnum><![CDATA[4069235]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4069235&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069235]]></pdf>

</document>

<document>

<rank>720</rank>

<title><![CDATA[Texture-based feature tracking for effective time-varying data visualization]]></title>

<authors><![CDATA[Caban, J.J.;  Joshi, A.;  Rheingans, P.]]></authors>

<affiliations><![CDATA[Univ. of Maryland Baltimore County, Baltimore]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[tracking]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Fluid dynamics]]></term>

<term><![CDATA[Hurricanes]]></term>

<term><![CDATA[IEEE members]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Tracking]]></term>

<term><![CDATA[Weather forecasting]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1472]]></spage>

<epage><![CDATA[1479]]></epage>

<abstract><![CDATA[Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376176]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70599]]></doi>

<publicationId><![CDATA[4376176]]></publicationId>

<partnum><![CDATA[4376176]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376176&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376176]]></pdf>

</document>

<document>

<rank>721</rank>

<title><![CDATA[Visualizing unstructured flow data using dual stream functions]]></title>

<authors><![CDATA[Knight, D.;  Mallinson, G.]]></authors>

<affiliations><![CDATA[Numerical Algorithms Group Ltd., Oxford, UK]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diagrams]]></term>

<term><![CDATA[differential equations]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[integration]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[physics computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Differential equations]]></term>

<term><![CDATA[Fluid flow]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Mechanical engineering]]></term>

<term><![CDATA[Particle tracking]]></term>

<term><![CDATA[Position measurement]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[355]]></spage>

<epage><![CDATA[363]]></epage>

<abstract><![CDATA[One of the most important ways of visualizing fluid flow is the construction of streamlines, which are lines that are everywhere tangential to the local fluid velocity. Stream surfaces are defined as surfaces through which no fluid penetrates. Streamlines can therefore be computed from the intersection of two nonparallel stream surfaces. This paper presents new algorithms for the computation of dual stream functions from computational fluid dynamics data that is defined on an unstructured tetrahedral mesh. These algorithms are compared with standard numerical routines for computing streamlines, and are shown to be quicker and more accurate than techniques involving numerical integration along the streamline]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[556503]]></arnumber>

<doi><![CDATA[10.1109/2945.556503]]></doi>

<publicationId><![CDATA[556503]]></publicationId>

<partnum><![CDATA[556503]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=556503&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556503]]></pdf>

</document>

<document>

<rank>722</rank>

<title><![CDATA[Call for Participation VIS 2004]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[242]]></spage>

<epage><![CDATA[242]]></epage>

<abstract><![CDATA[Provides notice of upcoming conference events of interest to practitioners and researchers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1304990]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1304990]]></doi>

<publicationId><![CDATA[1304990]]></publicationId>

<partnum><![CDATA[1304990]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1304990&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1304990]]></pdf>

</document>

<document>

<rank>723</rank>

<title><![CDATA[Lagrangian-Eulerian advection of noise and dye textures for unsteady flow visualization]]></title>

<authors><![CDATA[Jobard, B.;  Erlebacher, G.;  Hussaini, M.Y.]]></authors>

<affiliations><![CDATA[Swiss Centerfor Sci. Comput., Mano, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[convection]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[dyes]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[noise]]></term>

<term><![CDATA[spatial data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Capacitive sensors]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Facial animation]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Lagrangian functions]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[211]]></spage>

<epage><![CDATA[222]]></epage>

<abstract><![CDATA[A new hybrid scheme, called Lagrangian-Eulerian advection (LEA), that combines the advantages of the Eulerian and Lagrangian frameworks is applied to the visualization of dense representations of time-dependent vector fields. The algorithm encodes the particles into a texture that is then advected. By treating every particle equally, we can handle texture advection and dye advection within a single framework. High temporal and spatial correlation is achieved through the blending of successive frames. A combination of particle and dye advection enables the simultaneous visualization of streamlines, particle paths and streak-lines. We demonstrate various experimental techniques on several physical flow fields. The simplicity of both the resulting data structures and the implementation suggest that LEA could become a useful component of any scientific visualization toolkit concerned with the display of unsteady flows.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1021575]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2002.1021575]]></doi>

<publicationId><![CDATA[1021575]]></publicationId>

<partnum><![CDATA[1021575]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1021575&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1021575]]></pdf>

</document>

<document>

<rank>724</rank>

<title><![CDATA[A Modular Degree-of-Interest Specification for the Visual Analysis of Large Dynamic Networks]]></title>

<authors><![CDATA[Abello, J.;  Hadlak, S.;  Schumann, H.;  Schulz, H.-J.]]></authors>

<affiliations><![CDATA[Rutgers Univ., Piscataway, NJ, USA]]></affiliations>

<controlledterms>

<term><![CDATA[formal specification]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Radiation detectors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[337]]></spage>

<epage><![CDATA[350]]></epage>

<abstract><![CDATA[Large dynamic networks are targets of analysis in many fields. Tracking temporal changes at scale in these networks is challenging due in part to the fact that small changes can be missed or drowned-out by the rest of the network. For static networks, current approaches allow the identification of specific network elements within their context. However, in the case of dynamic networks, the user is left alone with finding salient local network elements and tracking them over time. In this work, we introduce a modular DoI specification to flexibly define what salient changes are and to assign them a measure of their importance in a time-varying setting. The specification takes into account neighborhood structure information, numerical attributes of nodes/edges, and their temporal evolution. A tailored visualization of the DoI specification complements our approach. Alongside a traditional node-link view of the dynamic network, it serves as an interface for the interactive definition of a DoI function. By using it to successively refine and investigate the captured details, it supports the analysis of dynamic networks from an initial view until pinpointing a user's analysis goal. We report on applying our approach to scientific coauthorship networks and give concrete results for the DBLP data set.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6574858]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.109]]></doi>

<publicationId><![CDATA[6574858]]></publicationId>

<partnum><![CDATA[6574858]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6574858&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574858]]></pdf>

</document>

<document>

<rank>725</rank>

<title><![CDATA[Visual Readability Analysis: How to Make Your Writings Easier to Read]]></title>

<authors><![CDATA[Oelke, D.;  Spretke, D.;  Stoffel, A.;  Keim, D.A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Univ. of Konstanz, Konstanz, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Length measurement]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Training data]]></term>

<term><![CDATA[Visual analytics]]></term>

<term><![CDATA[Vocabulary]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[662]]></spage>

<epage><![CDATA[674]]></epage>

<abstract><![CDATA[We present a tool that is specifically designed to support a writer in revising a draft version of a document. In addition to showing which paragraphs and sentences are difficult to read and understand, we assist the reader in understanding why this is the case. This requires features that are expressive predictors of readability, and are also semantically understandable. In the first part of the paper, we, therefore, discuss a semiautomatic feature selection approach that is used to choose appropriate measures from a collection of 141 candidate readability features. In the second part, we present the visual analysis tool VisRA, which allows the user to analyze the feature values across the text and within single sentences. Users can choose between different visual representations accounting for differences in the size of the documents and the availability of information about the physical and logical layout of the documents. We put special emphasis on providing as much transparency as possible to ensure that the user can purposefully improve the readability of a sentence. Several case studies are presented that show the wide range of applicability of our tool. Furthermore, an in-depth evaluation assesses the quality of the measure and investigates how well users do in revising a text with the help of the tool.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6051432]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.266]]></doi>

<publicationId><![CDATA[6051432]]></publicationId>

<partnum><![CDATA[6051432]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6051432&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051432]]></pdf>

</document>

<document>

<rank>726</rank>

<title><![CDATA[Intuitive Exploration of Volumetric Data Using Dynamic Galleries]]></title>

<authors><![CDATA[Jonsson, D.;  Falk, M.;  Ynnerman, A.]]></authors>

<affiliations><![CDATA[Linkoping Univ., Linkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[museums]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[896]]></spage>

<epage><![CDATA[905]]></epage>

<abstract><![CDATA[In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192682]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467294]]></doi>

<publicationId><![CDATA[7192682]]></publicationId>

<partnum><![CDATA[7192682]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192682&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192682]]></pdf>

</document>

<document>

<rank>727</rank>

<title><![CDATA[CGLX: A Scalable, High-Performance Visualization Framework for Networked Display Environments]]></title>

<authors><![CDATA[Doerr, K.-U.;  Kuester, F.]]></authors>

<affiliations><![CDATA[California Inst. for Telecommun. & Inf. Technol., Univ. of California, San Diego, La Jolla, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Engines]]></term>

<term><![CDATA[Graphical user interfaces]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Parallel programming]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[320]]></spage>

<epage><![CDATA[332]]></epage>

<abstract><![CDATA[The Cross Platform Cluster Graphics Library (CGLX) is a flexible and transparent OpenGL-based graphics framework for distributed, high-performance visualization systems. CGLX allows OpenGL based applications to utilize massively scalable visualization clusters such as multiprojector or high-resolution tiled display environments and to maximize the achievable performance and resolution. The framework features a programming interface for hardware-accelerated rendering of OpenGL applications on visualization clusters, mimicking a GLUT-like (OpenGL-Utility-Toolkit) interface to enable smooth translation of single-node applications to distributed parallel rendering applications. CGLX provides a unified, scalable, distributed OpenGL context to the user by intercepting and manipulating certain OpenGL directives. CGLX's interception mechanism, in combination with the core functionality for users to register callbacks, enables this framework to manage a visualization grid without additional implementation requirements to the user. Although CGLX grants access to its core engine, allowing users to change its default behavior, general development can occur in the context of a standalone desktop. The framework provides an easy-to-use graphical user interface (GUI) and tools to test, setup, and configure a visualization cluster. This paper describes CGLX's architecture, tools, and systems components. We present performance and scalability tests with different types of applications, and we compare the results with a Chromium-based approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5453361]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.59]]></doi>

<publicationId><![CDATA[5453361]]></publicationId>

<partnum><![CDATA[5453361]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5453361&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453361]]></pdf>

</document>

<document>

<rank>728</rank>

<title><![CDATA[A topological approach to simplification of three-dimensional scalar functions]]></title>

<authors><![CDATA[Gyulassy, A.;  Vijay Natarajan;  Pascucci, V.;  Bremer, P.-T.;  Hamann, B.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., California Univ., Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[combinatorial mathematics]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[474]]></spage>

<epage><![CDATA[484]]></epage>

<abstract><![CDATA[This paper describes an efficient combinatorial method for simplification of topological features in a 3D scalar function. The Morse-Smale complex, which provides a succinct representation of a function's associated gradient flow field, is used to identify topological features and their significance. The simplification process, guided by the Morse-Smale complex, proceeds by repeatedly applying two atomic operations that each remove a pair of critical points from the complex. Efficient storage of the complex results in execution of these atomic operations at interactive rates. Visualization of the simplified complex shows that the simplification preserves significant topological features while removing small features and noise.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634313]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.57]]></doi>

<publicationId><![CDATA[1634313]]></publicationId>

<partnum><![CDATA[1634313]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634313&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634313]]></pdf>

</document>

<document>

<rank>729</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6238455]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.156]]></doi>

<publicationId><![CDATA[6238455]]></publicationId>

<partnum><![CDATA[6238455]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6238455&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6238455]]></pdf>

</document>

<document>

<rank>730</rank>

<title><![CDATA[Garuda: A Scalable Tiled Display Wall Using Commodity PCs]]></title>

<authors><![CDATA[Nirnimesh;  Harish, P.;  Narayanan, P.J.]]></authors>

<affiliations><![CDATA[Int. Inst. of Inf. Technol., Hyderabad]]></affiliations>

<controlledterms>

<term><![CDATA[client-server systems]]></term>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[open systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Network servers]]></term>

<term><![CDATA[Personal communication networks]]></term>

<term><![CDATA[Scalability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[864]]></spage>

<epage><![CDATA[877]]></epage>

<abstract><![CDATA[Cluster-based tiled display walls can provide cost-effective and scalable displays with high resolution and a large display area. The software to drive them needs to scale too if arbitrarily large displays are to be built. Chromium is a popular software API used to construct such displays. Chromium transparently renders any OpenGL application to a tiled display by partitioning and sending individual OpenGL primitives to each client per frame. Visualization applications often deal with massive geometric data with millions of primitives. Transmitting them every frame results in huge network requirements that adversely affect the scalability of the system. In this paper, we present Garuda, a client-server-based display wall framework that uses off-the-shelf hardware and a standard network. Garuda is scalable to large tile configurations and massive environments. It can transparently render any application built using the open scene graph (OSG) API to a tiled display without any modification by the user. The Garuda server uses an object-based scene structure represented using a scene graph. The server determines the objects visible to each display tile using a novel adaptive algorithm that culls the scene graph to a hierarchy of frustums. Required parts of the scene graph are transmitted to the clients, which cache them to exploit the interframe redundancy. A multicast-based protocol is used to transmit the geometry to exploit the spatial redundancy present in tiled display systems. A geometry push philosophy from the server helps keep the clients in sync with one another. Neither the server nor a client needs to render the entire scene, making the system suitable for interactive rendering of massive models. Transparent rendering is achieved by intercepting the cull, draw, and swap functions of OSG and replacing them with our own. We demonstrate the performance and scalability of the Garuda system for different configurations of display wall. We also show that the serv- r and network loads grow sublinearly with the increase in the number of tiles, which makes our scheme suitable to construct very large displays.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4276073]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1049]]></doi>

<publicationId><![CDATA[4276073]]></publicationId>

<partnum><![CDATA[4276073]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4276073&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4276073]]></pdf>

</document>

<document>

<rank>731</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4384592]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.6]]></doi>

<publicationId><![CDATA[4384592]]></publicationId>

<partnum><![CDATA[4384592]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4384592&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4384592]]></pdf>

</document>

<document>

<rank>732</rank>

<title><![CDATA[Interactive View-Dependent Rendering over Networks]]></title>

<authors><![CDATA[Zhi Zheng;  Prakash, E.;  Chan, T.K.Y.]]></authors>

<affiliations><![CDATA[Nanyang Technol. Univ., Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[client-server systems]]></term>

<term><![CDATA[computer network management]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[synchronisation]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[576]]></spage>

<epage><![CDATA[589]]></epage>

<abstract><![CDATA[For a client-server-based view-dependent rendering system, the overhead of view-dependent rendering and the network latency are major obstacles in achieving interactivity. In this paper, we first present a multiresolution hierarchy traversal management strategy to control the overhead of view-dependent rendering for low-capacity clients. Then, we propose a predictive parallel strategy to overcome the network latency for client-server-based view-dependent multiresolution rendering systems. Our solution is to make the client process and the server process run in parallel using the rendering time to cover the network latency. For networks with long round-trip times, we manage to overlap the network latency for one frame with the rendering time for multiple frames. View parameter prediction is incorporated to make the parallelism of the client and the server feasible. In order to maintain an acceptable view-dependent rendering quality in the network environment, we develop a synchronization mechanism and a dynamic adjustment mechanism to handle the transient network slowdowns and the changes in the network condition. Our experimental results, in comparison with the sequential method, show that our predictive parallel approach can achieve an interactive frame rate while keeping an acceptable rendering quality for large triangle models over networks with relatively long round-trip times.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4384480]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70626]]></doi>

<publicationId><![CDATA[4384480]]></publicationId>

<partnum><![CDATA[4384480]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4384480&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4384480]]></pdf>

</document>

<document>

<rank>733</rank>

<title><![CDATA[Optimized Synthesis of Art Patterns and Layered Textures]]></title>

<authors><![CDATA[Ruobing Wu;  Wenping Wang;  Yizhou Yu]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Hong Kong, Hong Kong, China]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[set theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Digital art]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[436]]></spage>

<epage><![CDATA[446]]></epage>

<abstract><![CDATA[Line drawings and digital arts appear everywhere, from simple icons and logos to cartoons, maps, and illustrations. We define art patterns as the subset of line drawings and digital arts that are comprised of repeated elements. There exist textures that share characteristics with art patterns. Examples of such textures include piled discrete elements with curved contours. Inspired by recent success of exemplar-based texture synthesis, in this paper, we focus on synthesizing art patterns and textures with curvilinear features from exemplars, which we cast as a global optimization problem. Our energy function for this problem measures both the appearance similarity of color patterns and shape similarity of curvilinear features between an input exemplar and a synthesized image. We develop an overall expectation-maximization-style algorithm for minimizing this energy function. The shape similarity part of the energy is minimized through an innovative application of the level set method. We further generalize our energy function and optimization algorithm to multilayer pattern and texture synthesis. Our generalized optimization can effectively handle multiple layers and synthesize valid instances of interaction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6579613]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.113]]></doi>

<publicationId><![CDATA[6579613]]></publicationId>

<partnum><![CDATA[6579613]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6579613&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6579613]]></pdf>

</document>

<document>

<rank>734</rank>

<title><![CDATA[Point-Based Visualization for Large Hierarchies]]></title>

<authors><![CDATA[Schulz, H.;  Hadlak, S.;  Schumann, H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Graphics, Univ. of Rostock, Rostock, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Web sites]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[598]]></spage>

<epage><![CDATA[611]]></epage>

<abstract><![CDATA[Space-filling layout techniques for tree representations are frequently used when the available screen space is small or the data set is large. In this paper, we propose an efficient approach to space-filling tree representations that uses mechanisms from the point-based rendering paradigm. We present helpful interaction techniques and visual cues that tie in with our layout. Additionally, we relate this new layout approach to common layout mechanisms and evaluate the new layout along the lines of a numerical evaluation using the measures of the Ink-Paper Ratio and overplotted%, and in a preliminary user study. The flexibility of the general approach is illustrated by several enhancements of the basic layout, as well as its usage within the context of two software frameworks from different application fields.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5644519]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.89]]></doi>

<publicationId><![CDATA[5644519]]></publicationId>

<partnum><![CDATA[5644519]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5644519&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5644519]]></pdf>

</document>

<document>

<rank>735</rank>

<title><![CDATA[Editor's Note]]></title>

<authors><![CDATA[Ebert, D.S.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[417]]></spage>

<epage><![CDATA[418]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634307]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.68]]></doi>

<publicationId><![CDATA[1634307]]></publicationId>

<partnum><![CDATA[1634307]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634307&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634307]]></pdf>

</document>

<document>

<rank>736</rank>

<title><![CDATA[Learning Layouts for Single-PageGraphic Designs]]></title>

<authors><![CDATA[O'Donovan, P.;  Agarwala, A.;  Hertzmann, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Toronto, Toronto, ON, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[optimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Predictive models]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1200]]></spage>

<epage><![CDATA[1213]]></epage>

<abstract><![CDATA[This paper presents an approach for automatically creating graphic design layouts using a new energy-based model derived from design principles. The model includes several new algorithms for analyzing graphic designs, including the prediction of perceived importance, alignment detection, and hierarchical segmentation. Given the model, we use optimization to synthesize new layouts for a variety of single-page graphic designs. Model parameters are learned with Nonlinear Inverse Optimization (NIO) from a small number of example layouts. To demonstrate our approach, we show results for applications including generating design layouts in various styles, retargeting designs to new sizes, and improving existing designs. We also compare our automatic results with designs created using crowdsourcing and show that our approach performs slightly better than novice designers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6777138]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.48]]></doi>

<publicationId><![CDATA[6777138]]></publicationId>

<partnum><![CDATA[6777138]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777138&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777138]]></pdf>

</document>

<document>

<rank>737</rank>

<title><![CDATA[The Effect of Colour and Transparency on the Perception of Overlaid Grids]]></title>

<authors><![CDATA[Bartram, L.;  Cheung, B.;  Stone, M.C.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Image color analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1942]]></spage>

<epage><![CDATA[1948]]></epage>

<abstract><![CDATA[Overlaid reference elements need to be sufficiently visible to effectively relate to the underlying information, but not so obtrusive that they clutter the presentation. We seek to create guidelines for presenting such structures through experimental studies to define boundary conditions for visual intrusiveness. We base our work on the practice of designers, who use transparency to integrate overlaid grids with their underlying imagery. Previous work discovered a useful range of alpha values for black or white grids overlayed on scatterplot images rendered in shades of gray over gray backgrounds of different lightness values. This work compares black grids to blue and red ones on different image types of scatterplots and maps. We expected that the coloured grids over grayscale images would be more visually salient than black ones, resulting in lower alpha values. Instead, we found that there was no significant difference between the boundaries set for red and black grids, but that the boundaries for blue grids were set consistently higher (more opaque). As in our previous study, alpha values are affected by image density rather than image type, and are consistently lower than many default settings. These results have implications for the design of subtle reference structures.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064957]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.242]]></doi>

<publicationId><![CDATA[6064957]]></publicationId>

<partnum><![CDATA[6064957]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064957&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064957]]></pdf>

</document>

<document>

<rank>738</rank>

<title><![CDATA[Illustration-Inspired Depth Enhanced Volumetric Medical Visualization]]></title>

<authors><![CDATA[Svakhine, N.A.;  Ebert, D.S.;  Andrews, W.M.]]></authors>

<affiliations><![CDATA[Adobe Syst. Inc., San Jose, CA]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image enhancement]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anatomical structure]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Eyes]]></term>

<term><![CDATA[Focusing]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Manuals]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[77]]></spage>

<epage><![CDATA[86]]></epage>

<abstract><![CDATA[Volume illustration can be used to provide insight into source data from CT/MRI scanners in much the same way as medical illustration depicts the important details of anatomical structures. As such, proven techniques used in medical illustration should be transferable to volume illustration, providing scientists with new tools to visualize their data. In recent years, a number of techniques have been developed to enhance the rendering pipeline and create illustrative effects similar to the ones found in medical textbooks and surgery manuals. Such effects usually highlight important features of the subject while subjugating its context and providing depth cues for correct perception. Inspired by traditional visual and line-drawing techniques found in medical illustration, we have developed a collection of fast algorithms for more effective emphasis/de-emphasis of data as well as conveyance of spatial relationships. Our techniques utilize effective outlining techniques and selective depth enhancement to provide perceptual cues of object importance as well as spatial relationships in volumetric datasets. Moreover, we have used illustration principles to effectively combine and adapt basic techniques so that they work together to provide consistent visual information and a uniform style.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4479459]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.56]]></doi>

<publicationId><![CDATA[4479459]]></publicationId>

<partnum><![CDATA[4479459]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4479459&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479459]]></pdf>

</document>

<document>

<rank>739</rank>

<title><![CDATA[An Information-Aware Framework for Exploring Multivariate Data Sets]]></title>

<authors><![CDATA[Biswas, A.;  Dutta, S.;  Han-Wei Shen;  Woodring, J.]]></authors>

<affiliations><![CDATA[Gravity Group, Ohio State Univ., Columbus, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data models]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[entropy]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Entropy]]></term>

<term><![CDATA[Information technology]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Mutual information]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2683]]></spage>

<epage><![CDATA[2692]]></epage>

<abstract><![CDATA[Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634187]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.133]]></doi>

<publicationId><![CDATA[6634187]]></publicationId>

<partnum><![CDATA[6634187]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634187&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634187]]></pdf>

</document>

<document>

<rank>740</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6200793]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.125]]></doi>

<publicationId><![CDATA[6200793]]></publicationId>

<partnum><![CDATA[6200793]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6200793&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200793]]></pdf>

</document>

<document>

<rank>741</rank>

<title><![CDATA[A phase field model for continuous clustering on vector fields]]></title>

<authors><![CDATA[Garcke, H.;  Preusser, T.;  Rumpf, M.;  Telea, A.;  Weikard, U.;  van Wijk, J.J.]]></authors>

<affiliations><![CDATA[Inst. for Appl. Math., Bonn Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diffusion]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[flow separation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image thinning]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[phase separation]]></term>

<term><![CDATA[shear flow]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Density functional theory]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Shape measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[230]]></spage>

<epage><![CDATA[241]]></epage>

<abstract><![CDATA[A new method for the simplification of flow fields is presented. It is based on continuous clustering. A well-known physical clustering model, the Cahn-Hilliard (1958) model, which describes phase separation, is modified to reflect the properties of the data to be visualized. Clusters are defined implicitly as connected components of the positivity set of a density function. An evolution equation for this function is obtained as a suitable gradient flow of an underlying anisotropic energy functional, where time serves as the scale parameter. The evolution is characterized by a successive coarsening of patterns, during which the underlying simulation data specifies preferable pattern boundaries. We introduce specific physical quantities in the simulation to control the shape, orientation and distribution of the clusters as a function of the underlying flow field. In addition, the model is expanded, involving elastic effects. In the early stages of the evolution, a shear-layer-type representation of the flow field can thereby be generated, whereas, for later stages, the distribution of clusters can be influenced. Furthermore, we incorporate upwind ideas to give the clusters an oriented drop-shaped appearance. We discuss the applicability of this new type of approach mainly for flow fields, where the cluster energy penalizes cross-streamline boundaries. However, the method also carries provisions for other fields as well. The clusters can be displayed directly as a flow texture. Alternatively, the clusters can be visualized by iconic representations, which are positioned by using a skeletonization algorithm]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[942691]]></arnumber>

<doi><![CDATA[10.1109/2945.942691]]></doi>

<publicationId><![CDATA[942691]]></publicationId>

<partnum><![CDATA[942691]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=942691&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=942691]]></pdf>

</document>

<document>

<rank>742</rank>

<title><![CDATA[Sample-Based Cameras for Feed Forward Reflection Rendering]]></title>

<authors><![CDATA[Popescu, V.;  Sacks, E.;  Mei, C.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[reflection]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Feeds]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1590]]></spage>

<epage><![CDATA[1600]]></epage>

<abstract><![CDATA[This paper presents sample-based cameras for rendering high quality reflections on convex reflectors at interactive rates. The method supports change of view, moving objects and reflectors, higher order reflections, view-dependent lighting of reflected objects, and reflector surface properties. In order to render reflections with the feed forward graphics pipeline, one has to project reflected vertices. A sample-based camera is a collection of BSP trees of pinhole cameras that jointly approximate the projection function. It is constructed from the reflected rays defined by the desired view and the scene reflectors. A scene point is projected by invoking only the cameras that contain it in their frustums. Reflections are rendered by projecting the scene geometry and then rasterizing in hardware]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1703378]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.103]]></doi>

<publicationId><![CDATA[1703378]]></publicationId>

<partnum><![CDATA[1703378]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1703378&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703378]]></pdf>

</document>

<document>

<rank>743</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1407868]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.41]]></doi>

<publicationId><![CDATA[1407868]]></publicationId>

<partnum><![CDATA[1407868]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1407868&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407868]]></pdf>

</document>

<document>

<rank>744</rank>

<title><![CDATA[An Overview of 3D Software Visualization]]></title>

<authors><![CDATA[Teyseyre, A.R.;  Campo, M.R.]]></authors>

<affiliations><![CDATA[Fac. de Cienc. Exactas, Univ. Nac. del Centre de la Provincia de Buenos Aires, Tandil]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human computer interaction]]></term>

<term><![CDATA[program visualisation]]></term>

<term><![CDATA[reverse engineering]]></term>

<term><![CDATA[software maintenance]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[87]]></spage>

<epage><![CDATA[105]]></epage>

<abstract><![CDATA[Software visualization studies techniques and methods for graphically representing different aspects of software. Its main goal is to enhance, simplify and clarify the mental representation a software engineer has of a computer system. During many years, visualization in 2D space has been actively studied, but in the last decade, researchers have begun to explore new 3D representations for visualizing software. In this article, we present an overview of current research in the area, describing several major aspects like: visual representations, interaction issues, evaluation methods and development tools. We also perform a survey of some representative tools to support different tasks, i.e., software maintenance and comprehension, requirements validation and algorithm animation for educational purposes, among others. Finally, we conclude identifying future research directions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4564449]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.86]]></doi>

<publicationId><![CDATA[4564449]]></publicationId>

<partnum><![CDATA[4564449]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4564449&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4564449]]></pdf>

</document>

<document>

<rank>745</rank>

<title><![CDATA[Advanced Interactive Preintegrated Volume Rendering with a Power Series]]></title>

<authors><![CDATA[Byeonghun Lee;  Yeong-Gil Shin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Eng., Sungkyunkwan Univ., Suwon, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[prediction theory]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[storage management]]></term>

<term><![CDATA[table lookup]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1264]]></spage>

<epage><![CDATA[1273]]></epage>

<abstract><![CDATA[Preintegrated volume rendering produces high-quality renderings without increased sampling rates. However, a look-up table of a conventional preintegrated volume rendering requires a dimensionality of two, which disturbs interactive renderings when the transfer function is changed. Furthermore, as the resolution of the volume data set increases, the memory space required is impractical or inefficient, especially on GPUs. In the past, several approximation methods have been proposed to reduce the complexity of both the time and memory requirement, but most of them do not correctly present thin opaque structures within slabs and ignore the self-attenuation. We propose an advanced interactive preintegrated volume rendering algorithm that achieves not only high-quality renderings comparable to the conventional ones, but also O(n) time and memory space requirements even with the self-attenuation within the slabs applied. The algorithm proposed in this paper decomposes the exponential term of the ray integration equation into a power series of a finite order in the form of a linear combination to build a one-dimensional look-up table. Moreover, the proposed algorithm effectively applies the self-attenuation that is caused by fully opaque isosurfaces, by introducing an opaque prediction table. Experimental results demonstrate that the proposed algorithm offers renderings visibly identical to existing preintegrated volume renderings without degrading rendering speed.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6530590]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.313]]></doi>

<publicationId><![CDATA[6530590]]></publicationId>

<partnum><![CDATA[6530590]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6530590&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6530590]]></pdf>

</document>

<document>

<rank>746</rank>

<title><![CDATA[Scalable Hybrid Unstructured and Structured Grid Raycasting]]></title>

<authors><![CDATA[Muigg, P.;  Hadwiger, M.;  Doleisch, H.;  Hauser, H.]]></authors>

<affiliations><![CDATA[VRVis Res. Center]]></affiliations>

<controlledterms>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Finite volume methods]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Memory management]]></term>

<term><![CDATA[Quality management]]></term>

<term><![CDATA[Sorting]]></term>

<term><![CDATA[Temperature]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1592]]></spage>

<epage><![CDATA[1599]]></epage>

<abstract><![CDATA[This paper presents a scalable framework for real-time raycasting of large unstructured volumes that employs a hybrid bricking approach. It adaptively combines original unstructured bricks in important (focus) regions, with structured bricks that are resampled on demand in less important (context) regions. The basis of this focus+context approach is interactive specification of a scalar degree of interest (DOI) function. Thus, rendering always considers two volumes simultaneously: a scalar data volume, and the current DOI volume. The crucial problem of visibility sorting is solved by raycasting individual bricks and compositing in visibility order from front to back. In order to minimize visual errors at the grid boundary, it is always rendered accurately, even for resampled bricks. A variety of different rendering modes can be combined, including contour enhancement. A very important property of our approach is that it supports a variety of cell types natively, i.e., it is not constrained to tetrahedral grids, even when interpolation within cells is used. Moreover, our framework can handle multi-variate data, e.g., multiple scalar channels such as temperature or pressure, as well as time-dependent data. The combination of unstructured and structured bricks with different quality characteristics such as the type of interpolation or resampling resolution in conjunction with custom texture memory management yields a very scalable system.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376191]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70588]]></doi>

<publicationId><![CDATA[4376191]]></publicationId>

<partnum><![CDATA[4376191]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376191&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376191]]></pdf>

</document>

<document>

<rank>747</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1388239]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.32]]></doi>

<publicationId><![CDATA[1388239]]></publicationId>

<partnum><![CDATA[1388239]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1388239&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1388239]]></pdf>

</document>

<document>

<rank>748</rank>

<title><![CDATA[Peripheral Stimulation and its Effect on Perceived Spatial Scale in Virtual Environments]]></title>

<authors><![CDATA[Jones, J.A.;  Swan, J.E.;  Bolas, M.]]></authors>

<affiliations><![CDATA[Inst. for Creative Technol., Univ. of Southern California, Los Angeles, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[helmet mounted displays]]></term>

<term><![CDATA[peripheral interfaces]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive optics]]></term>

<term><![CDATA[Legged locomotion]]></term>

<term><![CDATA[Observers]]></term>

<term><![CDATA[Optical imaging]]></term>

<term><![CDATA[Stimulated emission]]></term>

<term><![CDATA[Virtual environments]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[701]]></spage>

<epage><![CDATA[710]]></epage>

<abstract><![CDATA[The following series of experiments explore the effect of static peripheral stimulation on the perception of distance and spatial scale in a typical head-mounted virtual environment. It was found that applying constant white light in an observers far periphery enabled the observer to more accurately judge distances using blind walking. An effect of similar magnitude was also found when observers estimated the size of a virtual space using a visual scale task. The presence of the effect across multiple psychophysical tasks provided confidence that a perceptual change was, in fact, being invoked by the addition of the peripheral stimulation. These results were also compared to observer performance in a very large field of view virtual environment and in the real world. The subsequent findings raise the possibility that distance judgments in virtual environments might be considerably more similar to those in the real world than previous work has suggested.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6479211]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.37]]></doi>

<publicationId><![CDATA[6479211]]></publicationId>

<partnum><![CDATA[6479211]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479211&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479211]]></pdf>

</document>

<document>

<rank>749</rank>

<title><![CDATA[The Squash-and-Stretch Stylization for Character Motions]]></title>

<authors><![CDATA[Ji-yong Kwon;  In-Kwon Lee]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Yonsei Univ., Seoul, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[covariance matrices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Covariance matrix]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Kinematics]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[488]]></spage>

<epage><![CDATA[500]]></epage>

<abstract><![CDATA[The squash-and-stretch describes the rigidity of the character. This effect is the most important technique in traditional cartoon animation. In this paper, we introduce a method that applies the squash-and-stretch effect to character motion. Our method exaggerates the motion by sequentially applying the spatial exaggeration technique and the temporal exaggeration technique. The spatial exaggeration technique globally deforms the pose in order to make the squashed or stretched pose by modeling it as a covariance matrix of joint positions. Then, the temporal exaggeration technique computes a time-warping function for each joint, and applies it to the position of the joint allowing the character to stretch its links appropriately. The motion stylized by our method is a sequence of squashed and stretched poses with stretching limbs. By performing a user survey, we prove that the motion created using our method is similar to that used in 2D cartoon animation and is funnier than the original motion for human observers who are familiar with 2D cartoon animation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5728801]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.48]]></doi>

<publicationId><![CDATA[5728801]]></publicationId>

<partnum><![CDATA[5728801]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5728801&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728801]]></pdf>

</document>

<document>

<rank>750</rank>

<title><![CDATA[Exchange of Avatars: Toward a Better Perception and Understanding]]></title>

<authors><![CDATA[Lopez, T.;  Bouville, R.;  Loup-escande, E.;  Nouviale, F.;  Gouranton, V.;  Arnaldi, B.]]></authors>

<controlledterms>

<term><![CDATA[avatars]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Avatars]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Engines]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Virtual environments]]></term>

<term><![CDATA[Visualization]]></term>

<term><![CDATA[Wheels]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[644]]></spage>

<epage><![CDATA[653]]></epage>

<abstract><![CDATA[The exchange of avatars, i.e. the actual fact of changing once avatar with another one, is a promising trend in multi-actor virtual environments. It provides new opportunities for users, such as controlling a different avatar for a specific action, retrieving knowledge belonging to a particular avatar, solving conflicts and deadlocks situations or even helping another user. Virtual Environments for Training are especially affected by this trend as a specific role derived from a scenario is usually assigned to a unique avatar. Despite the increasing use of avatar exchange, users' perception and understanding of this mechanism have not been studied. In this paper, we propose two complementary user-centered evaluations that aim at comparing several representations for the exchange of avatars; these are termed exchange metaphors. Our first experiment focuses on the perception of an exchange by a user who is not involved in the exchange, and the second experiment analyzes the perception of an exchange triggered by the user. Results show that the use of visual feedback globally aids better understanding of the exchange mechanism in both cases. Our first experiment suggests, however, that visual feedback is less efficient than a simple popup notification in terms of task duration. In addition, the second experiment shows that much simpler metaphors with no visual effect are generally preferred because of their efficiency.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6777431]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.22]]></doi>

<publicationId><![CDATA[6777431]]></publicationId>

<partnum><![CDATA[6777431]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777431&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777431]]></pdf>

</document>

<document>

<rank>751</rank>

<title><![CDATA[Visualizations everywhere: A Multiplatform Infrastructure for Linked Visualizations]]></title>

<authors><![CDATA[Fisher, D.;  Drucker, Steven M.;  Fernandez, R.;  Ruble, S.]]></authors>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[electronic data interchange]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Browsers]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Google]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Internet]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1157]]></spage>

<epage><![CDATA[1163]]></epage>

<abstract><![CDATA[In order to use new visualizations, most toolkits require application developers to rebuild their applications and distribute new versions to users. The WebCharts Framework take a different approach by hosting Javascript from within an application and providing a standard data and events interchange.. In this way, applications can be extended dynamically, with a wide variety of visualizations. We discuss the benefits of this architectural approach, contrast it to existing techniques, and give a variety of examples and extensions of the basic system.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613454]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.222]]></doi>

<publicationId><![CDATA[5613454]]></publicationId>

<partnum><![CDATA[5613454]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613454&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613454]]></pdf>

</document>

<document>

<rank>752</rank>

<title><![CDATA[The 2012 Virtual Reality Career Award]]></title>

<authors><![CDATA[Rosenblum, Lawrence]]></authors>

<thesaurusterms>

<term><![CDATA[Awards]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xv]]></spage>

<epage><![CDATA[xv]]></epage>

<abstract><![CDATA[Presents the recipient of the 2012 Virtual Reality Career Award.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479175]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.56]]></doi>

<publicationId><![CDATA[6479175]]></publicationId>

<partnum><![CDATA[6479175]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479175&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479175]]></pdf>

</document>

<document>

<rank>753</rank>

<title><![CDATA[Editor's Note]]></title>

<authors><![CDATA[Ertl, Thomas]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5331925]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.7]]></doi>

<publicationId><![CDATA[5331925]]></publicationId>

<partnum><![CDATA[5331925]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5331925&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331925]]></pdf>

</document>

<document>

<rank>754</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4384586]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.4]]></doi>

<publicationId><![CDATA[4384586]]></publicationId>

<partnum><![CDATA[4384586]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4384586&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4384586]]></pdf>

</document>

<document>

<rank>755</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1608015]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.44]]></doi>

<publicationId><![CDATA[1608015]]></publicationId>

<partnum><![CDATA[1608015]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1608015&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608015]]></pdf>

</document>

<document>

<rank>756</rank>

<title><![CDATA[SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space]]></title>

<authors><![CDATA[Bing Wang;  Ruchikachorn, P.;  Mueller, K.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Shape analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2060]]></spage>

<epage><![CDATA[2069]]></epage>

<abstract><![CDATA[High-dimensional data visualization has been attracting much attention. To fully test related software and algorithms, researchers require a diverse pool of data with known and desired features. Test data do not always provide this, or only partially. Here we propose the paradigm WYDIWYGS (What You Draw Is What You Get). Its embodiment, SketchPad<sup>ND</sup>, is a tool that allows users to generate high-dimensional data in the same interface they also use for visualization. This provides for an immersive and direct data generation activity, and furthermore it also enables users to interactively edit and clean existing high-dimensional data from possible artifacts. SketchPad<sup>ND</sup> offers two visualization paradigms, one based on parallel coordinates and the other based on a relatively new framework using an N-D polygon to navigate in high-dimensional space. The first interface allows users to draw arbitrary profiles of probability density functions along each dimension axis and sketch shapes for data density and connections between adjacent dimensions. The second interface embraces the idea of sculpting. Users can carve data at arbitrary orientations and refine them wherever necessary. This guarantees that the data generated is truly high-dimensional. We demonstrate our tool's usefulness in real data visualization scenarios.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634118]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.190]]></doi>

<publicationId><![CDATA[6634118]]></publicationId>

<partnum><![CDATA[6634118]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634118&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634118]]></pdf>

</document>

<document>

<rank>757</rank>

<title><![CDATA[Vortex Cores of Inertial Particles]]></title>

<authors><![CDATA[Gunther, T.;  Theisel, H.]]></authors>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[flow instability]]></term>

<term><![CDATA[two-phase flow]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Eigenvalues and eigenfunctions]]></term>

<term><![CDATA[Gravity]]></term>

<term><![CDATA[Jacobian matrices]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Time factors]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2535]]></spage>

<epage><![CDATA[2544]]></epage>

<abstract><![CDATA[The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875993]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346415]]></doi>

<publicationId><![CDATA[6875993]]></publicationId>

<partnum><![CDATA[6875993]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875993&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875993]]></pdf>

</document>

<document>

<rank>758</rank>

<title><![CDATA[Illustrative Deformation for Data Exploration]]></title>

<authors><![CDATA[Correa, C.D.;  Silver, D.;  Min Chen]]></authors>

<affiliations><![CDATA[State Univ. of New Jersey, Brunswick]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cognitive science]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Focusing]]></term>

<term><![CDATA[Geometrical optics]]></term>

<term><![CDATA[Information geometry]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Silver]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Taxonomy]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1320]]></spage>

<epage><![CDATA[1327]]></epage>

<abstract><![CDATA[Much of the visualization research has focused on improving the rendering quality and speed, and enhancing the perceptibility of features in the data. Recently, significant emphasis has been placed on focus+context (F+C) techniques (e.g., fisheye views and magnification lens) for data exploration in addition to viewing transformation and hierarchical navigation. However, most of the existing data exploration techniques rely on the manipulation of viewing attributes of the rendering system or optical attributes of the data objects, with users being passive viewers. In this paper, we propose a more active approach to data exploration, which attempts to mimic how we would explore data if we were able to hold it and interact with it in our hands. This involves allowing the users to physically or actively manipulate the geometry of a data object. While this approach has been traditionally used in applications, such as surgical simulation, where the original geometry of the data objects is well understood by the users, there are several challenges when this approach is generalized for applications, such as flow and information visualization, where there is no common perception as to the normal or natural geometry of a data object. We introduce a taxonomy and a set of transformations especially for illustrative deformation of general data exploration. We present combined geometric or optical illustration operators for focus+context visualization, and examine the best means for preventing the deformed context from being misperceived. We demonstrated the feasibility of this generalization with examples of flow, information and video visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376157]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70565]]></doi>

<publicationId><![CDATA[4376157]]></publicationId>

<partnum><![CDATA[4376157]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376157&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376157]]></pdf>

</document>

<document>

<rank>759</rank>

<title><![CDATA[Mesh parameterization by minimizing the synthesized distortion metric with the coefficient-optimizing algorithm]]></title>

<authors><![CDATA[Jingqi Yan;  Xin Yang;  Pengfei Shi;  Zhang, D.]]></authors>

<affiliations><![CDATA[Inst. of Image Process. & Pattern Recognition, Shanghai Jiao Tong Univ., China]]></affiliations>

<controlledterms>

<term><![CDATA[Laplace transforms]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[conformal mapping]]></term>

<term><![CDATA[convex programming]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[minimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Automatic control]]></term>

<term><![CDATA[Conformal mapping]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Iterative algorithms]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Piecewise linear techniques]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[83]]></spage>

<epage><![CDATA[92]]></epage>

<abstract><![CDATA[The parameterization of a 3D mesh into a planar domain requires a distortion metric and a minimizing process. Most previous work has sought to minimize the average area distortion, the average angle distortion, or a combination of these. Typical distortion metrics can reflect the overall performance of parameterizations but discount high local deformations. This affects the performance of postprocessing operations such as uniform remeshing and texture mapping. This paper introduces a new metric that synthesizes the average distortions and the variances of both the area deformations and the angle deformations over an entire mesh. Experiments show that, when compared with previous work, the use of synthesized distortion metric performs satisfactorily in terms of both the average area deformation and the average angle deformation; furthermore, the area and angle deformations are distributed more uniformly. This paper also develops a new iterative process for minimizing the synthesized distortion, the coefficient-optimizing algorithm. At each iteration, rather than updating the positions immediately after the local optimization, the coefficient-optimizing algorithm first update the coefficients for the linear convex combination and then globally updates the positions by solving the Laplace system. The high performance of the coefficient-optimizing algorithm has been demonstrated in many experiments.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1542002]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.10]]></doi>

<publicationId><![CDATA[1542002]]></publicationId>

<partnum><![CDATA[1542002]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1542002&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542002]]></pdf>

</document>

<document>

<rank>760</rank>

<title><![CDATA[International Program Committees]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[xv]]></spage>

<epage><![CDATA[xvi]]></epage>

<abstract><![CDATA[Provides a listing of current committee members.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327200]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.241]]></doi>

<publicationId><![CDATA[6327200]]></publicationId>

<partnum><![CDATA[6327200]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327200&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327200]]></pdf>

</document>

<document>

<rank>761</rank>

<title><![CDATA[Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites]]></title>

<authors><![CDATA[Merhof, D.;  Sonntag, M.;  Enders, F.;  Nimsky, C.;  Hastreiter, P.;  Greiner, G.]]></authors>

<affiliations><![CDATA[Dept. of Neurosurgery, Univ. Erlangen]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[brain]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[surgery]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Diffusion tensor imaging]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Meeting planning]]></term>

<term><![CDATA[Neurosurgery]]></term>

<term><![CDATA[Sprites (computer)]]></term>

<term><![CDATA[Streaming media]]></term>

<term><![CDATA[Strips]]></term>

<term><![CDATA[Surgery]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1181]]></spage>

<epage><![CDATA[1188]]></epage>

<abstract><![CDATA[Diffusion tensor imaging is of high value in neurosurgery, providing information about the location of white matter tracts in the human brain. For their reconstruction, streamline techniques commonly referred to as fiber tracking model the underlying fiber structures and have therefore gained interest. To meet the requirements of surgical planning and to overcome the visual limitations of line representations, a new real-time visualization approach of high visual quality is introduced. For this purpose, textured triangle strips and point sprites are combined in a hybrid strategy employing GPU programming. The triangle strips follow the fiber streamlines and are textured to obtain a tube-like appearance. A vertex program is used to orient the triangle strips towards the camera. In order to avoid triangle flipping in case of fiber segments where the viewing and segment direction are parallel, a correct visual representation is achieved in these areas by chains of point sprites. As a result, high quality visualization similar to tubes is provided allowing for interactive multimodal inspection. Overall, the presented approach is faster than existing techniques of similar visualization quality and at the same time allows for real-time rendering of dense bundles encompassing a high number of fibers, which is of high importance for diagnosis and surgical planning]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015480]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.151]]></doi>

<publicationId><![CDATA[4015480]]></publicationId>

<partnum><![CDATA[4015480]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015480&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015480]]></pdf>

</document>

<document>

<rank>762</rank>

<title><![CDATA[IEEE Computer Society Staff List]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[2]]></spage>

<epage><![CDATA[2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1272723]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1272723]]></doi>

<publicationId><![CDATA[1272723]]></publicationId>

<partnum><![CDATA[1272723]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1272723&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272723]]></pdf>

</document>

<document>

<rank>763</rank>

<title><![CDATA[Enhancing Depth Perception in Translucent Volumes]]></title>

<authors><![CDATA[Kersten, M.A.;  Stewart, A.J.;  Troje, N.;  Ellis, R.]]></authors>

<affiliations><![CDATA[Med. Comput. Lab., Queen''s Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[diagnostic radiography]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[surgery]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical computing]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Diagnostic radiography]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Light scattering]]></term>

<term><![CDATA[Orthopedic surgery]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface reconstruction]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1117]]></spage>

<epage><![CDATA[1124]]></epage>

<abstract><![CDATA[We present empirical studies that consider the effects of stereopsis and simulated aerial perspective on depth perception in translucent volumes. We consider a purely absorptive lighting model, in which light is not scattered or reflected, but is simply absorbed as it passes through the volume. A purely absorptive lighting model is used, for example, when rendering digitally reconstructed radiographs (DRRs), which are synthetic X-ray images reconstructed from CT volumes. Surgeons make use of DRRs in planning and performing operations, so an improvement of depth perception in DRRs may help diagnosis and surgical planning]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015472]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.139]]></doi>

<publicationId><![CDATA[4015472]]></publicationId>

<partnum><![CDATA[4015472]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015472&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015472]]></pdf>

</document>

<document>

<rank>764</rank>

<title><![CDATA[Variational Blue Noise Sampling]]></title>

<authors><![CDATA[Chen, Zhonggui;  Yuan, Zhan;  Choi, Yi-King;  Liu, Ligang;  Wang, Wenping]]></authors>

<affiliations><![CDATA[Xiamen University, Xiamen]]></affiliations>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Density functional theory]]></term>

<term><![CDATA[Noise measurement]]></term>

<term><![CDATA[Optimization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1784]]></spage>

<epage><![CDATA[1796]]></epage>

<abstract><![CDATA[Blue noise point sampling is one of the core algorithms in computer graphics. In this paper, we present a new and versatile variational framework for generating point distributions with high-quality blue noise characteristics while precisely adapting to given density functions. Different from previous approaches based on discrete settings of capacity-constrained Voronoi tessellation, we cast the blue noise sampling generation as a variational problem with continuous settings. Based on an accurate evaluation of the gradient of an energy function, an efficient optimization is developed which delivers significantly faster performance than the previous optimization-based methods. Our framework can easily be extended to generating blue noise point samples on manifold surfaces and for multi-class sampling. The optimization formulation also allows us to naturally deal with dynamic domains, such as deformable surfaces, and to yield blue noise samplings with temporal coherence. We present experimental results to validate the efficacy of our variational framework. Finally, we show a variety of applications of the proposed methods, including nonphotorealistic image stippling, color stippling, and blue noise sampling on deformable surfaces.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6197186]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.94]]></doi>

<publicationId><![CDATA[6197186]]></publicationId>

<partnum><![CDATA[6197186]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6197186&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197186]]></pdf>

</document>

<document>

<rank>765</rank>

<title><![CDATA[Anisotropic Ambient Volume Shading]]></title>

<authors><![CDATA[Ament, M.;  Dachsbacher, C.]]></authors>

<affiliations><![CDATA[Karlsruhe Inst. of Technol., Karlsruhe, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[covariance matrices]]></term>

<term><![CDATA[eigenvalues and eigenfunctions]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[principal component analysis]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Covariance matrices]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[1015]]></spage>

<epage><![CDATA[1024]]></epage>

<abstract><![CDATA[We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7194844]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467963]]></doi>

<publicationId><![CDATA[7194844]]></publicationId>

<partnum><![CDATA[7194844]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7194844&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194844]]></pdf>

</document>

<document>

<rank>766</rank>

<title><![CDATA[Drawing and Labeling High-Quality Metro Maps by Mixed-Integer Programming]]></title>

<authors><![CDATA[Nollenburg, M.;  Wolff, A.]]></authors>

<affiliations><![CDATA[Inst. of Theor. Inf., Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[integer programming]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Geography]]></term>

<term><![CDATA[Information geometry]]></term>

<term><![CDATA[Labeling]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Network topology]]></term>

<term><![CDATA[Space stations]]></term>

<term><![CDATA[Urban areas]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[626]]></spage>

<epage><![CDATA[641]]></epage>

<abstract><![CDATA[Metro maps are schematic diagrams of public transport networks that serve as visual aids for route planning and navigation tasks. It is a challenging problem in network visualization to automatically draw appealing metro maps. There are two aspects to this problem that depend on each other: the layout problem of finding station and link coordinates and the labeling problem of placing nonoverlapping station labels. In this paper, we present a new integral approach that solves the combined layout and labeling problem (each of which, independently, is known to be NP-hard) using mixed-integer programming (MIP). We identify seven design rules used in most real-world metro maps. We split these rules into hard and soft constraints and translate them into an MIP model. Our MIP formulation finds a metro map that satisfies all hard constraints (if such a drawing exists) and minimizes a weighted sum of costs that correspond to the soft constraints. We have implemented the MIP model and present a case study and the results of an expert assessment to evaluate the performance of our approach in comparison to both manually designed official maps and results of previous layout methods.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5473229]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.81]]></doi>

<publicationId><![CDATA[5473229]]></publicationId>

<partnum><![CDATA[5473229]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5473229&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473229]]></pdf>

</document>

<document>

<rank>767</rank>

<title><![CDATA[A Local Model of Light Interaction with Transparent Crystalline Media]]></title>

<authors><![CDATA[Debelov, V.A.;  Kozlov, D.S.]]></authors>

<affiliations><![CDATA[Lab. of Numerical Anal. & Comput. Graphics, Inst. of Comput. Math. & Math. Geophys., Novosibirsk, Russia]]></affiliations>

<controlledterms>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Crystals]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Media]]></term>

<term><![CDATA[Optical polarization]]></term>

<term><![CDATA[Optical refraction]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1274]]></spage>

<epage><![CDATA[1287]]></epage>

<abstract><![CDATA[The paper is devoted to the derivation of a bidirectional distribution function for crystals, which specifies all outgoing rays for a ray coming to the boundary of two transparent crystalline media with different optical properties, i.e., a particular mineral, directions of optical axes if they exist, and other features. A local model of interaction based on the notion of polarized light ray is introduced, which is specified by a geometric ray, its polarization state, light intensity, and so on. The computational algorithm that is suggested allows computing the directions and other properties of all (up to four) outgoing rays. In this paper, isotropic, uniaxial, and biaxial crystals are processed in a similar manner. The correctness of the model is validated by comparison of photos of real uniaxial crystals with corresponding computed images. The case of biaxial crystals is validated by testing the effect of conical refraction. Specifications of a series of tests devoted to rendering of optically different objects is presented also.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6341728]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.304]]></doi>

<publicationId><![CDATA[6341728]]></publicationId>

<partnum><![CDATA[6341728]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6341728&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6341728]]></pdf>

</document>

<document>

<rank>768</rank>

<title><![CDATA[The Influence of Contour on Similarity Perception of Star Glyphs]]></title>

<authors><![CDATA[Fuchs, J.;  Isenberg, P.;  Bezerianos, A.;  Fischer, F.;  Bertini, E.]]></authors>

<affiliations><![CDATA[Univ. of Konstanz, Konstanz, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Active contours]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Shape analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2251]]></spage>

<epage><![CDATA[2260]]></epage>

<abstract><![CDATA[We conducted three experiments to investigate the effects of contours on the detection of data similarity with star glyph variations. A star glyph is a small, compact, data graphic that represents a multi-dimensional data point. Star glyphs are often used in small-multiple settings, to represent data points in tables, on maps, or as overlays on other types of data graphics. In these settings, an important task is the visual comparison of the data points encoded in the star glyph, for example to find other similar data points or outliers. We hypothesized that for data comparisons, the overall shape of a star glyph-enhanced through contour lines-would aid the viewer in making accurate similarity judgments. To test this hypothesis, we conducted three experiments. In our first experiment, we explored how the use of contours influenced how visualization experts and trained novices chose glyphs with similar data values. Our results showed that glyphs without contours make the detection of data similarity easier. Given these results, we conducted a second study to understand intuitive notions of similarity. Star glyphs without contours most intuitively supported the detection of data similarity. In a third experiment, we tested the effect of star glyph reference structures (i.e., tickmarks and gridlines) on the detection of similarity. Surprisingly, our results show that adding reference structures does improve the correctness of similarity judgments for star glyphs with contours, but not for the standard star glyph. As a result of these experiments, we conclude that the simple star glyph without contours performs best under several criteria, reinforcing its practice and popularity in the literature. Contours seem to enhance the detection of other types of similarity, e. g., shape similarity and are distracting when data similarity has to be judged. Based on these findings we provide design considerations regarding the use of contours and reference structures on star glyp- s.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875973]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346426]]></doi>

<publicationId><![CDATA[6875973]]></publicationId>

<partnum><![CDATA[6875973]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875973&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875973]]></pdf>

</document>

<document>

<rank>769</rank>

<title><![CDATA[Radiance Transfer Biclustering for Real-Time All-Frequency Biscale Rendering]]></title>

<authors><![CDATA[Xin Sun;  Qiming Hou;  Zhong Ren;  Kun Zhou;  Baining Guo]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[image texture]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Image storage]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Sun]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[64]]></spage>

<epage><![CDATA[73]]></epage>

<abstract><![CDATA[We present a real-time algorithm to render all-frequency radiance transfer at both macroscale and mesoscale. At a mesoscale, the shading is computed on a per-pixel basis by integrating the product of the local incident radiance and a bidirectional texture function. While at a macroscale, the precomputed transfer matrix, which transfers the global incident radiance to the local incident radiance at each vertex, is losslessly compressed by a novel biclustering technique. The biclustering is directly applied on the radiance transfer represented in a pixel basis, on which the BTF is naturally defined. It exploits the coherence in the transfer matrix and a property of matrix element values to reduce both storage and runtime computation cost. Our new algorithm renders at real-time frame rates realistic materials and shadows under all-frequency direct environment lighting. Comparisons show that our algorithm is able to generate images that compare favorably with reference ray tracing results, and has obvious advantages over alternative methods in storage and preprocessing time.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5453360]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.58]]></doi>

<publicationId><![CDATA[5453360]]></publicationId>

<partnum><![CDATA[5453360]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5453360&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453360]]></pdf>

</document>

<document>

<rank>770</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5976482]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.136]]></doi>

<publicationId><![CDATA[5976482]]></publicationId>

<partnum><![CDATA[5976482]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5976482&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5976482]]></pdf>

</document>

<document>

<rank>771</rank>

<title><![CDATA[IEEE Visualization Conference and IEEE Information Visualization Conference Proceedings 2007 back matter]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[backmatter]]></spage>

<epage><![CDATA[backmatter]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4376213]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70563]]></doi>

<publicationId><![CDATA[4376213]]></publicationId>

<partnum><![CDATA[4376213]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376213&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376213]]></pdf>

</document>

<document>

<rank>772</rank>

<title><![CDATA[Visualization exploration and encapsulation via a spreadsheet-like interface]]></title>

<authors><![CDATA[Jankun-Kelly, T.J.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Visualization & Graphics Res. Group, California Univ., Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data encapsulation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[image retrieval]]></term>

<term><![CDATA[spreadsheet programs]]></term>

<term><![CDATA[very large databases]]></term>

<term><![CDATA[visual databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encapsulation]]></term>

<term><![CDATA[Knowledge representation]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Power generation economics]]></term>

<term><![CDATA[Space exploration]]></term>

<term><![CDATA[User interfaces]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[275]]></spage>

<epage><![CDATA[287]]></epage>

<abstract><![CDATA[Exploring complex, very large data sets requires interfaces to present and navigate through the visualization of the data. Two types of audience benefit from such coherent organization and representation: first, the user of the visualization system can examine and evaluate their data more efficiently; second, collaborators or reviewers can quickly understand and extend the visualization. The needs of these two groups are addressed by the spreadsheet-like interface described in this paper. The interface represents a 2D window in a multidimensional visualization parameter space. Data is explored by navigating this space via the interface. The visualization space is presented to the user in a manner that clearly identifies which parameters correspond to which visualized result. Operations defined on this space can be applied which generate new parameters or results. Combined with a general-purpose interpreter, these functions can be utilized to quickly extract desired results. Finally, by encapsulating the visualization process, redundant exploration is eliminated and collaboration is facilitated. The efficacy of this novel interface is demonstrated through examples using a variety of data sets in different domains]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[942695]]></arnumber>

<doi><![CDATA[10.1109/2945.942695]]></doi>

<publicationId><![CDATA[942695]]></publicationId>

<partnum><![CDATA[942695]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=942695&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=942695]]></pdf>

</document>

<document>

<rank>773</rank>

<title><![CDATA[Dynamic Visualization of Coexpression in Systems Genetics Data]]></title>

<authors><![CDATA[New, J.;  Kendall, W.;  Huang, J.;  Chesler, E.]]></authors>

<affiliations><![CDATA[Dept. of Electr. Eng. & Comput. Sci., Tennessee Univ., Knoxville, TN]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[fuzzy set theory]]></term>

<term><![CDATA[genetics]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1081]]></spage>

<epage><![CDATA[1095]]></epage>

<abstract><![CDATA[Biologists hope to address grand scientific challenges by exploring the abundance of data made available through modern microarray technology and other high-throughput techniques. The impact of this data, however, is limited unless researchers can effectively assimilate such complex information and integrate it into their daily research; interactive visualization tools are called for to support the effort. Specifically, typical studies of gene co-expression require novel visualization tools that enable the dynamic formulation and fine-tuning of hypotheses to aid the process of evaluating sensitivity of key parameters. These tools should allow biologists to develop an intuitive understanding of the structure of biological networks and discover genes residing in critical positions in networks and pathways. By using a graph as a universal representation of correlation in gene expression, our system employs several techniques that when used in an integrated manner provide innovative analytical capabilities. Our tool for interacting with gene co-expression data integrates techniques such as: graph layout, qualitative subgraph extraction through a novel 2D user interface, quantitative subgraph extraction using graph-theoretic algorithms or by compound queries, dynamic level-of-detail abstraction, and template-based fuzzy classification. We demonstrate our system using a real-world workflow from a large-scale, systems genetics study of mammalian gene coexpression.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4492772]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.61]]></doi>

<publicationId><![CDATA[4492772]]></publicationId>

<partnum><![CDATA[4492772]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4492772&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4492772]]></pdf>

</document>

<document>

<rank>774</rank>

<title><![CDATA[Acuity-Driven Gigapixel Visualization]]></title>

<authors><![CDATA[Papadopoulos, C.;  Kaufman, A.E.]]></authors>

<affiliations><![CDATA[Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Pixels]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2886]]></spage>

<epage><![CDATA[2895]]></epage>

<abstract><![CDATA[We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634175]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.127]]></doi>

<publicationId><![CDATA[6634175]]></publicationId>

<partnum><![CDATA[6634175]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634175&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634175]]></pdf>

</document>

<document>

<rank>775</rank>

<title><![CDATA[Scan-Based Volume Animation Driven by Locally Adaptive Articulated Registrations]]></title>

<authors><![CDATA[Taehyun Rhee;  Lewis, J.P.;  Neumann, U.;  Nayak, K.]]></authors>

<affiliations><![CDATA[3D Graphics & VR Group, Samsung Electron. Co., Ltd., Yongin, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[biomedical imaging]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[nonlinear programming]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Body regions]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Constraint optimization]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[In vivo]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[368]]></spage>

<epage><![CDATA[379]]></epage>

<abstract><![CDATA[This paper describes a complete system to create anatomically accurate example-based volume deformation and animation of articulated body regions, starting from multiple in vivo volume scans of a specific individual. In order to solve the correspondence problem across volume scans, a template volume is registered to each sample. The wide range of pose variations is first approximated by volume blend deformation (VBD), providing proper initialization of the articulated subject in different poses. A novel registration method is presented to efficiently reduce the computation cost while avoiding strong local minima inherent in complex articulated body volume registration. The algorithm highly constrains the degrees of freedom and search space involved in the nonlinear optimization, using hierarchical volume structures and locally constrained deformation based on the biharmonic clamped spline. Our registration step establishes a correspondence across scans, allowing a data-driven deformation approach in the volume domain. The results provide an occlusion-free person-specific 3D human body model, asymptotically accurate inner tissue deformations, and realistic volume animation of articulated movements driven by standard joint control estimated from the actual skeleton. Our approach also addresses the practical issues arising in using scans from living subjects. The robustness of our algorithms is tested by their applications on the hand, probably the most complex articulated region in the body, and the knee, a frequent subject area for medical imaging due to injuries.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5416708]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.39]]></doi>

<publicationId><![CDATA[5416708]]></publicationId>

<partnum><![CDATA[5416708]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5416708&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416708]]></pdf>

</document>

<document>

<rank>776</rank>

<title><![CDATA[Anisotropic Sampling of Planar and Two-Manifold Domains for Texture Generation and Glyph Distribution]]></title>

<authors><![CDATA[Kratz, A.;  Baum, D.;  Hotz, I.]]></authors>

<affiliations><![CDATA[Zuse Inst. Berlin, Berlin, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[relaxation theory]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sampling methods]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Texture analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1782]]></spage>

<epage><![CDATA[1794]]></epage>

<abstract><![CDATA[We present a new method for the generation of anisotropic sample distributions on planar and two-manifold domains. Most previous work that is concerned with aperiodic point distributions is designed for isotropically shaped samples. Methods focusing on anisotropic sample distributions are rare, and either they are restricted to planar domains, are highly sensitive to the choice of parameters, or they are computationally expensive. In this paper, we present a time-efficient approach for the generation of anisotropic sample distributions that only depends on intuitive design parameters for planar and two-manifold domains. We employ an anisotropic triangulation that serves as basis for the creation of an initial sample distribution as well as for a gravitational-centered relaxation. Furthermore, we present an approach for interactive rendering of anisotropic Voronoi cells as base element for texture generation. It represents a novel and flexible visualization approach to depict metric tensor fields that can be derived from general tensor fields as well as scalar or vector fields.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6517193]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.83]]></doi>

<publicationId><![CDATA[6517193]]></publicationId>

<partnum><![CDATA[6517193]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6517193&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6517193]]></pdf>

</document>

<document>

<rank>777</rank>

<title><![CDATA[Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design]]></title>

<authors><![CDATA[Kodagoda, N.;  Attfield, S.;  Wong, B.L.W.;  Rooney, C.;  Choudhury, S.]]></authors>

<affiliations><![CDATA[Middlesex Univ., London, UK]]></affiliations>

<controlledterms>

<term><![CDATA[cognition]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital libraries]]></term>

<term><![CDATA[query processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Query processing]]></term>

<term><![CDATA[User interfaces]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2217]]></spage>

<epage><![CDATA[2226]]></epage>

<abstract><![CDATA[This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6651935]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.211]]></doi>

<publicationId><![CDATA[6651935]]></publicationId>

<partnum><![CDATA[6651935]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6651935&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651935]]></pdf>

</document>

<document>

<rank>778</rank>

<title><![CDATA[LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation]]></title>

<authors><![CDATA[Kohlmann, P.;  Bruckner, S.;  Kanitsar, A.;  Kanitsar, A.]]></authors>

<affiliations><![CDATA[Vienna Univ. of Technol., Vienna]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[knowledge based systems]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anatomical structure]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Medical diagnostic imaging]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1544]]></spage>

<epage><![CDATA[1551]]></epage>

<abstract><![CDATA[Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376185]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70576]]></doi>

<publicationId><![CDATA[4376185]]></publicationId>

<partnum><![CDATA[4376185]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376185&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376185]]></pdf>

</document>

<document>

<rank>779</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5165579]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.78]]></doi>

<publicationId><![CDATA[5165579]]></publicationId>

<partnum><![CDATA[5165579]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5165579&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5165579]]></pdf>

</document>

<document>

<rank>780</rank>

<title><![CDATA[Detail-Preserving Controllable Deformation from Sparse Examples]]></title>

<authors><![CDATA[Haoda Huang;  KangKang Yin;  Ling Zhao;  Yue Qi;  Yizhou Yu;  Xin Tong]]></authors>

<affiliations><![CDATA[Microsoft Res. Asia, Mountain View, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[video signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Bones]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Training]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1215]]></spage>

<epage><![CDATA[1227]]></epage>

<abstract><![CDATA[Recent advances in laser scanning technology have made it possible to faithfully scan a real object with tiny geometric details, such as pores and wrinkles. However, a faithful digital model should not only capture static details of the real counterpart but also be able to reproduce the deformed versions of such details. In this paper, we develop a data-driven model that has two components; the first accommodates smooth large-scale deformations and the second captures high-resolution details. Large-scale deformations are based on a nonlinear mapping between sparse control points and bone transformations. A global mapping, however, would fail to synthesize realistic geometries from sparse examples, for highly deformable models with a large range of motion. The key is to train a collection of mappings defined over regions locally in both the geometry and the pose space. Deformable fine-scale details are generated from a second nonlinear mapping between the control points and per-vertex displacements. We apply our modeling scheme to scanned human hand models, scanned face models, face models reconstructed from multiview video sequences, and manually constructed dinosaur models. Experiments show that our deformation models, learned from extremely sparse training data, are effective and robust in synthesizing highly deformable models with rich fine features, for keyframe animation as well as performance-driven animation. We also compare our results with those obtained by alternative techniques.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6171183]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.88]]></doi>

<publicationId><![CDATA[6171183]]></publicationId>

<partnum><![CDATA[6171183]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6171183&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171183]]></pdf>

</document>

<document>

<rank>781</rank>

<title><![CDATA[Memorability of Visual Features in Network Diagrams]]></title>

<authors><![CDATA[Marriott, K.;  Purchase, H.;  Wybrow, M.;  Goncu, C.]]></authors>

<affiliations><![CDATA[Monash Univ., Melbourne, VIC, Australia]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[network theory (graphs)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2477]]></spage>

<epage><![CDATA[2485]]></epage>

<abstract><![CDATA[We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327253]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.245]]></doi>

<publicationId><![CDATA[6327253]]></publicationId>

<partnum><![CDATA[6327253]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327253&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327253]]></pdf>

</document>

<document>

<rank>782</rank>

<title><![CDATA[Shape Recognition and Pose Estimation for Mobile Augmented Reality]]></title>

<authors><![CDATA[Hagbi, N.;  Bergig, O.;  El-Sana, J.;  Billinghurst, M.]]></authors>

<affiliations><![CDATA[Visual Media Lab., Ben Gurion Univ., Beer-Sheva, Israel]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[error analysis]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image classification]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[mobile computing]]></term>

<term><![CDATA[mobile handsets]]></term>

<term><![CDATA[pose estimation]]></term>

<term><![CDATA[shape recognition]]></term>

<term><![CDATA[target tracking]]></term>

<term><![CDATA[ubiquitous computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1369]]></spage>

<epage><![CDATA[1379]]></epage>

<abstract><![CDATA[Nestor is a real-time recognition and camera pose estimation system for planar shapes. The system allows shapes that carry contextual meanings for humans to be used as Augmented Reality (AR) tracking targets. The user can teach the system new shapes in real time. New shapes can be shown to the system frontally, or they can be automatically rectified according to previously learned shapes. Shapes can be automatically assigned virtual content by classification according to a shape class library. Nestor performs shape recognition by analyzing contour structures and generating projective-invariant signatures from their concavities. The concavities are further used to extract features for pose estimation and tracking. Pose refinement is carried out by minimizing the reprojection error between sample points on each image contour and its library counterpart. Sample points are matched by evolving an active contour in real time. Our experiments show that the system provides stable and accurate registration, and runs at interactive frame rates on a Nokia N95 mobile phone.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5620901]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.241]]></doi>

<publicationId><![CDATA[5620901]]></publicationId>

<partnum><![CDATA[5620901]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5620901&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620901]]></pdf>

</document>

<document>

<rank>783</rank>

<title><![CDATA[Continuous Parallel Coordinates]]></title>

<authors><![CDATA[Heinrich, J.;  Weiskopf, D.]]></authors>

<affiliations><![CDATA[VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[interpolation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Scattering]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1531]]></spage>

<epage><![CDATA[1538]]></epage>

<abstract><![CDATA[Typical scientific data is represented on a grid with appropriate interpolation or approximation schemes,defined on a continuous domain. The visualization of such data in parallel coordinates may reveal patterns latently contained in the data and thus can improve the understanding of multidimensional relations. In this paper, we adopt the concept of continuous scatterplots for the visualization of spatially continuous input data to derive a density model for parallel coordinates. Based on the point-line duality between scatterplots and parallel coordinates, we propose a mathematical model that maps density from a continuous scatterplot to parallel coordinates and present different algorithms for both numerical and analytical computation of the resulting density field. In addition, we show how the 2-D model can be used to successively construct continuous parallel coordinates with an arbitrary number of dimensions. Since continuous parallel coordinates interpolate data values within grid cells, a scalable and dense visualization is achieved, which will be demonstrated for typical multi-variate scientific data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290770]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.131]]></doi>

<publicationId><![CDATA[5290770]]></publicationId>

<partnum><![CDATA[5290770]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290770&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290770]]></pdf>

</document>

<document>

<rank>784</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5506921]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.99]]></doi>

<publicationId><![CDATA[5506921]]></publicationId>

<partnum><![CDATA[5506921]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5506921&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5506921]]></pdf>

</document>

<document>

<rank>785</rank>

<title><![CDATA[CloudLines: Compact Display of Event Episodes in Multiple Time-Series]]></title>

<authors><![CDATA[Krstajic, M.;  Bertini, E.;  Keim, D.A.]]></authors>

<affiliations><![CDATA[Univ. of Konstanz, Konstanz, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[computer displays]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[financial management]]></term>

<term><![CDATA[information resources]]></term>

<term><![CDATA[security of data]]></term>

<term><![CDATA[time series]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Event detection]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Time series analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2432]]></spage>

<epage><![CDATA[2439]]></epage>

<abstract><![CDATA[We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065010]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.179]]></doi>

<publicationId><![CDATA[6065010]]></publicationId>

<partnum><![CDATA[6065010]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065010&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065010]]></pdf>

</document>

<document>

<rank>786</rank>

<title><![CDATA[Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System]]></title>

<authors><![CDATA[Matkovic, K.;  Gracanin, D.;  Jelovic, M.;  Hauser, H.]]></authors>

<affiliations><![CDATA[VRVis Res. Center, Vienna]]></affiliations>

<controlledterms>

<term><![CDATA[automotive engineering]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[design engineering]]></term>

<term><![CDATA[engineering graphics]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[rapid prototyping (industrial)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Automotive engineering]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Manufacturing industries]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Rails]]></term>

<term><![CDATA[System analysis and design]]></term>

<term><![CDATA[Virtual prototyping]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1699]]></spage>

<epage><![CDATA[1706]]></epage>

<abstract><![CDATA[Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658193]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.145]]></doi>

<publicationId><![CDATA[4658193]]></publicationId>

<partnum><![CDATA[4658193]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658193&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658193]]></pdf>

</document>

<document>

<rank>787</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4675195]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.4]]></doi>

<publicationId><![CDATA[4675195]]></publicationId>

<partnum><![CDATA[4675195]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4675195&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4675195]]></pdf>

</document>

<document>

<rank>788</rank>

<title><![CDATA[LiveGantt: Interactively Visualizing a Large Manufacturing Schedule]]></title>

<authors><![CDATA[Jaemin Jo;  Jaeseok Huh;  Jonghun Park;  Bohyoung Kim;  Jinwook Seo]]></authors>

<affiliations><![CDATA[Seoul Nat. Univ., Seoul, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computer aided manufacturing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[industrial engineering]]></term>

<term><![CDATA[interactive programming]]></term>

<term><![CDATA[scheduling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Job shop scheduling]]></term>

<term><![CDATA[Production facilities]]></term>

<term><![CDATA[Scheduling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2329]]></spage>

<epage><![CDATA[2338]]></epage>

<abstract><![CDATA[In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875942]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346454]]></doi>

<publicationId><![CDATA[6875942]]></publicationId>

<partnum><![CDATA[6875942]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875942&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875942]]></pdf>

</document>

<document>

<rank>789</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current staff, committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5946037]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.124]]></doi>

<publicationId><![CDATA[5946037]]></publicationId>

<partnum><![CDATA[5946037]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5946037&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946037]]></pdf>

</document>

<document>

<rank>790</rank>

<title><![CDATA[Making Graphical Information Visible in Real Shadows on Interactive Tabletops]]></title>

<authors><![CDATA[Isogawa, M.;  Iwai, D.;  Sato, K.]]></authors>

<affiliations><![CDATA[Grad. Sch. of Eng. Sci., Osaka Univ., Toyonaka, Japan]]></affiliations>

<controlledterms>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[touch sensitive screens]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Optical imaging]]></term>

<term><![CDATA[Optical polarization]]></term>

<term><![CDATA[Optical sensors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1293]]></spage>

<epage><![CDATA[1302]]></epage>

<abstract><![CDATA[We introduce a shadow-based interface for interactive tabletops. The proposed interface allows a user to browse graphical information by casting the shadow of his/her body, such as a hand, on a tabletop surface. Central to our technique is a new optical design that utilizes polarization in addition to the additive nature of light so that the desired graphical information is displayed only in a shadow area on a tabletop surface. In other words, our technique conceals the graphical information on surfaces other than the shadow area, such as the surface of the occluder and non-shadow areas on the tabletop surface. We combine the proposed shadow-based interface with a multi-touch detection technique to realize a novel interaction technique for interactive tabletops. We implemented a prototype system and conducted proof-of-concept experiments along with a quantitative evaluation to assess the feasibility of the proposed optical design. Finally, we showed implemented application systems of the proposed shadow-based interface.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6784085]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2316002]]></doi>

<publicationId><![CDATA[6784085]]></publicationId>

<partnum><![CDATA[6784085]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6784085&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784085]]></pdf>

</document>

<document>

<rank>791</rank>

<title><![CDATA[RelEx: Visualization for Actively Changing Overlay Network Specifications]]></title>

<authors><![CDATA[Sedlmair, M.;  Frank, A.;  Munzner, T.;  Butz, A.]]></authors>

<affiliations><![CDATA[Univ. of British Columbia, Vancouver, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[automotive electronics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[electronic engineering computing]]></term>

<term><![CDATA[on-board communications]]></term>

<term><![CDATA[overlay networks]]></term>

<term><![CDATA[user centred design]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Automotive engineering]]></term>

<term><![CDATA[Change detection algorithms]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Network topology]]></term>

<term><![CDATA[Traffic control]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2729]]></spage>

<epage><![CDATA[2738]]></epage>

<abstract><![CDATA[We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327279]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.255]]></doi>

<publicationId><![CDATA[6327279]]></publicationId>

<partnum><![CDATA[6327279]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327279&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327279]]></pdf>

</document>

<document>

<rank>792</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6097191]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.11]]></doi>

<publicationId><![CDATA[6097191]]></publicationId>

<partnum><![CDATA[6097191]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6097191&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6097191]]></pdf>

</document>

<document>

<rank>793</rank>

<title><![CDATA[Proactive Spatiotemporal Resource Allocation and Predictive Visual Analytics for Community Policing and Law Enforcement]]></title>

<authors><![CDATA[Malik, A.;  Maciejewski, R.;  Towers, S.;  McCullough, S.;  Ebert, D.S.]]></authors>

<affiliations><![CDATA[Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[estimation theory]]></term>

<term><![CDATA[law administration]]></term>

<term><![CDATA[resource allocation]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Decision making]]></term>

<term><![CDATA[Forecasting]]></term>

<term><![CDATA[Geospatial analysis]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Spatiotemporal phenomena]]></term>

<term><![CDATA[Time series analysis]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1863]]></spage>

<epage><![CDATA[1872]]></epage>

<abstract><![CDATA[In this paper, we present a visual analytics approach that provides decision makers with a proactive and predictive environment in order to assist them in making effective resource allocation and deployment decisions. The challenges involved with such predictive analytics processes include end-users' understanding, and the application of the underlying statistical algorithms at the right spatiotemporal granularity levels so that good prediction estimates can be established. In our approach, we provide analysts with a suite of natural scale templates and methods that enable them to focus and drill down to appropriate geospatial and temporal resolution levels. Our forecasting technique is based on the Seasonal Trend decomposition based on Loess (STL) method, which we apply in a spatiotemporal visual analytics context to provide analysts with predicted levels of future activity. We also present a novel kernel density estimation technique we have developed, in which the prediction process is influenced by the spatial correlation of recent incidents at nearby locations. We demonstrate our techniques by applying our methodology to Criminal, Traffic and Civil (CTC) incident datasets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875970]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346926]]></doi>

<publicationId><![CDATA[6875970]]></publicationId>

<partnum><![CDATA[6875970]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875970&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875970]]></pdf>

</document>

<document>

<rank>794</rank>

<title><![CDATA[Cluster Analysis of Vortical Flow in Simulations of Cerebral Aneurysm Hemodynamics]]></title>

<authors><![CDATA[Oeltze-Jafra, S.;  Cebral, J.R.;  Janiga, G.;  Preim, B.]]></authors>

<affiliations><![CDATA[Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[haemodynamics]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aneurysm]]></term>

<term><![CDATA[Bifurcation]]></term>

<term><![CDATA[Blood]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Hemodynamics]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[757]]></spage>

<epage><![CDATA[766]]></epage>

<abstract><![CDATA[Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192711]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467203]]></doi>

<publicationId><![CDATA[7192711]]></publicationId>

<partnum><![CDATA[7192711]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192711&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192711]]></pdf>

</document>

<document>

<rank>795</rank>

<title><![CDATA[Visualizing Statistical Mix Effects and Simpson&#x0027;s Paradox]]></title>

<authors><![CDATA[Armstrong, Z.;  Wattenberg, M.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Statistics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2132]]></spage>

<epage><![CDATA[2141]]></epage>

<abstract><![CDATA[We discuss how &#x201C;mix effects&#x201D; can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as &#x201C;omitted variable bias&#x201D; or, in extreme cases, as &#x201C;Simpson's paradox&#x201D;) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the &#x201C;comet chart,&#x201D; that is meant to ameliorate some of these issues.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875927]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346297]]></doi>

<publicationId><![CDATA[6875927]]></publicationId>

<partnum><![CDATA[6875927]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875927&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875927]]></pdf>

</document>

<document>

<rank>796</rank>

<title><![CDATA[Non-Eeuclidean spring embedders]]></title>

<authors><![CDATA[Kobourov, S.G.;  Wampler, K.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Arizona Univ., Tucson, AZ, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational geometry]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hydrogen]]></term>

<term><![CDATA[Information geometry]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Springs]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[757]]></spage>

<epage><![CDATA[767]]></epage>

<abstract><![CDATA[We present a conceptually simple approach to generalizing force-directed methods for graph layout from Euclidean geometry to Riemannian geometries. Unlike previous work on non-Euclidean force-directed methods, ours is not limited to special classes of graphs, but can be applied to arbitrary graphs. The method relies on extending the Euclidean notions of distance, angle, and force-interactions to smooth non-Euclidean geometries via projections to and from appropriately chosen tangent spaces. In particular, we formally describe the calculations needed to extend such algorithms to hyperbolic and spherical geometries. We also study the theoretical and practical considerations that arise when working with non-Euclidean geometries.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1512025]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.103]]></doi>

<publicationId><![CDATA[1512025]]></publicationId>

<partnum><![CDATA[1512025]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1512025&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512025]]></pdf>

</document>

<document>

<rank>797</rank>

<title><![CDATA[Improving Shape Depiction under Arbitrary Rendering]]></title>

<authors><![CDATA[Vergne, R.;  Pacanowski, R.;  Barla, P.;  Granier, X.;  Shlick, C.]]></authors>

<affiliations><![CDATA[LaBRI, Bordeaux 1 Univ., Talence, France]]></affiliations>

<controlledterms>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[shape recognition]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Materials]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1071]]></spage>

<epage><![CDATA[1081]]></epage>

<abstract><![CDATA[Based on the observation that shading conveys shape information through intensity gradients, we present a new technique called Radiance Scaling that modifies the classical shading equations to offer versatile shape depiction functionalities. It works by scaling reflected light intensities depending on both surface curvature and material characteristics. As a result, diffuse shading or highlight variations become correlated with surface feature variations, enhancing concavities and convexities. The first advantage of such an approach is that it produces satisfying results with any kind of material for direct and global illumination: we demonstrate results obtained with Phong and Ashikmin-Shirley BRDFs, Cartoon shading, sub-Lambertian materials, perfectly reflective or refractive objects. Another advantage is that there is no restriction to the choice of lighting environment: it works with a single light, area lights, and interreflections. Third, it may be adapted to enhance surface shape through the use of precomputed radiance data such as Ambient Occlusion, Prefiltered Environment Maps or Lit Spheres. Finally, our approach works in real time on modern graphics hardware making it suitable for any interactive 3D visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5669300]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.252]]></doi>

<publicationId><![CDATA[5669300]]></publicationId>

<partnum><![CDATA[5669300]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5669300&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669300]]></pdf>

</document>

<document>

<rank>798</rank>

<title><![CDATA[Scheduling in Heterogeneous Computing Environments for Proximity Queries]]></title>

<authors><![CDATA[Duksu Kim;  Jinkyu Lee;  Junghwan Lee;  Insik Shin;  Kim, J.;  Sung-Eui Yoon]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[computer architecture]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[linear programming]]></term>

<term><![CDATA[multiprocessing systems]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[query processing]]></term>

<term><![CDATA[scheduling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Multicore processing]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Scheduling algorithms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1513]]></spage>

<epage><![CDATA[1525]]></epage>

<abstract><![CDATA[We present a novel, linear programming (LP)-based scheduling algorithm that exploits heterogeneous multicore architectures such as CPUs and GPUs to accelerate a wide variety of proximity queries. To represent complicated performance relationships between heterogeneous architectures and different computations of proximity queries, we propose a simple, yet accurate model that measures the expected running time of these computations. Based on this model, we formulate an optimization problem that minimizes the largest time spent on computing resources, and propose a novel, iterative LP-based scheduling algorithm. Since our method is general, we are able to apply our method into various proximity queries used in five different applications that have different characteristics. Our method achieves an order of magnitude performance improvement by using four different GPUs and two hexa-core CPUs over using a hexa-core CPU only. Unlike prior scheduling methods, our method continually improves the performance, as we add more computing resources. Also, our method achieves much higher performance improvement compared with prior methods as heterogeneity of computing resources is increased. Moreover, for one of tested applications, our method achieves even higher performance than a prior parallel method optimized manually for the application. We also show that our method provides results that are close (e.g., 75 percent) to the performance provided by a conservative upper bound of the ideal throughput. These results demonstrate the efficiency and robustness of our algorithm that have not been achieved by prior methods. In addition, we integrate one of our contributions with a work stealing method. Our version of the work stealing method achieves 18 percent performance improvement on average over the original work stealing method. This result shows wide applicability of our approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6494570]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.71]]></doi>

<publicationId><![CDATA[6494570]]></publicationId>

<partnum><![CDATA[6494570]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6494570&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6494570]]></pdf>

</document>

<document>

<rank>799</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1542008]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.6]]></doi>

<publicationId><![CDATA[1542008]]></publicationId>

<partnum><![CDATA[1542008]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1542008&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542008]]></pdf>

</document>

<document>

<rank>800</rank>

<title><![CDATA[ISMAR 2015 EiC Message]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[v]]></spage>

<epage><![CDATA[v]]></epage>

<abstract><![CDATA[Presents the EIC message from this conference.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7283726]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2472755]]></doi>

<publicationId><![CDATA[7283726]]></publicationId>

<partnum><![CDATA[7283726]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7283726&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7283726]]></pdf>

</document>

<document>

<rank>801</rank>

<title><![CDATA[Reducing Photon-Mapping Bandwidth by Query Reordering]]></title>

<authors><![CDATA[Steinhurst, J.;  Coombe, G.;  Lastra, A.]]></authors>

<affiliations><![CDATA[Bucknell Univ., Lewisburg]]></affiliations>

<controlledterms>

<term><![CDATA[cache storage]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[13]]></spage>

<epage><![CDATA[24]]></epage>

<abstract><![CDATA[Photon mapping places an enormous burden on the memory hierarchy. Rendering a 512 x 512 image of a simple scene can require more than 196 Gbytes of raw bandwidth to the photon map data structure. This bandwidth is a major obstacle to real-time photon mapping. This paper investigates two approaches for reducing the required bandwidth: 1) reordering the <i>k</i>NN searches and 2) cache conscious data structures. Using a Hilbert curve reordering, we demonstrate an experimental lower bound of 15 Mbytes of bandwidth for the same scene. Unfortunately, this improvement of four orders of magnitude requires a prohibitive amount of intermediate storage. We introduce two novel cost-effective algorithms that reduce the bandwidth by one order of magnitude. Scenes of different complexities are shown to exhibit similar reductions in bandwidth. We explain why the choice of data structure does not achieve similar reductions. We also examine the interaction of query reordering with two photon map acceleration techniques, importance sampling, and the irradiance cache. Query reordering exploits the additional coherence that arises from the use of importance sampling in scenes with glossy surfaces. Irradiance caching also benefits from query reordering, even when complex surface geometry reduces the effectiveness of the irradiance cache.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359492]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70413]]></doi>

<publicationId><![CDATA[4359492]]></publicationId>

<partnum><![CDATA[4359492]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359492&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359492]]></pdf>

</document>

<document>

<rank>802</rank>

<title><![CDATA[Volume-preserving free-form solids]]></title>

<authors><![CDATA[Rappoport, A.;  Sheffer, A.;  Bercovier, M.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Sci., Hebrew Univ., Jerusalem, Israel]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[deformation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[least squares approximations]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Automatic control]]></term>

<term><![CDATA[Computer industry]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Least squares methods]]></term>

<term><![CDATA[Mechanical engineering]]></term>

<term><![CDATA[Optimization methods]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[19]]></spage>

<epage><![CDATA[27]]></epage>

<abstract><![CDATA[Some important trends in geometric modeling are the reliance on solid models rather than surface-based models and the enhancement of the expressive power of models, by using free-form objects in addition to the usual geometric primitives and by incorporating physical principles. An additional trend is the emphasis on interactive performance. In this paper, we integrate all of these requirements into a single geometric primitive by endowing the tri-variate tensor-product free-form solid with several important physical properties, including volume and internal deformation energy. Volume preservation is of benefit in several application areas of geometric modeling, including computer animation, industrial design and mechanical engineering. However, previous physics-based methods, which have usually used some form of &ldquo;energy&rdquo;, have neglected the issue of volume (or area) preservation. We present a novel method for modeling an object composed of several tensor-product solids while preserving the desired volume of each primitive and ensuring high-order continuity constraints between the primitives. The method utilizes the Uzawa algorithm for non-linear optimization, with objective functions based on deformation energy or least squares. We show how the algorithm can be used in an interactive environment by relaxing exactness requirements while the user interactively manipulates free-form solid primitives. On current workstations, the algorithm runs in real-time for tri-quadratic volumes and close to real-time for tri-cubic volumes]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[489383]]></arnumber>

<doi><![CDATA[10.1109/2945.489383]]></doi>

<publicationId><![CDATA[489383]]></publicationId>

<partnum><![CDATA[489383]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=489383&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=489383]]></pdf>

</document>

<document>

<rank>803</rank>

<title><![CDATA[Cubic Gradient-Based Material Interfaces]]></title>

<authors><![CDATA[Prilepov, I.;  Obermaier, H.;  Deines, E.;  Garth, C.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., UC Davis, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Materials]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1687]]></spage>

<epage><![CDATA[1699]]></epage>

<abstract><![CDATA[Multifluid simulations often create volume fraction data, representing fluid volumes per region or cell of a fluid data set. Accurate and visually realistic extraction of fluid boundaries is a challenging and essential task for efficient analysis of multifluid data. In this work, we present a new material interface reconstruction method for such volume fraction data. Within each cell of the data set, our method utilizes a gradient field approximation based on trilinearly blended Coons-patches to generate a volume fraction function, representing the change in volume fractions over the cells. A continuously varying isovalue field is applied to this function to produce a smooth interface that preserves the given volume fractions well. Further, the method allows user-controlled balance between volume accuracy and physical plausibility of the interface. The method works on two- and three-dimensional Cartesian grids, and handles multiple materials. Calculations are performed locally and utilize only the one-ring of cells surrounding a given cell, allowing visualizations of the material interfaces to be easily generated on a GPU or in a large-scale distributed parallel environment. Our results demonstrate the robustness, accuracy, and flexibility of the developed algorithms.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6461882]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.16]]></doi>

<publicationId><![CDATA[6461882]]></publicationId>

<partnum><![CDATA[6461882]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6461882&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461882]]></pdf>

</document>

<document>

<rank>804</rank>

<title><![CDATA[VisWeek 2012 Capstone Speaker]]></title>

<authors><![CDATA[Frankel, F.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[photography]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[xxii]]></spage>

<epage><![CDATA[xxii]]></epage>

<abstract><![CDATA[What you are doing as visualization researchers and developers is critical and, in fact, your role is more important than ever in this age of massive data. I and many others desperately want to use your work, but sometimes I just cannot seem to wrap my head around what you are showing-even if it really looks cool. Cool doesn't cut it for me. This talk will give examples from my own successes and failures in photography and graphics and suggest, with a little imagination and open minds, there might be some lessons learned from my own commitment to delving into and communicating information.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327302]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.289]]></doi>

<publicationId><![CDATA[6327302]]></publicationId>

<partnum><![CDATA[6327302]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327302&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327302]]></pdf>

</document>

<document>

<rank>805</rank>

<title><![CDATA[2002 reviewers list]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[IEEE]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[111]]></spage>

<epage><![CDATA[112]]></epage>

<abstract><![CDATA[The publication offers a note of thanks and lists its reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1175101]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1175101]]></doi>

<publicationId><![CDATA[1175101]]></publicationId>

<partnum><![CDATA[1175101]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1175101&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1175101]]></pdf>

</document>

<document>

<rank>806</rank>

<title><![CDATA[180,000 Computing Articles in the IEEE Computer Society Digital Library [advertisement]]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Government]]></term>

<term><![CDATA[Information technology]]></term>

<term><![CDATA[Keyboards]]></term>

<term><![CDATA[Software libraries]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[721]]></spage>

<epage><![CDATA[721]]></epage>

<abstract><![CDATA[Advertisement: The IEEE Computer Society Digital Library.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4472707]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.49]]></doi>

<publicationId><![CDATA[4472707]]></publicationId>

<partnum><![CDATA[4472707]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4472707&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4472707]]></pdf>

</document>

<document>

<rank>807</rank>

<title><![CDATA[Memory-efficient ray classification for visibility operations]]></title>

<authors><![CDATA[Bomjun Kwon;  Dae Seoung Kim;  Kyung-Yong Chwa;  Sung Yong Shin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Taejon, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[storage management]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Assembly]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Kirk field collapse effect]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Optical refraction]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Space technology]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[4]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1998]]></py>

<spage><![CDATA[193]]></spage>

<epage><![CDATA[201]]></epage>

<abstract><![CDATA[We present a new ray classification scheme that considerably reduces memory consumption while preserving its inherent time efficiency. Our key idea is due to the fact that the rays lying on the same line are duplicated over many cells in the ray classification scheme. We are thus able to lower the dimensions of the ray space by classifying lines instead of rays. Our scheme produces much simpler-shaped, compact ray cells that eventually accelerate ray shooting operations]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[722294]]></arnumber>

<doi><![CDATA[10.1109/2945.722294]]></doi>

<publicationId><![CDATA[722294]]></publicationId>

<partnum><![CDATA[722294]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=722294&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=722294]]></pdf>

</document>

<document>

<rank>808</rank>

<title><![CDATA[Branching and Circular Features in High Dimensional Data]]></title>

<authors><![CDATA[Bei Wang;  Summa, B.;  Pascucci, V.;  Vejdemo-Johansson, M.]]></authors>

<affiliations><![CDATA[SCI Inst., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1902]]></spage>

<epage><![CDATA[1911]]></epage>

<abstract><![CDATA[Large observations and simulations in scientific research give rise to high-dimensional data sets that present many challenges and opportunities in data analysis and visualization. Researchers in application domains such as engineering, computational biology, climate study, imaging and motion capture are faced with the problem of how to discover compact representations of highdimensional data while preserving their intrinsic structure. In many applications, the original data is projected onto low-dimensional space via dimensionality reduction techniques prior to modeling. One problem with this approach is that the projection step in the process can fail to preserve structure in the data that is only apparent in high dimensions. Conversely, such techniques may create structural illusions in the projection, implying structure not present in the original high-dimensional data. Our solution is to utilize topological techniques to recover important structures in high-dimensional data that contains non-trivial topology. Specifically, we are interested in high-dimensional branching structures. We construct local circle-valued coordinate functions to represent such features. Subsequently, we perform dimensionality reduction on the data while ensuring such structures are visually preserved. Additionally, we study the effects of global circular structures on visualizations. Our results reveal never-before-seen structures on real-world data sets from a variety of applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064953]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.177]]></doi>

<publicationId><![CDATA[6064953]]></publicationId>

<partnum><![CDATA[6064953]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064953&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064953]]></pdf>

</document>

<document>

<rank>809</rank>

<title><![CDATA[Reconstruction and Visualization of Coordinated 3D Cell Migration Based on Optical Flow]]></title>

<authors><![CDATA[Kappe, C.P.;  Schutz, L.;  Gunther, S.;  Hufnagel, L.;  Lemke, S.;  Leitte, H.]]></authors>

<affiliations><![CDATA[IWR, Heidelberg Univ., Heidelberg, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[cellular biophysics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[integration]]></term>

<term><![CDATA[video signal processing]]></term>

<term><![CDATA[zoology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive optics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Embryo]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Optical imaging]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[995]]></spage>

<epage><![CDATA[1004]]></epage>

<abstract><![CDATA[Animal development is marked by the repeated reorganization of cells and cell populations, which ultimately determine form and shape of the growing organism. One of the central questions in developmental biology is to understand precisely how cells reorganize, as well as how and to what extent this reorganization is coordinated. While modern microscopes can record video data for every cell during animal development in 3D+t, analyzing these videos remains a major challenge: reconstruction of comprehensive cell tracks turned out to be very demanding especially with decreasing data quality and increasing cell densities. In this paper, we present an analysis pipeline for coordinated cellular motions in developing embryos based on the optical flow of a series of 3D images. We use numerical integration to reconstruct cellular long-term motions in the optical flow of the video, we take care of data validation, and we derive a LIC-based, dense flow visualization for the resulting pathlines. This approach allows us to handle low video quality such as noisy data or poorly separated cells, and it allows the biologists to get a comprehensive understanding of their data by capturing dynamic growth processes in stills. We validate our methods using three videos of growing fruit fly embryos.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7210213]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467291]]></doi>

<publicationId><![CDATA[7210213]]></publicationId>

<partnum><![CDATA[7210213]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7210213&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210213]]></pdf>

</document>

<document>

<rank>810</rank>

<title><![CDATA[High-Quality Extraction of Isosurfaces from Regular and Irregular Grids]]></title>

<authors><![CDATA[Schreiner, J.;  Scheiclegger, C.E.;  Silva, C.T.]]></authors>

<affiliations><![CDATA[SCI Inst., Utah Univ., Salt Lake City, UT]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Pervasive computing]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1205]]></spage>

<epage><![CDATA[1212]]></epage>

<abstract><![CDATA[Isosurfaces are ubiquitous in many fields, including visualization, graphics, and vision. They are often the main computational component of important processing pipelines (e.g., surface reconstruction), and are heavily used in practice. The classical approach to compute isosurfaces is to apply the Marching Cubes algorithm, which although robust and simple to implement, generates surfaces that require additional processing steps to improve triangle quality and mesh size. An important issue is that in some cases, the surfaces generated by Marching Cubes are irreparably damaged, and important details are lost which can not be recovered by subsequent processing. The main motivation of this work is to develop a technique capable of constructing high-quality and high-fidelity isosurfaces. We propose a new advancing front technique that is capable of creating high-quality isosurfaces from regular and irregular volumetric datasets. Our work extends the guidance field framework of Schreiner et al. to implicit surfaces, and improves it in significant ways. In particular, we describe a set of sampling conditions that guarantee that surface features will be captured by the algorithm. We also describe an efficient technique to compute a minimal guidance field, which greatly improves performance. Our experimental results show that our technique can generate high-quality meshes from complex datasets]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015483]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.149]]></doi>

<publicationId><![CDATA[4015483]]></publicationId>

<partnum><![CDATA[4015483]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015483&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015483]]></pdf>

</document>

<document>

<rank>811</rank>

<title><![CDATA[Vortex Visualization in Ultra Low Reynolds Number Insect Flight]]></title>

<authors><![CDATA[Koehler, C.;  Wischgoll, T.;  Haibo Dong;  Gaston, Z.]]></authors>

<affiliations><![CDATA[Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[vortices]]></term>

<term><![CDATA[wakes]]></term>

<term><![CDATA[zoology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Flow visualization]]></term>

<term><![CDATA[Insects]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2071]]></spage>

<epage><![CDATA[2079]]></epage>

<abstract><![CDATA[We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6064971]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.260]]></doi>

<publicationId><![CDATA[6064971]]></publicationId>

<partnum><![CDATA[6064971]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064971&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064971]]></pdf>

</document>

<document>

<rank>812</rank>

<title><![CDATA[Finding Waldo: Learning about Users from their Interactions]]></title>

<authors><![CDATA[Brown, E.T.;  Ottley, A.;  Zhao, H.;  Quan Lin;  Souvenir, R.;  Endert, A.;  Chang, R.]]></authors>

<affiliations><![CDATA[Tufts Univ., Medford, MA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Computers]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1663]]></spage>

<epage><![CDATA[1672]]></epage>

<abstract><![CDATA[Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875913]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346575]]></doi>

<publicationId><![CDATA[6875913]]></publicationId>

<partnum><![CDATA[6875913]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875913&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875913]]></pdf>

</document>

<document>

<rank>813</rank>

<title><![CDATA[[Advertisement]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[288]]></spage>

<epage><![CDATA[288]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1580464]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.19]]></doi>

<publicationId><![CDATA[1580464]]></publicationId>

<partnum><![CDATA[1580464]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580464&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580464]]></pdf>

</document>

<document>

<rank>814</rank>

<title><![CDATA[Conformal Magnifier: A Focus+Context Technique with Local Shape Preservation]]></title>

<authors><![CDATA[Xin Zhao;  Wei Zeng;  Gu, X.D.;  Kaufman, A.E.;  Wei Xu;  Mueller, K.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[CAD]]></term>

<term><![CDATA[conformal mapping]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[deformation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Conformal mapping]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1928]]></spage>

<epage><![CDATA[1941]]></epage>

<abstract><![CDATA[We present the conformal magnifier, a novel interactive focus+context visualization technique that magnifies a region of interest (ROI) using conformal mapping. Our framework supports the arbitrary shape design of magnifiers for the user to enlarge the ROI while globally deforming the context region without any cropping. By using the mathematically well-defined conformal mapping theory and algorithm, the ROI is magnified with local shape preservation (angle distortion minimization), while the transition area between the focus and context regions is deformed smoothly and continuously. After the selection of a specified magnifier shape, our system can automatically magnify the ROI in real time with full resolution even for large volumetric data sets. These properties are important for many visualization applications, especially for the computer aided detection and diagnosis (CAD). Our framework is suitable for diverse applications, including the map visualization, and volumetric visualization. Experimental results demonstrate the effectiveness, robustness, and efficiency of our framework.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6165273]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.70]]></doi>

<publicationId><![CDATA[6165273]]></publicationId>

<partnum><![CDATA[6165273]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165273&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165273]]></pdf>

</document>

<document>

<rank>815</rank>

<title><![CDATA[Visual Analysis of Large Graphs Using (X,Y)-Clustering and Hybrid Visualizations]]></title>

<authors><![CDATA[Batagelj, V.;  Brandenburg, F.J.;  Didimo, W.;  Liotta, G.;  Palladino, P.;  Patrignani, M.]]></authors>

<affiliations><![CDATA[Dept. of Math., Univ. of Ljubljana, Ljubljana, Slovenia]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[social networking (online)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Social network services]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1587]]></spage>

<epage><![CDATA[1598]]></epage>

<abstract><![CDATA[Many different approaches have been proposed for the challenging problem of visually analyzing large networks. Clustering is one of the most promising. In this paper, we propose a new clustering technique whose goal is that of producing both intracluster graphs and intercluster graph with desired topological properties. We formalize this concept in the (X,Y) -clustering framework, where Y is the class that defines the desired topological properties of intracluster graphs and X is the class that defines the desired topological properties of the intercluster graph. By exploiting this approach, hybrid visualization tools can effectively combine different node-link and matrix-based representations, allowing users to interactively explore the graph by expansion/contraction of clusters without loosing their mental map. As a proof of concept, we describe the system Visual Hybrid (X,Y)-clustering (VHYXY) that implements our approach and we present the results of case studies to the visual analysis of social networks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5674029]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.265]]></doi>

<publicationId><![CDATA[5674029]]></publicationId>

<partnum><![CDATA[5674029]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5674029&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674029]]></pdf>

</document>

<document>

<rank>816</rank>

<title><![CDATA[On a construction of a hierarchy of best linear spline approximations using repeated bisection]]></title>

<authors><![CDATA[Hamann, B.;  Jordan, B.W.;  Wiley, D.F.]]></authors>

<affiliations><![CDATA[Center for Image Process. & Integrated Comput., California Univ., Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[function approximation]]></term>

<term><![CDATA[least squares approximations]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bandwidth]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Least squares approximation]]></term>

<term><![CDATA[Linear approximation]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Sparse matrices]]></term>

<term><![CDATA[Spline]]></term>

<term><![CDATA[Tellurium]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[30]]></spage>

<epage><![CDATA[46]]></epage>

<abstract><![CDATA[We present a method for the construction of hierarchies of single-valued functions in one, two, and three variables. The input to our method is a coarse decomposition of the compact domain of a function in the form of an interval (univariate case), triangles (bivariate case), or tetrahedra (trivariate case). We compute best linear spline approximations, understood in an integral least squares sense, for functions defined over such triangulations and refine triangulations using repeated bisection. This requires the identification of the interval (triangle, tetrahedron) with largest error and splitting it into two intervals (triangles, tetrahedra). Each bisection step requires the recomputation of all spline coefficients due to the global nature of the best approximation problem. Nevertheless, this can be done efficiently by bisecting multiple intervals (triangles, tetrahedra) in one step and by reducing the bandwidths of the matrices resulting from the normal equations]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[764868]]></arnumber>

<doi><![CDATA[10.1109/2945.764868]]></doi>

<publicationId><![CDATA[764868]]></publicationId>

<partnum><![CDATA[764868]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=764868&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=764868]]></pdf>

</document>

<document>

<rank>817</rank>

<title><![CDATA[A Comparison of the Perceptual Benefits of Linear Perspective and Physically-Based Illumination for Display of Dense 3D Streamtubes]]></title>

<authors><![CDATA[Weigle, C.;  Banks, D.C.]]></authors>

<affiliations><![CDATA[Dept. of Electr. Eng. & Comput. Sci., Univ. of Tennessee, Knoxville, TN]]></affiliations>

<controlledterms>

<term><![CDATA[computer vision]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aggregates]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visual system]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1723]]></spage>

<epage><![CDATA[1730]]></epage>

<abstract><![CDATA[Large datasets typically contain coarse features comprised of finer sub-features. Even if the shapes of the small structures are evident in a 3D display, the aggregate shapes they suggest may not be easily inferred. From previous studies in shape perception, the evidence has not been clear whether physically-based illumination confers any advantage over local illumination for understanding scenes that arise in visualization of large data sets that contain features at two distinct scales. In this paper we show that physically-based illumination can improve the perception for some static scenes of complex 3D geometry from flow fields. We perform human-subjects experiments to quantify the effect of physically-based illumination on participant performance for two tasks: selecting the closer of two streamtubes from a field of tubes, and identifying the shape of the domain of a flow field over different densities of tubes. We find that physically-based illumination influences participant performance as strongly as perspective projection, suggesting that physically-based illumination is indeed a strong cue to the layout of complex scenes. We also find that increasing the density of tubes for the shape identification task improved participant performance under physically-based illumination but not under the traditional hardware-accelerated illumination model.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658196]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.108]]></doi>

<publicationId><![CDATA[4658196]]></publicationId>

<partnum><![CDATA[4658196]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658196&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658196]]></pdf>

</document>

<document>

<rank>818</rank>

<title><![CDATA[SimpliFly: A Methodology for Simplification and Thematic Enhancement of Trajectories]]></title>

<authors><![CDATA[Vrotsou, K.;  Janetzko, H.;  Navarra, C.;  Fuchs, G.;  Spretke, D.;  Mansmann, F.;  Andrienko, N.;  Andrienko, G.]]></authors>

<affiliations><![CDATA[Linkoping Univ., Linkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context]]></term>

<term><![CDATA[Ocean temperature]]></term>

<term><![CDATA[Satellite broadcasting]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[107]]></spage>

<epage><![CDATA[121]]></epage>

<abstract><![CDATA[Movement data sets collected using today's advanced tracking devices consist of complex trajectories in terms of length, shape, and number of recorded positions. Multiple additional attributes characterizing the movement and its environment are often also included making the level of complexity even higher. Simplification of trajectories can improve the visibility of relevant information by reducing less relevant details while maintaining important movement patterns. We propose a systematic stepwise methodology for simplifying and thematically enhancing trajectories in order to support their visual analysis. The methodology is applied iteratively and is composed of: (a) a simplification step applied to reduce the morphological complexity of the trajectories, (b) a thematic enhancement step which aims at accentuating patterns of movement, and (c) the representation and interactive exploration of the results in order to make interpretations of the findings and further refinement to the simplification and enhancement process. We illustrate our methodology through an analysis example of two different types of tracks, aircraft and pedestrian movement.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6851202]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2337333]]></doi>

<publicationId><![CDATA[6851202]]></publicationId>

<partnum><![CDATA[6851202]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6851202&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6851202]]></pdf>

</document>

<document>

<rank>819</rank>

<title><![CDATA[Out-of-core streamline visualization on large unstructured meshes]]></title>

<authors><![CDATA[Shyh-Kuang Ueng;  Sikorski, C.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Nat. Taiwan Ocean Univ., Keelung, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[octrees]]></term>

<term><![CDATA[scheduling]]></term>

<term><![CDATA[software performance evaluation]]></term>

<term><![CDATA[storage management]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed computing]]></term>

<term><![CDATA[Information retrieval]]></term>

<term><![CDATA[Memory management]]></term>

<term><![CDATA[Partitioning algorithms]]></term>

<term><![CDATA[Processor scheduling]]></term>

<term><![CDATA[Workstations]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[370]]></spage>

<epage><![CDATA[380]]></epage>

<abstract><![CDATA[This paper presents an out-of-core approach for interactive streamline construction on large unstructured tetrahedral meshes containing millions of elements. The out-of-core algorithm uses an octree to partition and restructure the raw data into subsets stored into disk files for fast data retrieval. A memory management policy tailored to the streamline calculations is used such that, during the streamline construction, only a very small amount of data are brought into the main memory on demand. By carefully scheduling computation and data fetching, the overhead of reading data from the disk is significantly reduced and good memory performance results. This out-of-core algorithm makes possible interactive streamline visualization of large unstructured-grid data sets on a single mid-range workstation with relatively low main-memory capacity: 5-15 megabytes. We also demonstrate that this approach is much more efficient than relying on virtual memory and operating system's paging algorithms]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[646239]]></arnumber>

<doi><![CDATA[10.1109/2945.646239]]></doi>

<publicationId><![CDATA[646239]]></publicationId>

<partnum><![CDATA[646239]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=646239&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=646239]]></pdf>

</document>

<document>

<rank>820</rank>

<title><![CDATA[Interactive Mesostructures withVolumetric Collisions]]></title>

<authors><![CDATA[Nykl, S.;  Mourning, C.;  Chelberg, D.]]></authors>

<affiliations><![CDATA[Dept. of Electr. Eng. & Comput. Sci., Ohio Univ., Athens, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics processing units]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Physics]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[970]]></spage>

<epage><![CDATA[982]]></epage>

<abstract><![CDATA[This paper presents a technique for interactively colliding with and deforming mesostructures at a per-texel level. It is compatible with a broad range of existing mesostructure rendering techniques including both safe and unsafe ray-height field intersection algorithms. This technique is able to replace traditional 3D geometrical deformations (vertex-based) with 2D image space operations (pixel-based) that are parallelized on a GPU without CPU-GPU data shuffling and integrates well with existing physics engines. Additionally, surface and material properties may be specified at a per-texel level enabling a mesostructure to possess varying attributes intrinsic to its surface and collision behavior. Furthermore, this approach may replace traditional decals with image-based operations that naturally accumulate deformations without inserting any new geometry. This technique provides a simple and efficient way to make almost every surface in a virtual world responsive to user actions and events. It requires no preprocessing time and storage requirements of one additional texture or less. The algorithm uses existing inverse displacement map algorithms as well as existing physics engines and can be easily incorporated into new or existing game pipelines.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6799298]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2317700]]></doi>

<publicationId><![CDATA[6799298]]></publicationId>

<partnum><![CDATA[6799298]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6799298&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799298]]></pdf>

</document>

<document>

<rank>821</rank>

<title><![CDATA[HDR VolVis: high dynamic range volume visualization]]></title>

<authors><![CDATA[Xiaoru Yuan;  Nguyen, M.Z.;  Baoquan Chen;  Porter, D.H.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Minnesota Univ., Minneapolis, MN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[display devices]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Dynamic range]]></term>

<term><![CDATA[Fluctuations]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[433]]></spage>

<epage><![CDATA[445]]></epage>

<abstract><![CDATA[In this paper, we present an interactive high dynamic range volume visualization framework (HDR VolVis) for visualizing volumetric data with both high spatial and intensity resolutions. Volumes with high dynamic range values require high precision computing during the rendering process to preserve data precision. Furthermore, it is desirable to render high resolution volumes with low opacity values to reveal detailed internal structures, which also requires high precision compositing. High precision rendering will result in a high precision intermediate image (also known as high dynamic range image). Simply rounding up pixel values to regular display scales will result in loss of computed details. Our method performs high precision compositing followed by dynamic tone mapping to preserve details on regular display devices. Rendering high precision volume data requires corresponding resolution in the transfer function. To assist the users in designing a high resolution transfer function on a limited resolution display device, we propose a novel transfer function specification interface with nonlinear magnification of the density range and logarithmic scaling of the color/opacity range. By leveraging modern commodity graphics hardware, multiresolution rendering techniques and out-of-core acceleration, our system can effectively produce an interactive visualization of large volume data, such as 2.048<sup>3</sup>.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1634310]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.72]]></doi>

<publicationId><![CDATA[1634310]]></publicationId>

<partnum><![CDATA[1634310]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1634310&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1634310]]></pdf>

</document>

<document>

<rank>822</rank>

<title><![CDATA[Quartic Box-Spline Reconstruction on the BCC Lattice]]></title>

<authors><![CDATA[Minho Kim]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci., Univ. of Seoul, Seoul, South Korea]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[polynomial approximation]]></term>

<term><![CDATA[signal reconstruction]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[FCC]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[319]]></spage>

<epage><![CDATA[330]]></epage>

<abstract><![CDATA[This paper presents an alternative box-spline filter for the body-centered cubic (BCC) lattice, the seven-direction quartic box-spline M<sub>7</sub> that has the same approximation order as the eight-direction quintic box-spline M<sub>8</sub> but a lower polynomial degree, smaller support, and is computationally more efficient. When applied to reconstruction with quasi-interpolation prefilters, M<sub>7</sub> shows less aliasing, which is verified quantitatively by integral filter metrics and frequency error kernels. To visualize and analyze distributional aliasing characteristics, each spectrum is evaluated on the planes and lines with various orientations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6200269]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.130]]></doi>

<publicationId><![CDATA[6200269]]></publicationId>

<partnum><![CDATA[6200269]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6200269&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200269]]></pdf>

</document>

<document>

<rank>823</rank>

<title><![CDATA[Sampling and Visualizing Creases with Scale-Space Particles]]></title>

<authors><![CDATA[Kindlmann, G.L.;  Estepar, R.S.J.;  Smith, S.M.;  Westin, C.-F.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Chicago, Chicago, IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anatomical structure]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Spline]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1415]]></spage>

<epage><![CDATA[1424]]></epage>

<abstract><![CDATA[Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290756]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.177]]></doi>

<publicationId><![CDATA[5290756]]></publicationId>

<partnum><![CDATA[5290756]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290756&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290756]]></pdf>

</document>

<document>

<rank>824</rank>

<title><![CDATA[VIS International Program Committees]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[xviii]]></spage>

<epage><![CDATA[xix]]></epage>

<abstract><![CDATA[Presents a listing of the conference program committee.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7307921]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2471377]]></doi>

<publicationId><![CDATA[7307921]]></publicationId>

<partnum><![CDATA[7307921]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7307921&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307921]]></pdf>

</document>

<document>

<rank>825</rank>

<title><![CDATA[IEEE Visualization Conference and IEEE Information Visualization Conference Proceedings 2011 title page]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[i]]></spage>

<epage><![CDATA[ii]]></epage>

<abstract><![CDATA[Provides notice of upcoming conference events of interest to practitioners and researchers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6064927]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.210]]></doi>

<publicationId><![CDATA[6064927]]></publicationId>

<partnum><![CDATA[6064927]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064927&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064927]]></pdf>

</document>

<document>

<rank>826</rank>

<title><![CDATA[Interactive Approximate Rendering of Reflections, Refractions, and Caustics]]></title>

<authors><![CDATA[Wei Hu;  Kaihuai Qin]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[realistic images]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Optical reflection]]></term>

<term><![CDATA[Optical refraction]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[46]]></spage>

<epage><![CDATA[57]]></epage>

<abstract><![CDATA[Reflections, refractions, and caustics are very important for rendering global illumination images. Although many methods can be applied to generate these effects, the rendering performance is not satisfactory for interactive applications. In this paper, complex ray-object intersections are simplified so that the intersections can be computed on a GPU, and an iterative computing scheme based on the depth buffers is used for correcting the approximate results caused by the simplification. As a result, reflections and refractions of environment maps and nearby geometry can be rendered on a GPU interactively without preprocessing. We can even achieve interactive recursive reflections and refractions by using an object-impostor technique. Moreover, caustic effects caused by reflections and refractions can be rendered by placing the eye at the light. Rendered results prove that our method is sufficiently efficient to render plausible images interactively for many interactive applications]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015397]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.14]]></doi>

<publicationId><![CDATA[4015397]]></publicationId>

<partnum><![CDATA[4015397]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015397&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015397]]></pdf>

</document>

<document>

<rank>827</rank>

<title><![CDATA[Task-Driven Comparison of Topic Models]]></title>

<authors><![CDATA[Alexander, E.;  Gleicher, M.]]></authors>

<affiliations><![CDATA[Univ. of Wisconsin-Madison, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Color]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Numerical models]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[320]]></spage>

<epage><![CDATA[329]]></epage>

<abstract><![CDATA[Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7194832]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467618]]></doi>

<publicationId><![CDATA[7194832]]></publicationId>

<partnum><![CDATA[7194832]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7194832&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194832]]></pdf>

</document>

<document>

<rank>828</rank>

<title><![CDATA[Hybrid Rendering with Scheduling under Uncertainty]]></title>

<authors><![CDATA[Tamm, G.;  Kru&#x0308; ger, J.]]></authors>

<affiliations><![CDATA[DFKI, Saarbrucken, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Probabilistic logic]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Schedules]]></term>

<term><![CDATA[Servers]]></term>

<term><![CDATA[Timing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[767]]></spage>

<epage><![CDATA[780]]></epage>

<abstract><![CDATA[As scientific data of increasing size is generated by today's simulations and measurements, utilizing dedicated server resources to process the visualization pipeline becomes necessary. In a purely server-based approach, requirements on the client-side are minimal as the client only displays results received from the server. However, the client may have a considerable amount of hardware available, which is left idle. Further, the visualization is put at the whim of possibly unreliable server and network conditions. Server load, bandwidth and latency may substantially affect the response time on the client. In this paper, we describe a hybrid method, where visualization workload is assigned to server and client. A capable client can produce images independently. The goal is to determine a workload schedule that enables a synergy between the two sides to provide rendering results to the user as fast as possible. The schedule is determined based on processing and transfer timings obtained at runtime. Our probabilistic scheduler adapts to changing conditions by shifting workload between server and client, and accounts for the performance variability in the dynamic system.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6727579]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2303092]]></doi>

<publicationId><![CDATA[6727579]]></publicationId>

<partnum><![CDATA[6727579]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6727579&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727579]]></pdf>

</document>

<document>

<rank>829</rank>

<title><![CDATA[BiSet: Semantic Edge Bundling with Biclusters for Sensemaking]]></title>

<authors><![CDATA[Maoyuan Sun;  Peng Mi;  North, C.;  Ramakrishnan, N.]]></authors>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cities and towns]]></term>

<term><![CDATA[Clutter]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Semantics]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[310]]></spage>

<epage><![CDATA[319]]></epage>

<abstract><![CDATA[Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, &#x201C;in-between&#x201D;, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192715]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467813]]></doi>

<publicationId><![CDATA[7192715]]></publicationId>

<partnum><![CDATA[7192715]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192715&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192715]]></pdf>

</document>

<document>

<rank>830</rank>

<title><![CDATA[Interactive Visualization of Rotational Symmetry Fields on Surfaces]]></title>

<authors><![CDATA[Palacios, J.;  Zhang, E.]]></authors>

<affiliations><![CDATA[Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[probability]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[947]]></spage>

<epage><![CDATA[955]]></epage>

<abstract><![CDATA[Rotational symmetries (RoSys) have found uses in several computer graphics applications, such as global surface parameterization, geometry remeshing, texture and geometry synthesis, and nonphotorealistic visualization of surfaces. The visualization of N-way rotational symmetry (N-RoSy) fields is a challenging problem due to the ambiguities in the N directions represented by an N-way symmetry. We provide an algorithm that allows faithful and interactive representation of N-RoSy fields in the plane and on surfaces, by adapting the well-known line integral convolution (LIC) technique from vector and second-order tensor fields. Our algorithm captures N directions associated with each point in a given field by decomposing the field into multiple different vector fields, generating LIC images of these fields, and then blending the results. To address the loss of contrast caused by the blending of images, we observe that the pixel values in LIC images closely approximate normally distributed random variables. This allows us to use concepts from probability theory to correct the loss of contrast without the need to perform any image analysis at each frame.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5582087]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.121]]></doi>

<publicationId><![CDATA[5582087]]></publicationId>

<partnum><![CDATA[5582087]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5582087&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582087]]></pdf>

</document>

<document>

<rank>831</rank>

<title><![CDATA[Towards an Understanding of Mobile Touch Navigation in a Stereoscopic Viewing Environment for 3D Data Exploration]]></title>

<authors><![CDATA[Lopez, D.;  Oehlberg, L.;  Doger, C.;  Isenberg, T.]]></authors>

<affiliations><![CDATA[David Lopez is with Inria, France, and University of Antioquia, Colombia.(email:david.lopezb@udea.edu.co)]]></affiliations>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Mobile handsets]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Stereo image processing]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[We discuss touch-based navigation of 3D visualizations in a combined monoscopic and stereoscopic viewing environment. We identify a set of interaction modes, and a workflow that helps users transition between these modes to improve their interaction experience. In our discussion we analyze, in particular, the control-display space mapping between the different reference frames of the stereoscopic and monoscopic displays. We show how this mapping supports interactive data exploration, but may also lead to conflicts between the stereoscopic and monoscopic views due to users&#x2019; movement in space; we resolve these problems through synchronization. To support our discussion, we present results from an exploratory observational evaluation with domain experts in fluid mechanics and structural biology. These experts explored domain-specific datasets using variations of a system that embodies the interaction modes and workflows; we report on their interactions and qualitative feedback on the system and its workflow.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7118242]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2440233]]></doi>

<publicationId><![CDATA[7118242]]></publicationId>

<partnum><![CDATA[7118242]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7118242&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118242]]></pdf>

</document>

<document>

<rank>832</rank>

<title><![CDATA[Effects of VR System Fidelity on Analyzing Isosurface Visualization of Volume Datasets]]></title>

<authors><![CDATA[Laha, B.;  Bowman, D.A.;  Socha, J.J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Abstracts]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[513]]></spage>

<epage><![CDATA[522]]></epage>

<abstract><![CDATA[Volume visualization is an important technique for analyzing datasets from a variety of different scientific domains. Volume data analysis is inherently difficult because volumes are three-dimensional, dense, and unfamiliar, requiring scientists to precisely control the viewpoint and to make precise spatial judgments. Researchers have proposed that more immersive (higher fidelity) VR systems might improve task performance with volume datasets, and significant results tied to different components of display fidelity have been reported. However, more information is needed to generalize these results to different task types, domains, and rendering styles. We visualized isosurfaces extracted from synchrotron microscopic computed tomography (SR-&#x03BC;CT) scans of beetles, in a CAVE-like display. We ran a controlled experiment evaluating the effects of three components of system fidelity (field of regard, stereoscopy, and head tracking) on a variety of abstract task categories that are applicable to various scientific domains, and also compared our results with those from our prior experiment using 3D texture-based rendering. We report many significant findings. For example, for search and spatial judgment tasks with isosurface visualization, a stereoscopic display provides better performance, but for tasks with 3D texture-based rendering, displays with higher field of regard were more effective, independent of the levels of the other display components. We also found that systems with high field of regard and head tracking improve performance in spatial judgment tasks. Our results extend existing knowledge and produce new guidelines for designing VR systems to improve the effectiveness of volume data analysis.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6777465]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.20]]></doi>

<publicationId><![CDATA[6777465]]></publicationId>

<partnum><![CDATA[6777465]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777465&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777465]]></pdf>

</document>

<document>

<rank>833</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[4530426]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.74]]></doi>

<publicationId><![CDATA[4530426]]></publicationId>

<partnum><![CDATA[4530426]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4530426&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4530426]]></pdf>

</document>

<document>

<rank>834</rank>

<title><![CDATA[Interactive ray tracing for volume visualization]]></title>

<authors><![CDATA[Parker, S.;  Parker, M.;  Livnat, Y.;  Sloan, P.-P.;  Hansen, C.;  Shirley, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[colour graphics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[distributed shared memory systems]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[parallel programming]]></term>

<term><![CDATA[ray tracing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Flat panel displays]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scalability]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[238]]></spage>

<epage><![CDATA[250]]></epage>

<abstract><![CDATA[Presents a brute-force ray-tracing system for interactive volume visualization. The system runs on a conventional (distributed) shared-memory multiprocessor machine. For each pixel, we trace a ray through a volume to compute the color for that pixel. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large data sets on current high-end parallel systems. To gain efficiency, several optimizations are used, including a volume bricking scheme and a shallow data hierarchy. These optimizations are used in three separate visualization algorithms: isosurfacing of rectilinear data, isosurfacing of unstructured data, and maximum-intensity projection on rectilinear data. The system runs interactively (i.e. at several frames per second) on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[795215]]></arnumber>

<doi><![CDATA[10.1109/2945.795215]]></doi>

<publicationId><![CDATA[795215]]></publicationId>

<partnum><![CDATA[795215]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=795215&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=795215]]></pdf>

</document>

<document>

<rank>835</rank>

<title><![CDATA[The floating column algorithm for shaded, parallel display of function surfaces without patches]]></title>

<authors><![CDATA[Gordon, D.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Haifa Univ., Israel]]></affiliations>

<controlledterms>

<term><![CDATA[antialiasing]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[image resolution]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[parallel algorithms]]></term>

<term><![CDATA[real-time systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sampling methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Software algorithms]]></term>

<term><![CDATA[Workstations]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[76]]></spage>

<epage><![CDATA[91]]></epage>

<abstract><![CDATA[The floating column algorithm is a new method for the shaded rendering of function surfaces. Derived from the monochromatic floating horizon algorithm, it uses the partial derivatives of the function to compute surface normals, thus enabling intensity or normal-interpolation shading. Current rendering methods require tiling the surface with patches, so higher-resolution patching is required for zoom-in views, interactive modification or time-varying surfaces. The new algorithm requires no patching and uses only constant space, so it can be implemented on graphics cards and hand-held devices. Each pixel column is displayed independently of the others, and this "independent column mode" makes the algorithm inherently parallel in the image space, so it is suitable for multiprocessor workstations and clusters and it is scalable in the resolution size. Furthermore, the sampling frequency of the surface can be controlled locally, matching local surface features, distance or artifact elimination requirements. Space-efficient super-sampling for anti-aliasing is also possible. The new algorithm, which allows orthogonal and perspective projections, produces pixel-wide strips which can be displayed in software or hardware. Various extensions are described, including shadows and texture mapping. These properties, together with the algorithm's parallelism, make it potentially useful for the real-time display of functionally-defined textured terrains and the animated display of time-varying surfaces]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[981853]]></arnumber>

<doi><![CDATA[10.1109/2945.981853]]></doi>

<publicationId><![CDATA[981853]]></publicationId>

<partnum><![CDATA[981853]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=981853&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981853]]></pdf>

</document>

<document>

<rank>836</rank>

<title><![CDATA[Sequence Surveyor: Leveraging Overview for Scalable Genomic Alignment Visualization]]></title>

<authors><![CDATA[Albers, D.;  Dewey, C.;  Gleicher, M.]]></authors>

<affiliations><![CDATA[Univ. of Wisconsin-Madison, Madison, WI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[genomics]]></term>

<term><![CDATA[signal processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Design methodology]]></term>

<term><![CDATA[Genomics]]></term>

<term><![CDATA[Image color analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2392]]></spage>

<epage><![CDATA[2401]]></epage>

<abstract><![CDATA[In this paper, we introduce overview visualization tools for large-scale multiple genome alignment data. Genome alignment visualization and, more generally, sequence alignment visualization are an important tool for understanding genomic sequence data. As sequencing techniques improve and more data become available, greater demand is being placed on visualization tools to scale to the size of these new datasets. When viewing such large data, we necessarily cannot convey details, rather we specifically design overview tools to help elucidate large-scale patterns. Perceptual science, signal processing theory, and generality provide a framework for the design of such visualizations that can scale well beyond current approaches. We present Sequence Surveyor, a prototype that embodies these ideas for scalable multiple whole-genome alignment overview visualization. Sequence Surveyor visualizes sequences in parallel, displaying data using variable color, position, and aggregation encodings. We demonstrate how perceptual science can inform the design of visualization techniques that remain visually manageable at scale and how signal processing concepts can inform aggregation schemes that highlight global trends, outliers, and overall data distributions as the problem scales. These techniques allow us to visualize alignments with over 100 whole bacterial-sized genomes.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065006]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.232]]></doi>

<publicationId><![CDATA[6065006]]></publicationId>

<partnum><![CDATA[6065006]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065006&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065006]]></pdf>

</document>

<document>

<rank>837</rank>

<title><![CDATA[Ordered Boolean List (OBL): Reducing the Footprint for Evaluating Boolean Expressions]]></title>

<authors><![CDATA[Rossignac, Jarek]]></authors>

<affiliations><![CDATA[Sch. of Interactive Comput., Georgia Tech, Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Boolean algebra]]></term>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[parallel architectures]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Boolean functions]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Solids]]></term>

<term><![CDATA[Switches]]></term>

<term><![CDATA[Weaving]]></term>

<term><![CDATA[Wiring]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1337]]></spage>

<epage><![CDATA[1351]]></epage>

<abstract><![CDATA[An Expanded Boolean Expression (EBE) does not contain any XOR or EQUAL operators. The occurrence of each variable is a different literal. We provide a linear time algorithm that converts an EBE of n literals into a logically equivalent Ordered Boolean List (OBL) and show how to use the OBL to evaluate the EBE in n steps and O(log log n) space, if the values of the literals are each read once in the order prescribed by the OBL. (An evaluation workspace of 5 bits suffices for all EBEs of up to six billion literals.) The primary application is the SIMD architecture, where the same EBE is evaluated in parallel for different input vectors when rendering solid models on the GPU directly from their Constructive Solid Geometry (CSG) representation. We compare OBL to the Reduced Ordered Binary Decision Diagram (ROBDD) and suggest possible applications of OBL to logic verification and to circuit design.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5611514]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.232]]></doi>

<publicationId><![CDATA[5611514]]></publicationId>

<partnum><![CDATA[5611514]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5611514&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611514]]></pdf>

</document>

<document>

<rank>838</rank>

<title><![CDATA[Aggregate Constraints for Virtual Manipulation with Soft Fingers]]></title>

<authors><![CDATA[Talvas, A.;  Marchal, M.;  Duriez, C.;  Otaduy, M.A.]]></authors>

<affiliations><![CDATA[Inria Rennes & INSA Rennes, France]]></affiliations>

<controlledterms>

<term><![CDATA[constraint handling]]></term>

<term><![CDATA[control engineering computing]]></term>

<term><![CDATA[dexterous manipulators]]></term>

<term><![CDATA[friction]]></term>

<term><![CDATA[mechanical contact]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[torsion]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aggregates]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Force]]></term>

<term><![CDATA[Friction]]></term>

<term><![CDATA[Grasping]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[452]]></spage>

<epage><![CDATA[461]]></epage>

<abstract><![CDATA[Interactive dexterous manipulation of virtual objects remains a complex challenge that requires both appropriate hand models and accurate physically-based simulation of interactions. In this paper, we propose an approach based on novel aggregate constraints for simulating dexterous grasping using soft fingers. Our approach aims at improving the computation of contact mechanics when many contact points are involved, by aggregating the multiple contact constraints into a minimal set of constraints. We also introduce a method for non-uniform pressure distribution over the contact surface, to adapt the response when touching sharp edges. We use the Coulomb-Contensou friction model to efficiently simulate tangential and torsional friction. We show through different use cases that our aggregate constraint formulation is well-suited for simulating interactively dexterous manipulation of virtual objects through soft fingers, and efficiently reduces the computation time of constraint solving.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7010977]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2391863]]></doi>

<publicationId><![CDATA[7010977]]></publicationId>

<partnum><![CDATA[7010977]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7010977&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7010977]]></pdf>

</document>

<document>

<rank>839</rank>

<title><![CDATA[Visualizing Causal Semantics Using Animations]]></title>

<authors><![CDATA[Kadaba, N.R.;  Irani, P.P.;  Leboe, J.]]></authors>

<affiliations><![CDATA[Univ. of Manitoba, Winnipeg]]></affiliations>

<controlledterms>

<term><![CDATA[behavioural sciences computing]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Fires]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Iron]]></term>

<term><![CDATA[Motion pictures]]></term>

<term><![CDATA[Physics]]></term>

<term><![CDATA[Spatiotemporal phenomena]]></term>

<term><![CDATA[Tires]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1254]]></spage>

<epage><![CDATA[1261]]></epage>

<abstract><![CDATA[Michotte's theory of ampliation suggests that causal relationships are perceived by objects animated under appropriate spatiotemporal conditions. We extend the theory of ampliation and propose that the immediate perception of complex causal relations is also dependent on a set of structural and temporal rules. We designed animated representations, based on Michotte's rules, for showing complex causal relationships or causal semantics. In this paper we describe a set of animations for showing semantics such as causal amplification, causal strength, causal dampening, and causal multiplicity. In a two part study we compared the effectiveness of both the static and animated representations. The first study (N=44) asked participants to recall passages that were previously displayed using both types of representations. Participants were 8% more accurate in recalling causal semantics when they were presented using animations instead of static graphs. In the second study (N=112) we evaluated the intuitiveness of the representations. Our results showed that while users were as accurate with the static graphs as with the animations, they were 9% faster in matching the correct causal statements in the animated condition. Overall our results show that animated diagrams that are designed based on perceptual rules such as those proposed by Michotte have the potential to facilitate comprehension of complex causal relations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376148]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70528]]></doi>

<publicationId><![CDATA[4376148]]></publicationId>

<partnum><![CDATA[4376148]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376148&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376148]]></pdf>

</document>

<document>

<rank>840</rank>

<title><![CDATA[Sketch-Based Image Retrieval: Benchmark and Bag-of-Features Descriptors]]></title>

<authors><![CDATA[Eitz, M.;  Hildebrand, K.;  Boubekeur, T.;  Alexa, M.]]></authors>

<affiliations><![CDATA[Fak. IV-Elektrotechnik & Inf., Tech. Univ. Berlin, Berlin, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[image matching]]></term>

<term><![CDATA[image retrieval]]></term>

<term><![CDATA[visual databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Benchmark testing]]></term>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Image retrieval]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1624]]></spage>

<epage><![CDATA[1636]]></epage>

<abstract><![CDATA[We introduce a benchmark for evaluating the performance of large-scale sketch-based image retrieval systems. The necessary data are acquired in a controlled user study where subjects rate how well given sketch/image pairs match. We suggest how to use the data for evaluating the performance of sketch-based image retrieval systems. The benchmark data as well as the large image database are made publicly available for further studies of this type. Furthermore, we develop new descriptors based on the bag-of-features approach and use the benchmark to demonstrate that they significantly outperform other descriptors in the literature.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5674030]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.266]]></doi>

<publicationId><![CDATA[5674030]]></publicationId>

<partnum><![CDATA[5674030]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5674030&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674030]]></pdf>

</document>

<document>

<rank>841</rank>

<title><![CDATA[Regularization Based Iterative Point Match Weighting for Accurate Rigid Transformation Estimation]]></title>

<authors><![CDATA[Yonghuai Liu;  De Dominicis, L.;  Baogang Wei;  Liang Chen;  Martin, R.R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Aberystwyth Univ., Ceredigion, UK]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[computer vision]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[least squares approximations]]></term>

<term><![CDATA[object recognition]]></term>

<term><![CDATA[optical scanners]]></term>

<term><![CDATA[parameter estimation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Finite element analysis]]></term>

<term><![CDATA[Linear programming]]></term>

<term><![CDATA[Reliability]]></term>

<term><![CDATA[Shape]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1058]]></spage>

<epage><![CDATA[1071]]></epage>

<abstract><![CDATA[Feature extraction and matching (FEM) for 3D shapes finds numerous applications in computer graphics and vision for object modeling, retrieval, morphing, and recognition. However, unavoidable incorrect matches lead to inaccurate estimation of the transformation relating different datasets. Inspired by AdaBoost, this paper proposes a novel iterative re-weighting method to tackle the challenging problem of evaluating point matches established by typical FEM methods. Weights are used to indicate the degree of belief that each point match is correct. Our method has three key steps: (i) estimation of the underlying transformation using weighted least squares, (ii) penalty parameter estimation via minimization of the weighted variance of the matching errors, and (iii) weight re-estimation taking into account both matching errors and information learnt in previous iterations. A comparative study, based on real shapes captured by two laser scanners, shows that the proposed method outperforms four other state-of-the-art methods in terms of evaluating point matches between overlapping shapes established by two typical FEM methods, resulting in more accurate estimates of the underlying transformation. This improved transformation can be used to better initialize the iterative closest point algorithm and its variants, making 3D shape registration more likely to succeed.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7055263]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2410272]]></doi>

<publicationId><![CDATA[7055263]]></publicationId>

<partnum><![CDATA[7055263]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7055263&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7055263]]></pdf>

</document>

<document>

<rank>842</rank>

<title><![CDATA[Editor's note]]></title>

<authors><![CDATA[Ebert, D.S.]]></authors>

<affiliations><![CDATA[University of Utah]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1260753]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1260753]]></doi>

<publicationId><![CDATA[1260753]]></publicationId>

<partnum><![CDATA[1260753]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260753&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260753]]></pdf>

</document>

<document>

<rank>843</rank>

<title><![CDATA[Illustrative interactive stipple rendering]]></title>

<authors><![CDATA[Aidong Lu;  Morris, C.J.;  Taylor, J.;  Ebert, D.S.;  Hansen, C.;  Rheingans, P.;  Hartner, M.]]></authors>

<affiliations><![CDATA[Rendering & Perceptualization Lab., Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical engineering]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Concrete]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Data engineering]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Ink]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surgery]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[127]]></spage>

<epage><![CDATA[138]]></epage>

<abstract><![CDATA[Simulating hand-drawn illustration can succinctly express information in a manner that is communicative and informative. We present a framework for an interactive direct stipple rendering of volume and surface-based objects. By combining the principles of artistic and scientific illustration, we explore several feature enhancement techniques to create effective, interactive visualizations of scientific and medical data sets. We also introduce a rendering mechanism that generates appropriate point lists at all resolutions during an automatic preprocess and modifies rendering styles through different combinations of these feature enhancements. The new system is an effective way to interactively preview large, complex volume and surface data sets in a concise, meaningful, and illustrative manner. Stippling is effective for many applications and provides a quick and efficient method to investigate both volume and surface models.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1196001]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1196001]]></doi>

<publicationId><![CDATA[1196001]]></publicationId>

<partnum><![CDATA[1196001]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1196001&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196001]]></pdf>

</document>

<document>

<rank>844</rank>

<title><![CDATA[Interactive visualization of state transition systems]]></title>

<authors><![CDATA[van Ham, F.;  Van De Wetering, H.;  van Wijk, J.J.]]></authors>

<affiliations><![CDATA[Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Optimized production technology]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Space technology]]></term>

<term><![CDATA[State-space methods]]></term>

<term><![CDATA[System recovery]]></term>

<term><![CDATA[Testing]]></term>

<term><![CDATA[Tree data structures]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[319]]></spage>

<epage><![CDATA[329]]></epage>

<abstract><![CDATA[A new method for the visualization of state transition systems is presented. Visual information is reduced by clustering nodes, forming a tree structure of related clusters. This structure is visualized in three dimensions with concepts from cone trees and emphasis on symmetry. A number of interactive options are provided as well, allowing the user to superimpose detail information on this tree structure. The resulting visualization enables the user to relate features in the visualization of the state transition graph to semantic concepts in the corresponding process and vice versa]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1044518]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2002.1044518]]></doi>

<publicationId><![CDATA[1044518]]></publicationId>

<partnum><![CDATA[1044518]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1044518&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044518]]></pdf>

</document>

<document>

<rank>845</rank>

<title><![CDATA[Annual Index]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[730]]></spage>

<epage><![CDATA[736]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under he primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1333670]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.37]]></doi>

<publicationId><![CDATA[1333670]]></publicationId>

<partnum><![CDATA[1333670]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1333670&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333670]]></pdf>

</document>

<document>

<rank>846</rank>

<title><![CDATA[Exploring the Spectrum of Dynamic Scheduling Algorithms for Scalable Distributed-MemoryRay Tracing]]></title>

<authors><![CDATA[Navra&#x0301; til, P.A.;  Childs, H.;  Fussell, D.S.;  Lin, C.]]></authors>

<affiliations><![CDATA[Texas Adv. Comput. Center, Univ. of Texas at Austin, Austin, TX, USA]]></affiliations>

<controlledterms>

<term><![CDATA[distributed memory systems]]></term>

<term><![CDATA[dynamic scheduling]]></term>

<term><![CDATA[parallel algorithms]]></term>

<term><![CDATA[processor scheduling]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Coherence]]></term>

<term><![CDATA[Dynamic scheduling]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Processor scheduling]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Schedules]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[893]]></spage>

<epage><![CDATA[906]]></epage>

<abstract><![CDATA[This paper extends and evaluates a family of dynamic ray scheduling algorithms that can be performed in-situ on large distributed memory parallel computers. The key idea is to consider both ray state and data accesses when scheduling ray computations. We compare three instances of this family of algorithms against two traditional statically scheduled schemes. We show that our dynamic scheduling approach can render data sets that are larger than aggregate system memory and that cannot be rendered by existing statically scheduled ray tracers. For smaller problems that fit in aggregate memory but are larger than typical shared memory, our dynamic approach is competitive with the best static scheduling algorithm.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6674299]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.261]]></doi>

<publicationId><![CDATA[6674299]]></publicationId>

<partnum><![CDATA[6674299]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6674299&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6674299]]></pdf>

</document>

<document>

<rank>847</rank>

<title><![CDATA[Modeling and rendering of points with local geometry]]></title>

<authors><![CDATA[Kalaiah, A.;  Varshney, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[differential geometry]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Information geometry]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[30]]></spage>

<epage><![CDATA[42]]></epage>

<abstract><![CDATA[We present a novel rendering primitive that combines the modeling brevity of points with the rasterization efficiency of polygons. The surface is represented by a sampled collection of Differential Points (DP), each with embedded curvature information that captures the local differential geometry in the vicinity of that point. This is a more general point representation that, for the cost of a few additional bytes, packs much more information per point than the traditional point-based models. This information is used to efficiently render the surface as a collection of local geometries. To use the hardware acceleration, the DPs are quantized into 256 different types and each sampled point is approximated by the closest quantized DP and is rendered as a normal-mapped rectangle. The advantages to this representation are: 1) The surface can be represented more sparsely compared to other point primitives, 2) it achieves a robust hardware accelerated per-pixel shading - even with no connectivity information, and 3) it offers a novel point-based simplification technique that factors in the complexity of the local geometry. The number of primitives being equal, DPs produce a much better quality of rendering than a pure splat-based approach. Visual appearances being similar, DPs are about two times faster and require about 75 percent less disk space in comparison to splatting primitives.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1175095]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1175095]]></doi>

<publicationId><![CDATA[1175095]]></publicationId>

<partnum><![CDATA[1175095]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1175095&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1175095]]></pdf>

</document>

<document>

<rank>848</rank>

<title><![CDATA[Cross-Organizational Collaboration Supported by Augmented Reality]]></title>

<authors><![CDATA[Nilsson, S.;  Johansson, B.J.E.;  Jo&#x0308; nsson, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Linkoping Univ., Linkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[emergency services]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[military systems]]></term>

<term><![CDATA[organisational aspects]]></term>

<term><![CDATA[personnel]]></term>

<term><![CDATA[police]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Augmented reality]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Command and control systems]]></term>

<term><![CDATA[Helicopters]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Personnel]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1380]]></spage>

<epage><![CDATA[1392]]></epage>

<abstract><![CDATA[This paper presents a study where Augmented Reality (AR) technology has been used as a tool for supporting collaboration between the rescue services, the police and military personnel in a crisis management scenario. There are few studies on how AR systems should be designed to improve cooperation between actors from different organizations while at the same time supporting individual needs. In the present study, an AR system was utilized for supporting joint planning tasks by providing organization specific views of a shared map. The study involved a simulated emergency event conducted in close to real settings with representatives from the organizations for which the system is developed. As a baseline, a series of trials without the AR system was carried out. Results show that the users were positive toward the AR system and would like to use it in real work. They also experience some performance benefits of using the AR system compared to their traditional tools. Finally, the problem of designing for collaborative work as well as the benefits of using an iterative design processes is discussed.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5620908]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.249]]></doi>

<publicationId><![CDATA[5620908]]></publicationId>

<partnum><![CDATA[5620908]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5620908&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620908]]></pdf>

</document>

<document>

<rank>849</rank>

<title><![CDATA[In Situ Eddy Analysis in a High-Resolution Ocean Climate Model]]></title>

<authors><![CDATA[Woodring, J.;  Petersen, M.;  Schmeisser, A.;  Patchett, J.;  Ahrens, J.;  Hagen, H.]]></authors>

<affiliations><![CDATA[Los Alamos Nat. Lab., Los Alamos, NM, USA]]></affiliations>

<controlledterms>

<term><![CDATA[climatology]]></term>

<term><![CDATA[oceanography]]></term>

<term><![CDATA[rotational flow]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Atmospheric modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Meteorology]]></term>

<term><![CDATA[Microprocessors]]></term>

<term><![CDATA[Oceans]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[857]]></spage>

<epage><![CDATA[866]]></epage>

<abstract><![CDATA[An eddy is a feature associated with a rotating body of fluid, surrounded by a ring of shearing fluid. In the ocean, eddies are 10 to 150 km in diameter, are spawned by boundary currents and baroclinic instabilities, may live for hundreds of days, and travel for hundreds of kilometers. Eddies are important in climate studies because they transport heat, salt, and nutrients through the world's oceans and are vessels of biological productivity. The study of eddies in global ocean-climate models requires large-scale, high-resolution simulations. This poses a problem for feasible (timely) eddy analysis, as ocean simulations generate massive amounts of data, causing a bottleneck for traditional analysis workflows. To enable eddy studies, we have developed an in situ workflow for the quantitative and qualitative analysis of MPAS-Ocean, a high-resolution ocean climate model, in collaboration with the ocean model research and development process. Planned eddy analysis at high spatial and temporal resolutions will not be possible with a postprocessing workflow due to various constraints, such as storage size and I/O time, but the in situ workflow enables it and scales well to ten-thousand processing elements.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192723]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467411]]></doi>

<publicationId><![CDATA[7192723]]></publicationId>

<partnum><![CDATA[7192723]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192723&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192723]]></pdf>

</document>

<document>

<rank>850</rank>

<title><![CDATA[A Parallelized Surface Extraction Algorithm for Large Binary Image Data Sets Based on an Adaptive 3-D Delaunay Subdivision Strategy]]></title>

<authors><![CDATA[YingLiang Ma;  Saetzler, K.]]></authors>

<affiliations><![CDATA[King''s Coll. London, London]]></affiliations>

<controlledterms>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[multi-threading]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[160]]></spage>

<epage><![CDATA[172]]></epage>

<abstract><![CDATA[In this paper, we describe a novel 3D subdivision strategy to extract the surface of binary image data. This iterative approach generates a series of surface meshes that capture different levels of detail of the underlying structure. At the highest level of detail, the resulting surface mesh generated by our approach uses only about 10 percent of the triangles in comparison to the Marching Cube (MC) algorithm, even in settings where almost no image noise is present. Our approach also eliminates the so-called "staircase effect," which voxel-based algorithms like the MC are likely to show, particularly if nonuniformly sampled images are processed. Finally, we show how the presented algorithm can be parallelized by subdividing 3D image space into rectilinear blocks of subimages. As the algorithm scales very well with an increasing number of processors in a multithreaded setting, this approach is suited to process large image data sets of several gigabytes. Although the presented work is still computationally more expensive than simple voxel-based algorithms, it produces fewer surface triangles while capturing the same level of detail, is more robust toward image noise, and eliminates the above-mentioned "staircase" effect in anisotropic settings. These properties make it particularly useful for biomedical applications, where these conditions are often encountered.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359480]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1057]]></doi>

<publicationId><![CDATA[4359480]]></publicationId>

<partnum><![CDATA[4359480]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359480&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359480]]></pdf>

</document>

<document>

<rank>851</rank>

<title><![CDATA[Extracting objects from range and radiance images]]></title>

<authors><![CDATA[Yizhou Yu;  Ferencz, A.;  Malik, J.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image registration]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Geometrical optics]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Partitioning algorithms]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[351]]></spage>

<epage><![CDATA[364]]></epage>

<abstract><![CDATA[In this paper, we present a pipeline and several key techniques necessary for editing a real scene captured with both cameras and laser range scanners. We develop automatic algorithms to segment the geometry from range images into distinct surfaces, register texture from radiance images with the geometry, and synthesize compact high-quality texture maps. The result is an object-level representation of the scene which can be rendered with modifications to structure via traditional rendering methods. The segmentation algorithm for geometry operates directly on the point cloud from multiple registered 3D range images instead of a reconstructed mesh. It is a top-down algorithm which recursively partitions a point set into two subsets using a pairwise similarity measure. The result is a binary tree with individual surfaces as leaves. Our image registration technique performs a very efficient search to automatically find the camera poses for arbitrary position and orientation relative to the geometry. Thus, we can take photographs from any location without precalibration between the scanner and the camera. The algorithms have been applied to large-scale real data. We demonstrate our ability to edit a captured scene by moving, inserting, and deleting objects]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[965349]]></arnumber>

<doi><![CDATA[10.1109/2945.965349]]></doi>

<publicationId><![CDATA[965349]]></publicationId>

<partnum><![CDATA[965349]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=965349&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965349]]></pdf>

</document>

<document>

<rank>852</rank>

<title><![CDATA[Computing Multiscale Curve and Surface Skeletons of Genus 0 Shapes Using a Global Importance Measure]]></title>

<authors><![CDATA[Reniers, D.;  van Wijk, J.J.;  Telea, A.]]></authors>

<affiliations><![CDATA[Eindhoven Univ. of Technol., Eindhoven]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[curve fitting]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Multi-stage noise shaping]]></term>

<term><![CDATA[Noise robustness]]></term>

<term><![CDATA[Noise shaping]]></term>

<term><![CDATA[Shape measurement]]></term>

<term><![CDATA[Size measurement]]></term>

<term><![CDATA[Skeleton]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[355]]></spage>

<epage><![CDATA[368]]></epage>

<abstract><![CDATA[We present a practical algorithm for computing robust multiscale curve and surface skeletons of 3D objects of genus zero. Based on a model that follows an advection principle, we assign to each point on the skeleton a part of the object surface, called the collapse. The size of the collapse is used as a uniform importance measure for the curve and surface skeleton, so that both can be simplified by imposing a single threshold on this intuitive measure. The simplified skeletons are connected by default, without special precautions, due to the monotonicity of the importance measure. The skeletons possess additional desirable properties: They are centered, robust to noise, hierarchical, and provide a natural skeleton-to-boundary mapping. We present a voxel-based algorithm that is straightforward to implement and simple to use. We illustrate our method on several realistic 3D objects.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4437726]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.23]]></doi>

<publicationId><![CDATA[4437726]]></publicationId>

<partnum><![CDATA[4437726]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4437726&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4437726]]></pdf>

</document>

<document>

<rank>853</rank>

<title><![CDATA[Data-Driven Visualization and Group Analysis of Multichannel EEG Coherence with Functional Units]]></title>

<authors><![CDATA[ten Caat, M.;  Maurits, N.M.;  Roerdink, J.B.T.M.]]></authors>

<affiliations><![CDATA[BCN Neuroimaging Center, Univ. of Groningen, Groningen]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[electrodes]]></term>

<term><![CDATA[electroencephalography]]></term>

<term><![CDATA[medical signal processing]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[756]]></spage>

<epage><![CDATA[771]]></epage>

<abstract><![CDATA[A typical data-driven visualization of electroencephalography (EEG) coherence is a graph layout, with vertices representing electrodes and edges representing significant coherences between electrode signals. A drawback of this layout is its visual clutter for multichannel EEG. To reduce clutter, we define a functional unit (FU) as a data-driven region of interest (ROI). An FU is a spatially connected set of electrodes recording pairwise significantly coherent signals, represented in the coherence graph by a spatially connected clique. Earlier, we presented two methods to detect FUs: a maximal clique-based (MCB) method (time complexity O(3<sup>n/3</sup>), with n being the number of vertices) and a more efficient watershed-based (WB) method (time complexity O(n<sup>2</sup> logn)). To reduce the potential oversegmentation of the WB method, we introduce an improved WB (IWB) method (time complexity O(n<sup>2</sup> log n)). The IWB method merges basins representing FUs during the segmentation if they are spatially connected and if their union is a clique. The WB and IWB methods are both up to a factor of 100,000 faster than the MCB method for a typical multichannel setting with 128 EEG channels, thus making interactive visualization of multichannel EEG coherence possible. Results show that considering the MCB method as the gold standard, the difference between IWB and MCB FU maps is smaller than between WB and MCB FU maps. We also introduce two novel group maps for data-driven group analysis as extensions of the IWB method. First, the group mean coherence map preserves dominant features from a collection of individual FU maps. Second, the group FU size map visualizes the average FU size per electrode across a collection of individual FU maps. Finally, we employ an extensive case study to evaluate the IWB FU map and the two new group maps for data-driven group analysis. Results, in accordance with conventional findings, indicate differences in EEG coherence between younger- - and older adults. However, they also suggest that an initial selection of hypothesis-driven ROIs could be extended with additional data-driven ROIs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4433991]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.21]]></doi>

<publicationId><![CDATA[4433991]]></publicationId>

<partnum><![CDATA[4433991]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4433991&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4433991]]></pdf>

</document>

<document>

<rank>854</rank>

<title><![CDATA[Interactive Blood Damage Analysis for Ventricular Assist Devices]]></title>

<authors><![CDATA[Hentschel, B.;  Tedjo, I.;  Probst, M.;  Wolter, M.;  Behr, M.;  Bischof, C.;  Kuhlen, T.]]></authors>

<affiliations><![CDATA[Virtual Reality Group, RWTH Aachen Univ., Aachen]]></affiliations>

<controlledterms>

<term><![CDATA[blood vessels]]></term>

<term><![CDATA[cardiovascular system]]></term>

<term><![CDATA[cellular biophysics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[orthotics]]></term>

<term><![CDATA[tensors]]></term>

<term><![CDATA[user interfaces]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Blood]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Degenerative diseases]]></term>

<term><![CDATA[Fluid flow]]></term>

<term><![CDATA[Heart]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Maintenance engineering]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1515]]></spage>

<epage><![CDATA[1522]]></epage>

<abstract><![CDATA[Ventricular Assist Devices (VADs) support the heart in its vital task of maintaining circulation in the human body when the heart alone is not able to maintain a sufficient flow rate due to illness or degenerative diseases. However, the engineering of these devices is a highly demanding task. Advanced modeling methods and computer simulations allow the investigation of the fluid flow inside such a device and in particular of potential blood damage. In this paper we present a set of visualization methods which have been designed to specifically support the analysis of a tensor-based blood damage prediction model. This model is based on the tracing of particles through the VAD, for each of which the cumulative blood damage can be computed. The model's tensor output approximates a single blood cell's deformation in the flow field. The tensor and derived scalar data are subsequently visualized using techniques based on icons, particle visualization, and function plotting. All these techniques are accessible through a Virtual Reality-based user interface, which features not only stereoscopic rendering but also natural interaction with the complex three-dimensional data. To illustrate the effectiveness of these visualization methods, we present the results of an analysis session that was performed by domain experts for a specific data set for the MicroMed DeBakey VAD.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658170]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.142]]></doi>

<publicationId><![CDATA[4658170]]></publicationId>

<partnum><![CDATA[4658170]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658170&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658170]]></pdf>

</document>

<document>

<rank>855</rank>

<title><![CDATA[Fast iterative refinement of articulated solid dynamics]]></title>

<authors><![CDATA[Faure, F.]]></authors>

<affiliations><![CDATA[Inst. fur Computergraphik, Tech. Univ. Wien, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[dynamics]]></term>

<term><![CDATA[integration]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[kinematics]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Heuristic algorithms]]></term>

<term><![CDATA[Iterative algorithms]]></term>

<term><![CDATA[Iterative methods]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Solids]]></term>

<term><![CDATA[Virtual reality]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[268]]></spage>

<epage><![CDATA[276]]></epage>

<abstract><![CDATA[A new dynamics algorithm for articulated solid animation is presented. It provides enhancements of computational efficiency and accuracy control with respect to previous solutions. Iterative refinement allows us to perform interactive animations which could be only computed off-line using previous methods. The efficiency results from managing two sets of constraints associated with the kinematic graph, and proceeding in two steps. First, the acyclic constraints are solved in linear time. An iterative process then reduces the closed-loop errors while maintaining the acyclic constraints. This allows the user to efficiently trade off accuracy for computation time. We analyze the complexity and investigate practical efficiency compared with other approaches. In contrast with previous research, we present a single method which is computationally efficient for acyclic bodies as well as for mesh-like bodies. The accuracy control is provided by the iterative improvement performed by the algorithm and also from the existence of two constraint priority levels induced by the method. Used in conjunction with a robust integration scheme, this new algorithm allows the interactive animation of scenes containing a few thousand geometric constraints, including closed loops. It has been successfully applied to real-time simulations]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[795217]]></arnumber>

<doi><![CDATA[10.1109/2945.795217]]></doi>

<publicationId><![CDATA[795217]]></publicationId>

<partnum><![CDATA[795217]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=795217&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=795217]]></pdf>

</document>

<document>

<rank>856</rank>

<title><![CDATA[Perceptual Guidelines for Creating Rectangular Treemaps]]></title>

<authors><![CDATA[Kong, N.;  Heer, J.;  Agrawala, M.]]></authors>

<affiliations><![CDATA[Univ. of California, Berkeley, Berkeley, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[tree data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Bars]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Guidelines]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[990]]></spage>

<epage><![CDATA[998]]></epage>

<abstract><![CDATA[Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613436]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.186]]></doi>

<publicationId><![CDATA[5613436]]></publicationId>

<partnum><![CDATA[5613436]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613436&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613436]]></pdf>

</document>

<document>

<rank>857</rank>

<title><![CDATA[&#x0201C;Search, Show Context, Expand on Demand&#x0201D;: Supporting Large Graph Exploration with Degree-of-Interest]]></title>

<authors><![CDATA[van Ham, F.;  Perer, A.]]></authors>

<affiliations><![CDATA[IBM-ILOG Res., Gentilly, France]]></affiliations>

<controlledterms>

<term><![CDATA[citation analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[mathematics computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context modeling]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Law]]></term>

<term><![CDATA[Legal factors]]></term>

<term><![CDATA[Mobile computing]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Visual databases]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[953]]></spage>

<epage><![CDATA[960]]></epage>

<abstract><![CDATA[A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290699]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.108]]></doi>

<publicationId><![CDATA[5290699]]></publicationId>

<partnum><![CDATA[5290699]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290699&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290699]]></pdf>

</document>

<document>

<rank>858</rank>

<title><![CDATA[All-Frequency Direct Illumination with Vectorized Visibility]]></title>

<authors><![CDATA[Tze-Yiu Ho;  Yi Xiao;  Rui-Bin Feng;  Chi-Sing Leung;  Tien-Tsin Wong]]></authors>

<affiliations><![CDATA[Dept. of Electron. Eng., City Univ. of Hong Kong, Kowloon Tong, China]]></affiliations>

<controlledterms>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[945]]></spage>

<epage><![CDATA[958]]></epage>

<abstract><![CDATA[Many existing pre-computed radiance transfer (PRT) approaches for all-frequency lighting store the information of a 3D object in the pre-vertex manner. To preserve the fidelity of high frequency effects, the 3D object must be tessellated densely. Otherwise, rendering artifacts due to interpolation may appear. This paper presents an all-frequency lighting algorithm for direct illumination based on a new visibility representation which approximates a visibility function using a sequence of 3D vectors. The algorithm is able to construct the visibility function of an on-screen pixel on-the-fly. Hence even though the 3D object is not tessellated densely, the rendering artifacts can be suppressed greatly. Besides, a summed area table based rendering algorithm, which is able to handle the integration over a non-axis aligned polygon, is developed. Using our approach, we can rotate lighting environment, change view point, and adjust the shininess of the 3D object in a real-time manner. Experimental results show that our approach can render plausible all-frequency lighting effects for direct illumination in real-time, especially for specular shadows, which are difficult for other methods to obtain.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7050311]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2407398]]></doi>

<publicationId><![CDATA[7050311]]></publicationId>

<partnum><![CDATA[7050311]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7050311&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050311]]></pdf>

</document>

<document>

<rank>859</rank>

<title><![CDATA[Visualization of Parameter Space for Image Analysis]]></title>

<authors><![CDATA[Pretorius, A.J.;  Bray, M.-A.P.;  Carpenter, A.E.;  Ruddle, R.A.]]></authors>

<affiliations><![CDATA[Sch. of Comput., Univ. of Leeds, Leeds, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[medical image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Image analysis]]></term>

<term><![CDATA[Information processing]]></term>

<term><![CDATA[Sampling methods]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2402]]></spage>

<epage><![CDATA[2411]]></epage>

<abstract><![CDATA[Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6065007]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.253]]></doi>

<publicationId><![CDATA[6065007]]></publicationId>

<partnum><![CDATA[6065007]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6065007&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065007]]></pdf>

</document>

<document>

<rank>860</rank>

<title><![CDATA[A Neuron Membrane Mesh Representation for Visualization of Electrophysiological Simulations]]></title>

<authors><![CDATA[Lasserre, S.;  Hernando, J.;  Hill, S.;  Schuermann, F.;  de Miguel Anasagasti, P.;  Jaoude, G.A.;  Markram, H.]]></authors>

<affiliations><![CDATA[Blue Brain Project, EPFL, Lausanne, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[bioelectric phenomena]]></term>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[brain]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomembranes]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Morphology]]></term>

<term><![CDATA[Neurons]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Surface morphology]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[214]]></spage>

<epage><![CDATA[227]]></epage>

<abstract><![CDATA[We present a process to automatically generate three-dimensional mesh representations of the complex, arborized cell membrane surface of cortical neurons (the principal information processing cells of the brain) from nonuniform morphological measurements. Starting from manually sampled morphological points (3D points and diameters) from neurons in a brain slice preparation, we construct a polygonal mesh representation that realistically represents the continuous membrane surface, closely matching the original experimental data. A mapping between the original morphological points and the newly generated mesh enables simulations of electrophysiolgical activity to be visualized on this new membrane representation. We compare the new mesh representation with the state of the art and present a series of use cases and applications of this technique to visualize simulations of single neurons and networks of multiple neurons.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5728807]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.55]]></doi>

<publicationId><![CDATA[5728807]]></publicationId>

<partnum><![CDATA[5728807]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5728807&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728807]]></pdf>

</document>

<document>

<rank>861</rank>

<title><![CDATA[Volume rendering of DCT-based compressed 3D scalar data]]></title>

<authors><![CDATA[Boon-Lock Yeo;  Liu, B.]]></authors>

<affiliations><![CDATA[Dept. of Electr. Eng., Princeton Univ., NJ, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data compression]]></term>

<term><![CDATA[discrete cosine transforms]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Books]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Discrete cosine transforms]]></term>

<term><![CDATA[Discrete transforms]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Visual effects]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[29]]></spage>

<epage><![CDATA[43]]></epage>

<abstract><![CDATA[The paper proposes a scheme to perform volume rendering from compressed scalar data. Instead of decompressing the entire data set before rendering, blocks of data are decompressed as needed. Discrete cosine transform based compression technique is used to illustrate the method. The data is partitioned into overlapping blocks to permit local rendering and allow easy parallelization. Compression by factor of 20 to 30 produces rendering virtually indistinguishable from rendering using the original uncompressed data. Speedup is obtained by making use of spatial homogeneity detected in the transform domain. Rendering time using the proposed approach is less than that of direct rendering from the entire uncompressed data. The proposed method thus offers an attractive option to reduce storage, computation, and transmission overhead of otherwise huge data sets]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[468390]]></arnumber>

<doi><![CDATA[10.1109/2945.468390]]></doi>

<publicationId><![CDATA[468390]]></publicationId>

<partnum><![CDATA[468390]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=468390&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468390]]></pdf>

</document>

<document>

<rank>862</rank>

<title><![CDATA[Reliable path for virtual endoscopy: ensuring complete examination of human organs]]></title>

<authors><![CDATA[Taosong He;  Lichan Hong;  Dongqing Chen;  Zhengrong Liang]]></authors>

<affiliations><![CDATA[Network & Service Manage. Res. Dept., Lucent Technol. Bell Labs., Murray Hill, NJ, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[computerised navigation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[path planning]]></term>

<term><![CDATA[reliability]]></term>

<term><![CDATA[visibility]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Automatic control]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Endoscopes]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Reliability theory]]></term>

<term><![CDATA[Switches]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[333]]></spage>

<epage><![CDATA[342]]></epage>

<abstract><![CDATA[Virtual endoscopy is a computerized, noninvasive procedure for detecting anomalies inside human organs. Several preliminary studies have demonstrated the benefits and effectiveness of this modality. Unfortunately, previous work cannot guarantee that an existing anomaly will be detected, especially for complex organs with multiple branches. In this paper, we introduce the concept of reliable navigation, which ensures the interior organ surface is fully examined by the physician performing the virtual endoscopy procedure. To achieve this, we propose computing a reliable fly-through path that ensures no blind areas during the navigation. Theoretically, we discuss the criteria of evaluating a reliable path and prove that the problem of generating an optimal reliable path for virtual endoscopy is NP-complete. In practice, we develop an efficient method for the calculation of an effective reliable path. First, a small set of center observation points are automatically located inside the hollow organ. For each observation point, there exists at least one patch of interior surface visible to it, but that cannot be seen from any of the other observation points. These chosen points are then linked with a path that stays in the center of the organ. Finally, new points inside the organ are recursively selected and connected into the path until the entire organ surface is visible from the path. We present encouraging results from experiments on several data sets. For a medium-size volumetric model with several hundred thousand inner voxels, an effective reliable path can be generated in several minutes]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[965347]]></arnumber>

<doi><![CDATA[10.1109/2945.965347]]></doi>

<publicationId><![CDATA[965347]]></publicationId>

<partnum><![CDATA[965347]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=965347&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=965347]]></pdf>

</document>

<document>

<rank>863</rank>

<title><![CDATA[Deriving a particle system from continuum mechanics for the animation of deformable objects]]></title>

<authors><![CDATA[Etzmuss, O.;  Gross, J.;  Strasser, W.]]></authors>

<affiliations><![CDATA[Wilhelm- Schickard-Inst., Tubingen Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[finite difference methods]]></term>

<term><![CDATA[physics computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Capacitive sensors]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Elasticity]]></term>

<term><![CDATA[Finite difference methods]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Nonlinear equations]]></term>

<term><![CDATA[Springs]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[538]]></spage>

<epage><![CDATA[550]]></epage>

<abstract><![CDATA[Mass-spring and particle systems have been widely employed in computer graphics to model deformable objects because they allow fast numerical solutions. In this work, we establish a link between these discrete models and classical mathematical elasticity. It turns out that discrete systems can be derived from a continuum model by a finite difference formulation and approximate classical continuum models unless the deformations are large. In this work, we present the derivation of a particle system from a continuum model, compare it to the models of classical elasticity theory, and assess its accuracy. In this way, we gain insight into the way discrete systems work and we are able to specify the correct scaling when the discretization is changed. Physical material parameters that describe materials in continuum mechanics are also used in the derived particle system.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1260747]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1260747]]></doi>

<publicationId><![CDATA[1260747]]></publicationId>

<partnum><![CDATA[1260747]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260747&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260747]]></pdf>

</document>

<document>

<rank>864</rank>

<title><![CDATA[Hand Motion Prediction for Distributed Virtual Environments]]></title>

<authors><![CDATA[Chan, A.;  Lau, Rynson W.H.;  Li, L.]]></authors>

<affiliations><![CDATA[Durham Univ., Durham]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[groupware]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[146]]></spage>

<epage><![CDATA[159]]></epage>

<abstract><![CDATA[We use our hands to manipulate objects in our daily life. The hand is capable of accomplishing diverse tasks such as pointing, gripping, twisting, and tearing. However, there is not much work that considers using the hand as input in distributed virtual environments (DVEs), in particular, over the Internet. The main reasons are that the Internet suffers from high network latency, which affects interaction, and the hand has many degrees of freedom, which adds additional challenges to synchronizing the collaboration. In this paper, we propose a prediction method specifically designed for human hand motion to address the network latency problem in DVEs. Through a thorough analysis of finger motion, we have identified various finger motion constraints, and we propose a constraint-based motion prediction method for hand motion. To reduce the average prediction error under high network latency, for example, over the Internet, we further propose a revised dead-reckoning scheme here. Our performance results show that the proposed prediction method produces a lower prediction error than some popular methods, and the revised dead-reckoning scheme produces a lower average prediction error than the traditional dead-reckoning scheme, particularly at high network latency.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4359479]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1056]]></doi>

<publicationId><![CDATA[4359479]]></publicationId>

<partnum><![CDATA[4359479]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4359479&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359479]]></pdf>

</document>

<document>

<rank>865</rank>

<title><![CDATA[Visualization of Simulated Urban Spaces: Inferring Parameterized Generation of Streets, Parcels, and Aerial Imagery]]></title>

<authors><![CDATA[Vanegas, Carlos A.;  Aliaga, Daniel G.;  Benes, B.;  Waddell, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geographic information systems]]></term>

<term><![CDATA[geophysical signal processing]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[land use planning]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Investments]]></term>

<term><![CDATA[Land use planning]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Protection]]></term>

<term><![CDATA[Telecommunication traffic]]></term>

<term><![CDATA[Transportation]]></term>

<term><![CDATA[Urban planning]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[424]]></spage>

<epage><![CDATA[435]]></epage>

<abstract><![CDATA[Urban simulation models and their visualization are used to help regional planning agencies evaluate alternative transportation investments, land use regulations, and environmental protection policies. Typical urban simulations provide spatially distributed data about number of inhabitants, land prices, traffic, and other variables. In this article, we build on a synergy of urban simulation, urban visualization, and computer graphics to automatically infer an urban layout for any time step of the simulation sequence. In addition to standard visualization tools, our method gathers data of the original street network, parcels, and aerial imagery and uses the available simulation results to infer changes to the original urban layout and produce a new and plausible layout for the simulation results. In contrast with previous work, our approach automatically updates the layout based on changes in the simulation data and thus can scale to a large simulation over many years. The method in this article offers a substantial step forward in building integrated visualization and behavioral simulation systems for use in community visioning, planning, and policy analysis. We demonstrate our method on several real cases using a 200-Gbyte database for a 16,300 km<sup>2</sup> area surrounding Seattle.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4668343]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.193]]></doi>

<publicationId><![CDATA[4668343]]></publicationId>

<partnum><![CDATA[4668343]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4668343&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4668343]]></pdf>

</document>

<document>

<rank>866</rank>

<title><![CDATA[Visual Analysis and Steering of Flooding Simulations]]></title>

<authors><![CDATA[Ribicic, H.;  Waser, J.;  Fuchs, R.;  Bloschl, G.;  Groller, E.]]></authors>

<affiliations><![CDATA[VRVis Forschungs-GmbH, Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[floods]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[meteorology]]></term>

<term><![CDATA[real-time systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aggregates]]></term>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1062]]></spage>

<epage><![CDATA[1075]]></epage>

<abstract><![CDATA[We present a visualization tool for the real-time analysis of interactively steered ensemble-simulation runs, and apply it to flooding simulations. Simulations are performed on-the-fly, generating large quantities of data. The user wants to make sense of the data as it is created. The tool facilitates understanding of what happens in all scenarios, where important events occur, and how simulation runs are related. We combine different approaches to achieve this goal. To maintain an overview, data are aggregated and embedded into the simulation rendering, showing trends, outliers, and robustness. For a detailed view, we use information-visualization views and interactive visual analysis techniques. A selection mechanism connects the two approaches. Points of interest are selected by clicking on aggregates, supplying data for visual analysis. This allows the user to maintain an overview of the ensemble and perform analysis even as new data are supplied through simulation steering. Unexpected or unwanted developments are detected easily, and the user can focus the exploration on them. The solution was evaluated with two case studies focusing on placing and testing flood defense measures. Both were evaluated by a consortium of flood simulation and defense experts, who found the system to be both intuitive and relevant.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6280550]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.175]]></doi>

<publicationId><![CDATA[6280550]]></publicationId>

<partnum><![CDATA[6280550]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6280550&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6280550]]></pdf>

</document>

<document>

<rank>867</rank>

<title><![CDATA[Volume Analysis Using Multimodal Surface Similarity]]></title>

<authors><![CDATA[Haidacher, M.;  Bruckner, S.;  Groller, E.]]></authors>

<affiliations><![CDATA[Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[computerised tomography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Mutual information]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1969]]></spage>

<epage><![CDATA[1978]]></epage>

<abstract><![CDATA[The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064960]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.258]]></doi>

<publicationId><![CDATA[6064960]]></publicationId>

<partnum><![CDATA[6064960]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064960&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064960]]></pdf>

</document>

<document>

<rank>868</rank>

<title><![CDATA[Comprehensible Visualization for Augmented Reality]]></title>

<authors><![CDATA[Kalkofen, D.;  Mendez, E.;  Schmalstieg, D.]]></authors>

<affiliations><![CDATA[Inst. for Comput. Graphics & Vision, Graz Univ. of Technol., Graz]]></affiliations>

<controlledterms>

<term><![CDATA[augmented reality]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[193]]></spage>

<epage><![CDATA[204]]></epage>

<abstract><![CDATA[This article presents interactive visualizations to support the comprehension of spatial relationships between virtual and real world objects for augmented reality (AR) applications. To enhance the clarity of such relationships we discuss visualization techniques and their suitability for AR. We apply them on different AR applications with different goals, e.g. in X-Ray vision or in applications which draw a user's attention to an object of interest. We demonstrate how Focus and Context (F+C) visualizations are used to affect the user's perception of hidden or nearby objects by presenting contextual information in the area of augmentation. We discuss the organization and the possible sources of data for visualizations in augmented reality and present cascaded and multi level F+C visualizations to address complex, cluttered scenes that are inevitable in real environments. This article also shows filters and tools to interactively control the amount of augmentation. It compares the impact of real world context preserving to a pure virtual and uniform enhancement of these structures for augmentations of real world imagery. Finally this paper discusses the stylization of sparse object representations for AR to improve x-ray vision.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4569839]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.96]]></doi>

<publicationId><![CDATA[4569839]]></publicationId>

<partnum><![CDATA[4569839]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4569839&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4569839]]></pdf>

</document>

<document>

<rank>869</rank>

<title><![CDATA[Scatter/Gather Clustering: Flexibly Incorporating User Feedback to Steer Clustering Results]]></title>

<authors><![CDATA[Hossain, M.S.;  Ojili, P.K.R.;  Grimm, C.;  Muller, R.;  Watson, L.T.;  Ramakrishnan, N.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[bioacoustics]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[nonlinear programming]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[sonar]]></term>

<term><![CDATA[zoology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Clustering algorithms]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Linear programming]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2829]]></spage>

<epage><![CDATA[2838]]></epage>

<abstract><![CDATA[Significant effort has been devoted to designing clustering algorithms that are responsive to user feedback or that incorporate prior domain knowledge in the form of constraints. However, users desire more expressive forms of interaction to influence clustering outcomes. In our experiences working with diverse application scientists, we have identified an interaction style scatter/gather clustering that helps users iteratively restructure clustering results to meet their expectations. As the names indicate, scatter and gather are dual primitives that describe whether clusters in a current segmentation should be broken up further or, alternatively, brought back together. By combining scatter and gather operations in a single step, we support very expressive dynamic restructurings of data. Scatter/gather clustering is implemented using a nonlinear optimization framework that achieves both locality of clusters and satisfaction of user-supplied constraints. We illustrate the use of our scatter/gather clustering approach in a visual analytic application to study baffle shapes in the bat biosonar (ears and nose) system. We demonstrate how domain experts are adept at supplying scatter/gather constraints, and how our framework incorporates these constraints effectively without requiring numerous instance-level constraints.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327289]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.258]]></doi>

<publicationId><![CDATA[6327289]]></publicationId>

<partnum><![CDATA[6327289]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327289&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327289]]></pdf>

</document>

<document>

<rank>870</rank>

<title><![CDATA[View-Dependent Streamlines for 3D Vector Fields]]></title>

<authors><![CDATA[Marchesin, S.;  Cheng-Kai Chen;  Ho, C.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Univ. of California, Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[vectors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Entropy]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Streaming media]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1578]]></spage>

<epage><![CDATA[1586]]></epage>

<abstract><![CDATA[This paper introduces a new streamline placement and selection algorithm for 3D vector fields. Instead of considering the problem as a simple feature search in data space, we base our work on the observation that most streamline fields generate a lot of self-occlusion which prevents proper visualization. In order to avoid this issue, we approach the problem in a view-dependent fashion and dynamically determine a set of streamlines which contributes to data understanding without cluttering the view. Since our technique couples flow characteristic criteria and view-dependent streamline selection we are able achieve the best of both worlds: relevant flow description and intelligible, uncluttered pictures. We detail an efficient GPU implementation of our algorithm, show comprehensive visual results on multiple datasets and compare our method with existing flow depiction techniques. Our results show that our technique greatly improves the readability of streamline visualizations on different datasets without requiring user intervention.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613500]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.212]]></doi>

<publicationId><![CDATA[5613500]]></publicationId>

<partnum><![CDATA[5613500]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613500&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613500]]></pdf>

</document>

<document>

<rank>871</rank>

<title><![CDATA[Visual Comparability of 3D Regular Sampling and Reconstruction]]></title>

<authors><![CDATA[Tai Meng;  Entezari, A.;  Smith, B.;  Moller, T.;  Weiskopf, D.;  Kirkpatrick, A.E.]]></authors>

<affiliations><![CDATA[Graphics, Usability & Visualization Lab., Simon Eraser Univ., Burnaby, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[sampling methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[FCC]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Image resolution]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Marine animals]]></term>

<term><![CDATA[Observers]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1420]]></spage>

<epage><![CDATA[1432]]></epage>

<abstract><![CDATA[The Body-Centered Cubic (BCC) and Face-Centered Cubic (FCC) lattices have been analytically shown to be more efficient sampling lattices than the traditional Cartesian Cubic (CC) lattice, but there has been no estimate of their visual comparability. Two perceptual studies (each with N = 12 participants) compared the visual quality of images rendered from BCC and FCC lattices to images rendered from the CC lattice. Images were generated from two signals: the commonly used Marschner-Lobb synthetic function and a computed tomography scan of a fish tail. Observers found that BCC and FCC could produce images of comparable visual quality to CC, using 30-35 percent fewer samples. For the images used in our studies, the L<sub>2</sub> error metric shows high correlation with the judgement of human observers. Using the L<sub>2</sub> metric as a proxy, the results of the experiments appear to extend across a wide range of images and parameter choices.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5620894]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.234]]></doi>

<publicationId><![CDATA[5620894]]></publicationId>

<partnum><![CDATA[5620894]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5620894&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620894]]></pdf>

</document>

<document>

<rank>872</rank>

<title><![CDATA[Keynote Speaker: Welcome to the Future! Technology and Innovation at Disney]]></title>

<authors><![CDATA[Mine, M.]]></authors>

<affiliations><![CDATA[Walt Disney Imagineering, Glendale, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[artificial intelligence]]></term>

<term><![CDATA[leisure industry]]></term>

<term><![CDATA[mobile computing]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xiii]]></spage>

<epage><![CDATA[xiii]]></epage>

<abstract><![CDATA[Jet packs, self-driving cars, universal translators, space tourism; many of the science fiction dreams of yesterday are on the verge of becoming realities of today and promise to transform the world of tomorrow. We have complex communicators/supercomputers in our pockets that would make Captain Kirk proud; robotic dogs that could play fetch with R2D2; and computers, though maybe not quite up to HAL 9000 standards, that can play a mean game of Jeopardy. (Still waiting for that flying car in every garage!) In a similar manner, advances in artificial intelligence, robotics, virtual and augmented realities, and mobile technology are transforming the world of Disney and its theme parks. In this talk I will give an overview of some of the exciting new advances in technology and innovation in Disney theme parks. I will discuss the technology being used both in front of guests and behind the scenes. I will include examples and videos from some of the newest Disney attractions, many of which can be found right next door to the conference. I will also discuss some of the work being done in the area of immersive design and review at Walt Disney Imagineering, in Glendale CA. Welcome to the future! It's a great big beautiful tomorrow!]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6479172]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.52]]></doi>

<publicationId><![CDATA[6479172]]></publicationId>

<partnum><![CDATA[6479172]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6479172&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479172]]></pdf>

</document>

<document>

<rank>873</rank>

<title><![CDATA[Predicate-Based Focus-and-Context Visualization for 3D Ultrasound]]></title>

<authors><![CDATA[Schulte zu Berge, C.;  Baust, M.;  Kapoor, A.;  Navab, N.]]></authors>

<affiliations><![CDATA[Dept. of Comput.-Aided Med. Procedures, Tech. Univ. Munchen, Mu&#x0308;nchen, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[transfer functions]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Ultrasonic imaging]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2379]]></spage>

<epage><![CDATA[2387]]></epage>

<abstract><![CDATA[Direct volume visualization techniques offer powerful insight into volumetric medical images and are part of the clinical routine for many applications. Up to now, however, their use is mostly limited to tomographic imaging modalities such as CT or MRI. With very few exceptions, such as fetal ultrasound, classic volume rendering using one-dimensional intensity-based transfer functions fails to yield satisfying results in case of ultrasound volumes. This is particularly due its gradient-like nature, a high amount of noise and speckle, and the fact that individual tissue types are rather characterized by a similar texture than by similar intensity values. Therefore, clinicians still prefer to look at 2D slices extracted from the ultrasound volume. In this work, we present an entirely novel approach to the classification and compositing stage of the volume rendering pipeline, specifically designed for use with ultrasonic images. We introduce point predicates as a generic formulation for integrating the evaluation of not only low-level information like local intensity or gradient, but also of high-level information, such as non-local image features or even anatomical models. Thus, we can successfully filter clinically relevant from non-relevant information. In order to effectively reduce the potentially high dimensionality of the predicate configuration space, we propose the predicate histogram as an intuitive user interface. This is augmented by a scribble technique to provide a comfortable metaphor for selecting predicates of interest. Assigning importance factors to the predicates allows for focus-and-context visualization that ensures to always show important (focus) regions of the data while maintaining as much context information as possible. Our method naturally integrates into standard ray casting algorithms and yields superior results in comparison to traditional methods in terms of visualizing a specific target anatomy in ultrasound volumes.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876031]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346317]]></doi>

<publicationId><![CDATA[6876031]]></publicationId>

<partnum><![CDATA[6876031]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876031&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876031]]></pdf>

</document>

<document>

<rank>874</rank>

<title><![CDATA[Fast and intuitive metamorphosis of 3D polyhedral models using SMCC mesh merging scheme]]></title>

<authors><![CDATA[Tong-Yee Lee;  Po-Hua Huang]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[image morphing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Automatic control]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Merging]]></term>

<term><![CDATA[Mesh generation]]></term>

<term><![CDATA[Relaxation methods]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Table lookup]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[85]]></spage>

<epage><![CDATA[98]]></epage>

<abstract><![CDATA[A very fast and intuitive approach to generate the metamorphosis of two genus 0 3D polyhedral models is presented. There are two levels of correspondence specified by animators to control morphs. The higher level requires the animators to specify scatter features to decompose the input models into several corresponding patches. The lower level optionally allows the animators to specify extra features on each corresponding patch for finer correspondence control. Once these two levels of correspondence are established, the proposed schemes automatically and efficiently establish a complete one-to-one correspondence between two models. We propose a novel technique called SMCC (Structures of Minimal Contour Coverage) to efficiently and robustly merge corresponding embeddings. The SMCC scheme can compute merging in linear time. The performance of the proposed methods is comparable to or better than state-of-the-art 3D polyhedral metamorphosis. We demonstrate several examples of aesthetically pleasing morphs, which can be created very quickly and intuitively.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1175099]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1175099]]></doi>

<publicationId><![CDATA[1175099]]></publicationId>

<partnum><![CDATA[1175099]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1175099&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1175099]]></pdf>

</document>

<document>

<rank>875</rank>

<title><![CDATA[[Cover 2]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6129451]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.16]]></doi>

<publicationId><![CDATA[6129451]]></publicationId>

<partnum><![CDATA[6129451]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6129451&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6129451]]></pdf>

</document>

<document>

<rank>876</rank>

<title><![CDATA[TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients]]></title>

<authors><![CDATA[Loorak, M.H.;  Perin, C.;  Kamal, N.;  Hill, M.;  Carpendale, S.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diseases]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[patient treatment]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Delays]]></term>

<term><![CDATA[Hospitals]]></term>

<term><![CDATA[Interviews]]></term>

<term><![CDATA[Needles]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[409]]></spage>

<epage><![CDATA[418]]></epage>

<abstract><![CDATA[We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192713]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467325]]></doi>

<publicationId><![CDATA[7192713]]></publicationId>

<partnum><![CDATA[7192713]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192713&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192713]]></pdf>

</document>

<document>

<rank>877</rank>

<title><![CDATA[Visual Parameter Space Analysis: A Conceptual Framework]]></title>

<authors><![CDATA[Sedlmair, M.;  Heinzl, C.;  Bruckner, S.;  Piringer, H.;  Moller, T.]]></authors>

<affiliations><![CDATA[Univ. of Vienna, Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Predictive models]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2161]]></spage>

<epage><![CDATA[2170]]></epage>

<abstract><![CDATA[Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876043]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346321]]></doi>

<publicationId><![CDATA[6876043]]></publicationId>

<partnum><![CDATA[6876043]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876043&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876043]]></pdf>

</document>

<document>

<rank>878</rank>

<title><![CDATA[GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data]]></title>

<authors><![CDATA[Im, J.-F.;  McGuffin, M.J.;  Leung, R.]]></authors>

<affiliations><![CDATA[Ecole de Technol. Super., Montreal, QC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Visual databases]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2606]]></spage>

<epage><![CDATA[2614]]></epage>

<abstract><![CDATA[Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6634192]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.160]]></doi>

<publicationId><![CDATA[6634192]]></publicationId>

<partnum><![CDATA[6634192]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634192&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634192]]></pdf>

</document>

<document>

<rank>879</rank>

<title><![CDATA[Graphical Tests for Power Comparison of Competing Designs]]></title>

<authors><![CDATA[Hofmann, H.;  Follett, L.;  Majumder, M.;  Cook, D.]]></authors>

<affiliations><![CDATA[Stat., Iowa State Univ., Ames, IA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Inference mechanisms]]></term>

<term><![CDATA[Observers]]></term>

<term><![CDATA[Statistical analysis]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2441]]></spage>

<epage><![CDATA[2448]]></epage>

<abstract><![CDATA[Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327249]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.230]]></doi>

<publicationId><![CDATA[6327249]]></publicationId>

<partnum><![CDATA[6327249]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327249&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327249]]></pdf>

</document>

<document>

<rank>880</rank>

<title><![CDATA[Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization]]></title>

<authors><![CDATA[Satyanarayan, A.;  Russell, R.;  Hoffswell, J.;  Heer, J.]]></authors>

<controlledterms>

<term><![CDATA[data flow graphs]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[formal specification]]></term>

<term><![CDATA[optimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer architecture]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Indexes]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[659]]></spage>

<epage><![CDATA[668]]></epage>

<abstract><![CDATA[We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192704]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467091]]></doi>

<publicationId><![CDATA[7192704]]></publicationId>

<partnum><![CDATA[7192704]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192704&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192704]]></pdf>

</document>

<document>

<rank>881</rank>

<title><![CDATA[Interactive Visualization of Hyperspectral Images of Historical Documents]]></title>

<authors><![CDATA[Seon Joo Kim;  Shaojie Zhuo;  Fanbo Deng;  Chi-Wing Fu;  Brown, M.S.]]></authors>

<affiliations><![CDATA[Nat. Univ. of Singapore, Singapore, Singapore]]></affiliations>

<controlledterms>

<term><![CDATA[art]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[document handling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aging]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humidity]]></term>

<term><![CDATA[Hyperspectral imaging]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Strips]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1441]]></spage>

<epage><![CDATA[1448]]></epage>

<abstract><![CDATA[This paper presents an interactive visualization tool to study and analyze hyperspectral images (HSI) of historical documents. This work is part of a collaborative effort with the Nationaal Archief of the Netherlands (NAN) and Art Innovation, a manufacturer of hyperspectral imaging hardware designed for old and fragile documents. The NAN is actively capturing HSI of historical documents for use in a variety of tasks related to the analysis and management of archival collections, from ink and paper analysis to monitoring the effects of environmental aging. To assist their work, we have developed a comprehensive visualization tool that offers an assortment of visualization and analysis methods, including interactive spectral selection, spectral similarity analysis, time-varying data analysis and visualization, and selective spectral band fusion. This paper describes our visualization software and how it is used to facilitate the tasks needed by our collaborators. Evaluation feedback from our collaborators on how this tool benefits their work is included.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613485]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.172]]></doi>

<publicationId><![CDATA[5613485]]></publicationId>

<partnum><![CDATA[5613485]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613485&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613485]]></pdf>

</document>

<document>

<rank>882</rank>

<title><![CDATA[ABySS-Explorer: Visualizing Genome Sequence Assemblies]]></title>

<authors><![CDATA[Nielsen, C.B.;  Jackman, S.D.;  Birol, I.;  Jones, S.J.M.]]></authors>

<affiliations><![CDATA[Genome Sci. Centre, BC Cancer Agency, Vancouver, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[DNA]]></term>

<term><![CDATA[bioinformatics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[genomics]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Assembly]]></term>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Feedback]]></term>

<term><![CDATA[Genomics]]></term>

<term><![CDATA[Inspection]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Sequences]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[881]]></spage>

<epage><![CDATA[888]]></epage>

<abstract><![CDATA[One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290690]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.116]]></doi>

<publicationId><![CDATA[5290690]]></publicationId>

<partnum><![CDATA[5290690]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290690&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290690]]></pdf>

</document>

<document>

<rank>883</rank>

<title><![CDATA[Constructing Overview + Detail Dendrogram-Matrix Views]]></title>

<authors><![CDATA[Jin Chen;  MacEachren, A.M.;  Peuquet, D.J.]]></authors>

<affiliations><![CDATA[Dept. of Geogr., Pennsylvania State Univ., University Park, PA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[matrix algebra]]></term>

<term><![CDATA[pattern clustering]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Binary trees]]></term>

<term><![CDATA[Cervical cancer]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Demography]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Geography]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Scalability]]></term>

<term><![CDATA[Statistics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[889]]></spage>

<epage><![CDATA[896]]></epage>

<abstract><![CDATA[A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290691]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.130]]></doi>

<publicationId><![CDATA[5290691]]></publicationId>

<partnum><![CDATA[5290691]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290691&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290691]]></pdf>

</document>

<document>

<rank>884</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5613415]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.140]]></doi>

<publicationId><![CDATA[5613415]]></publicationId>

<partnum><![CDATA[5613415]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613415&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613415]]></pdf>

</document>

<document>

<rank>885</rank>

<title><![CDATA[Vessel Visualization using Curved Surface Reformation]]></title>

<authors><![CDATA[Auzinger, T.;  Mistelbauer, G.;  Baclija, I.;  Schernthaner, R.;  Kochl, A.;  Wimmer, M.;  Groller, M.E.;  Bruckner, S.]]></authors>

<affiliations><![CDATA[Vienna Univ. of Technol., Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diagnostic radiography]]></term>

<term><![CDATA[image reconstruction]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Radiology]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Vascular structures]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2858]]></spage>

<epage><![CDATA[2867]]></epage>

<abstract><![CDATA[Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634141]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.215]]></doi>

<publicationId><![CDATA[6634141]]></publicationId>

<partnum><![CDATA[6634141]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634141&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634141]]></pdf>

</document>

<document>

<rank>886</rank>

<title><![CDATA[A Statistical Quality Model for Data-Driven Speech Animation]]></title>

<authors><![CDATA[Xiaohan Ma;  Zhigang Deng]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. of Houston, Houston, TX, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[regression analysis]]></term>

<term><![CDATA[speech processing]]></term>

<term><![CDATA[speech synthesis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Face]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Predictive models]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Speech]]></term>

<term><![CDATA[Trajectory]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1915]]></spage>

<epage><![CDATA[1927]]></epage>

<abstract><![CDATA[In recent years, data-driven speech animation approaches have achieved significant successes in terms of animation quality. However, how to automatically evaluate the realism of novel synthesized speech animations has been an important yet unsolved research problem. In this paper, we propose a novel statistical model (called SAQP) to automatically predict the quality of on-the-fly synthesized speech animations by various data-driven techniques. Its essential idea is to construct a phoneme-based, Speech Animation Trajectory Fitting (SATF) metric to describe speech animation synthesis errors and then build a statistical regression model to learn the association between the obtained SATF metric and the objective speech animation synthesis quality. Through delicately designed user studies, we evaluate the effectiveness and robustness of the proposed SAQP model. To the best of our knowledge, this work is the first-of-its-kind, quantitative quality model for data-driven speech animation. We believe it is the important first step to remove a critical technical barrier for applying data-driven speech animation techniques to numerous online or interactive talking avatar applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6155718]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.67]]></doi>

<publicationId><![CDATA[6155718]]></publicationId>

<partnum><![CDATA[6155718]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6155718&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155718]]></pdf>

</document>

<document>

<rank>887</rank>

<title><![CDATA[Fast Sparse Level Sets on Graphics Hardware]]></title>

<authors><![CDATA[Jalba, A.C.;  van der Laan, W.J.;  Roerdink, J.B.T.M.]]></authors>

<affiliations><![CDATA[Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Eindhoven, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Arrays]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Instruction sets]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Level set]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[30]]></spage>

<epage><![CDATA[44]]></epage>

<abstract><![CDATA[The level-set method is one of the most popular techniques for capturing and tracking deformable interfaces. Although level sets have demonstrated great potential in visualization and computer graphics applications, such as surface editing and physically based modeling, their use for interactive simulations has been limited due to the high computational demands involved. In this paper, we address this computational challenge by leveraging the increased computing power of graphics processors, to achieve fast simulations based on level sets. Our efficient, sparse GPU level-set method is substantially faster than other state-of-the-art, parallel approaches on both CPU and GPU hardware. We further investigate its performance through a method for surface reconstruction, based on GPU level sets. Our novel multiresolution method for surface reconstruction from unorganized point clouds compares favorably with recent, existing techniques and other parallel implementations. Finally, we point out that both level-set computations and rendering of level-set surfaces can be performed at interactive rates, even on large volumetric grids. Therefore, many applications based on level sets can benefit from our sparse level-set method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6165272]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.69]]></doi>

<publicationId><![CDATA[6165272]]></publicationId>

<partnum><![CDATA[6165272]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6165272&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165272]]></pdf>

</document>

<document>

<rank>888</rank>

<title><![CDATA[Author Index]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[xxix]]></spage>

<epage><![CDATA[xxx]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634136]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.136]]></doi>

<publicationId><![CDATA[6634136]]></publicationId>

<partnum><![CDATA[6634136]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634136&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634136]]></pdf>

</document>

<document>

<rank>889</rank>

<title><![CDATA[[Front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c1]]></spage>

<epage><![CDATA[c1]]></epage>

<abstract><![CDATA[Presents the front cover/table of contents for this issue of the periodical.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5380815]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.11]]></doi>

<publicationId><![CDATA[5380815]]></publicationId>

<partnum><![CDATA[5380815]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5380815&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380815]]></pdf>

</document>

<document>

<rank>890</rank>

<title><![CDATA[Performing Efficient NURBS Modeling Operations on the GPU]]></title>

<authors><![CDATA[Krishnamurthy, A.;  Khardekar, R.;  McMains, S.;  Haller, K.;  Elber, G.]]></authors>

<affiliations><![CDATA[Dept. of Mech. Eng., Univ. of California, Berkeley, CA]]></affiliations>

<controlledterms>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[530]]></spage>

<epage><![CDATA[543]]></epage>

<abstract><![CDATA[We present algorithms for evaluating and performing modeling operations on NURBS surfaces using the programmable fragment processor on the Graphics Processing Unit (GPU). We extend our GPU-based NURBS evaluator that evaluates NURBS surfaces to compute exact normals for either standard or rational B-spline surfaces for use in rendering and geometric modeling. We build on these calculations in our new GPU algorithms to perform standard modeling operations such as inverse evaluations, ray intersections, and surface-surface intersections on the GPU. Our modeling algorithms run in real time, enabling the user to sketch on the actual surface to create new features. In addition, the designer can edit the surface by interactively trimming it without the need for retessellation. Our GPU-accelerated algorithm to perform surface-surface intersection operations with NURBS surfaces can output intersection curves in the model space as well as in the parametric spaces of both the intersecting surfaces at interactive rates. We also extend our surface-surface intersection algorithm to evaluate self-intersections in NURBS surfaces.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4782957]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.29]]></doi>

<publicationId><![CDATA[4782957]]></publicationId>

<partnum><![CDATA[4782957]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4782957&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4782957]]></pdf>

</document>

<document>

<rank>891</rank>

<title><![CDATA[Interactive display of isosurfaces with global illumination]]></title>

<authors><![CDATA[Wyman, C.;  Parker, S.;  Shirley, P.;  Hansen, C.]]></authors>

<affiliations><![CDATA[Iowa Univ., Iowa City, IA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Manipulator dynamics]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[186]]></spage>

<epage><![CDATA[196]]></epage>

<abstract><![CDATA[In many applications, volumetric data sets are examined by displaying isosurfaces, surfaces where the data, or some function of the data, takes on a given value. Interactive applications typically use local lighting models to render such surfaces. This work introduces a method to precompute or lazily compute global illumination to improve interactive isosurface renderings. The precompiled illumination resides in a separate volume and includes direct light, shadows, and intersections. Using this volume, interactive globally illuminated renderings of isosurfaces become feasible while still allowing dynamic manipulation of lighting, viewpoint and isovalue.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1580453]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.33]]></doi>

<publicationId><![CDATA[1580453]]></publicationId>

<partnum><![CDATA[1580453]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580453&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580453]]></pdf>

</document>

<document>

<rank>892</rank>

<title><![CDATA[OpinionSeer: Interactive Visualization of Hotel Customer Feedback]]></title>

<authors><![CDATA[Yingcai Wu;  Furu Wei;  Shixia Liu;  Au, N.;  Weiwei Cui;  Hong Zhou;  Huamin Qu]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China]]></affiliations>

<controlledterms>

<term><![CDATA[Internet]]></term>

<term><![CDATA[data mining]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feedback]]></term>

<term><![CDATA[hotel industry]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Uncertainty]]></term>

<term><![CDATA[Visualization]]></term>

<term><![CDATA[Wheels]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1109]]></spage>

<epage><![CDATA[1118]]></epage>

<abstract><![CDATA[The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613449]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.183]]></doi>

<publicationId><![CDATA[5613449]]></publicationId>

<partnum><![CDATA[5613449]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613449&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613449]]></pdf>

</document>

<document>

<rank>893</rank>

<title><![CDATA[Particle-based Sampling and Meshing of Surfaces in Multimaterial Volumes]]></title>

<authors><![CDATA[Meyer, M.;  Whitaker, R.;  Kirby, R.M.;  Ledergerber, C.;  Pfister, H.]]></authors>

<affiliations><![CDATA[Initiative in Innovative Comput., Harvard Univ., Cambridge, MA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[mathematics computing]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[sampling methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological materials]]></term>

<term><![CDATA[Biomedical materials]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Geophysics computing]]></term>

<term><![CDATA[Magnetic resonance imaging]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Scientific computing]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1539]]></spage>

<epage><![CDATA[1546]]></epage>

<abstract><![CDATA[Methods that faithfully and robustly capture the geometry of complex material interfaces in labeled volume data are important for generating realistic and accurate visualizations and simulations of real-world objects. The generation of such multimaterial models from measured data poses two unique challenges: first, the surfaces must be well-sampled with regular, efficient tessellations that are consistent across material boundaries; and second, the resulting meshes must respect the nonmanifold geometry of the multimaterial interfaces. This paper proposes a strategy for sampling and meshing multimaterial volumes using dynamic particle systems, including a novel, differentiable representation of the material junctions that allows the particle system to explicitly sample corners, edges, and surfaces of material intersections. The distributions of particles are controlled by fundamental sampling constraints, allowing Delaunay-based meshing algorithms to reliably extract watertight meshes of consistently high-quality.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658173]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.154]]></doi>

<publicationId><![CDATA[4658173]]></publicationId>

<partnum><![CDATA[4658173]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658173&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658173]]></pdf>

</document>

<document>

<rank>894</rank>

<title><![CDATA[Evaluation and design of filters using a Taylor series expansion]]></title>

<authors><![CDATA[Moller, T.;  Machiraju, R.;  Mueller, K.;  Yagel, R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[error analysis]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[splines (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Image quality]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Read only memory]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Taylor series]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[184]]></spage>

<epage><![CDATA[199]]></epage>

<abstract><![CDATA[We describe a new method for analyzing, classifying, and evaluating filters that can be applied to interpolation filters as well as to arbitrary derivative filters of any order. Our analysis is based on the Taylor series expansion of the convolution sum. Our analysis shows the need and derives the method for the normalization of derivative filter weights. Under certain minimal restrictions of the underlying function, we are able to compute tight absolute error bounds of the reconstruction process. We demonstrate the utilization of our methods to the analysis of the class of cubic BC-spline filters. As our technique is not restricted to interpolation filters, we are able to show that the Catmull-Rom spline filter and its derivative are the most accurate reconstruction and derivative filters, respectively, among the class of BC-spline filters. We also present a new derivative filter which features better spatial accuracy than any derivative BC-spline filter, and is optimal within our framework. We conclude by demonstrating the use of these optimal filters for accurate interpolation and gradient estimation in volume rendering]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[597800]]></arnumber>

<doi><![CDATA[10.1109/2945.597800]]></doi>

<publicationId><![CDATA[597800]]></publicationId>

<partnum><![CDATA[597800]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=597800&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=597800]]></pdf>

</document>

<document>

<rank>895</rank>

<title><![CDATA[Visualization of Barrier Tree Sequences]]></title>

<authors><![CDATA[Heine, C.;  Scheuermann, G.;  Flamm, C.;  Hofacker, I.L.;  Stadler, P.F.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Leipzig Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[macromolecules]]></term>

<term><![CDATA[molecular biophysics]]></term>

<term><![CDATA[organic compounds]]></term>

<term><![CDATA[sequences]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Biomedical signal processing]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Heuristic algorithms]]></term>

<term><![CDATA[Joining processes]]></term>

<term><![CDATA[RNA]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[US Department of Transportation]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[781]]></spage>

<epage><![CDATA[788]]></epage>

<abstract><![CDATA[Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015430]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.196]]></doi>

<publicationId><![CDATA[4015430]]></publicationId>

<partnum><![CDATA[4015430]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015430&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015430]]></pdf>

</document>

<document>

<rank>896</rank>

<title><![CDATA[Enabling Automatic Clutter Reduction in Parallel Coordinate Plots]]></title>

<authors><![CDATA[Ellis, G.;  Dix, A.]]></authors>

<affiliations><![CDATA[Lancaster Univ.]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[hidden feature removal]]></term>

<term><![CDATA[probability]]></term>

<term><![CDATA[sampling methods]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Coordinate measuring machines]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Motion measurement]]></term>

<term><![CDATA[Sampling methods]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[717]]></spage>

<epage><![CDATA[724]]></epage>

<abstract><![CDATA[We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a 'binning' technique is very fast and yet approaches the accuracy of the more expensive 'true' complete measurement]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015422]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.138]]></doi>

<publicationId><![CDATA[4015422]]></publicationId>

<partnum><![CDATA[4015422]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015422&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015422]]></pdf>

</document>

<document>

<rank>897</rank>

<title><![CDATA[Choking Loops on Surfaces]]></title>

<authors><![CDATA[Xin Feng;  Yiying Tong]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Michigan State Univ., East Lansing, MI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[image representation]]></term>

<term><![CDATA[surface morphology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Face]]></term>

<term><![CDATA[Generators]]></term>

<term><![CDATA[Inductors]]></term>

<term><![CDATA[Noise]]></term>

<term><![CDATA[Noise measurement]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1298]]></spage>

<epage><![CDATA[1306]]></epage>

<abstract><![CDATA[We present a method for computing &#x201C;choking&#x201D; loops-a set of surface loops that describe the narrowing of the volumes inside/outside of the surface and extend the notion of surface homology and homotopy loops. The intuition behind their definition is that a choking loop represents the region where an offset of the original surface would get pinched. Our generalized loops naturally include the usual 2g handles/tunnels computed based on the topology of the genus-g surface, but also include loops that identify chokepoints or bottlenecks, i.e., boundaries of small membranes separating the inside or outside volume of the surface into disconnected regions. Our definition is based on persistent homology theory, which gives a measure to topological structures, thus providing resilience to noise and a well-defined way to determine topological feature size. More precisely, the persistence computed here is based on the lower star filtration of the interior or exterior 3D domain with the distance field to the surface being the associated 3D Morse function.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6409845]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.9]]></doi>

<publicationId><![CDATA[6409845]]></publicationId>

<partnum><![CDATA[6409845]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6409845&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6409845]]></pdf>

</document>

<document>

<rank>898</rank>

<title><![CDATA[Fast Collision Detection for Fracturing Rigid Bodies]]></title>

<authors><![CDATA[Glondu, L.;  Schvartzman, S.C.;  Marchal, M.;  Dumont, G.;  Otaduy, M.A.]]></authors>

<affiliations><![CDATA[IRISA, Inria, Rennes, France]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Detection algorithms]]></term>

<term><![CDATA[Surface cracks]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[30]]></spage>

<epage><![CDATA[41]]></epage>

<abstract><![CDATA[In complex scenes with many objects, collision detection plays a key role in the simulation performance. This is particularly true in fracture simulation for two main reasons. One is that fracture fragments tend to exhibit very intensive contact, and the other is that collision detection data structures for new fragments need to be computed on the fly. In this paper, we present novel collision detection algorithms and data structures for real-time simulation of fracturing rigid bodies. We build on a combination of well-known efficient data structures, namely, distance fields and sphere trees, making our algorithm easy to integrate on existing simulation engines. We propose novel methods to construct these data structures, such that they can be efficiently updated upon fracture events and integrated in a simple yet effective self-adapting contact selection algorithm. Altogether, we drastically reduce the cost of both collision detection and collision response. We have evaluated our global solution for collision detection on challenging scenarios, achieving high frame rates suited for hard real-time applications such as video games or haptics. Our solution opens promising perspectives for complex fracture simulations involving many dynamically created rigid objects.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6559973]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.98]]></doi>

<publicationId><![CDATA[6559973]]></publicationId>

<partnum><![CDATA[6559973]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6559973&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6559973]]></pdf>

</document>

<document>

<rank>899</rank>

<title><![CDATA[An Advanced Evenly-Spaced Streamline Placement Algorithm]]></title>

<authors><![CDATA[Liu, Z.;  Moorhead, R.J.;  Groner, J.]]></authors>

<affiliations><![CDATA[HPC, Mississippi State Univ., MS]]></affiliations>

<controlledterms>

<term><![CDATA[Runge-Kutta methods]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[interpolation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive control]]></term>

<term><![CDATA[Error correction]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Iterative algorithms]]></term>

<term><![CDATA[Noise robustness]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Polynomials]]></term>

<term><![CDATA[Programmable control]]></term>

<term><![CDATA[Streaming media]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[965]]></spage>

<epage><![CDATA[972]]></epage>

<abstract><![CDATA[This paper presents an advanced evenly-spaced streamline placement algorithm for fast, high-quality, and robust layout of flow lines. A fourth-order Runge-Kutta integrator with adaptive step size and error control is employed for rapid accurate streamline advection. Cubic Hermite polynomial interpolation with large sample-spacing is adopted to create fewer evenly-spaced samples along each streamline to reduce the amount of distance checking. We propose two methods to enhance placement quality. Double queues are used to prioritize topological seeding and to favor long streamlines to minimize discontinuities. Adaptive distance control based on the local flow variance is explored to reduce cavities. Furthermore, we propose a universal, effective, fast, and robust loop detection strategy to address closed and spiraling streamlines. Our algorithm is an order-of-magnitude faster than Jobard and Lefer's algorithm with better placement quality and over 5 times faster than Mebarki et al.'s algorithm with comparable placement quality, but with a more robust solution to loop detection]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015453]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.116]]></doi>

<publicationId><![CDATA[4015453]]></publicationId>

<partnum><![CDATA[4015453]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015453&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015453]]></pdf>

</document>

<document>

<rank>900</rank>

<title><![CDATA[Semiautomatic Transfer Function Initialization for Abdominal Visualization Using Self-Generating Hierarchical Radial Basis Function Networks]]></title>

<authors><![CDATA[Alper Selver, M.;  Guzelis, C.]]></authors>

<affiliations><![CDATA[Dept. of Electr. & Electron. Eng., Dokuz Eylul Univ., Izmir]]></affiliations>

<controlledterms>

<term><![CDATA[Gaussian processes]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image recognition]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[radial basis function networks]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Abdomen]]></term>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Biomedical optical imaging]]></term>

<term><![CDATA[Computed tomography]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Histograms]]></term>

<term><![CDATA[Optical network units]]></term>

<term><![CDATA[Radial basis function networks]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Transfer functions]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[395]]></spage>

<epage><![CDATA[409]]></epage>

<abstract><![CDATA[Being a tool that assigns optical parameters used in interactive visualization, transfer functions (TF) have important effects on the quality of volume rendered medical images. Unfortunately, finding accurate TFs is a tedious and time consuming task because of the trade off between using extensive search spaces and fulfilling the physician's expectations with interactive data exploration tools and interfaces. By addressing this problem, we introduce a semi-automatic method for initial generation of TFs. The proposed method uses a self generating hierarchical radial basis function network to determine the lobes of a volume histogram stack (VHS) which is introduced as a new domain by aligning the histograms of slices of a image series. The new self generating hierarchical design strategy allows the recognition of suppressed lobes corresponding to suppressed tissues and representation of the overlapping regions which are parts of the lobes but can not be represented by the Gaussian bases in VHS. Moreover, approximation with a minimum set of basis functions provides the possibility of selecting and adjusting suitable units to optimize the TF. Applications on different CT/MR data sets show enhanced rendering quality and reduced optimization time in abdominal studies.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4721434]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.198]]></doi>

<publicationId><![CDATA[4721434]]></publicationId>

<partnum><![CDATA[4721434]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4721434&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721434]]></pdf>

</document>

<document>

<rank>901</rank>

<title><![CDATA[2009 Annual Index [IEEE Transactions on Visualization and Computer Graphics]]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Indexes]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[not in print]]></spage>

<epage><![CDATA[not in print]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the coauthors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5331928]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.1]]></doi>

<publicationId><![CDATA[5331928]]></publicationId>

<partnum><![CDATA[5331928]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5331928&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5331928]]></pdf>

</document>

<document>

<rank>902</rank>

<title><![CDATA[Image-based Building Regularization Using Structural Linear Features]]></title>

<authors><![CDATA[Wang, J.;  Fang, T.;  Su, Q.;  Zhu, S.;  Liu, J.;  Cai, S.;  Tai, C.;  Quan, L.]]></authors>

<affiliations><![CDATA[Jinglu Wang is with the Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong]]></affiliations>

<thesaurusterms>

<term><![CDATA[Buildings]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Reconstructed building models using stereo-based methods inevitably suffer from noise, leading to the lack of regularity which is characterized by straightness of structural linear features and smoothness of homogeneous regions. We leverage the structural linear features embedded in the mesh to construct a novel surface scaffold structure for model regularization. The regularization comprises two iterative stages: (1) the linear features are semi-automatically proposed from images by exploiting photometric and geometric clues jointly; (2) the scaffold topology represented by spatial relations among the linear features is optimized according to data fidelity and topological rules, then the mesh is refined by adjusting itself to the consolidated scaffold. Our method has two advantages. First, the proposed scaffold representation is able to concisely describe semantic building structures. Second, the scaffold structure is embedded in the mesh, which can preserve the mesh connectivity and avoid stitching or intersecting surfaces in challenging cases. We demonstrate that our method can enhance structural characteristics and suppress irregularities in the building models robustly in some challenging datasets. Moreover, the regularization can significantly improve the results of general applications such as simplification and non-photorealistic rendering.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7167718]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2461163]]></doi>

<publicationId><![CDATA[7167718]]></publicationId>

<partnum><![CDATA[7167718]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7167718&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167718]]></pdf>

</document>

<document>

<rank>903</rank>

<title><![CDATA[[Back cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[11]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2005]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1359742]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2005.8]]></doi>

<publicationId><![CDATA[1359742]]></publicationId>

<partnum><![CDATA[1359742]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1359742&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359742]]></pdf>

</document>

<document>

<rank>904</rank>

<title><![CDATA[Generation of Accurate Integral Surfaces in Time-Dependent Vector Fields]]></title>

<authors><![CDATA[Garth, C.;  Krishnan, H.;  Tricoche, X.;  Tricoche, X.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Electronic mail]]></term>

<term><![CDATA[Fluid flow measurement]]></term>

<term><![CDATA[Iterative algorithms]]></term>

<term><![CDATA[Skeleton]]></term>

<term><![CDATA[Surface treatment]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1404]]></spage>

<epage><![CDATA[1411]]></epage>

<abstract><![CDATA[We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658156]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.133]]></doi>

<publicationId><![CDATA[4658156]]></publicationId>

<partnum><![CDATA[4658156]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658156&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658156]]></pdf>

</document>

<document>

<rank>905</rank>

<title><![CDATA[Using motion to illustrate static 3D shape-kinetic visualization]]></title>

<authors><![CDATA[Lum, E.B.;  Stompel, A.;  Kwan-Liu Ma]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., California Univ., Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Fires]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Kinetic theory]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Videos]]></term>

<term><![CDATA[Visual perception]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[9]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2003]]></py>

<spage><![CDATA[115]]></spage>

<epage><![CDATA[126]]></epage>

<abstract><![CDATA[In this paper, we present a novel visualization technique-kinetic visualization-that uses motion along a surface to aid in the perception of 3D shape and structure of static objects. The method uses particle systems, with rules such that particles flow over the surface of an object to not only bring out, but also attract attention to information on a shape that might not be readily visible with a conventional rendering method which uses lighting and view changes. Replacing still images with animations in this fashion, we demonstrate with both surface and volumetric models in the accompanying videos that, in many cases, the resulting visualizations effectively enhance the perception of three-dimensional shape and structure. We also describe how, for both types of data, a texture-based representation of this motion can be used for interactive visualization using PC graphics hardware. Finally, the results of a user study that we have conducted are presented, which show evidence that the supplemental motion cues can be helpful.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1196000]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2003.1196000]]></doi>

<publicationId><![CDATA[1196000]]></publicationId>

<partnum><![CDATA[1196000]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1196000&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1196000]]></pdf>

</document>

<document>

<rank>906</rank>

<title><![CDATA[Feature extraction and iconic visualization]]></title>

<authors><![CDATA[Van Walsum, T.;  Post, F.H.;  Silver, D.;  Post, F.J.]]></authors>

<affiliations><![CDATA[Dept. of Diagnostic Radiol., Leiden Univ. Hospital, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[visual languages]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Laboratories]]></term>

<term><![CDATA[Mathematics]]></term>

<term><![CDATA[Radiology]]></term>

<term><![CDATA[Silver]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[111]]></spage>

<epage><![CDATA[119]]></epage>

<abstract><![CDATA[We present a conceptual framework and a process model for feature extraction and iconic visualization. The features are regions of interest extracted from a dataset. They are represented by attribute sets, which play a key role in the visualization process. These attribute sets are mapped to icons, or symbolic parametric objects, for visualization. The features provide a compact abstraction of the original data, and the icons are a natural way to visualize them. We present generic techniques to extract features and to calculate attribute sets, and describe a simple but powerful modeling language which was developed to create icons and to link the attributes to the icon parameters. We present illustrative examples of iconic visualization created with the techniques described, showing the effectiveness of this approach]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[506223]]></arnumber>

<doi><![CDATA[10.1109/2945.506223]]></doi>

<publicationId><![CDATA[506223]]></publicationId>

<partnum><![CDATA[506223]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=506223&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506223]]></pdf>

</document>

<document>

<rank>907</rank>

<title><![CDATA[Visual Simulation of Heat Shimmering and Mirage]]></title>

<authors><![CDATA[Ye Zhao;  Han, Y.;  Zhe Fan;  Feng Qiu;  Kuo, Y.-C.;  Kaufman, A.E.;  Mueller, K.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Kent State Univ., OH]]></affiliations>

<controlledterms>

<term><![CDATA[Boltzmann equation]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[computer graphic equipment]]></term>

<term><![CDATA[diffusion]]></term>

<term><![CDATA[finite difference methods]]></term>

<term><![CDATA[flow simulation]]></term>

<term><![CDATA[heat transfer]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Difference equations]]></term>

<term><![CDATA[Finite difference methods]]></term>

<term><![CDATA[Heat transfer]]></term>

<term><![CDATA[Lattice Boltzmann methods]]></term>

<term><![CDATA[Nonlinear equations]]></term>

<term><![CDATA[Ray tracing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Temperature distribution]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[179]]></spage>

<epage><![CDATA[189]]></epage>

<abstract><![CDATA[We provide a physically-based framework for simulating the natural phenomena related to heat interaction between objects and the surrounding air. We introduce a heat transfer model between the heat source objects and the ambient flow environment, which includes conduction, convection, and radiation. The heat distribution of the objects is represented by a novel temperature texture. We simulate the thermal flow dynamics that models the air flow interacting with the heat by a hybrid thermal lattice Boltzmann model (HTLBM). The computational approach couples a multiple-relaxation-time LBM (MRTLBM) with a finite difference discretization of a standard advection-diffusion equation for temperature. In heat shimmering and mirage, the changes in the index of refraction of the surrounding air are attributed to temperature variation. A nonlinear ray tracing method is used for rendering. Interactive performance is achieved by accelerating the computation of both the MRTLBM and the heat transfer, as well as the rendering on contemporary graphics hardware (GPU)]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4015408]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.24]]></doi>

<publicationId><![CDATA[4015408]]></publicationId>

<partnum><![CDATA[4015408]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4015408&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015408]]></pdf>

</document>

<document>

<rank>908</rank>

<title><![CDATA[Sample-Based Surface Coloring]]></title>

<authors><![CDATA[Bu&#x0308; rger, K.;  Kruger, J.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Inf. 15 (Comput. Graphik & Visualisierung, Tech. Univ. Munchen, Garching, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[tree data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brushes]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Painting]]></term>

<term><![CDATA[Paints]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Tree data structures]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[763]]></spage>

<epage><![CDATA[776]]></epage>

<abstract><![CDATA[In this paper, we present a sample-based approach for surface coloring, which is independent of the original surface resolution and representation. To achieve this, we introduce the Orthogonal Fragment Buffer (OFB)-an extension of the Layered Depth Cube-as a high-resolution view-independent surface representation. The OFB is a data structure that stores surface samples at a nearly uniform distribution over the surface, and it is specifically designed to support efficient random read/write access to these samples. The data access operations have a complexity that is logarithmic in the depth complexity of the surface. Thus, compared to data access operations in tree data structures like octrees, data-dependent memory access patterns are greatly reduced. Due to the particular sampling strategy that is employed to generate an OFB, it also maintains sample coherence, and thus, exhibits very good spatial access locality. Therefore, OFB-based surface coloring performs significantly faster than sample-based approaches using tree structures. In addition, since in an OFB, the surface samples are internally stored in uniform 2D grids, OFB-based surface coloring can efficiently be realized on the GPU to enable interactive coloring of high-resolution surfaces. On the OFB, we introduce novel algorithms for color painting using volumetric and surface-aligned brushes, and we present new approaches for particle-based color advection along surfaces in real time. Due to the intermediate surface representation we choose, our method can be used to color polygonal surfaces as well as any other type of surface that can be sampled.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5262943]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.107]]></doi>

<publicationId><![CDATA[5262943]]></publicationId>

<partnum><![CDATA[5262943]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5262943&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5262943]]></pdf>

</document>

<document>

<rank>909</rank>

<title><![CDATA[Discrete Sibson interpolation]]></title>

<authors><![CDATA[Park, S.W.;  Linsen, L.;  Kreylos, O.;  Owens, J.D.;  Hamann, B.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., California Univ., Davis, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Fitting]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Nearest neighbor searches]]></term>

<term><![CDATA[Reconstruction algorithms]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Temperature measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[243]]></spage>

<epage><![CDATA[253]]></epage>

<abstract><![CDATA[Natural-neighbor interpolation methods, such as Sibson's method, are well-known schemes for multivariate data fitting and reconstruction. Despite its many desirable properties, Sibson's method is computationally expensive and difficult to implement, especially when applied to higher-dimensional data. The main reason for both problems is the method's implementation based on a Voronoi diagram of all data points. We describe a discrete approach to evaluating Sibson's interpolant on a regular grid, based solely on finding nearest neighbors and rendering and blending d-dimensional spheres. Our approach does not require us to construct an explicit Voronoi diagram, is easily implemented using commodity three-dimensional graphics hardware, leads to a significant speed increase compared to traditional approaches, and generalizes easily to higher dimensions. For large scattered data sets, we achieve two-dimensional (2D) interpolation at interactive rates and 3D interpolation (3D) with computation times of a few seconds.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1580458]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.27]]></doi>

<publicationId><![CDATA[1580458]]></publicationId>

<partnum><![CDATA[1580458]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1580458&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580458]]></pdf>

</document>

<document>

<rank>910</rank>

<title><![CDATA[Grid With a View: Optimal Texturing for Perception of Layered Surface Shape]]></title>

<authors><![CDATA[Bair, A.;  House, D.]]></authors>

<affiliations><![CDATA[Texas A&M Univ., College Station]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[image texture]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geologic measurements]]></term>

<term><![CDATA[Geology]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Pediatrics]]></term>

<term><![CDATA[Probes]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1656]]></spage>

<epage><![CDATA[1663]]></epage>

<abstract><![CDATA[We present the results of two controlled studies comparing layered surface visualizations under various texture conditions. The task was to estimate surface normals, measured by accuracy of a hand-set surface normal probe. A single surface visualization was compared with the two-surfaces case under conditions of no texture and with projected grid textures. Variations in relative texture spacing on top and bottom surfaces were compared, as well as opacity of the top surface. Significant improvements are found for the textured cases over non-textured surfaces. Either larger or thinner top-surface textures, and lower top surface opacities are shown to give less bottom surface error. Top surface error appears to be highly resilient to changes in texture. Given the results we also present an example of how appropriate textures might be useful in volume visualization.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376199]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70559]]></doi>

<publicationId><![CDATA[4376199]]></publicationId>

<partnum><![CDATA[4376199]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376199&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376199]]></pdf>

</document>

<document>

<rank>911</rank>

<title><![CDATA[TVCG Information for authors]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[c3]]></spage>

<epage><![CDATA[c3]]></epage>

<abstract><![CDATA[Provides instructions and guidelines to prospective authors who wish to submit manuscripts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5506924]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.100]]></doi>

<publicationId><![CDATA[5506924]]></publicationId>

<partnum><![CDATA[5506924]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5506924&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5506924]]></pdf>

</document>

<document>

<rank>912</rank>

<title><![CDATA[World Lines]]></title>

<authors><![CDATA[Waser, J.;  Fuchs, R.;  Ribicic, H.;  Schindler, B.;  Bloschl, G.;  Groller, M.E.]]></authors>

<affiliations><![CDATA[VRVis Vienna, Vienna, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[decision making]]></term>

<term><![CDATA[digital simulation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Target tracking]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1458]]></spage>

<epage><![CDATA[1467]]></epage>

<abstract><![CDATA[In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613487]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.223]]></doi>

<publicationId><![CDATA[5613487]]></publicationId>

<partnum><![CDATA[5613487]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613487&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613487]]></pdf>

</document>

<document>

<rank>913</rank>

<title><![CDATA[Adaptive Composite Map Projections]]></title>

<authors><![CDATA[Jenny, B.]]></authors>

<affiliations><![CDATA[Oregon State Univ., Corvallis, OR, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Web services]]></term>

<term><![CDATA[cartography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geographic information systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Continents]]></term>

<term><![CDATA[Decision trees]]></term>

<term><![CDATA[Earth]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Mapping]]></term>

<term><![CDATA[Shape analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2575]]></spage>

<epage><![CDATA[2582]]></epage>

<abstract><![CDATA[All major web mapping services use the web Mercator projection. This is a poor choice for maps of the entire globe or areas of the size of continents or larger countries because the Mercator projection shows medium and higher latitudes with extreme areal distortion and provides an erroneous impression of distances and relative areas. The web Mercator projection is also not able to show the entire globe, as polar latitudes cannot be mapped. When selecting an alternative projection for information visualization, rivaling factors have to be taken into account, such as map scale, the geographic area shown, the map's height-to-width ratio, and the type of cartographic visualization. It is impossible for a single map projection to meet the requirements for all these factors. The proposed composite map projection combines several projections that are recommended in cartographic literature and seamlessly morphs map space as the user changes map scale or the geographic region displayed. The composite projection adapts the map's geometry to scale, to the map's height-to-width ratio, and to the central latitude of the displayed area by replacing projections and adjusting their parameters. The composite projection shows the entire globe including poles; it portrays continents or larger countries with less distortion (optionally without areal distortion); and it can morph to the web Mercator projection for maps showing small regions.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327263]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.192]]></doi>

<publicationId><![CDATA[6327263]]></publicationId>

<partnum><![CDATA[6327263]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327263&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327263]]></pdf>

</document>

<document>

<rank>914</rank>

<title><![CDATA[A multiscale model for structure-based volume rendering]]></title>

<authors><![CDATA[Guo, B.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Toronto Univ., Ont., Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[user interfaces]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Clouds]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[H infinity control]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Wavelet transforms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[291]]></spage>

<epage><![CDATA[301]]></epage>

<abstract><![CDATA[A scalar volume V={(x,f(x))|x&isin;R} is described by a function f(x) defined over some region R of the 3D space. We present a simple technique for rendering multiscale interval sets of the form I<sub>s </sub>(a,b)={(x,f<sub>s</sub>(x))|a&les;g<sub>s</sub>(x)&les;b}, where a and b are either real numbers or infinities, and f<sub>s</sub>(x) is a smoothed version of f(x). At each scale s, the constraint a&les;g<sub>s </sub>(x)&les;b identifies a subvolume in which the most significant variations of V are found. We use a dyadic wavelet transform to construct g<sub>s</sub>(x) from f(x) and derive subvolumes with the following attractive properties: 1) the information contained in the subvolumes are sufficient for reconstructing the entire V; and 2) the shapes of the subvolumes provide a hierarchical description of the geometric structures of V. Numerically, the reconstruction in 1) is only an approximation, but it is visually accurate as errors reside at fine scales where our visual sensitivity is not so acute. We triangulate interval sets as &alpha;-shapes, which can be efficiently rendered as semi-transparent clouds. Because interval sets are extracted in the object space, their visual display can respond to changes of the view point or transfer function quite fast. The result is a volume rendering technique that provides faster, more effective user interaction with practically no loss of information from the original data. The hierarchical nature of multiscale interval sets also makes it easier to understand the usual complicated structures in scalar volumes]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[485616]]></arnumber>

<doi><![CDATA[10.1109/2945.485616]]></doi>

<publicationId><![CDATA[485616]]></publicationId>

<partnum><![CDATA[485616]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=485616&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485616]]></pdf>

</document>

<document>

<rank>915</rank>

<title><![CDATA[2003 Reviewers list]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[IEEE]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[111]]></spage>

<epage><![CDATA[112]]></epage>

<abstract><![CDATA[The publication offers a note of thanks and lists its reviewers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1260762]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1260762]]></doi>

<publicationId><![CDATA[1260762]]></publicationId>

<partnum><![CDATA[1260762]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1260762&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1260762]]></pdf>

</document>

<document>

<rank>916</rank>

<title><![CDATA[FromDaDy: Spreading Aircraft Trajectories Across Views to Support Iterative Queries]]></title>

<authors><![CDATA[Hurter, C.;  Tissoires, B.;  Conversy, S.]]></authors>

<affiliations><![CDATA[DSNA, DTI R&D, ENAC, Toulouse, France]]></affiliations>

<controlledterms>

<term><![CDATA[air traffic]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[query processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aerospace control]]></term>

<term><![CDATA[Aerospace safety]]></term>

<term><![CDATA[Air safety]]></term>

<term><![CDATA[Air traffic control]]></term>

<term><![CDATA[Aircraft]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Railway safety]]></term>

<term><![CDATA[Uncertainty]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1017]]></spage>

<epage><![CDATA[1024]]></epage>

<abstract><![CDATA[When displaying thousands of aircraft trajectories on a screen, the visualization is spoiled by a tangle of trails. The visual analysis is therefore difficult, especially if a specific class of trajectories in an erroneous dataset has to be studied. We designed FromDaDy, a trajectory visualization tool that tackles the difficulties of exploring the visualization of multiple trails. This multidimensional data exploration is based on scatterplots, brushing, pick and drop, juxtaposed views and rapid visual design. Users can organize the workspace composed of multiple juxtaposed views. They can define the visual configuration of the views by connecting data dimensions from the dataset to Bertin's visual variables. They can then brush trajectories, and with a pick and drop operation they can spread the brushed information across views. They can then repeat these interactions, until they extract a set of relevant data, thus formulating complex queries. Through two real-world scenarios, we show how FromDaDy supports iterative queries and the extraction of trajectories in a dataset that contains up to 5 million data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290707]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.145]]></doi>

<publicationId><![CDATA[5290707]]></publicationId>

<partnum><![CDATA[5290707]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290707&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290707]]></pdf>

</document>

<document>

<rank>917</rank>

<title><![CDATA[Large datasets at a glance: combining textures and colors in scientific visualization]]></title>

<authors><![CDATA[Healey, Christopher G.;  Enns, J.T.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[colour graphics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[natural sciences computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Asia]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Interference]]></term>

<term><![CDATA[Psychology]]></term>

<term><![CDATA[Surface topography]]></term>

<term><![CDATA[Typhoons]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[145]]></spage>

<epage><![CDATA[167]]></epage>

<abstract><![CDATA[We present a new method for using texture and color to visualize multivariate data elements arranged on an underlying height field. We combine simple texture patterns with perceptually uniform colors to increase the number of attribute values we can display simultaneously. Our technique builds multicolored perceptual texture elements (or pexels) to represent each data element. Attribute values encoded in an element are used to vary the appearance of its pexel. Texture and color patterns that form when the pexels are displayed can be used to rapidly and accurately explore the dataset. Our pexels are built by varying three separate texture dimensions: height, density, and regularity. Results from computer graphics, computer vision, and human visual psychophysics have identified these dimensions as important for the formation of perceptual texture patterns. The pexels are colored using a selection technique that controls color distance, linear separation, and color category. Proper use of these criteria guarantees colors that are equally distinguishable from one another. We describe a set of controlled experiments that demonstrate the effectiveness of our texture dimensions and color selection criteria. We then discuss new work that studies how texture and color can be used simultaneously in a single display]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[773807]]></arnumber>

<doi><![CDATA[10.1109/2945.773807]]></doi>

<publicationId><![CDATA[773807]]></publicationId>

<partnum><![CDATA[773807]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=773807&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=773807]]></pdf>

</document>

<document>

<rank>918</rank>

<title><![CDATA[Stacked Graphs &#x02013; Geometry &amp; Aesthetics]]></title>

<authors><![CDATA[Byron, L.;  Wattenberg, M.]]></authors>

<affiliations><![CDATA[New York Times, New York, NY]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Blogs]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[History]]></term>

<term><![CDATA[Mathematical analysis]]></term>

<term><![CDATA[Motion pictures]]></term>

<term><![CDATA[Optimization methods]]></term>

<term><![CDATA[Process design]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1245]]></spage>

<epage><![CDATA[1252]]></epage>

<abstract><![CDATA[In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658136]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.166]]></doi>

<publicationId><![CDATA[4658136]]></publicationId>

<partnum><![CDATA[4658136]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658136&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658136]]></pdf>

</document>

<document>

<rank>919</rank>

<title><![CDATA[Guest Editors' Introduction: Special Section on Virtual Reality]]></title>

<authors><![CDATA[Frohlich, Bernd;  Bowman, D.A.;  Iwata, H.]]></authors>

<thesaurusterms>

<term><![CDATA[Augmented reality]]></term>

<term><![CDATA[Biomedical optical imaging]]></term>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Haptic interfaces]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Medical simulation]]></term>

<term><![CDATA[Olfactory]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[420]]></spage>

<epage><![CDATA[421]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4297684]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70419]]></doi>

<publicationId><![CDATA[4297684]]></publicationId>

<partnum><![CDATA[4297684]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4297684&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297684]]></pdf>

</document>

<document>

<rank>920</rank>

<title><![CDATA[VectorLens: Angular Selection of Curves within 2D Dense Visualizations]]></title>

<authors><![CDATA[Dumas, M.;  McGuffin, M.J.;  Chasse, P.]]></authors>

<affiliations><![CDATA[Ecole de Technol. Super. of Montreal, Montreal, QC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[interactive systems]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brushes]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Lenses]]></term>

<term><![CDATA[Mice]]></term>

<term><![CDATA[Solids]]></term>

<term><![CDATA[Time series analysis]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[402]]></spage>

<epage><![CDATA[412]]></epage>

<abstract><![CDATA[We investigate the selection of curves within a 2D visualization by specifying their angle or slope. Such angular selection has applications in parallel coordinates, time series visualizations, spatio-temporal movement data, etc. Our interaction technique specifies a region of interest in the visualization (with a position and diameter), a direction, and an angular tolerance, all with a single drag. We experimentally compared this angular selection technique with other techniques for selecting curves, and found that angular selection resulted in a higher number of trials that were successful on the first attempt and fewer incorrectly selected curves, and was also subjectively preferred by participants. We then present the design of a popup lens widget, called the VectorLens, that allows for easy angular selection and also allows the user to perform additional filtering operations based on type of curve. Multiple VectorLens widgets can also be instantiated to combine the results of their filtering operations with boolean operators.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6919281]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2362543]]></doi>

<publicationId><![CDATA[6919281]]></publicationId>

<partnum><![CDATA[6919281]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6919281&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6919281]]></pdf>

</document>

<document>

<rank>921</rank>

<title><![CDATA[Efficient Visualization of Lagrangian Coherent Structures by Filtered AMR Ridge Extraction]]></title>

<authors><![CDATA[Sadlo, F.;  Peikert, R.]]></authors>

<affiliations><![CDATA[ETH Zurich, Zurich]]></affiliations>

<controlledterms>

<term><![CDATA[Lyapunov methods]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[filtering theory]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[mesh generation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Adaptive filters]]></term>

<term><![CDATA[Adaptive mesh refinement]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Fluid dynamics]]></term>

<term><![CDATA[Grid computing]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Lagrangian functions]]></term>

<term><![CDATA[Sampling methods]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1456]]></spage>

<epage><![CDATA[1463]]></epage>

<abstract><![CDATA[This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376174]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70554]]></doi>

<publicationId><![CDATA[4376174]]></publicationId>

<partnum><![CDATA[4376174]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376174&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376174]]></pdf>

</document>

<document>

<rank>922</rank>

<title><![CDATA[A rule-based interactive behavioral animation system for humanoids]]></title>

<authors><![CDATA[Noser, H.;  Thalmann, D.]]></authors>

<affiliations><![CDATA[Multimedia Lab., Zurich Univ., Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[knowledge based systems]]></term>

<term><![CDATA[speech recognition]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acoustic sensors]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Autonomous agents]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Power system modeling]]></term>

<term><![CDATA[Production systems]]></term>

<term><![CDATA[Sensor systems]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[281]]></spage>

<epage><![CDATA[307]]></epage>

<abstract><![CDATA[We present a versatile, behavioral, and rule-based animation system that includes autonomous humanoid actors whose behavior is based on synthetic sensors that are used for perceiving the virtual environment. We combine the following in a consistent approach: L-systems, a behavioral production rule system; a particle system; an acoustic environment model, including a speech recognition module; a virtual life network; and a humanoid library. Together, these systems create a real-time-structured virtual environment that both high-level autonomous humanoids and interactive users can easily share]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[817347]]></arnumber>

<doi><![CDATA[10.1109/2945.817347]]></doi>

<publicationId><![CDATA[817347]]></publicationId>

<partnum><![CDATA[817347]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=817347&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=817347]]></pdf>

</document>

<document>

<rank>923</rank>

<title><![CDATA[Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions]]></title>

<authors><![CDATA[Stahnke, J.;  Do&#x0308; rk, M.;  Mu&#x0308; ller, B.;  Thom, A.]]></authors>

<controlledterms>

<term><![CDATA[data reduction]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation error]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distortion]]></term>

<term><![CDATA[Heating]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Stress]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[629]]></spage>

<epage><![CDATA[638]]></epage>

<abstract><![CDATA[We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7192695]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2467717]]></doi>

<publicationId><![CDATA[7192695]]></publicationId>

<partnum><![CDATA[7192695]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7192695&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192695]]></pdf>

</document>

<document>

<rank>924</rank>

<title><![CDATA[Guest Editor's Introduction: Special Section on EuroVis]]></title>

<authors><![CDATA[Museth, K.;  Ynnerman, A.;  Moller, Torsten]]></authors>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Electrodes]]></term>

<term><![CDATA[Electroencephalography]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Pattern analysis]]></term>

<term><![CDATA[Quantum computing]]></term>

<term><![CDATA[Sections]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[725]]></spage>

<epage><![CDATA[726]]></epage>

<abstract><![CDATA[The three papers in this special section are extended versions of three papers from the Ninth Eurographics/IEEE VGTC Symposium on Visualization (EuroVis '07), held in Norrkoping, Sweden, May 23-25, 2007. The papers are summarized here.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4530418]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.76]]></doi>

<publicationId><![CDATA[4530418]]></publicationId>

<partnum><![CDATA[4530418]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4530418&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4530418]]></pdf>

</document>

<document>

<rank>925</rank>

<title><![CDATA[Effects of Video Placement and Spatial Context Presentation on Path Reconstruction Tasks with Contextualized Videos]]></title>

<authors><![CDATA[Yi Wang;  Bowman, Doug;  Krum, D.;  Coalho, E.;  Smith-Jackson, T.;  Bailey, D.;  Peck, S.;  Anand, S.;  Kennedy, T.;  Abdrazakov, Y.]]></authors>

<affiliations><![CDATA[Virginia Tech., Blacksburg, VA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[video signal processing]]></term>

<term><![CDATA[video surveillance]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Decision making]]></term>

<term><![CDATA[Guidelines]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Information security]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Prototypes]]></term>

<term><![CDATA[Traffic control]]></term>

<term><![CDATA[Video surveillance]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1755]]></spage>

<epage><![CDATA[1762]]></epage>

<abstract><![CDATA[Many interesting and promising prototypes for visualizing video data have been proposed, including those that combine videos with their spatial context (contextualized videos). However, relatively little work has investigated the fundamental design factors behind these prototypes in order to provide general design guidance. Focusing on real-time video data visualization, we evaluated two important design factors - video placement method and spatial context presentation method - through a user study. In addition, we evaluated the effect of spatial knowledge of the environment. Participantspsila performance was measured through path reconstruction tasks, where the participants followed a target through simulated surveillance videos and marked the target paths on the environment model. We found that embedding videos inside the model enabled realtime strategies and led to faster performance. With the help of contextualized videos, participants not familiar with the real environment achieved similar task performance to participants that worked in that environment. We discuss design implications and provide general design recommendations for traffic and security surveillance system interfaces.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658200]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.126]]></doi>

<publicationId><![CDATA[4658200]]></publicationId>

<partnum><![CDATA[4658200]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658200&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658200]]></pdf>

</document>

<document>

<rank>926</rank>

<title><![CDATA[The 2014 Virtual Reality Career Award: Steve Feiner]]></title>

<authors><![CDATA[]]></authors>

<thesaurusterms>

<term><![CDATA[Awards]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[xiii]]></spage>

<epage><![CDATA[xiii]]></epage>

<abstract><![CDATA[Presents the recipient of the 2014 Virtual Reality Career Award.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6777426]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.42]]></doi>

<publicationId><![CDATA[6777426]]></publicationId>

<partnum><![CDATA[6777426]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6777426&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777426]]></pdf>

</document>

<document>

<rank>927</rank>

<title><![CDATA[Projector Placement Planning for High Quality Visualizations on Real-World Colored Objects]]></title>

<authors><![CDATA[Law, A.J.;  Aliaga, Daniel G.;  Majumder, A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[mobile computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Linear systems]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Planning]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1633]]></spage>

<epage><![CDATA[1641]]></epage>

<abstract><![CDATA[Many visualization applications benefit from displaying content on real-world objects rather than on a traditional display (e.g., a monitor). This type of visualization display is achieved by projecting precisely controlled illumination from multiple projectors onto the real-world colored objects. For such a task, the placement of the projectors is critical in assuring that the desired visualization is possible. Using ad hoc projector placement may cause some appearances to suffer from color shifting due to insufficient projector light radiance being exposed onto the physical surface. This leads to an incorrect appearance and ultimately to a false and potentially misleading visualization. In this paper, we present a framework to discover the optimal position and orientation of the projectors for such projection-based visualization displays. An optimal projector placement should be able to achieve the desired visualization with minimal projector light radiance. When determining optimal projector placement, object visibility, surface reflectance properties, and projector-surface distance and orientation need to be considered. We first formalize a theory for appearance editing image formation and construct a constrained linear system of equations that express when a desired novel appearance or visualization is possible given a geometric and surface reflectance model of the physical surface. Then, we show how to apply this constrained system in an adaptive search to efficiently discover the optimal projector placement which achieves the desired appearance. Constraints can be imposed on the maximum radiance allowed by the projectors and the projectors' placement to support specific goals of various visualization applications. We perform several real-world and simulated appearance edits and visualizations to demonstrate the improvement obtained by our discovered projector placement over ad hoc projector placement.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613506]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.189]]></doi>

<publicationId><![CDATA[5613506]]></publicationId>

<partnum><![CDATA[5613506]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613506&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613506]]></pdf>

</document>

<document>

<rank>928</rank>

<title><![CDATA[An Efficient Solution to Systems of Multivariate Polynomial Using Expression Trees]]></title>

<authors><![CDATA[Elber, G.;  Grandine, T.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., Technion - Israel Inst. of Technol., Haifa]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[polynomials]]></term>

<term><![CDATA[trees (mathematics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[596]]></spage>

<epage><![CDATA[604]]></epage>

<abstract><![CDATA[In recent years, several quite successful attempts have been made to solve systems of polynomial constraints, using geometric design tools, exploiting the availability of subdivision-based solvers [7], [11], [12], [15]. This broad range of methods includes both binary domain subdivision as well as the projected polyhedron method of Sherbrooke and Patrikalakis [15]. A prime obstacle in using subdivision solvers is their scalability. When the given constraint is represented as a tensor product of all its independent variables, it grows exponentially in size as a function of the number of variables. In this work, we show that for many applications, especially geometric ones, the exponential complexity of the constraints can be reduced to a polynomial by representing the underlying structure of the problem in the form of expression trees that represent the constraints. We demonstrate the applicability and scalability of this representation and compare its performance to that of tensor product constraint representation through several examples.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4815236]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.42]]></doi>

<publicationId><![CDATA[4815236]]></publicationId>

<partnum><![CDATA[4815236]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4815236&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815236]]></pdf>

</document>

<document>

<rank>929</rank>

<title><![CDATA[Subdivision Analysis of the Trilinear Interpolant]]></title>

<authors><![CDATA[Carr, H.;  Max, N.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci. & Inf., Univ. Coll. Dublin, Dublin, Ireland]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[divide and conquer methods]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[surface fitting]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[533]]></spage>

<epage><![CDATA[547]]></epage>

<abstract><![CDATA[Isosurfaces are fundamental volumetric visualization tools and are generated by approximating contours of trilinearly interpolated scalar fields. While a complete set of cases has recently been published by Nielson, the formal proof that these cases are the only ones possible and that they are topologically correct is difficult to follow. We present a more straightforward proof of the correctness and completeness of these cases based on a variation of the Dividing Cubes algorithm. Since this proof is based on topological arguments and a divide-and-conquer approach, this also sets the stage for developing tessellation cases for higher order interpolants and the quadrilinear interpolant in four dimensions. We also demonstrate that apart from degenerate cases, Nielson's cases are, in fact, subsets of two basic configurations of the trilinear interpolant.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4745634]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.10]]></doi>

<publicationId><![CDATA[4745634]]></publicationId>

<partnum><![CDATA[4745634]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4745634&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745634]]></pdf>

</document>

<document>

<rank>930</rank>

<title><![CDATA[High-quality splatting on rectilinear grids with efficient culling of occluded voxels]]></title>

<authors><![CDATA[Mueller, K.;  Shareef, N.;  Huang, Jian;  Crawfis, R.]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA]]></affiliations>

<controlledterms>

<term><![CDATA[brightness]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Brightness]]></term>

<term><![CDATA[Costs]]></term>

<term><![CDATA[Image quality]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Medical simulation]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[116]]></spage>

<epage><![CDATA[134]]></epage>

<abstract><![CDATA[Splatting is a popular volume rendering algorithm that pairs good image quality with an efficient volume projection scheme. The current axis-aligned sheet-buffer approach, however, bears certain inaccuracies. The effect of these is less noticeable in still images, but clearly revealed in animated viewing, where disturbing popping of object brightness occurs at certain view angle transitions. In previous work, we presented a new variant of sheet-buffered splatting in which the compositing sheets are oriented parallel to the image plane. This scheme not only eliminates the condition for popping, but also produces images of higher quality. In this paper, we summarize this new paradigm and extend it in a number of ways. We devise a new solution to render rectilinear grids of equivalent cost to the traditional approach that treats the anisotropic volume as being warped into a cubic grid. This enables us to use the usual radially symmetric kernels, which can be projected without inaccuracies. Next, current splatting approaches necessitate the projection of all voxels in the iso-interval(s), although only a subset of these voxels may eventually be visible in the final image. To eliminate these wasteful computations we propose a novel front-to-back approach that employs an occlusion map to determine if a splat contributes to the image before it is projected, thus skipping occluded splats. Additional measures are presented for further speedups. In addition, we present an efficient list-based volume traversal scheme that facilitates the quick modification of transfer functions and iso-values]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[773804]]></arnumber>

<doi><![CDATA[10.1109/2945.773804]]></doi>

<publicationId><![CDATA[773804]]></publicationId>

<partnum><![CDATA[773804]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=773804&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=773804]]></pdf>

</document>

<document>

<rank>931</rank>

<title><![CDATA[A level-set approach for the metamorphosis of solid models]]></title>

<authors><![CDATA[Breen, D.E.;  Whitaker, R.T.]]></authors>

<affiliations><![CDATA[Comput. Graphics Lab., California Inst. of Technol., Pasadena, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[image morphing]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solid modeling]]></term>

<term><![CDATA[Space technology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[173]]></spage>

<epage><![CDATA[192]]></epage>

<abstract><![CDATA[We present a new approach to 3D shape metamorphosis. We express the interpolation of two shapes as a process where one shape deforms to maximize its similarity with another shape. The process incrementally optimizes an objective function while deforming an implicit surface model. We represent the deformable surface as a level set (iso-surface) of a densely sampled scalar function of three dimensions. Such level-set models have been shown to mimic conventional parametric deformable surface models by encoding surface movements as changes in the grayscale values of a volume data set. Thus, a well-founded mathematical structure leads to a set of procedures that describes how voxel values can be manipulated to create deformations that are represented as a sequence of volumes. The result is a 3D morphing method that offers several advantages over previous methods, including minimal need for user input, no model parameterization, flexible topology, and subvoxel accuracy]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[928169]]></arnumber>

<doi><![CDATA[10.1109/2945.928169]]></doi>

<publicationId><![CDATA[928169]]></publicationId>

<partnum><![CDATA[928169]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=928169&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=928169]]></pdf>

</document>

<document>

<rank>932</rank>

<title><![CDATA[Change Blindness Phenomena for Virtual Reality Display Systems]]></title>

<authors><![CDATA[Steinicke, F.;  Bruder, G.;  Hinrichs, K.;  Willemsen, P.]]></authors>

<affiliations><![CDATA[IEEE Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[natural scenes]]></term>

<term><![CDATA[stereo image processing]]></term>

<term><![CDATA[three-dimensional displays]]></term>

<term><![CDATA[virtual reality]]></term>

<term><![CDATA[vision defects]]></term>

<term><![CDATA[visual perception]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Blindness]]></term>

<term><![CDATA[Context]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Observers]]></term>

<term><![CDATA[Virtual reality]]></term>

<term><![CDATA[Visual perception]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[9]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1223]]></spage>

<epage><![CDATA[1233]]></epage>

<abstract><![CDATA[In visual perception, change blindness describes the phenomenon that persons viewing a visual scene may apparently fail to detect significant changes in that scene. These phenomena have been observed in both computer-generated imagery and real-world scenes. Several studies have demonstrated that change blindness effects occur primarily during visual disruptions such as blinks or saccadic eye movements. However, until now the influence of stereoscopic vision on change blindness has not been studied thoroughly in the context of visual perception research. In this paper, we introduce change blindness techniques for stereoscopic virtual reality (VR) systems, providing the ability to substantially modify a virtual scene in a manner that is difficult for observers to perceive. We evaluate techniques for semiimmersive VR systems, i.e., a passive and active stereoscopic projection system as well as an immersive VR system, i.e., a head-mounted display, and compare the results to those of monoscopic viewing conditions. For stereoscopic viewing conditions, we found that change blindness phenomena occur with the same magnitude as in monoscopic viewing conditions. Furthermore, we have evaluated the potential of the presented techniques for allowing abrupt, and yet significant, changes of a stereoscopically displayed virtual reality environment.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5710911]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.41]]></doi>

<publicationId><![CDATA[5710911]]></publicationId>

<partnum><![CDATA[5710911]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5710911&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710911]]></pdf>

</document>

<document>

<rank>933</rank>

<title><![CDATA[Text Scaffolds for Effective Surface Labeling]]></title>

<authors><![CDATA[Cipriano, G.;  Gleicher, M.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Wisconsin Univ., Madison, WI]]></affiliations>

<controlledterms>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Art]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Labeling]]></term>

<term><![CDATA[Rough surfaces]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Solids]]></term>

<term><![CDATA[Surface roughness]]></term>

<term><![CDATA[Surface texture]]></term>

<term><![CDATA[Three dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1675]]></spage>

<epage><![CDATA[1682]]></epage>

<abstract><![CDATA[In this paper we introduce a technique for applying textual labels to 3D surfaces. An effective labeling must balance the conflicting goals of conveying the shape of the surface while being legible from a range of viewing directions. Shape can be conveyed by placing the text as a texture directly on the surface, providing shape cues, meaningful landmarks and minimally obstructing the rest of the model. But rendering such surface text is problematic both in regions of high curvature, where text would be warped, and in highly occluded regions, where it would be hidden. Our approach achieves both labeling goals by applying surface labels to a psilatext scaffoldpsila, a surface explicitly constructed to hold the labels. Text scaffolds conform to the underlying surface whenever possible, but can also float above problem regions, allowing them to be smooth while still conveying the overall shape. This paper provides methods for constructing scaffolds from a variety of input sources, including meshes, constructive solid geometry, and scalar fields. These sources are first mapped into a distance transform, which is then filtered and used to construct a new mesh on which labels are either manually or automatically placed. In the latter case, annotated regions of the input surface are associated with proximal regions on the new mesh, and labels placed using cartographic principles.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658190]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.168]]></doi>

<publicationId><![CDATA[4658190]]></publicationId>

<partnum><![CDATA[4658190]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658190&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658190]]></pdf>

</document>

<document>

<rank>934</rank>

<title><![CDATA[Message from the Editor-in-Chief]]></title>

<authors><![CDATA[Ertl, T.]]></authors>

<affiliations><![CDATA[INRIA]]></affiliations>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[x]]></spage>

<epage><![CDATA[x]]></epage>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5613418]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.178]]></doi>

<publicationId><![CDATA[5613418]]></publicationId>

<partnum><![CDATA[5613418]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613418&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613418]]></pdf>

</document>

<document>

<rank>935</rank>

<title><![CDATA[Computing Robustness and Persistence for Images]]></title>

<authors><![CDATA[Bendich, P.;  Edelsbrunner, H.;  Kerber, M.]]></authors>

<affiliations><![CDATA[IST Austria, Klosterneuburg, Austria]]></affiliations>

<controlledterms>

<term><![CDATA[botany]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[octrees]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Approximation algorithms]]></term>

<term><![CDATA[Approximation methods]]></term>

<term><![CDATA[Diamond-like carbon]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Piecewise linear approximation]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Software algorithms]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1251]]></spage>

<epage><![CDATA[1260]]></epage>

<abstract><![CDATA[We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R<sup>3</sup> and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613465]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.139]]></doi>

<publicationId><![CDATA[5613465]]></publicationId>

<partnum><![CDATA[5613465]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613465&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613465]]></pdf>

</document>

<document>

<rank>936</rank>

<title><![CDATA[Polaris: a system for query, analysis, and visualization of multidimensional relational databases]]></title>

<authors><![CDATA[Stolte, C.;  Tang, D.;  Hanrahan, P.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stanford Univ., CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[formal specification]]></term>

<term><![CDATA[graphical user interfaces]]></term>

<term><![CDATA[query processing]]></term>

<term><![CDATA[relational databases]]></term>

<term><![CDATA[very large databases]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Feedback]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Polarization]]></term>

<term><![CDATA[Relational databases]]></term>

<term><![CDATA[Scientific computing]]></term>

<term><![CDATA[Spatial databases]]></term>

<term><![CDATA[Visual databases]]></term>

<term><![CDATA[Warehousing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[52]]></spage>

<epage><![CDATA[65]]></epage>

<abstract><![CDATA[In the last several years, large multidimensional databases have become common in a variety of applications, such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. In this paper, we present Polaris, an interface for exploring large multidimensional databases that extends the well-known pivot table interface. The novel features of Polaris include an interface for constructing visual specifications of table-based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as he constructs complex queries and visualizations]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[981851]]></arnumber>

<doi><![CDATA[10.1109/2945.981851]]></doi>

<publicationId><![CDATA[981851]]></publicationId>

<partnum><![CDATA[981851]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=981851&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981851]]></pdf>

</document>

<document>

<rank>937</rank>

<title><![CDATA[How Hierarchical Topics Evolve in Large Text Corpora]]></title>

<authors><![CDATA[Weiwei Cui;  Shixia Liu;  Zhuofeng Wu;  Hao Wei]]></authors>

<affiliations><![CDATA[Microsoft Res., Redmond, WA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Document handling]]></term>

<term><![CDATA[Text analysis]]></term>

<term><![CDATA[Text mining]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2281]]></spage>

<epage><![CDATA[2290]]></epage>

<abstract><![CDATA[Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875938]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346433]]></doi>

<publicationId><![CDATA[6875938]]></publicationId>

<partnum><![CDATA[6875938]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875938&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875938]]></pdf>

</document>

<document>

<rank>938</rank>

<title><![CDATA[A fast Gibbs sampler for synthesizing constrained fractals]]></title>

<authors><![CDATA[Vemuri, B.C.;  Mandal, C.;  Shang-Hong Lai]]></authors>

<affiliations><![CDATA[Dept. of Comput. & Inf. Sci., Florida Univ., Gainesville, FL, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[conjugate gradient methods]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[fractals]]></term>

<term><![CDATA[realistic images]]></term>

<term><![CDATA[splines (mathematics)]]></term>

<term><![CDATA[surface fitting]]></term>

<term><![CDATA[wavelet transforms]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomembranes]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Fractals]]></term>

<term><![CDATA[Frequency]]></term>

<term><![CDATA[Random processes]]></term>

<term><![CDATA[Shape control]]></term>

<term><![CDATA[Statistics]]></term>

<term><![CDATA[Stochastic processes]]></term>

<term><![CDATA[Surface waves]]></term>

<term><![CDATA[White noise]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[3]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[1997]]></py>

<spage><![CDATA[337]]></spage>

<epage><![CDATA[351]]></epage>

<abstract><![CDATA[It is well known that the spatial frequency spectrum of membrane and thin plate splines exhibit self-affine characteristics and, hence, behave as fractals. This behavior was exploited in generating the constrained fractal surfaces, which were generated by using a Gibbs sampler algorithm in the work of Szeliski and Terzopoulos (1989). The algorithm involves locally perturbing a constrained spline surface with white noise until the spline surface reaches an equilibrium state. We introduce a fast generalized Gibbs sampler that combines two novel techniques, namely, a preconditioning technique in a wavelet basis for constraining the splines and a perturbation scheme in which, unlike the traditional Gibbs sampler, all sites (surface nodes) that do not share a common neighbor are updated simultaneously. In addition, we demonstrate the capability to generate arbitrary order fractal surfaces without resorting to blending techniques. Using this fast Gibbs sampler algorithm, we demonstrate the synthesis of realistic terrain models from sparse elevation data]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[646237]]></arnumber>

<doi><![CDATA[10.1109/2945.646237]]></doi>

<publicationId><![CDATA[646237]]></publicationId>

<partnum><![CDATA[646237]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=646237&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=646237]]></pdf>

</document>

<document>

<rank>939</rank>

<title><![CDATA[Efficient example-based painting and synthesis of 2D directional texture]]></title>

<authors><![CDATA[Bin Wang;  Wenping Wang;  Huaiping Yang;  Jiaguang Sun]]></authors>

<affiliations><![CDATA[Tsinghua Univ., Beijing, China]]></affiliations>

<controlledterms>

<term><![CDATA[image sampling]]></term>

<term><![CDATA[image segmentation]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Image converters]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Painting]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Quantization]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Sun]]></term>

<term><![CDATA[Testing]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[10]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2004]]></py>

<spage><![CDATA[266]]></spage>

<epage><![CDATA[277]]></epage>

<abstract><![CDATA[We present a new method for converting a photo or image to a synthesized painting following the painting style of an example painting. Treating painting styles of brush strokes as sample textures, we reduce the problem of learning an example painting to a texture synthesis problem. The proposed method uses a hierarchical patch-based approach to the synthesis of directional textures. The key features of our method are: 1) Painting styles are represented as one or more blocks of sample textures selected by the user from the example painting; 2) image segmentation and brush stroke directions defined by the medial axis are used to better represent and communicate shapes and objects present in the synthesized painting; 3) image masks and a hierarchy of texture patches are used to efficiently synthesize high-quality directional textures. The synthesis process is further accelerated through texture direction quantization and the use of Gaussian pyramids. Our method has the following advantages: First, the synthesized stroke textures can follow a direction field determined by the shapes of regions to be painted. Second, the method is very efficient; the generation time of a synthesized painting ranges from a few seconds to about one minute, rather than hours, as required by other existing methods, on a commodity PC. Furthermore, the technique presented here provides a new and efficient solution to the problem of synthesizing a 2D directional texture. We use a number of test examples to demonstrate the efficiency of the proposed method and the high quality of results produced by the method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1272726]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2004.1272726]]></doi>

<publicationId><![CDATA[1272726]]></publicationId>

<partnum><![CDATA[1272726]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1272726&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1272726]]></pdf>

</document>

<document>

<rank>940</rank>

<title><![CDATA[Interactive Visual Analysis of Heterogeneous Scientific Data across an Interface]]></title>

<authors><![CDATA[Kehrer, J.;  Muigg, P.;  Doleisch, H.;  Hauser, H.]]></authors>

<affiliations><![CDATA[Dept. of Inf., Univ. of Bergen, Bergen, Norway]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[grid computing]]></term>

<term><![CDATA[iterative methods]]></term>

<term><![CDATA[natural sciences computing]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Atmospheric modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Solids]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[934]]></spage>

<epage><![CDATA[946]]></epage>

<abstract><![CDATA[We present a systematic approach to the interactive visual analysis of heterogeneous scientific data. The data consist of two interrelated parts given on spatial grids over time (e.g., atmosphere and ocean part from a coupled climate model). By integrating both data parts in a framework of coordinated multiple views (with linking and brushing), the joint investigation of features across the data parts is enabled. An interface is constructed between the data parts that specifies 1) which grid cells in one part are related to grid cells in the other part, and vice versa, 2) how selections (in terms of feature extraction via brushing) are transferred between the two parts, and 3) how an update mechanism keeps the feature specification in both data parts consistent during the analysis. We also propose strategies for visual analysis that result in an iterative refinement of features specified across both data parts. Our approach is demonstrated in the context of a complex simulation of fluid-structure interaction and a multirun climate simulation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5557870]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.111]]></doi>

<publicationId><![CDATA[5557870]]></publicationId>

<partnum><![CDATA[5557870]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5557870&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557870]]></pdf>

</document>

<document>

<rank>941</rank>

<title><![CDATA[SuperMatching: Feature Matching Using Supersymmetric Geometric Constraints]]></title>

<authors><![CDATA[Zhi-Quan Cheng;  Yin Chen;  Martin, R.R.;  Yu-Kun Lai;  Aiping Wang]]></authors>

<affiliations><![CDATA[Nat. Lab. for Parallel & Distrib. Process., Nat. Univ. of Defense Technol., Changsha, China]]></affiliations>

<controlledterms>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Tensile stress]]></term>

<term><![CDATA[Transmission line matrix methods]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[11]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1885]]></spage>

<epage><![CDATA[1894]]></epage>

<abstract><![CDATA[Feature matching is a challenging problem at the heart of numerous computer graphics and computer vision applications. We present the SuperMatching algorithm for finding correspondences between two sets of features. It does so by considering triples or higher order tuples of points, going beyond the pointwise and pairwise approaches typically used. SuperMatching is formulated using a supersymmetric tensor representing an affinity metric that takes into account feature similarity and geometric constraints between features: Feature matching is cast as a higher order graph matching problem. SuperMatching takes advantage of supersymmetry to devise an efficient sampling strategy to estimate the affinity tensor, as well as to store the estimated tensor compactly. Matching is performed by an efficient higher order power iteration approach that takes advantage of this compact representation. Experiments on both synthetic and real data show that SuperMatching provides more accurate feature matching than other state-of-the-art approaches for a wide range of 2D and 3D features, with competitive computational cost.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6461881]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.15]]></doi>

<publicationId><![CDATA[6461881]]></publicationId>

<partnum><![CDATA[6461881]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6461881&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461881]]></pdf>

</document>

<document>

<rank>942</rank>

<title><![CDATA[Visual Data Analysis as an Integral Part of Environmental Management]]></title>

<authors><![CDATA[Meyer, J.;  Bethel, E.W.;  Horsman, J.L.;  Hubbard, S.S.;  Krishnan, H.;  Romosan, A.;  Keating, E.H.;  Monroe, L.;  Strelitz, R.;  Moore, P.;  Taylor, G.;  Torkian, B.;  Johnson, T.C.;  Gorton, I.]]></authors>

<affiliations><![CDATA[Lawrence Berkeley Nat. Lab., Berkeley, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[contamination]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[environmental science computing]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[waste management]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Environmental management]]></term>

<term><![CDATA[Google]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Pollution measurement]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2088]]></spage>

<epage><![CDATA[2094]]></epage>

<abstract><![CDATA[The U.S. Department of Energy's (DOE) Office of Environmental Management (DOE/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6327213]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.278]]></doi>

<publicationId><![CDATA[6327213]]></publicationId>

<partnum><![CDATA[6327213]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327213&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327213]]></pdf>

</document>

<document>

<rank>943</rank>

<title><![CDATA[DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation]]></title>

<authors><![CDATA[Rufiange, S.;  McGuffin, M.J.]]></authors>

<affiliations><![CDATA[Ecole de Technol. Super., Montreal, QC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Prototypes]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2556]]></spage>

<epage><![CDATA[2565]]></epage>

<abstract><![CDATA[Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6634116]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.149]]></doi>

<publicationId><![CDATA[6634116]]></publicationId>

<partnum><![CDATA[6634116]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634116&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634116]]></pdf>

</document>

<document>

<rank>944</rank>

<title><![CDATA[Optimization Integrator for Large Time Steps]]></title>

<authors><![CDATA[Gast, T.F.;  Schroeder, C.;  Stomakhin, A.;  Chenfanfu Jiang;  Teran, J.M.]]></authors>

<affiliations><![CDATA[Univ. of California Los Angeles, Los Angeles, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[Newton method]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[integration]]></term>

<term><![CDATA[minimisation]]></term>

<term><![CDATA[nonlinear equations]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Digital TV]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Minimization]]></term>

<term><![CDATA[Newton method]]></term>

<term><![CDATA[Nonlinear systems]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Robustness]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1103]]></spage>

<epage><![CDATA[1115]]></epage>

<abstract><![CDATA[Practical time steps in today's state-of-the-art simulators typically rely on Newton's method to solve large systems of nonlinear equations. In practice, this works well for small time steps but is unreliable at large time steps at or near the frame rate, particularly for difficult or stiff simulations. We show that recasting backward Euler as a minimization problem allows Newton's method to be stabilized by standard optimization techniques with some novel improvements of our own. The resulting solver is capable of solving even the toughest simulations at the 24Hz frame rate and beyond. We show how simple collisions can be incorporated directly into the solver through constrained minimization without sacrificing efficiency. We also present novel penalty collision formulations for self collisions and collisions against scripted bodies designed for the unique demands of this solver. Finally, we show that these techniques improve the behavior of Material Point Method (MPM) simulations by recasting it as an optimization problem.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7164346]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2459687]]></doi>

<publicationId><![CDATA[7164346]]></publicationId>

<partnum><![CDATA[7164346]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7164346&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164346]]></pdf>

</document>

<document>

<rank>945</rank>

<title><![CDATA[[Cover 4]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[c4]]></spage>

<epage><![CDATA[c4]]></epage>

<abstract><![CDATA[Provides a listing of current society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6097194]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.14]]></doi>

<publicationId><![CDATA[6097194]]></publicationId>

<partnum><![CDATA[6097194]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6097194&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6097194]]></pdf>

</document>

<document>

<rank>946</rank>

<title><![CDATA[Moment Invariants for the Analysis of 2D Flow Fields]]></title>

<authors><![CDATA[Schlemmer, M.;  Heringer, M.;  Morr, F.;  Hotz, I.;  Bertram, M.-H.;  Garth, C.;  Kollmann, W.;  Hamann, B.;  Hagen, H.]]></authors>

<affiliations><![CDATA[Univ. of Kaiserslautern, Kaiserslautern]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[pattern classification]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Pattern analysis]]></term>

<term><![CDATA[Pattern recognition]]></term>

<term><![CDATA[Space technology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1743]]></spage>

<epage><![CDATA[1750]]></epage>

<abstract><![CDATA[We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376210]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70579]]></doi>

<publicationId><![CDATA[4376210]]></publicationId>

<partnum><![CDATA[4376210]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376210&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376210]]></pdf>

</document>

<document>

<rank>947</rank>

<title><![CDATA[A Task Taxonomy for Temporal Graph Visualisation]]></title>

<authors><![CDATA[Kerracher, N.;  Kennedy, J.;  Chalmers, K.]]></authors>

<affiliations><![CDATA[Inst. for Inf. & Digital Innovation, Edinburgh Napier Univ., Edinburgh, UK]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Joining processes]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Sociology]]></term>

<term><![CDATA[Statistics]]></term>

<term><![CDATA[Taxonomy]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1160]]></spage>

<epage><![CDATA[1172]]></epage>

<abstract><![CDATA[By extending and instantiating an existing formal task framework, we define a task taxonomy and task design space for temporal graph visualisation. We discuss the process involved in their generation, and describe how the design space can be `sliced and diced' into multiple overlapping task categories, requiring distinct visual techniques for their support. The approach addresses deficiencies in the task literature, offering domain independence, greater task coverage, and unambiguous task specification. The taxonomy and design space capture tasks for temporal graphs, and also static graphs, multivariate graphs, and graph comparison, and will be of value in the design and evaluation of temporal graph visualisation systems.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7091028]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2424889]]></doi>

<publicationId><![CDATA[7091028]]></publicationId>

<partnum><![CDATA[7091028]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7091028&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091028]]></pdf>

</document>

<document>

<rank>948</rank>

<title><![CDATA[Runtime Visualization of the Human Arterial Tree]]></title>

<authors><![CDATA[Insley, J.A.;  Papka, M.E.;  Suchuan Dong;  Karniadakis, G.;  Karonis, N.T.]]></authors>

<affiliations><![CDATA[Argonne Nat. Lab., Argonne]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Analytical models]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Distributed computing]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Runtime]]></term>

<term><![CDATA[Stability]]></term>

<term><![CDATA[State feedback]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[810]]></spage>

<epage><![CDATA[821]]></epage>

<abstract><![CDATA[Large-scale simulation codes typically execute for extended periods of time and often on distributed computational resources. Because these simulations can run for hours, or even days, scientists like to get feedback about the state of the computation and the validity of its results as it runs. It is also important that these capabilities be made available with little impact on the performance and stability of the simulation. Visualizing and exploring data in the early stages of the simulation can help scientists identify problems early, potentially avoiding a situation where a simulation runs for several days, only to discover that an error with an input parameter caused both time and resources to be wasted. We describe an application that aids in the monitoring and analysis of a simulation of the human arterial tree. The application provides researchers with high-level feedback about the state of the ongoing simulation and enables them to investigate particular areas of interest in greater detail. The application also offers monitoring information about the amount of data produced and data transfer performance among the various components of the application.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4293023]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1017]]></doi>

<publicationId><![CDATA[4293023]]></publicationId>

<partnum><![CDATA[4293023]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4293023&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293023]]></pdf>

</document>

<document>

<rank>949</rank>

<title><![CDATA[An Insight-Based Longitudinal Study of Visual Analytics]]></title>

<authors><![CDATA[Saraiya, P.;  North, C.;  Lam, V.;  Duca, K.A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graphical user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Failure analysis]]></term>

<term><![CDATA[Graphical user interfaces]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Performance analysis]]></term>

<term><![CDATA[Software systems]]></term>

<term><![CDATA[Time measurement]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1511]]></spage>

<epage><![CDATA[1522]]></epage>

<abstract><![CDATA[Visualization tools are typically evaluated in controlled studies that observe the short-term usage of these tools by participants on preselected data sets and benchmark tasks. Though such studies provide useful suggestions, they miss the long-term usage of the tools. A longitudinal study of a bioinformatics data set analysis is reported here. The main focus of this work is to capture the entire analysts process that an analyst goes through from a raw data set to the insights sought from the data. The study provides interesting observations about the use of visual representations and interaction mechanisms provided by the tools, and also about the process of insight generation in general. This deepens our understanding of visual analytics, guides visualization developers in creating more effective visualization tools in terms of user requirements, and guides evaluators in designing future studies that are more representative of insights sought by users from their data sets]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1703371]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.85]]></doi>

<publicationId><![CDATA[1703371]]></publicationId>

<partnum><![CDATA[1703371]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1703371&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703371]]></pdf>

</document>

<document>

<rank>950</rank>

<title><![CDATA[Terrain Synthesis from Digital Elevation Models]]></title>

<authors><![CDATA[Zhou, H.;  Jie Sun;  Turk, G.;  Rehg, J.M.]]></authors>

<affiliations><![CDATA[Georgia Inst. of Tech., Atlanta]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[geomorphology]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[terrain mapping]]></term>

<term><![CDATA[tree searching]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Aerospace simulation]]></term>

<term><![CDATA[Application software]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer simulation]]></term>

<term><![CDATA[Digital elevation models]]></term>

<term><![CDATA[Fractals]]></term>

<term><![CDATA[Geology]]></term>

<term><![CDATA[Large-scale systems]]></term>

<term><![CDATA[Sun]]></term>

<term><![CDATA[Tree graphs]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[834]]></spage>

<epage><![CDATA[848]]></epage>

<abstract><![CDATA[In this paper, we present an example-based system for terrain synthesis. In our approach, patches from a sample terrain (represented by a height field) are used to generate a new terrain. The synthesis is guided by a user-sketched feature map that specifies where terrain features occur in the resulting synthetic terrain. Our system emphasizes large-scale curvilinear features (ridges and valleys) because such features are the dominant visual elements in most terrains. Both the example height field and user's sketch map are analyzed using a technique from the field of geomorphology. The system finds patches from the example data that match the features found in the user's sketch. Patches are joined together using graph cuts and Poisson editing. The order in which patches are placed in the synthesized terrain is determined by breadth-first traversal of a feature tree and this generates improved results over standard raster-scan placement orders. Our technique supports user-controlled terrain synthesis in a wide variety of styles, based upon the visual richness of real-world terrain data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4293025]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.1027]]></doi>

<publicationId><![CDATA[4293025]]></publicationId>

<partnum><![CDATA[4293025]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4293025&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4293025]]></pdf>

</document>

<document>

<rank>951</rank>

<title><![CDATA[Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles]]></title>

<authors><![CDATA[Hummel, M.;  Obermaier, H.;  Garth, C.;  Joy, K.I.]]></authors>

<affiliations><![CDATA[Univ. of Kaiserslautern, Kaiserslautern, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[mechanical engineering computing]]></term>

<term><![CDATA[pattern classification]]></term>

<term><![CDATA[principal component analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Principal component analysis]]></term>

<term><![CDATA[Trajectory]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2743]]></spage>

<epage><![CDATA[2752]]></epage>

<abstract><![CDATA[Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634122]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.141]]></doi>

<publicationId><![CDATA[6634122]]></publicationId>

<partnum><![CDATA[6634122]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634122&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634122]]></pdf>

</document>

<document>

<rank>952</rank>

<title><![CDATA[A Deeper Understanding of Sequence in Narrative Visualization]]></title>

<authors><![CDATA[Hullman, J.;  Drucker, S.;  Riche, N.H.;  Bongshin Lee;  Fisher, D.;  Adar, E.]]></authors>

<controlledterms>

<term><![CDATA[cognition]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[humanities]]></term>

<term><![CDATA[sequences]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Encoding]]></term>

<term><![CDATA[Linear programming]]></term>

<term><![CDATA[Parallel processing]]></term>

<term><![CDATA[Sequential analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2406]]></spage>

<epage><![CDATA[2415]]></epage>

<abstract><![CDATA[Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634182]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.119]]></doi>

<publicationId><![CDATA[6634182]]></publicationId>

<partnum><![CDATA[6634182]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634182&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634182]]></pdf>

</document>

<document>

<rank>953</rank>

<title><![CDATA[Diminished Reality Based on Image Inpainting Considering Background Geometry]]></title>

<authors><![CDATA[Kawai, N.;  Sato, T.;  Yokoya, N.]]></authors>

<affiliations><![CDATA[Norihiko Kawai is with the Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan, 630-0192. (e-mail: norihi-k@is.naist.jp).]]></affiliations>

<thesaurusterms>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Coherence]]></term>

<term><![CDATA[Distortion]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Real-time systems]]></term>

<term><![CDATA[Target tracking]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Early Access Articles]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[PP]]></volume>

<issue><![CDATA[99]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[1]]></spage>

<epage><![CDATA[1]]></epage>

<abstract><![CDATA[Diminished reality aims to remove real objects from video images and fill in the missing regions with plausible background textures in real time. Most conventional methods based on image inpainting achieve diminished reality by assuming that the background around a target object is almost planar. This paper proposes a new diminished reality method that considers background geometries with less constraints than the conventional ones. In this study, we approximate the background geometry by combining local planes, and improve the quality of image inpainting by correcting the perspective distortion of texture and limiting the search area for finding similar textures as exemplars. The temporal coherence of texture is preserved using the geometries and camera pose estimated by visual-SLAM (Simultaneous Localization and Mapping). The mask region that includes a target object is robustly set in each frame by projecting a 3D region, rather than tracking the object in 2D image space. The effectiveness of the proposed method is successfully demonstrated using several experimental environments.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7180400]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2462368]]></doi>

<publicationId><![CDATA[7180400]]></publicationId>

<partnum><![CDATA[7180400]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7180400&contentType=Early+Access+Articles]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7180400]]></pdf>

</document>

<document>

<rank>954</rank>

<title><![CDATA[Local Ambient Occlusion in Direct Volume Rendering]]></title>

<authors><![CDATA[Hernell, F.;  Ljung, P.;  Ynnerman, A.]]></authors>

<affiliations><![CDATA[Dept. of Visual Inf. Technol. & Applic. (VITA), Linkoping Univ., Norrkoping, Sweden]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[hidden feature removal]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[medical computing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[548]]></spage>

<epage><![CDATA[559]]></epage>

<abstract><![CDATA[This paper presents a novel technique to efficiently compute illumination for Direct Volume Rendering using a local approximation of ambient occlusion to integrate the intensity of incident light for each voxel. An advantage with this local approach is that fully shadowed regions are avoided, a desirable feature in many applications of volume rendering such as medical visualization. Additional transfer function interactions are also presented, for instance, to highlight specific structures with luminous tissue effects and create an improved context for semitransparent tissues with a separate absorption control for the illumination settings. Multiresolution volume management and GPU-based computation are used to accelerate the calculations and support large data sets. The scheme yields interactive frame rates with an adaptive sampling approach for incrementally refined illumination under arbitrary transfer function changes. The illumination effects can give a better understanding of the shape and density of tissues and so has the potential to increase the diagnostic value of medical volume rendering. Since the proposed method is gradient-free, it is especially beneficial at the borders of clip planes, where gradients are undefined, and for noisy data sets.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4840341]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.45]]></doi>

<publicationId><![CDATA[4840341]]></publicationId>

<partnum><![CDATA[4840341]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4840341&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4840341]]></pdf>

</document>

<document>

<rank>955</rank>

<title><![CDATA[LoyalTracker: Visualizing Loyalty Dynamics in Search Engines]]></title>

<authors><![CDATA[Conglei Shi;  Yingcai Wu;  Shixia Liu;  Hong Zhou;  Huamin Qu]]></authors>

<affiliations><![CDATA[Hong Kong Univ. of Sci. & Technol., Hong Kong, China]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human factors]]></term>

<term><![CDATA[search engines]]></term>

<term><![CDATA[text analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Behavioral science]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Search engines]]></term>

<term><![CDATA[Search methods]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[1733]]></spage>

<epage><![CDATA[1742]]></epage>

<abstract><![CDATA[The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6876038]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346912]]></doi>

<publicationId><![CDATA[6876038]]></publicationId>

<partnum><![CDATA[6876038]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6876038&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6876038]]></pdf>

</document>

<document>

<rank>956</rank>

<title><![CDATA[Interactive Rendering of Dynamic Geometry]]></title>

<authors><![CDATA[Ponchio, F.;  Hormann, K.]]></authors>

<affiliations><![CDATA[Dept. of Inf., Clausthal Univ. of Technol., Clausthal-Zellerfeld]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[914]]></spage>

<epage><![CDATA[925]]></epage>

<abstract><![CDATA[Fluid simulations typically produce complex three-dimensional (3D) isosurfaces whose geometry and topology change over time. The standard way of representing such "dynamic geometry" is by a set of isosurfaces that are extracted individually at certain time steps. An alternative strategy is to represent the whole sequence as a four-dimensional (4D) tetrahedral mesh. The isosurface at a specific time step can then be computed by intersecting the tetrahedral mesh with a 3D hyperplane. This not only allows the animation of the surface continuously over time without having to worry about the topological changes, but also enables simplification algorithms to exploit temporal coherence. We show how to interactively render such 4D tetrahedral meshes by improving previous GPU-accelerated techniques and building an out-of-core multiresolution structure based on quadric error simplification. As a second application, we apply our framework to time-varying surfaces that result from morphing one triangle mesh into another.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4447669]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.35]]></doi>

<publicationId><![CDATA[4447669]]></publicationId>

<partnum><![CDATA[4447669]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4447669&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4447669]]></pdf>

</document>

<document>

<rank>957</rank>

<title><![CDATA[2002 Index IEEE Transactions on Visualization and Computer Graphics]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[8]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2002]]></py>

<spage><![CDATA[395]]></spage>

<epage><![CDATA[396]]></epage>

<abstract><![CDATA[This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[1044570]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2002.1044570]]></doi>

<publicationId><![CDATA[1044570]]></publicationId>

<partnum><![CDATA[1044570]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1044570&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044570]]></pdf>

</document>

<document>

<rank>958</rank>

<title><![CDATA[GL4D: A GPU-based Architecture for Interactive 4D Visualization]]></title>

<authors><![CDATA[Chu, A.;  Chi-Wing Fu;  Hanson, A.J.;  Pheng-Ann Heng]]></authors>

<affiliations><![CDATA[Chinese Univ. of Hong Kong, Hong Kong, China]]></affiliations>

<controlledterms>

<term><![CDATA[application program interfaces]]></term>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[coprocessors]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[hidden feature removal]]></term>

<term><![CDATA[mathematics computing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[transfer functions]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Buffer storage]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Graphics]]></term>

<term><![CDATA[Interactive systems]]></term>

<term><![CDATA[Libraries]]></term>

<term><![CDATA[Light sources]]></term>

<term><![CDATA[Pipelines]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Transfer functions]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1587]]></spage>

<epage><![CDATA[1594]]></epage>

<abstract><![CDATA[This paper describes GL4D, an interactive system for visualizing 2-manifolds and 3-manifolds embedded in four Euclidean dimensions and illuminated by 4D light sources. It is a tetrahedron-based rendering pipeline that projects geometry into volume images, an exact parallel to the conventional triangle-based rendering pipeline for 3D graphics. Novel features include GPU-based algorithms for real-time 4D occlusion handling and transparency compositing; we thus enable a previously impossible level of quality and interactivity for exploring lit 4D objects. The 4D tetrahedrons are stored in GPU memory as vertex buffer objects, and the vertex shader is used to perform per-vertex 4D modelview transformations and 4D-to-3D projection. The geometry shader extension is utilized to slice the projected tetrahedrons and rasterize the slices into individual 2D layers of voxel fragments. Finally, the fragment shader performs per-voxel operations such as lighting and alpha blending with previously computed layers. We account for 4D voxel occlusion along the 4D-to-3D projection ray by supporting a multi-pass back-to-front fragment composition along the projection ray; to accomplish this, we exploit a new adaptation of the dual depth peeling technique to produce correct volume image data and to simultaneously render the resulting volume data using 3D transfer functions into the final 2D image. Previous CPU implementations of the rendering of 4D-embedded 3-manifolds could not perform either the 4D depth-buffered projection or manipulation of the volume-rendered image in real-time; in particular, the dual depth peeling algorithm is a novel GPU-based solution to the real-time 4D depth-buffering problem. GL4D is implemented as an integrated OpenGL-style API library, so that the underlying shader operations are as transparent as possible to the user.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290777]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.147]]></doi>

<publicationId><![CDATA[5290777]]></publicationId>

<partnum><![CDATA[5290777]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290777&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290777]]></pdf>

</document>

<document>

<rank>959</rank>

<title><![CDATA[StereoPasting: Interactive Composition in Stereoscopic Images]]></title>

<authors><![CDATA[Ruo-Feng Tong;  Yun Zhang;  Ke-Li Cheng]]></authors>

<affiliations><![CDATA[State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[stereo image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Paints]]></term>

<term><![CDATA[Stereo image processing]]></term>

<term><![CDATA[Videos]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[1375]]></spage>

<epage><![CDATA[1385]]></epage>

<abstract><![CDATA[We propose "StereoPasting,&#x201D; an efficient method for depth-consistent stereoscopic composition, in which a source 2D image is interactively blended into a target stereoscopic image. As we paint "disparity&#x201D; on a 2D image, the disparity map of the selected region is gradually produced by edge-aware diffusion, and then blended with that of the target stereoscopic image. By considering constraints of the expected disparities and perspective scaling, the 2D object is warped to generate an image pair, which is then blended into the target image pair to get the composition result. The warping is formulated as an energy minimization, which could be solved in real time. We also present an interactive composition system, in which users can edit the disparity maps of 2D images by strokes, while viewing the composition results instantly. Experiments show that our method is intuitive and efficient for interactive stereoscopic composition. A lot of applications demonstrate the versatility of our method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6381405]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.319]]></doi>

<publicationId><![CDATA[6381405]]></publicationId>

<partnum><![CDATA[6381405]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6381405&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381405]]></pdf>

</document>

<document>

<rank>960</rank>

<title><![CDATA[Toward High-Quality Gradient Estimation on Regular Lattices]]></title>

<authors><![CDATA[Hossain, Z.;  Alim, U.;  Mo&#x0308; ller, T.]]></authors>

<affiliations><![CDATA[Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada]]></affiliations>

<controlledterms>

<term><![CDATA[approximation theory]]></term>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[series (mathematics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Convolution]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Hilbert space]]></term>

<term><![CDATA[Image reconstruction]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Lattices]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[State estimation]]></term>

<term><![CDATA[Taylor series]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[426]]></spage>

<epage><![CDATA[439]]></epage>

<abstract><![CDATA[In this paper, we present two methods for accurate gradient estimation from scalar field data sampled on regular lattices. The first method is based on the multidimensional Taylor series expansion of the convolution sum and allows us to specify design criteria such as compactness and approximation power. The second method is based on a Hilbert space framework and provides a minimum error solution in the form of an orthogonal projection operating between two approximation spaces. Both methods lead to discrete filters, which can be combined with continuous reconstruction kernels to yield highly accurate estimators as compared to the current state of the art. We demonstrate the advantages of our methods in the context of volume rendering of data sampled on Cartesian and Body-Centered Cubic lattices. Our results show significant qualitative and quantitative improvements for both synthetic and real data, while incurring a moderate preprocessing and storage overhead.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5416706]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.37]]></doi>

<publicationId><![CDATA[5416706]]></publicationId>

<partnum><![CDATA[5416706]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5416706&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416706]]></pdf>

</document>

<document>

<rank>961</rank>

<title><![CDATA[A vectorial algorithm for tracing discrete straight lines in N-dimensional generalized grids]]></title>

<authors><![CDATA[Ibanez, L.;  Hamitouche, C.;  Roux, C.]]></authors>

<affiliations><![CDATA[Div. of Neurosurgery, North Carolina Univ., Chapel Hill, NC, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[ray tracing]]></term>

<term><![CDATA[topology]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biomedical imaging]]></term>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Computer Society]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[FCC]]></term>

<term><![CDATA[Functional analysis]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Signal processing algorithms]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[7]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2001]]></py>

<spage><![CDATA[97]]></spage>

<epage><![CDATA[108]]></epage>

<abstract><![CDATA[This paper presents an algorithm to trace discrete straight lines in regular grids of any dimension. Most known line tracing algorithms have been developed in <e2>Z</e2><sup>2</sup> and <e2>Z</e2><sup>3</sup> orthogonal grids. The contribution of this paper is the definition of a method to trace lines in nonorthogonal grids in any dimension. This method is not restricted to being used with a specific grid connectivity as other widespread methods are. Good performance can be achieved because only additions are used during line tracing]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[928163]]></arnumber>

<doi><![CDATA[10.1109/2945.928163]]></doi>

<publicationId><![CDATA[928163]]></publicationId>

<partnum><![CDATA[928163]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=928163&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=928163]]></pdf>

</document>

<document>

<rank>962</rank>

<title><![CDATA[Lagrangian Coherent Structures for Design Analysis of Revolving Doors]]></title>

<authors><![CDATA[Schindler, B.;  Fuchs, R.;  Barp, S.;  Waser, J.;  Pobitzer, A.;  Carnecky, R.;  Matkovic, K.;  Peikert, R.]]></authors>

<affiliations><![CDATA[ETH Zurich, Zurich, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[HVAC]]></term>

<term><![CDATA[building management systems]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[design engineering]]></term>

<term><![CDATA[doors]]></term>

<term><![CDATA[fast Fourier transforms]]></term>

<term><![CDATA[structural engineering computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Atmospheric modeling]]></term>

<term><![CDATA[Energy efficiency]]></term>

<term><![CDATA[Flow control]]></term>

<term><![CDATA[Heating]]></term>

<term><![CDATA[Lyapunov methods]]></term>

<term><![CDATA[Meteorology]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2159]]></spage>

<epage><![CDATA[2168]]></epage>

<abstract><![CDATA[Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327221]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.243]]></doi>

<publicationId><![CDATA[6327221]]></publicationId>

<partnum><![CDATA[6327221]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327221&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327221]]></pdf>

</document>

<document>

<rank>963</rank>

<title><![CDATA[Interactive Separating Streak Surfaces]]></title>

<authors><![CDATA[Ferstl, F.;  Burger, K.;  Theisel, H.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization group, Tech. Univ. Munchen, Mu&#x0308;nchen, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[solid modelling]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Skeleton]]></term>

<term><![CDATA[Surface reconstruction]]></term>

<term><![CDATA[Three dimensional displays]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1569]]></spage>

<epage><![CDATA[1577]]></epage>

<abstract><![CDATA[Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613499]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.169]]></doi>

<publicationId><![CDATA[5613499]]></publicationId>

<partnum><![CDATA[5613499]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613499&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613499]]></pdf>

</document>

<document>

<rank>964</rank>

<title><![CDATA[Fast Exact Nearest Patch Matching for Patch-Based Image Editing and Processing]]></title>

<authors><![CDATA[Chunxia Xiao;  Meng Liu;  Nie Yongwei;  Zhao Dong]]></authors>

<affiliations><![CDATA[Comput. Sch., Wuhan Univ., Wuhan, China]]></affiliations>

<controlledterms>

<term><![CDATA[data structures]]></term>

<term><![CDATA[image matching]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Acceleration]]></term>

<term><![CDATA[Complexity theory]]></term>

<term><![CDATA[Force]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Memory management]]></term>

<term><![CDATA[Pixel]]></term>

<term><![CDATA[Principal component analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1122]]></spage>

<epage><![CDATA[1134]]></epage>

<abstract><![CDATA[This paper presents an efficient exact nearest patch matching algorithm which can accurately find the most similar patch-pairs between source and target image. Traditional match matching algorithms treat each pixel/patch as an independent sample and build a hierarchical data structure, such as kd-tree, to accelerate nearest patch finding. However, most of these approaches can only find approximate nearest patch and do not explore the sequential overlap between patches. Hence, they are neither accurate in quality nor optimal in speed. By eliminating redundant similarity computation of sequential overlap between patches, our method finds the exact nearest patch in brute-force style but reduces its running time complexity to be linear on the patch size. Furthermore, relying on recent multicore graphics hardware, our method can be further accelerated by at least an order of magnitude (&#x2265; 10 &#x00D7;). This greatly improves performance and ensures that our method can be efficiently applied in an interactive editing framework for moderate-sized image even video. To our knowledge, this approach is the fastest exact nearest patch matching method for high-dimensional patch and also its extra memory requirement is minimal. Comparisons with the popular nearest patch matching methods in the experimental results demonstrate the merits of our algorithm.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5611508]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.226]]></doi>

<publicationId><![CDATA[5611508]]></publicationId>

<partnum><![CDATA[5611508]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5611508&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611508]]></pdf>

</document>

<document>

<rank>965</rank>

<title><![CDATA[Anisotropic diffusion in vector field visualization on Euclidean domains and surfaces]]></title>

<authors><![CDATA[Diewald, U.;  Preusser, T.;  Rumpf, M.]]></authors>

<affiliations><![CDATA[Inst. for Appl. Math., Bonn Univ., Germany]]></affiliations>

<controlledterms>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[flow visualisation]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[partial differential equations]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Computational fluid dynamics]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Helium]]></term>

<term><![CDATA[Image edge detection]]></term>

<term><![CDATA[Image processing]]></term>

<term><![CDATA[Smoothing methods]]></term>

<term><![CDATA[Spatial resolution]]></term>

<term><![CDATA[Surface texture]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[6]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2000]]></py>

<spage><![CDATA[139]]></spage>

<epage><![CDATA[149]]></epage>

<abstract><![CDATA[Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data on two and three-dimensional domains and on surfaces in an intuitively understandable way. Here, a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of vector field data and serves as an appropriate scale space method for the visualization of complicated flow pattern. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. Here, an initial noisy image intensity is smoothed along integral lines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown for flow fields in 2D and 3D, as well as for principal directions of curvature on general triangulated surfaces. Furthermore, the provisions for flow segmentation are outlined]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[856995]]></arnumber>

<doi><![CDATA[10.1109/2945.856995]]></doi>

<publicationId><![CDATA[856995]]></publicationId>

<partnum><![CDATA[856995]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=856995&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=856995]]></pdf>

</document>

<document>

<rank>966</rank>

<title><![CDATA[SI-Cut: Structural Inconsistency Analysis for Image Foreground Extraction]]></title>

<authors><![CDATA[I-Chen Lin;  Yu-Chien Lan;  Po-Wen Cheng]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Inst. of Multimedia Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[image colour analysis]]></term>

<term><![CDATA[image processing]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[object detection]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Image segmentation]]></term>

<term><![CDATA[Optimization]]></term>

<term><![CDATA[Silicon]]></term>

<term><![CDATA[Vectors]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[860]]></spage>

<epage><![CDATA[872]]></epage>

<abstract><![CDATA[This paper presents a novel approach for extracting foreground objects from an image. Existing methods involve separating the foreground and background mainly according to their color distributions and neighbor similarities. This paper proposes using a more discriminative strategy, structural inconsistency analysis, in which the localities of color and texture are considered. Given an indicated rectangle, the proposed system iteratively maximizes the consensus regions between the original image and predicted structures from the known background. The object contour can then be extracted according to inconsistency in the predicted background and foreground structures. The proposed method includes an efficient image completion technique for structural prediction. The results of experiments showed that the extraction accuracy of the proposed method is higher than that of related methods for structural scenes, and is also comparable to that of related methods for less structural situations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[7018970]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2396063]]></doi>

<publicationId><![CDATA[7018970]]></publicationId>

<partnum><![CDATA[7018970]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7018970&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7018970]]></pdf>

</document>

<document>

<rank>967</rank>

<title><![CDATA[Interactive Visibility Retargeting in VR Using Conformal Visualization]]></title>

<authors><![CDATA[Petkov, K.;  Papadopoulos, C.;  Min Zhang;  Kaufman, A.E.;  Xianfeng Gu]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Stony Brook Univ., Stony Brook, NY, USA]]></affiliations>

<controlledterms>

<term><![CDATA[conformal mapping]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[user interfaces]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Conformal mapping]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[7]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[1027]]></spage>

<epage><![CDATA[1040]]></epage>

<abstract><![CDATA[In Virtual Reality, immersive systems such as the CAVE provide an important tool for the collaborative exploration of large 3D data. Unlike head-mounted displays, these systems are often only partially immersive due to space, access, or cost constraints. The resulting loss of visual information becomes a major obstacle for critical tasks that need to utilize the users' entire field of vision. We have developed a conformal visualization technique that establishes a conformal mapping between the full 360^circ field of view and the display geometry of a given visualization system. The mapping is provably angle-preserving and has the desirable property of preserving shapes locally, which is important for identifying shape-based features in the visual data. We apply the conformal visualization to both forward and backward rendering pipelines in a variety of retargeting scenarios, including CAVEs and angled arrangements of flat panel displays. In contrast to image-based retargeting approaches, our technique constructs accurate stereoscopic images that are free of resampling artifacts. Our user study shows that on the visual polyp detection task in Immersive Virtual Colonoscopy, conformal visualization leads to imprrenderingoved sensitivity at comparable examination times against the traditional rendering approach. We also develop a novel user interface based on the interactive recreation of the conformal mapping and the real-time regeneration of the view direction correspondence.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6086538]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.278]]></doi>

<publicationId><![CDATA[6086538]]></publicationId>

<partnum><![CDATA[6086538]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6086538&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6086538]]></pdf>

</document>

<document>

<rank>968</rank>

<title><![CDATA[Stress Tensor Field Visualization for Implant Planning in Orthopedics]]></title>

<authors><![CDATA[Dick, C.;  Georgii, J.;  Burgkart, R.;  Westermann, R.]]></authors>

<affiliations><![CDATA[Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[biomechanics]]></term>

<term><![CDATA[bone]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical diagnostic computing]]></term>

<term><![CDATA[orthopaedics]]></term>

<term><![CDATA[physiological models]]></term>

<term><![CDATA[planning]]></term>

<term><![CDATA[prosthetics]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[stress analysis]]></term>

<term><![CDATA[surgery]]></term>

<term><![CDATA[tensors]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bones]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Implants]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Orthopedic surgery]]></term>

<term><![CDATA[Prosthetics]]></term>

<term><![CDATA[Surges]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1399]]></spage>

<epage><![CDATA[1406]]></epage>

<abstract><![CDATA[We demonstrate the application of advanced 3D visualization techniques to determine the optimal implant design and position in hip joint replacement planning. Our methods take as input the physiological stress distribution inside a patient's bone under load and the stress distribution inside this bone under the same load after a simulated replacement surgery. The visualization aims at showing principal stress directions and magnitudes, as well as differences in both distributions. By visualizing changes of normal and shear stresses with respect to the principal stress directions of the physiological state, a comparative analysis of the physiological stress distribution and the stress distribution with implant is provided, and the implant parameters that most closely replicate the physiological stress state in order to avoid stress shielding can be determined. Our method combines volume rendering for the visualization of stress magnitudes with the tracing of short line segments for the visualization of stress directions. To improve depth perception, transparent, shaded, and antialiased lines are rendered in correct visibility order, and they are attenuated by the volume rendering. We use a focus+context approach to visually guide the user to relevant regions in the data, and to support a detailed stress analysis in these regions while preserving spatial context information. Since all of our techniques have been realized on the GPU, they can immediately react to changes in the simulated stress tensor field and thus provide an effective means for optimal implant selection and positioning in a computational steering environment.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290754]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.184]]></doi>

<publicationId><![CDATA[5290754]]></publicationId>

<partnum><![CDATA[5290754]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290754&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290754]]></pdf>

</document>

<document>

<rank>969</rank>

<title><![CDATA[Pre-Integrated Volume Rendering with Non-Linear Gradient Interpolation]]></title>

<authors><![CDATA[Guetat, A.;  Ancel, A.;  Marchesin, S.;  Dischler, J.-M.]]></authors>

<controlledterms>

<term><![CDATA[gradient methods]]></term>

<term><![CDATA[interpolation]]></term>

<term><![CDATA[lighting]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[table lookup]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Equations]]></term>

<term><![CDATA[Interpolation]]></term>

<term><![CDATA[Lighting]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Niobium]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[1487]]></spage>

<epage><![CDATA[1494]]></epage>

<abstract><![CDATA[Shading is an important feature for the comprehension of volume datasets, but is difficult to implement accurately. Current techniques based on pre-integrated direct volume rendering approximate the volume rendering integral by ignoring non-linear gradient variations between front and back samples, which might result in cumulated shading errors when gradient variations are important and / or when the illumination function features high frequencies. In this paper, we explore a simple approach for pre-integrated volume rendering with non-linear gradient interpolation between front and back samples. We consider that the gradient smoothly varies along a quadratic curve instead of a segment in-between consecutive samples. This not only allows us to compute more accurate shaded pre-integrated look-up tables, but also allows us to more efficiently process shading amplifying effects, based on gradient filtering. An interesting property is that the pre-integration tables we use remain two-dimensional as for usual pre-integrated classification. We conduct experiments using a full hardware approach with the Blinn-Phong illumination model as well as with a non-photorealistic illumination model.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613490]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.187]]></doi>

<publicationId><![CDATA[5613490]]></publicationId>

<partnum><![CDATA[5613490]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613490&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613490]]></pdf>

</document>

<document>

<rank>970</rank>

<title><![CDATA[The Benefits of Synchronous Collaborative Information Visualization: Evidence from an Experimental Evaluation]]></title>

<authors><![CDATA[Bresciani, S.;  Eppler, M.J.]]></authors>

<affiliations><![CDATA[Univ. of Lugano, Lugano, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Collaboration]]></term>

<term><![CDATA[Collaborative work]]></term>

<term><![CDATA[Data analysis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Knowledge management]]></term>

<term><![CDATA[Optimal control]]></term>

<term><![CDATA[Particle measurements]]></term>

<term><![CDATA[Productivity]]></term>

<term><![CDATA[Statistical analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[1073]]></spage>

<epage><![CDATA[1080]]></epage>

<abstract><![CDATA[A great corpus of studies reports empirical evidence of how information visualization supports comprehension and analysis of data. The benefits of visualization for synchronous group knowledge work, however, have not been addressed extensively. Anecdotal evidence and use cases illustrate the benefits of synchronous collaborative information visualization, but very few empirical studies have rigorously examined the impact of visualization on group knowledge work. We have consequently designed and conducted an experiment in which we have analyzed the impact of visualization on knowledge sharing in situated work groups. Our experimental study consists of evaluating the performance of 131 subjects (all experienced managers) in groups of 5 (for a total of 26 groups), working together on a real-life knowledge sharing task. We compare (1) the control condition (no visualization provided), with two visualization supports: (2) optimal and (3) suboptimal visualization (based on a previous survey). The facilitator of each group was asked to populate the provided interactive visual template with insights from the group, and to organize the contributions according to the group consensus. We have evaluated the results through both objective and subjective measures. Our statistical analysis clearly shows that interactive visualization has a statistically significant, objective and positive impact on the outcomes of knowledge sharing, but that the subjects seem not to be aware of this. In particular, groups supported by visualization achieved higher productivity, higher quality of outcome and greater knowledge gains. No statistically significant results could be found between an optimal and a suboptimal visualization though (as classified by the pre-experiment survey). Subjects also did not seem to be aware of the benefits that the visualizations provided as no difference between the visualization and the control conditions was found for the self-reported measures of satisfaction a- - nd participation. An implication of our study for information visualization applications is to extend them by using real-time group annotation functionalities that aid in the group sense making process of the represented data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5290714]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.188]]></doi>

<publicationId><![CDATA[5290714]]></publicationId>

<partnum><![CDATA[5290714]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5290714&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5290714]]></pdf>

</document>

<document>

<rank>971</rank>

<title><![CDATA[Geometrically Consistent Stereoscopic Image Editing Using Patch-Based Synthesis]]></title>

<authors><![CDATA[Sheng-Jie Luo;  Ying-Tse Sun;  I-Chao Shen;  Bing-Yu Chen;  Yung-Yu Chuang]]></authors>

<affiliations><![CDATA[Nat. Taiwan Univ., Taipei, Taiwan]]></affiliations>

<controlledterms>

<term><![CDATA[controllability]]></term>

<term><![CDATA[image texture]]></term>

<term><![CDATA[optimisation]]></term>

<term><![CDATA[stereo image processing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Media]]></term>

<term><![CDATA[Stereo image processing]]></term>

<term><![CDATA[Three-dimensional displays]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[21]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2015]]></py>

<spage><![CDATA[56]]></spage>

<epage><![CDATA[67]]></epage>

<abstract><![CDATA[This paper presents a patch-based synthesis framework for stereoscopic image editing. The core of the proposed method builds upon a patch-based optimization framework with two key contributions: First, we introduce a depth-dependent patch-pair similarity measure for distinguishing and better utilizing image contents with different depth structures. Second, a joint patch-pair search is proposed for properly handling the correlation between two views. The proposed method successfully overcomes two main challenges of editing stereoscopic 3D media: (1) maintaining the depth interpretation, and (2) providing controllability of the scene depth. The method offers patch-based solutions to a wide variety of stereoscopic image editing problems, including depth-guided texture synthesis, stereoscopic NPR, paint by depth, content adaptation, and 2D to 3D conversion. Several challenging cases are demonstrated to show the effectiveness of the proposed method. The results of user studies also show that the proposed method produces stereoscopic images with good stereoscopics and visual quality.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6824802]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2327979]]></doi>

<publicationId><![CDATA[6824802]]></publicationId>

<partnum><![CDATA[6824802]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6824802&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824802]]></pdf>

</document>

<document>

<rank>972</rank>

<title><![CDATA[Message from the Editor-in-Chief]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[22]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2016]]></py>

<spage><![CDATA[x]]></spage>

<epage><![CDATA[x]]></epage>

<abstract><![CDATA[Presents a message from the Editor-in-Chief for this issue of the publication.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[7307929]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2015.2469111]]></doi>

<publicationId><![CDATA[7307929]]></publicationId>

<partnum><![CDATA[7307929]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7307929&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307929]]></pdf>

</document>

<document>

<rank>973</rank>

<title><![CDATA[Editor's Note [new Associate Editors]]]></title>

<authors><![CDATA[Lin, Ming C.]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[177]]></spage>

<epage><![CDATA[177]]></epage>

<abstract><![CDATA[The IEEE Computer Society's policy limits the terms of the members of its Editorial Board. This allows new people and expertise to come in and benefi ts the growth and vitality of the journal. The success of the journal relies on the quality of the submissions and reviews, and the work of the associate editors. The dedication of associate editors is essential to the continuing growth of the journal. On behalf of the IEEE TVCG's Editorial Board, it is the Editor-in-Chief's pleasure to introduce Gennady Andrienko and Steve Marschner, who have recently joined the TVCG Editorial Board as Associate Editors. Below are the biographical sketches listing their accomplishments and areas of expertise. The TVCG Editorial Board is pleased to welcome these outstanding researchers to their new role.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6376575]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.6]]></doi>

<publicationId><![CDATA[6376575]]></publicationId>

<partnum><![CDATA[6376575]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6376575&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376575]]></pdf>

</document>

<document>

<rank>974</rank>

<title><![CDATA[Perceptually Guided Polygon Reduction]]></title>

<authors><![CDATA[Qu, Lijun;  Meyer, Gary W.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[mesh generation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1015]]></spage>

<epage><![CDATA[1029]]></epage>

<abstract><![CDATA[The properties of the human visual system are taken into account, along with the geometric aspects of an object, in a new surface remeshing algorithm and a new mesh simplification algorithm. Both algorithms have a preprocessing step and are followed by the remeshing or mesh simplification steps. The preprocessing step computes an importance map that indicates the visual masking potential of the visual patterns on the surface. The importance map is then used to guide the remeshing or mesh simplification algorithms. Two different methods are proposed for computing an importance map that indicates the masking potential of the visual patterns on the surface. The first one is based on the Sarnoff visual discrimination metric, and the second one is inspired by the visual masking tool available in the current JPEG2000 standard. Given an importance map, the surface remeshing algorithm automatically distributes few samples to surface regions with strong visual masking properties due to surface texturing, lighting variations, bump mapping, surface reflectance and inter-reflections. Similarly, the mesh simplification algorithm simplifies more aggressively where the light field of an object can hide more geometric artifacts.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4479454]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.51]]></doi>

<publicationId><![CDATA[4479454]]></publicationId>

<partnum><![CDATA[4479454]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4479454&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479454]]></pdf>

</document>

<document>

<rank>975</rank>

<title><![CDATA[Mental Models, Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective]]></title>

<authors><![CDATA[Zhicheng Liu;  Stasko, J.T.]]></authors>

<affiliations><![CDATA[Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[cognition]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Brain modeling]]></term>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Cognitive science]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[999]]></spage>

<epage><![CDATA[1008]]></epage>

<abstract><![CDATA[Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5613437]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.177]]></doi>

<publicationId><![CDATA[5613437]]></publicationId>

<partnum><![CDATA[5613437]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5613437&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613437]]></pdf>

</document>

<document>

<rank>976</rank>

<title><![CDATA[Design Study of LineSets, a Novel Set Visualization Technique]]></title>

<authors><![CDATA[Alper, B.;  Riche, N.H.;  Ramos, G.;  Czerwinski, Mary]]></authors>

<controlledterms>

<term><![CDATA[cartography]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[geometry]]></term>

<term><![CDATA[set theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Geometry]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Social network services]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[2259]]></spage>

<epage><![CDATA[2267]]></epage>

<abstract><![CDATA[Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6064991]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.186]]></doi>

<publicationId><![CDATA[6064991]]></publicationId>

<partnum><![CDATA[6064991]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6064991&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6064991]]></pdf>

</document>

<document>

<rank>977</rank>

<title><![CDATA[AdaptiviTree: Adaptive Tree Visualization for Tournament-Style Brackets]]></title>

<authors><![CDATA[Tan, D.S.;  Smith, G.;  Bongshin Lee;  Robertson, G.G.]]></authors>

<affiliations><![CDATA[Microsoft Res., Redmond]]></affiliations>

<controlledterms>

<term><![CDATA[computer games]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human factors]]></term>

<term><![CDATA[sport]]></term>

<term><![CDATA[tree data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Economic forecasting]]></term>

<term><![CDATA[Educational institutions]]></term>

<term><![CDATA[Industrial economics]]></term>

<term><![CDATA[Jupiter]]></term>

<term><![CDATA[Monitoring]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Statistics]]></term>

<term><![CDATA[Toy industry]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1113]]></spage>

<epage><![CDATA[1120]]></epage>

<abstract><![CDATA[Online pick'em games, such as the recent NCAA college basketball March Madness tournament, form a large and rapidly growing industry. In these games, players make predictions on a tournament bracket that defines which competitors play each other and how they proceed toward a single champion. Throughout the course of the tournament, players monitor the brackets to track progress and to compare predictions made by multiple players. This is often a complex sense making task. The classic bracket visualization was designed for use on paper and utilizes an incrementally additive system in which the winner of each match-up is rewritten in the next round as the tournament progresses. Unfortunately, this representation requires a significant amount of space and makes it relatively difficult to get a quick overview of the tournament state since competitors take arbitrary paths through the static bracket. In this paper, we present AdaptiviTree, a novel visualization that adaptively deforms the representation of the tree and uses its shape to convey outcome information. AdaptiviTree not only provides a more compact and understandable representation, but also allows overlays that display predictions as well as other statistics. We describe results from a lab study we conducted to explore the efficacy of AdaptiviTree, as well as from a deployment of the system in a recent real-world sports tournament.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376130]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70537]]></doi>

<publicationId><![CDATA[4376130]]></publicationId>

<partnum><![CDATA[4376130]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376130&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376130]]></pdf>

</document>

<document>

<rank>978</rank>

<title><![CDATA[Dynamic scene occlusion culling]]></title>

<authors><![CDATA[Sudarsky, O.;  Gotsman, C.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Israel Inst. of Technol., Haifa, Israel]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[virtual reality]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Hardware]]></term>

<term><![CDATA[Heuristic algorithms]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Robots]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Virtual environment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[5]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[1999]]></py>

<spage><![CDATA[13]]></spage>

<epage><![CDATA[29]]></epage>

<abstract><![CDATA[Large, complex 3D scenes are best rendered in an output-sensitive way, i.e., in time largely independent of the entire scene model's complexity. Occlusion culling is one of the key techniques for output-sensitive rendering. We generalize existing occlusion culling algorithms, intended for static scenes, to handle dynamic scenes having numerous moving objects. The data structure used by an occlusion culling method is updated to reflect the objects' possible positions. To avoid updating the structure for every dynamic object at each frame, a temporal bounding volume (TBV) is created for each occluded dynamic object, using some known constraints on the object's motion. The TBV is inserted into the structure instead of the object. Subsequently, the object is ignored as long as the TBV is occluded and guaranteed to contain the object. The generalized algorithms' rendering time is linearly affected only by the scene's visible parts, not by hidden parts or by occluded dynamic objects. Our techniques also save communications in distributed graphic systems, e.g., multiuser virtual environments, by eliminating update messages for hidden dynamic objects. We demonstrate the adaptation of two occlusion culling algorithms to dynamic scenes: hierarchical Z-buffering and BSP tree projection]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[764866]]></arnumber>

<doi><![CDATA[10.1109/2945.764866]]></doi>

<publicationId><![CDATA[764866]]></publicationId>

<partnum><![CDATA[764866]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=764866&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=764866]]></pdf>

</document>

<document>

<rank>979</rank>

<title><![CDATA[Toward a Deeper Understanding of the Role of Interaction in Information Visualization]]></title>

<authors><![CDATA[Ji Soo Yi;  Youn ah Kang;  Stasko, J.T.;  Jacko, J.A.]]></authors>

<affiliations><![CDATA[Georgia Inst. of Technol., Atlanta]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[human computer interaction]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer displays]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Conference proceedings]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Human computer interaction]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Research and development]]></term>

<term><![CDATA[Taxonomy]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[13]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2007]]></py>

<spage><![CDATA[1224]]></spage>

<epage><![CDATA[1231]]></epage>

<abstract><![CDATA[Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4376144]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2007.70515]]></doi>

<publicationId><![CDATA[4376144]]></publicationId>

<partnum><![CDATA[4376144]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4376144&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376144]]></pdf>

</document>

<document>

<rank>980</rank>

<title><![CDATA[Interactive Comparison of Scalar Fields Based on Largest Contours with Applications to Flow Visualization]]></title>

<authors><![CDATA[Schneider, D.;  Wiebel, A.;  Carr, H.;  Hlawitschka, M.;  Scheuermann, G.]]></authors>

<affiliations><![CDATA[Leipzig Univ., Leipzig]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[edge detection]]></term>

<term><![CDATA[flow visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computer vision]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Fluid flow]]></term>

<term><![CDATA[Isosurfaces]]></term>

<term><![CDATA[Navigation]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Topology]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Volume measurement]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1475]]></spage>

<epage><![CDATA[1482]]></epage>

<abstract><![CDATA[Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658165]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.143]]></doi>

<publicationId><![CDATA[4658165]]></publicationId>

<partnum><![CDATA[4658165]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658165&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658165]]></pdf>

</document>

<document>

<rank>981</rank>

<title><![CDATA[Example-Based Automatic Music-Driven Conventional Dance Motion Synthesis]]></title>

<authors><![CDATA[Rukun Fan;  Songhua Xu;  Weidong Geng]]></authors>

<affiliations><![CDATA[Coll. of Comput. Sci., Zhejiang Univ. (Yuquan Campus), Hangzhou, China]]></affiliations>

<controlledterms>

<term><![CDATA[dynamic programming]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[image matching]]></term>

<term><![CDATA[image motion analysis]]></term>

<term><![CDATA[image sequences]]></term>

<term><![CDATA[learning (artificial intelligence)]]></term>

<term><![CDATA[music]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Feature extraction]]></term>

<term><![CDATA[Humans]]></term>

<term><![CDATA[Joints]]></term>

<term><![CDATA[Motion segmentation]]></term>

<term><![CDATA[Synchronization]]></term>

<term><![CDATA[Training]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[3]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[501]]></spage>

<epage><![CDATA[515]]></epage>

<abstract><![CDATA[We introduce a novel method for synthesizing dance motions that follow the emotions and contents of a piece of music. Our method employs a learning-based approach to model the music to motion mapping relationship embodied in example dance motions along with those motions' accompanying background music. A key step in our method is to train a music to motion matching quality rating function through learning the music to motion mapping relationship exhibited in synchronized music and dance motion data, which were captured from professional human dance performance. To generate an optimal sequence of dance motion segments to match with a piece of music, we introduce a constraint-based dynamic programming procedure. This procedure considers both music to motion matching quality and visual smoothness of a resultant dance motion sequence. We also introduce a two-way evaluation strategy, coupled with a GPU-based implementation, through which we can execute the dynamic programming process in parallel, resulting in significant speedup. To evaluate the effectiveness of our method, we quantitatively compare the dance motions synthesized by our method with motion synthesis results by several peer methods using the motions captured from professional human dancers' performance as the gold standard. We also conducted several medium-scale user studies to explore how perceptually our dance motion synthesis method can outperform existing methods in synthesizing dance motions to match with a piece of music. These user studies produced very positive results on our music-driven dance motion synthesis experiments for several Asian dance genres, confirming the advantages of our method.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5753889]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.73]]></doi>

<publicationId><![CDATA[5753889]]></publicationId>

<partnum><![CDATA[5753889]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5753889&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753889]]></pdf>

</document>

<document>

<rank>982</rank>

<title><![CDATA[High-Dimensional Visual Analytics: Interactive Exploration Guided by Pairwise Views of Point Distributions]]></title>

<authors><![CDATA[Wilkinson, L.;  Anand, A.;  Grossman, R.]]></authors>

<affiliations><![CDATA[SPSS Inc., Chicago, IL]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[sorting]]></term>

<term><![CDATA[statistical analysis]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Coordinate measuring machines]]></term>

<term><![CDATA[Density measurement]]></term>

<term><![CDATA[Displays]]></term>

<term><![CDATA[Multidimensional systems]]></term>

<term><![CDATA[Organizing]]></term>

<term><![CDATA[Scattering]]></term>

<term><![CDATA[Shape measurement]]></term>

<term><![CDATA[Sorting]]></term>

<term><![CDATA[Statistical analysis]]></term>

<term><![CDATA[Visual analytics]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[12]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2006]]></py>

<spage><![CDATA[1363]]></spage>

<epage><![CDATA[1372]]></epage>

<abstract><![CDATA[We introduce a method for organizing multivariate displays and for guiding interactive exploration through high-dimensional data. The method is based on nine characterizations of the 2D distributions of orthogonal pairwise projections on a set of points in multidimensional Euclidean space. These characterizations include such measures as density, skewness, shape, outliers, and texture. Statistical analysis of these measures leads to ways for 1) organizing 2D scatterplots of points for coherent viewing, 2) locating unusual (outlying) marginal 2D distributions of points for anomaly detection and 3) sorting multivariate displays based on high-dimensional data, such as trees, parallel coordinates, and glyphs]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[1703359]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2006.94]]></doi>

<publicationId><![CDATA[1703359]]></publicationId>

<partnum><![CDATA[1703359]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1703359&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703359]]></pdf>

</document>

<document>

<rank>983</rank>

<title><![CDATA[Hybrid Parallelism for Volume Rendering on Large-, Multi-, and Many-Core Systems]]></title>

<authors><![CDATA[Howison, M.;  Bethel, E.W.;  Childs, H.]]></authors>

<affiliations><![CDATA[Center for Comput. & Visualization, Brown Univ., Providence, RI, USA]]></affiliations>

<controlledterms>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[distributed shared memory systems]]></term>

<term><![CDATA[multiprocessing systems]]></term>

<term><![CDATA[parallel processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Concurrent computing]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Instruction sets]]></term>

<term><![CDATA[Parallel processing]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[17]]></spage>

<epage><![CDATA[29]]></epage>

<abstract><![CDATA[With the computing industry trending toward multi- and many-core processors, we study how a standard visualization algorithm, raycasting volume rendering, can benefit from a hybrid parallelism approach. Hybrid parallelism provides the best of both worlds: using distributed-memory parallelism across a large numbers of nodes increases available FLOPs and memory, while exploiting shared-memory parallelism among the cores within each node ensures that each node performs its portion of the larger calculation as efficiently as possible. We demonstrate results from weak and strong scaling studies, at levels of concurrency ranging up to 216,000, and with data sets as large as 12.2 trillion cells. The greatest benefit from hybrid parallelism lies in the communication portion of the algorithm, the dominant cost at higher levels of concurrency. We show that reducing the number of participants with a hybrid approach significantly improves performance.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5708139]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.24]]></doi>

<publicationId><![CDATA[5708139]]></publicationId>

<partnum><![CDATA[5708139]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5708139&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708139]]></pdf>

</document>

<document>

<rank>984</rank>

<title><![CDATA[Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes]]></title>

<authors><![CDATA[Hadlak, S.;  Schumann, H.;  Cap, C.H.;  Wollenberg, T.]]></authors>

<affiliations><![CDATA[Univ. of Rostock, Rostock, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[graph theory]]></term>

<term><![CDATA[pattern clustering]]></term>

<term><![CDATA[telecommunication computing]]></term>

<term><![CDATA[wireless mesh networks]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Current measurement]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Market research]]></term>

<term><![CDATA[Power system dynamics]]></term>

<term><![CDATA[Time measurement]]></term>

<term><![CDATA[Time series analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2267]]></spage>

<epage><![CDATA[2276]]></epage>

<abstract><![CDATA[The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6634085]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.198]]></doi>

<publicationId><![CDATA[6634085]]></publicationId>

<partnum><![CDATA[6634085]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634085&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634085]]></pdf>

</document>

<document>

<rank>985</rank>

<title><![CDATA[Smart Transparency for Illustrative Visualization of Complex Flow Surfaces]]></title>

<authors><![CDATA[Carnecky, R.;  Fuchs, R.;  Mehl, S.;  Yun Jang;  Peikert, R.]]></authors>

<affiliations><![CDATA[Comput. Sci. Dept., ETH Zurich, Zurich, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[buffer storage]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Buffer storage]]></term>

<term><![CDATA[Graphics processing unit]]></term>

<term><![CDATA[Image color analysis]]></term>

<term><![CDATA[Indexes]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Surface treatment]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[838]]></spage>

<epage><![CDATA[851]]></epage>

<abstract><![CDATA[The perception of transparency and the underlying neural mechanisms have been subject to extensive research in the cognitive sciences. However, we have yet to develop visualization techniques that optimally convey the inner structure of complex transparent shapes. In this paper, we apply the findings of perception research to develop a novel illustrative rendering method that enhances surface transparency nonlocally. Rendering of transparent geometry is computationally expensive since many optimizations, such as visibility culling, are not applicable and fragments have to be sorted by depth for correct blending. In order to overcome these difficulties efficiently, we propose the illustration buffer. This novel data structure combines the ideas of the A and G-buffers to store a list of all surface layers for each pixel. A set of local and nonlocal operators is then used to process these depth-lists to generate the final image. Our technique is interactive on current graphics hardware and is only limited by the available graphics memory. Based on this framework, we present an efficient algorithm for a nonlocal transparency enhancement that creates expressive renderings of transparent surfaces. A controlled quantitative double blind user study shows that the presented approach improves the understanding of complex transparent surfaces significantly.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6244795]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.159]]></doi>

<publicationId><![CDATA[6244795]]></publicationId>

<partnum><![CDATA[6244795]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6244795&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6244795]]></pdf>

</document>

<document>

<rank>986</rank>

<title><![CDATA[Curve Boxplot: Generalization of Boxplot for Ensembles of Curves]]></title>

<authors><![CDATA[Mirzargar, M.;  Whitaker, R.T.;  Kirby, R.M.]]></authors>

<affiliations><![CDATA[Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA]]></affiliations>

<controlledterms>

<term><![CDATA[computational geometry]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Curve fitting]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Robustness]]></term>

<term><![CDATA[Shape analysis]]></term>

<term><![CDATA[Statistical analysis]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[2654]]></spage>

<epage><![CDATA[2663]]></epage>

<abstract><![CDATA[In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6875964]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2014.2346455]]></doi>

<publicationId><![CDATA[6875964]]></publicationId>

<partnum><![CDATA[6875964]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6875964&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6875964]]></pdf>

</document>

<document>

<rank>987</rank>

<title><![CDATA[Fused DTI/HARDI Visualization]]></title>

<authors><![CDATA[Prckovska, V.;  Peeters, T.H.J.M.;  van Almsick, M.;  ter Haar Romeny, B.;  Vilanova i Bartroli, A.]]></authors>

<affiliations><![CDATA[Dept. of Biomed. Eng., Tech. Univ. Eindhoven, Eindhoven, Netherlands]]></affiliations>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[rendering (computer graphics)]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anisotropic magnetoresistance]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Diffusion tensor imaging]]></term>

<term><![CDATA[Ellipsoids]]></term>

<term><![CDATA[Harmonic analysis]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Tensile stress]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[10]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[1407]]></spage>

<epage><![CDATA[1419]]></epage>

<abstract><![CDATA[High-angular resolution diffusion imaging (HARDI) is a diffusion weighted MRI technique that overcomes some of the decisive limitations of its predecessor, diffusion tensor imaging (DTI), in the areas of composite nerve fiber structure. Despite its advantages, HARDI raises several issues: complex modeling of the data, nonintuitive and computationally demanding visualization, inability to interactively explore and transform the data, etc. To overcome these drawbacks, we present a novel, multifield visualization framework that adopts the benefits of both DTI and HARDI. By applying a classification scheme based on HARDI anisotropy measures, the most suitable model per imaging voxel is automatically chosen. This classification allows simplification of the data in areas with single fiber bundle coherence. To accomplish fast and interactive visualization for both HARDI and DTI modalities, we exploit the capabilities of modern GPUs for glyph rendering and adopt DTI fiber tracking in suitable regions. The resulting framework, allows user-friendly data exploration of fused HARDI and DTI data. Many incorporated features such as sharpening, normalization, maxima enhancement and different types of color coding of the HARDI glyphs, simplify the data and enhance its features. We provide a qualitative user evaluation that shows the potentials of our visualization tools in several HARDI applications.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5620904]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.244]]></doi>

<publicationId><![CDATA[5620904]]></publicationId>

<partnum><![CDATA[5620904]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5620904&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620904]]></pdf>

</document>

<document>

<rank>988</rank>

<title><![CDATA[Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets]]></title>

<authors><![CDATA[Lex, A.;  Partl, C.;  Kalkofen, D.;  Streit, M.;  Gratzl, S.;  Wassermann, A.M.;  Schmalstieg, D.;  Pfister, H.]]></authors>

<affiliations><![CDATA[Harvard Univ., Cambridge, MA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[biology computing]]></term>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Bioinformatics]]></term>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Drugs]]></term>

<term><![CDATA[Portals]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2536]]></spage>

<epage><![CDATA[2545]]></epage>

<abstract><![CDATA[Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6634190]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.154]]></doi>

<publicationId><![CDATA[6634190]]></publicationId>

<partnum><![CDATA[6634190]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634190&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634190]]></pdf>

</document>

<document>

<rank>989</rank>

<title><![CDATA[Improving the Efficiency of Viewpoint Composition]]></title>

<authors><![CDATA[Ranon, R.;  Urli, T.]]></authors>

<affiliations><![CDATA[Dept. of Math & Comput. Sci., Univ. of Udine, Udine, Italy]]></affiliations>

<controlledterms>

<term><![CDATA[computer graphics]]></term>

<term><![CDATA[particle swarm optimisation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Accuracy]]></term>

<term><![CDATA[Cameras]]></term>

<term><![CDATA[Cognition]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Search problems]]></term>

<term><![CDATA[TV]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[20]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2014]]></py>

<spage><![CDATA[795]]></spage>

<epage><![CDATA[807]]></epage>

<abstract><![CDATA[In this paper, we concentrate on the problem of finding the viewpoint that best satisfies a set of visual composition properties, often referred to as Virtual Camera or Viewpoint Composition. Previous approaches in the literature, which are based on general optimization solvers, are limited in their practical applicability because of unsuitable computation times and limited experimental analysis. To bring performances much closer to the needs of interactive applications, we introduce novel ways to define visual properties, evaluate their satisfaction, and initialize the search for optimal viewpoints, and test them in several problems under various time budgets, quantifying also, for the first time in the domain, the importance of tuning the parameters that control the behavior of the solving process. While our solver, as others in the literature, is based on Particle Swarm Optimization, our contributions could be applied to any stochastic search process that solves through many viewpoint evaluations, such as the genetic algorithms employed by other papers in the literature. The complete source code of our approach, together with the scenes and problems we have employed, can be downloaded from https://bitbucket.org/rranon/smart-viewpoint-computation-lib.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6702501]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.2297932]]></doi>

<publicationId><![CDATA[6702501]]></publicationId>

<partnum><![CDATA[6702501]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6702501&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702501]]></pdf>

</document>

<document>

<rank>990</rank>

<title><![CDATA[Obliq-3D: a high-level, fast-turnaround 3D animation system]]></title>

<authors><![CDATA[Najork, M.A.;  Brown, M.H.]]></authors>

<affiliations><![CDATA[Syst. Res. Center, Digital Equipment Corp., Palo Alto, CA, USA]]></affiliations>

<controlledterms>

<term><![CDATA[authoring languages]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[software libraries]]></term>

<term><![CDATA[solid modelling]]></term>

<term><![CDATA[tree data structures]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Instruments]]></term>

<term><![CDATA[LAN interconnection]]></term>

<term><![CDATA[Layout]]></term>

<term><![CDATA[Programming profession]]></term>

<term><![CDATA[Software libraries]]></term>

<term><![CDATA[Tree graphs]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[1]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1995]]></py>

<spage><![CDATA[175]]></spage>

<epage><![CDATA[193]]></epage>

<abstract><![CDATA[Describes Obliq-3D, a high-level, fast-turnaround system for building 3D animations. Obliq-3D consists of an interpreted language that is embedded into a 3D animation library. This library is based on a few simple, yet powerful constructs that allow programmers to describe 3D scenes and animations of such scenes. By virtue of its interpretive nature, Obliq-3D provides a fast-turnaround environment. The combination of simplicity and fast turnaround allows programmers to construct nontrivial animations quickly and easily. The paper is divided into three major parts. The first part introduces the basic concepts of Obliq-3D, using a series of graduated examples. The second part shows how the system can be used to implement cone trees. The third part develops a complete animation of Dijkstra's (1959) shortest-path algorithm]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[468402]]></arnumber>

<doi><![CDATA[10.1109/2945.468402]]></doi>

<publicationId><![CDATA[468402]]></publicationId>

<partnum><![CDATA[468402]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=468402&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=468402]]></pdf>

</document>

<document>

<rank>991</rank>

<title><![CDATA[Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles]]></title>

<authors><![CDATA[Coffey, D.;  Chi-Lun Lin;  Erdman, A.G.;  Keefe, D.F.]]></authors>

<affiliations><![CDATA[Univ. of Minnesota, Minneapolis, MN, USA]]></affiliations>

<controlledterms>

<term><![CDATA[CAD]]></term>

<term><![CDATA[computational fluid dynamics]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[digital simulation]]></term>

<term><![CDATA[drag]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[user interfaces]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Biological system modeling]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Data models]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Real-time systems]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2783]]></spage>

<epage><![CDATA[2791]]></epage>

<abstract><![CDATA[We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634138]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.147]]></doi>

<publicationId><![CDATA[6634138]]></publicationId>

<partnum><![CDATA[6634138]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634138&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634138]]></pdf>

</document>

<document>

<rank>992</rank>

<title><![CDATA[A Minimal Contouring Approach to the Computation of the Reeb Graph]]></title>

<authors><![CDATA[Patane, G.;  Spagnuolo, M.;  Falcidieno, B.]]></authors>

<affiliations><![CDATA[Ist. di Mat. Applicata e Tecnol. Inormatiche, Consiglio Naz. delle Ric., Genova]]></affiliations>

<controlledterms>

<term><![CDATA[computational complexity]]></term>

<term><![CDATA[data structures]]></term>

<term><![CDATA[graph theory]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Algorithm design and analysis]]></term>

<term><![CDATA[Computational efficiency]]></term>

<term><![CDATA[Cost function]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Data structures]]></term>

<term><![CDATA[Eigenvalues and eigenfunctions]]></term>

<term><![CDATA[Laplace equations]]></term>

<term><![CDATA[Level set]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Topology]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[15]]></volume>

<issue><![CDATA[4]]></issue>

<py><![CDATA[2009]]></py>

<spage><![CDATA[583]]></spage>

<epage><![CDATA[595]]></epage>

<abstract><![CDATA[Given a manifold surface M and a continuous scalar function f:Mrarr IR, the Reeb graph of (M, f) is a widely used high-level descriptor of M and its usefulness has been demonstrated for a variety of applications, which range from shape parameterization and abstraction to deformation and comparison. In this context, we propose a novel contouring algorithm for the construction of a discrete Reeb graph with a minimal number of nodes, which correspond to the critical points of f (i.e., minima, maxima, and saddle points) and its level sets passing through the saddle points. In this way, we do not need to sample, sweep, or increasingly sort the f-values. Since most of the computation uses only local information on the mesh connectivity, equipped with the f-values at the surface vertices, the proposed approach is insensitive to noise and requires a small-memory footprint and temporary data structures. Furthermore, we maintain the parametric nature of the Reeb graph with respect to the input scalar function and we efficiently extract the Reeb graph of time-varying maps. Indicating with n and s the number of vertices of M and saddle points of f, the overall computational cost O(sn) is competitive with respect to the O(n log n) cost of previous work. This cost becomes optimal if M is highly sampled or s les log n, as it happens for Laplacian eigenfunctions, harmonic maps, and one-forms.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4770097]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2009.22]]></doi>

<publicationId><![CDATA[4770097]]></publicationId>

<partnum><![CDATA[4770097]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4770097&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4770097]]></pdf>

</document>

<document>

<rank>993</rank>

<title><![CDATA[Visualization of Temporal Similarity in Field Data]]></title>

<authors><![CDATA[Frey, S.;  Sadlo, F.;  Ertl, T.]]></authors>

<affiliations><![CDATA[Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany]]></affiliations>

<controlledterms>

<term><![CDATA[data analysis]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[inspection]]></term>

<term><![CDATA[interactive systems]]></term>

<term><![CDATA[matrix algebra]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Context awareness]]></term>

<term><![CDATA[Correlation]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Information analysis]]></term>

<term><![CDATA[Machine learning]]></term>

<term><![CDATA[Smoothing methods]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[2023]]></spage>

<epage><![CDATA[2032]]></epage>

<abstract><![CDATA[This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6327206]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.284]]></doi>

<publicationId><![CDATA[6327206]]></publicationId>

<partnum><![CDATA[6327206]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6327206&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327206]]></pdf>

</document>

<document>

<rank>994</rank>

<title><![CDATA[Errata to &#x0201C;Isosurface Extraction and View-Dependent Filtering from Time-Varying Fields Using Persistent Time-Octree (PTOT)&#x0201D; [Nov-Dec 09 1367-1374]]]></title>

<authors><![CDATA[Wang, Cong;  Chiang, Yi-Jen]]></authors>

<thesaurusterms>

<term><![CDATA[Binary search trees]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Computer graphics]]></term>

<term><![CDATA[Computer science]]></term>

<term><![CDATA[Filtering]]></term>

<term><![CDATA[Visualization]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[16]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[2010]]></py>

<spage><![CDATA[350]]></spage>

<epage><![CDATA[351]]></epage>

<abstract><![CDATA[In the above titled paper (ibid., vol. 15, no. 6, pp. 1367-1374, Nov.-Dec. 09), there were errors contained in Figs. 1, 2, 3, and 4. The correct figures are presented here.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5380818]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2010.15]]></doi>

<publicationId><![CDATA[5380818]]></publicationId>

<partnum><![CDATA[5380818]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5380818&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380818]]></pdf>

</document>

<document>

<rank>995</rank>

<title><![CDATA[Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates]]></title>

<authors><![CDATA[Kohler, B.;  Gasteiger, R.;  Preim, U.;  Theisel, H.;  Gutberlet, M.;  Preim, B.]]></authors>

<controlledterms>

<term><![CDATA[biomedical MRI]]></term>

<term><![CDATA[blood flow measurement]]></term>

<term><![CDATA[feature extraction]]></term>

<term><![CDATA[graphics processing units]]></term>

<term><![CDATA[haemodynamics]]></term>

<term><![CDATA[medical image processing]]></term>

<term><![CDATA[vortices]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Arteries]]></term>

<term><![CDATA[Biomedical monitoring]]></term>

<term><![CDATA[Blood flow]]></term>

<term><![CDATA[Cardiovascular system]]></term>

<term><![CDATA[Data mining]]></term>

<term><![CDATA[Heart]]></term>

<term><![CDATA[Pathology]]></term>

<term><![CDATA[Smoothing methods]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[12]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[2773]]></spage>

<epage><![CDATA[2782]]></epage>

<abstract><![CDATA[Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[6634153]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2013.189]]></doi>

<publicationId><![CDATA[6634153]]></publicationId>

<partnum><![CDATA[6634153]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6634153&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634153]]></pdf>

</document>

<document>

<rank>996</rank>

<title><![CDATA[Splatting of non rectilinear volumes through stochastic resampling]]></title>

<authors><![CDATA[Xiaoyang Mao]]></authors>

<affiliations><![CDATA[Dept. of Electr. Eng. & Comput. Sci., Yamanashi Univ., Kofu, Japan]]></affiliations>

<controlledterms>

<term><![CDATA[rendering (computer graphics)]]></term>

<term><![CDATA[statistical analysis]]></term>

<term><![CDATA[stochastic processes]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Casting]]></term>

<term><![CDATA[Ellipsoids]]></term>

<term><![CDATA[Feedforward systems]]></term>

<term><![CDATA[Filters]]></term>

<term><![CDATA[Image generation]]></term>

<term><![CDATA[Image sampling]]></term>

<term><![CDATA[Kernel]]></term>

<term><![CDATA[Rendering (computer graphics)]]></term>

<term><![CDATA[Shape]]></term>

<term><![CDATA[Stochastic processes]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[2]]></volume>

<issue><![CDATA[2]]></issue>

<py><![CDATA[1996]]></py>

<spage><![CDATA[156]]></spage>

<epage><![CDATA[170]]></epage>

<abstract><![CDATA[The paper extends the conventional splatting algorithm for volume rendering non rectilinear grids. A stochastic sampling technique called Poisson sphere/ellipsoid is employed to adaptively resample a non rectilinear grid with a set of randomly distributed points whose energy support extents are well approximated by spheres or ellipsoids. Then volume rendered images can be generated by splatting the scalar values at the new sample points with filter kernels corresponding to these spheres and ellipsoids. Experiments have been carried out to investigate the image quality as well as the time/space efficiency of the new approach, and the results suggest that our approach can be regarded as an alternative for existing fast volume rendering techniques of non rectilinear grids]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[506227]]></arnumber>

<doi><![CDATA[10.1109/2945.506227]]></doi>

<publicationId><![CDATA[506227]]></publicationId>

<partnum><![CDATA[506227]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=506227&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506227]]></pdf>

</document>

<document>

<rank>997</rank>

<title><![CDATA[[Inside front cover]]]></title>

<authors><![CDATA[]]></authors>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[17]]></volume>

<issue><![CDATA[8]]></issue>

<py><![CDATA[2011]]></py>

<spage><![CDATA[c2]]></spage>

<epage><![CDATA[c2]]></epage>

<abstract><![CDATA[Provides a listing of current committee members and society officers.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<arnumber><![CDATA[5872086]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.90]]></doi>

<publicationId><![CDATA[5872086]]></publicationId>

<partnum><![CDATA[5872086]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5872086&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5872086]]></pdf>

</document>

<document>

<rank>998</rank>

<title><![CDATA[Animating Wrinkles by Example on Non-Skinned Cloth]]></title>

<authors><![CDATA[Zurdo, J.S.;  Brito, J.P.;  Otaduy, M.A.]]></authors>

<affiliations><![CDATA[Dept. of Comput. Sci., Univ. Rey Juan Carlos, Madrid, Spain]]></affiliations>

<controlledterms>

<term><![CDATA[clothing]]></term>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[digital simulation]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Animation]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Measurement]]></term>

<term><![CDATA[Skin]]></term>

<term><![CDATA[Strain]]></term>

<term><![CDATA[Training]]></term>

<term><![CDATA[Vectors]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[19]]></volume>

<issue><![CDATA[1]]></issue>

<py><![CDATA[2013]]></py>

<spage><![CDATA[149]]></spage>

<epage><![CDATA[158]]></epage>

<abstract><![CDATA[The simulation of cloth with rich folds and wrinkles is a computationally expensive process. In this paper, we introduce an example-based algorithm for fast animation of plausible cloth wrinkles. Our algorithm does not depend on a character's pose, therefore it is valid for loose dresses, curtains, etc., not just cloth defined by skinning techniques. Central to our approach is a correspondence between low and high-resolution cloth deformations, both at the training and synthesis stages. Based on this correspondence, we define an algorithm for synthesizing cloth wrinkles as a function of the deformation of a low-resolution cloth and a set of example poses. We demonstrate the animation of plausible high-resolution wrinkles at high frame rates, suitable for interactive applications such as video games.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[6171179]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2012.79]]></doi>

<publicationId><![CDATA[6171179]]></publicationId>

<partnum><![CDATA[6171179]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6171179&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171179]]></pdf>

</document>

<document>

<rank>999</rank>

<title><![CDATA[Maintaining Large Time Steps in Explicit Finite Element Simulations Using Shape Matching]]></title>

<authors><![CDATA[Fierz, B.;  Spillmann, J.;  Hoyos, I.A.;  Harders, M.]]></authors>

<affiliations><![CDATA[Comput. Vision Lab., ETH Zurich, Zurich, Switzerland]]></affiliations>

<controlledterms>

<term><![CDATA[computer animation]]></term>

<term><![CDATA[finite element analysis]]></term>

<term><![CDATA[pattern matching]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Deformable models]]></term>

<term><![CDATA[Estimation]]></term>

<term><![CDATA[Finite element methods]]></term>

<term><![CDATA[Mathematical model]]></term>

<term><![CDATA[Sockets]]></term>

<term><![CDATA[Solid modeling]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[18]]></volume>

<issue><![CDATA[5]]></issue>

<py><![CDATA[2012]]></py>

<spage><![CDATA[717]]></spage>

<epage><![CDATA[728]]></epage>

<abstract><![CDATA[We present a novel hybrid method to allow large time steps in explicit integrations for the simulation of deformable objects. In explicit integration schemes, the time step is typically limited by the size and the shape of the discretization elements as well as by the material parameters. We propose a two-step strategy to enable large time steps for meshes with elements potentially destabilizing the integration. First, the necessary time step for a stable computation is identified per element using modal analysis. This allows determining which elements have to be handled specially given a desired simulation time step. The identified critical elements are treated by a geometric deformation model, while the remaining ones are simulated with a standard deformation model (in our case, a corotational linear Finite Element Method). In order to achieve a valid deformation behavior, we propose a strategy to determine appropriate parameters for the geometric model. Our hybrid method allows taking much larger time steps than using an explicit Finite Element Method alone. The total computational costs per second are significantly lowered. The proposed scheme is especially useful for simulations requiring interactive mesh updates, such as for instance cutting in surgical simulations.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[5887332]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2011.105]]></doi>

<publicationId><![CDATA[5887332]]></publicationId>

<partnum><![CDATA[5887332]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=5887332&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887332]]></pdf>

</document>

<document>

<rank>1000</rank>

<title><![CDATA[Visualization of Myocardial Perfusion Derived from Coronary Anatomy]]></title>

<authors><![CDATA[Termeer, M.;  Bescos, J.O.;  Breeuwer, M.;  Vilanova, A.;  Gerritsen, F.;  Groller, M.E.;  Nagel, E.]]></authors>

<affiliations><![CDATA[Vienna Univ. of Technol., Vienna]]></affiliations>

<controlledterms>

<term><![CDATA[blood]]></term>

<term><![CDATA[cardiology]]></term>

<term><![CDATA[data visualisation]]></term>

<term><![CDATA[diseases]]></term>

<term><![CDATA[medical diagnostic computing]]></term>

</controlledterms>

<thesaurusterms>

<term><![CDATA[Anatomy]]></term>

<term><![CDATA[Arteries]]></term>

<term><![CDATA[Blood]]></term>

<term><![CDATA[Computational modeling]]></term>

<term><![CDATA[Coronary arteriosclerosis]]></term>

<term><![CDATA[Data visualization]]></term>

<term><![CDATA[Heart]]></term>

<term><![CDATA[Medical simulation]]></term>

<term><![CDATA[Muscles]]></term>

<term><![CDATA[Myocardium]]></term>

</thesaurusterms>

<pubtitle><![CDATA[Visualization and Computer Graphics, IEEE Transactions on]]></pubtitle>

<punumber><![CDATA[2945]]></punumber>

<pubtype><![CDATA[Journals & Magazines]]></pubtype>

<publisher><![CDATA[IEEE]]></publisher>

<volume><![CDATA[14]]></volume>

<issue><![CDATA[6]]></issue>

<py><![CDATA[2008]]></py>

<spage><![CDATA[1595]]></spage>

<epage><![CDATA[1602]]></epage>

<abstract><![CDATA[Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.]]></abstract>

<issn><![CDATA[1077-2626]]></issn>

<htmlFlag><![CDATA[1]]></htmlFlag>

<arnumber><![CDATA[4658180]]></arnumber>

<doi><![CDATA[10.1109/TVCG.2008.180]]></doi>

<publicationId><![CDATA[4658180]]></publicationId>

<partnum><![CDATA[4658180]]></partnum>

<mdurl><![CDATA[http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=4658180&contentType=Journals+%26+Magazines]]></mdurl>

<pdf><![CDATA[http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4658180]]></pdf>

</document>

</root>
